{"task_id": "BigCodeBench/0", "solution": "import itertools\nfrom random import shuffle\ndef task_func(numbers=list(range(1, 11))):\n    total = 0\n    for perm in itertools.permutations(numbers):\n        total += sum(abs(perm[i] - perm[i+1]) for i in range(len(perm)-1))\n    return total / len(list(itertools.permutations(numbers)))", "raw_solution": "import itertools\nfrom random import shuffle\n\ndef task_func(numbers=list(range(1, 11))):\n    total = 0\n    for perm in itertools.permutations(numbers):\n        total += sum(abs(perm[i] - perm[i+1]) for i in range(len(perm)-1))\n    return total / len(list(itertools.permutations(numbers)))\n```"}
{"task_id": "BigCodeBench/1", "solution": "import collections\nimport random\nimport string\ndef task_func(length=100):\n    if length < 0:\n        raise ValueError(\"Length must be a non-negative number\")\n    random_string = ''.join(random.choice(string.ascii_letters) for _ in range(length))\n    char_count = collections.Counter(random_string)\n    return char_count", "raw_solution": "import collections\nimport random\nimport string\n\ndef task_func(length=100):\n    if length < 0:\n        raise ValueError(\"Length must be a non-negative number\")\n    random_string = ''.join(random.choice(string.ascii_letters) for _ in range(length))\n    char_count = collections.Counter(random_string)\n    return char_count\n```"}
{"task_id": "BigCodeBench/2", "solution": "import random\nimport statistics\ndef task_func(LETTERS):\n    # Create a dictionary with random letters as keys and lists of random integers as values\n    dict = {letter: [random.randint(1, 100) for _ in range(10)] for letter in LETTERS}\n    \n    # Sort the dictionary by the mean of the values in descending order\n    sorted_dict = dict(sorted(dict.items(), key=lambda x: statistics.mean(x[1]), reverse=True))\n    \n    return sorted_dict", "raw_solution": "import random\nimport statistics\n\ndef task_func(LETTERS):\n    # Create a dictionary with random letters as keys and lists of random integers as values\n    dict = {letter: [random.randint(1, 100) for _ in range(10)] for letter in LETTERS}\n    \n    # Sort the dictionary by the mean of the values in descending order\n    sorted_dict = dict(sorted(dict.items(), key=lambda x: statistics.mean(x[1]), reverse=True))\n    \n    return sorted_dict\n```"}
{"task_id": "BigCodeBench/3", "solution": "import random\nimport numpy as np\ndef task_func(LETTERS):\n    dict = {}\n    for letter in LETTERS:\n        list = [random.randint(0, 100) for _ in range(random.randint(1, 10))]\n        dict[letter] = np.mean(list)\n    return dict", "raw_solution": "import random\nimport numpy as np\n\ndef task_func(LETTERS):\n    dict = {}\n    for letter in LETTERS:\n        list = [random.randint(0, 100) for _ in range(random.randint(1, 10))]\n        dict[letter] = np.mean(list)\n    return dict\n```"}
{"task_id": "BigCodeBench/4", "solution": "from collections import Counter\nimport itertools\ndef task_func(d):\n    return dict(Counter(itertools.chain.from_iterable(d.values())))", "raw_solution": "from collections import Counter\nimport itertools\n\ndef task_func(d):\n    return dict(Counter(itertools.chain.from_iterable(d.values())))\n```"}
{"task_id": "BigCodeBench/5", "solution": "import random\nimport math\ndef task_func(LETTERS=[chr(i) for i in range(97, 123)]):\n    result = {}\n    for letter in LETTERS:\n        random_list = [random.randint(0, 100) for _ in range(random.randint(1, 10))]\n        result[letter] = math.sqrt(sum((x - sum(random_list) / len(random_list)) ** 2 for x in random_list) / len(random_list))\n    return result", "raw_solution": "import random\nimport math\ndef task_func(LETTERS=[chr(i) for i in range(97, 123)]):\n    result = {}\n    for letter in LETTERS:\n        random_list = [random.randint(0, 100) for _ in range(random.randint(1, 10))]\n        result[letter] = math.sqrt(sum((x - sum(random_list) / len(random_list)) ** 2 for x in random_list) / len(random_list))\n    return result\n```"}
{"task_id": "BigCodeBench/6", "solution": "import os\nimport re\ndef task_func(pattern, log_dir='/var/log/'):\n    # Get all files in the log directory\n    files = os.listdir(log_dir)\n    # Filter files based on the provided regex pattern\n    log_files = [f for f in files if re.match(pattern, f)]\n    # Sort files by modification time\n    log_files.sort(key=os.path.getmtime, reverse=True)\n    # Return the path to the most recent log file\n    if log_files:\n        return os.path.join(log_dir, log_files[0])\n    else:\n        return None", "raw_solution": "import os\nimport re\ndef task_func(pattern, log_dir='/var/log/'):\n    # Get all files in the log directory\n    files = os.listdir(log_dir)\n    # Filter files based on the provided regex pattern\n    log_files = [f for f in files if re.match(pattern, f)]\n    # Sort files by modification time\n    log_files.sort(key=os.path.getmtime, reverse=True)\n    # Return the path to the most recent log file\n    if log_files:\n        return os.path.join(log_dir, log_files[0])\n    else:\n        return None\n```"}
{"task_id": "BigCodeBench/7", "solution": "import csv\nimport collections\nimport operator\ndef task_func(csv_file_path):\n    with open(csv_file_path, newline='') as csvfile:\n        reader = csv.DictReader(csvfile)\n        sales = collections.defaultdict(int)\n        for row in reader:\n            sales[row['product']] += int(row['quantity'])\n    return max(sales.items(), key=operator.itemgetter(1))[0]", "raw_solution": "import csv\nimport collections\nimport operator\n\ndef task_func(csv_file_path):\n    with open(csv_file_path, newline='') as csvfile:\n        reader = csv.DictReader(csvfile)\n        sales = collections.defaultdict(int)\n        for row in reader:\n            sales[row['product']] += int(row['quantity'])\n    return max(sales.items(), key=operator.itemgetter(1))[0]\n```"}
{"task_id": "BigCodeBench/8", "solution": "from collections import Counter\nimport itertools\nfrom random import randint\ndef task_func(T1, RANGE=100):\n    T1 = [int(i) for i in T1]\n    num_count = sum(T1)\n    random_list = [randint(0, RANGE) for _ in range(num_count)]\n    counter = Counter(random_list)\n    return counter", "raw_solution": "from collections import Counter\nimport itertools\nfrom random import randint\n\ndef task_func(T1, RANGE=100):\n    T1 = [int(i) for i in T1]\n    num_count = sum(T1)\n    random_list = [randint(0, RANGE) for _ in range(num_count)]\n    counter = Counter(random_list)\n    return counter\n```"}
{"task_id": "BigCodeBench/9", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\ndef task_func(list_of_pairs):\n    df = pd.DataFrame(list_of_pairs, columns=['Category', 'Value'])\n    plt.figure(figsize=(10, 6))\n    sns.barplot(x='Category', y='Value', data=df)\n    plt.title('Category vs Value')\n    plt.show()\n    return (df, plt.gca())", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\ndef task_func(list_of_pairs):\n    df = pd.DataFrame(list_of_pairs, columns=['Category', 'Value'])\n    plt.figure(figsize=(10, 6))\n    sns.barplot(x='Category', y='Value', data=df)\n    plt.title('Category vs Value')\n    plt.show()\n    return (df, plt.gca())\n```"}
{"task_id": "BigCodeBench/10", "solution": "import numpy as np\nimport itertools\nimport random\nimport statistics\ndef task_func(T1, RANGE=100):\n    if not T1:\n        raise statistics.StatisticsError(\"T1 is empty\")\n    T1 = [int(i) for i in T1]\n    T2 = [random.randint(0, RANGE) for _ in range(sum(T1))]\n    mean = statistics.mean(T2)\n    median = statistics.median(T2)\n    mode = statistics.mode(T2)\n    return (mean, median, mode)", "raw_solution": "import numpy as np\nimport itertools\nimport random\nimport statistics\n\ndef task_func(T1, RANGE=100):\n    if not T1:\n        raise statistics.StatisticsError(\"T1 is empty\")\n    T1 = [int(i) for i in T1]\n    T2 = [random.randint(0, RANGE) for _ in range(sum(T1))]\n    mean = statistics.mean(T2)\n    median = statistics.median(T2)\n    mode = statistics.mode(T2)\n    return (mean, median, mode)\n```"}
{"task_id": "BigCodeBench/11", "solution": "import numpy as np\nimport itertools\nimport random\ndef task_func(T1, max_value=100):\n    # Convert elements in T1 to integers\n    T1 = [tuple(map(int, t)) for t in T1]\n    # Create a list of random integers\n    random_list = [random.randint(0, max_value) for _ in range(sum(T1))]\n    # Sort the list\n    random_list.sort()\n    # Calculate the 25th, 50th, and 75th percentiles\n    p25 = random_list[int(len(random_list) * 0.25)]\n    p50 = random_list[int(len(random_list) * 0.5)]\n    p75 = random_list[int(len(random_list) * 0.75)]\n    # Return the result as a tuple\n    return (p25, p50, p75)", "raw_solution": "import numpy as np\nimport itertools\nimport random\n\ndef task_func(T1, max_value=100):\n    # Convert elements in T1 to integers\n    T1 = [tuple(map(int, t)) for t in T1]\n    # Create a list of random integers\n    random_list = [random.randint(0, max_value) for _ in range(sum(T1))]\n    # Sort the list\n    random_list.sort()\n    # Calculate the 25th, 50th, and 75th percentiles\n    p25 = random_list[int(len(random_list) * 0.25)]\n    p50 = random_list[int(len(random_list) * 0.5)]\n    p75 = random_list[int(len(random_list) * 0.75)]\n    # Return the result as a tuple\n    return (p25, p50, p75)\n```"}
{"task_id": "BigCodeBench/12", "solution": "import subprocess\nimport os\nimport json\nfrom datetime import datetime\ndef task_func(script_name='backup.sh', log_file='/home/user/backup_log.json'):\n    try:\n        # Get the start time\n        start_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n        # Run the script\n        subprocess.run(['bash', script_name], check=True)\n        # Get the end time\n        end_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n        # Log the start time, end time, and exit status\n        with open(log_file, 'w') as f:\n            json.dump({'start_time': start_time, 'end_time': end_time, 'exit_status': 0}, f)\n    except FileNotFoundError:\n        raise FileNotFoundError(f\"Script file {script_name} does not exist.\")\n    except RuntimeError as e:\n        raise RuntimeError(f\"Error executing script: {e}\")", "raw_solution": "import subprocess\nimport os\nimport json\nfrom datetime import datetime\n\ndef task_func(script_name='backup.sh', log_file='/home/user/backup_log.json'):\n    try:\n        # Get the start time\n        start_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n        # Run the script\n        subprocess.run(['bash', script_name], check=True)\n        # Get the end time\n        end_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n        # Log the start time, end time, and exit status\n        with open(log_file, 'w') as f:\n            json.dump({'start_time': start_time, 'end_time': end_time, 'exit_status': 0}, f)\n    except FileNotFoundError:\n        raise FileNotFoundError(f\"Script file {script_name} does not exist.\")\n    except RuntimeError as e:\n        raise RuntimeError(f\"Error executing script: {e}\")\n```"}
{"task_id": "BigCodeBench/13", "solution": "import subprocess\nimport ftplib\nimport os\ndef task_func(ftp_server='ftp.dlptest.com', ftp_user='dlpuser', ftp_password='rNrKYTX9g7z3RgJRmxWuGHbeu', ftp_dir='/ftp/test'):\n    try:\n        ftp = ftplib.FTP(ftp_server)\n        ftp.login(user=ftp_user, passwd=ftp_password)\n        ftp.cwd(ftp_dir)\n        ftp.retrlines('LIST', lambda x: print(x))\n        ftp.quit()\n    except Exception as e:\n        print(f\"Failed to connect to FTP server {ftp_server}: {str(e)}\")\n        print(f\"Failed to log into FTP server {ftp_server} with user {ftp_user}: {str(e)}\")\n        print(f\"Failed to change to directory {ftp_dir} on server {ftp_server}: {str(e)}\")\n    return os.listdir(ftp_dir)", "raw_solution": "import subprocess\nimport ftplib\nimport os\ndef task_func(ftp_server='ftp.dlptest.com', ftp_user='dlpuser', ftp_password='rNrKYTX9g7z3RgJRmxWuGHbeu', ftp_dir='/ftp/test'):\n    try:\n        ftp = ftplib.FTP(ftp_server)\n        ftp.login(user=ftp_user, passwd=ftp_password)\n        ftp.cwd(ftp_dir)\n        ftp.retrlines('LIST', lambda x: print(x))\n        ftp.quit()\n    except Exception as e:\n        print(f\"Failed to connect to FTP server {ftp_server}: {str(e)}\")\n        print(f\"Failed to log into FTP server {ftp_server} with user {ftp_user}: {str(e)}\")\n        print(f\"Failed to change to directory {ftp_dir} on server {ftp_server}: {str(e)}\")\n    return os.listdir(ftp_dir)\n```"}
{"task_id": "BigCodeBench/14", "solution": "import configparser\nimport os\nimport shutil\ndef task_func(config_file_path, archieve_dir = '/home/user/archive'):\n    if not os.path.exists(config_file_path):\n        raise FileNotFoundError(\"Config file does not exist\")\n    if not os.path.exists(os.path.dirname(config_file_path)):\n        raise FileNotFoundError(\"Project directory does not exist\")\n    config = configparser.ConfigParser()\n    config.read(config_file_path)\n    project_dir = config['Project']['directory']\n    if not os.path.exists(project_dir):\n        raise FileNotFoundError(\"Project directory does not exist\")\n    zip_file_name = os.path.basename(project_dir)\n    zip_file_path = os.path.join(archieve_dir, zip_file_name)\n    try:\n        shutil.make_archive(zip_file_path, 'zip', project_dir)\n        return True\n    except Exception as e:\n        raise Exception(\"Failed to create ZIP archive: \" + str(e))", "raw_solution": "import configparser\nimport os\nimport shutil\ndef task_func(config_file_path, archieve_dir = '/home/user/archive'):\n    if not os.path.exists(config_file_path):\n        raise FileNotFoundError(\"Config file does not exist\")\n    if not os.path.exists(os.path.dirname(config_file_path)):\n        raise FileNotFoundError(\"Project directory does not exist\")\n    config = configparser.ConfigParser()\n    config.read(config_file_path)\n    project_dir = config['Project']['directory']\n    if not os.path.exists(project_dir):\n        raise FileNotFoundError(\"Project directory does not exist\")\n    zip_file_name = os.path.basename(project_dir)\n    zip_file_path = os.path.join(archieve_dir, zip_file_name)\n    try:\n        shutil.make_archive(zip_file_path, 'zip', project_dir)\n        return True\n    except Exception as e:\n        raise Exception(\"Failed to create ZIP archive: \" + str(e))\n```"}
{"task_id": "BigCodeBench/15", "solution": "import subprocess\nimport csv\nimport os\ndef task_func(commands_file_path, output_dir_path):\n    if not os.path.exists(commands_file_path):\n        raise FileNotFoundError(\"commands_file_path does not exist\")\n    with open(commands_file_path, newline='') as f:\n        reader = csv.reader(f)\n        for i, row in enumerate(reader):\n            command = row[0]\n            try:\n                output = subprocess.check_output(command, shell=True, text=True)\n                with open(os.path.join(output_dir_path, f'command_{i+1}_output.txt'), 'w') as f:\n                    f.write(output)\n            except subprocess.CalledProcessError as e:\n                with open(os.path.join(output_dir_path, f'command_{i+1}_output.txt'), 'w') as f:\n                    f.write(f'Error: {e.output}\\nExit code: {e.returncode}')", "raw_solution": "import subprocess\nimport csv\nimport os\n\ndef task_func(commands_file_path, output_dir_path):\n    if not os.path.exists(commands_file_path):\n        raise FileNotFoundError(\"commands_file_path does not exist\")\n    with open(commands_file_path, newline='') as f:\n        reader = csv.reader(f)\n        for i, row in enumerate(reader):\n            command = row[0]\n            try:\n                output = subprocess.check_output(command, shell=True, text=True)\n                with open(os.path.join(output_dir_path, f'command_{i+1}_output.txt'), 'w') as f:\n                    f.write(output)\n            except subprocess.CalledProcessError as e:\n                with open(os.path.join(output_dir_path, f'command_{i+1}_output.txt'), 'w') as f:\n                    f.write(f'Error: {e.output}\\nExit code: {e.returncode}')\n```"}
{"task_id": "BigCodeBench/16", "solution": "import os\nimport glob\nimport subprocess\ndef task_func(directory, backup_dir='/path/to/backup'):\n    if not os.path.exists(directory):\n        raise FileNotFoundError('Directory does not exist')\n    log_files = glob.glob(os.path.join(directory, '*.log'))\n    if not log_files:\n        return 'No logs found to backup'\n    backup_file = os.path.join(backup_dir, 'logs_backup.tar.gz')\n    subprocess.run(['tar', '-czvf', backup_file, *log_files])\n    for file in log_files:\n        os.remove(file)\n    return backup_file", "raw_solution": "import os\nimport glob\nimport subprocess\ndef task_func(directory, backup_dir='/path/to/backup'):\n    if not os.path.exists(directory):\n        raise FileNotFoundError('Directory does not exist')\n    log_files = glob.glob(os.path.join(directory, '*.log'))\n    if not log_files:\n        return 'No logs found to backup'\n    backup_file = os.path.join(backup_dir, 'logs_backup.tar.gz')\n    subprocess.run(['tar', '-czvf', backup_file, *log_files])\n    for file in log_files:\n        os.remove(file)\n    return backup_file\n```"}
{"task_id": "BigCodeBench/17", "solution": "import subprocess\nimport psutil\nimport time\ndef task_func(process_name: str) -> str:\n    try:\n        # Check if the process is running\n        process = psutil.Process(name=process_name)\n        if process.is_running():\n            # Process is running, terminate it\n            process.terminate()\n            time.sleep(2)\n            # Restart the process\n            subprocess.Popen(process_name)\n            return \"Process found. Restarting \" + process_name + \".\"\n        else:\n            # Process is not running, start it\n            subprocess.Popen(process_name)\n            return \"Process not found. Starting \" + process_name + \".\"\n    except Exception as e:\n        return \"Error: \" + str(e)", "raw_solution": "import subprocess\nimport psutil\nimport time\n\ndef task_func(process_name: str) -> str:\n    try:\n        # Check if the process is running\n        process = psutil.Process(name=process_name)\n        if process.is_running():\n            # Process is running, terminate it\n            process.terminate()\n            time.sleep(2)\n            # Restart the process\n            subprocess.Popen(process_name)\n            return \"Process found. Restarting \" + process_name + \".\"\n        else:\n            # Process is not running, start it\n            subprocess.Popen(process_name)\n            return \"Process not found. Starting \" + process_name + \".\"\n    except Exception as e:\n        return \"Error: \" + str(e)\n```"}
{"task_id": "BigCodeBench/18", "solution": "import subprocess\nimport csv\nimport glob\nimport random\nimport os\ndef task_func(file):\n    if not os.path.isfile(file) or not file.endswith('.csv'):\n        return []\n    split_files = glob.glob('split_*')\n    for split_file in split_files:\n        os.remove(split_file)\n    subprocess.run(['split', '-l', '1000', file, 'split_'])\n    split_files = glob.glob('split_*')\n    for split_file in split_files:\n        with open(split_file, 'r') as f:\n            reader = csv.reader(f)\n            lines = list(reader)\n        random.shuffle(lines)\n        with open(split_file, 'w') as f:\n            writer = csv.writer(f)\n            writer.writerows(lines)\n    return split_files", "raw_solution": "import subprocess\nimport csv\nimport glob\nimport random\nimport os\ndef task_func(file):\n    if not os.path.isfile(file) or not file.endswith('.csv'):\n        return []\n    split_files = glob.glob('split_*')\n    for split_file in split_files:\n        os.remove(split_file)\n    subprocess.run(['split', '-l', '1000', file, 'split_'])\n    split_files = glob.glob('split_*')\n    for split_file in split_files:\n        with open(split_file, 'r') as f:\n            reader = csv.reader(f)\n            lines = list(reader)\n        random.shuffle(lines)\n        with open(split_file, 'w') as f:\n            writer = csv.writer(f)\n            writer.writerows(lines)\n    return split_files\n```"}
{"task_id": "BigCodeBench/19", "solution": "import os\nimport glob\nimport zipfile\ndef task_func(directory):\n    if not os.path.exists(directory):\n        raise FileNotFoundError(\"The specified directory does not exist\")\n    files = glob.glob(os.path.join(directory, '*'))\n    if not files:\n        return None\n    zip_path = os.path.join(directory, 'files.zip')\n    with zipfile.ZipFile(zip_path, 'w') as zipf:\n        for file in files:\n            zipf.write(file)\n    return zip_path", "raw_solution": "import os\nimport glob\nimport zipfile\ndef task_func(directory):\n    if not os.path.exists(directory):\n        raise FileNotFoundError(\"The specified directory does not exist\")\n    files = glob.glob(os.path.join(directory, '*'))\n    if not files:\n        return None\n    zip_path = os.path.join(directory, 'files.zip')\n    with zipfile.ZipFile(zip_path, 'w') as zipf:\n        for file in files:\n            zipf.write(file)\n    return zip_path\n```"}
{"task_id": "BigCodeBench/20", "solution": "import ast\nimport pandas as pd\nimport seaborn as sns\ndef task_func(csv_file):\n    df = pd.read_csv(csv_file)\n    df['dict_column'] = df['dict_column'].apply(ast.literal_eval)\n    ax = sns.pairplot(df)\n    return df, ax", "raw_solution": "import ast\nimport pandas as pd\nimport seaborn as sns\n\ndef task_func(csv_file):\n    df = pd.read_csv(csv_file)\n    df['dict_column'] = df['dict_column'].apply(ast.literal_eval)\n    ax = sns.pairplot(df)\n    return df, ax\n```"}
{"task_id": "BigCodeBench/21", "solution": "import psutil\nimport platform\ndef task_func():\n    os = platform.system()\n    arch = platform.architecture()[0]\n    mem = psutil.virtual_memory()\n    mem_usage = f\"{mem.percent:.2f}%\"\n    return {'OS': os, 'Architecture': arch, 'Memory Usage': mem_usage}", "raw_solution": "import psutil\nimport platform\n\ndef task_func():\n    os = platform.system()\n    arch = platform.architecture()[0]\n    mem = psutil.virtual_memory()\n    mem_usage = f\"{mem.percent:.2f}%\"\n    return {'OS': os, 'Architecture': arch, 'Memory Usage': mem_usage}\n```"}
{"task_id": "BigCodeBench/22", "solution": "import collections\nfrom itertools import zip_longest\nfrom random import choices\ndef task_func(l1, l2, K=10):\n    combined_list = list(zip_longest(l1, l2, fillvalue=None))\n    combined_list = [item for sublist in combined_list for item in sublist if item is not None]\n    sample = choices(combined_list, k=K)\n    return collections.Counter(sample)", "raw_solution": "import collections\nfrom itertools import zip_longest\nfrom random import choices\n\ndef task_func(l1, l2, K=10):\n    combined_list = list(zip_longest(l1, l2, fillvalue=None))\n    combined_list = [item for sublist in combined_list for item in sublist if item is not None]\n    sample = choices(combined_list, k=K)\n    return collections.Counter(sample)\n```"}
{"task_id": "BigCodeBench/23", "solution": "import numpy as np\nfrom itertools import zip_longest\ndef task_func(l1, l2, THRESHOLD = 0.5):\n    combined = list(zip_longest(l1, l2, fillvalue=None))\n    abs_diffs = [abs(x - y) for x, y in combined if x is not None and y is not None]\n    closest = min(abs_diffs, key=lambda x: abs(x - THRESHOLD))\n    return closest", "raw_solution": "import numpy as np\nfrom itertools import zip_longest\n\ndef task_func(l1, l2, THRESHOLD = 0.5):\n    combined = list(zip_longest(l1, l2, fillvalue=None))\n    abs_diffs = [abs(x - y) for x, y in combined if x is not None and y is not None]\n    closest = min(abs_diffs, key=lambda x: abs(x - THRESHOLD))\n    return closest\n```"}
{"task_id": "BigCodeBench/24", "solution": "import base64\nimport hashlib\nimport os\ndef task_func(password, SALT_LENGTH = 32):\n    if password is None or password == '':\n        raise ValueError('Password cannot be None or empty')\n    salt = os.urandom(SALT_LENGTH)\n    key = hashlib.pbkdf2_hmac('sha256', password.encode('utf-8'), salt, 100000)\n    return (base64.b64encode(salt), base64.b64encode(key))", "raw_solution": "import base64\nimport hashlib\nimport os\n\ndef task_func(password, SALT_LENGTH = 32):\n    if password is None or password == '':\n        raise ValueError('Password cannot be None or empty')\n    salt = os.urandom(SALT_LENGTH)\n    key = hashlib.pbkdf2_hmac('sha256', password.encode('utf-8'), salt, 100000)\n    return (base64.b64encode(salt), base64.b64encode(key))\n```"}
{"task_id": "BigCodeBench/25", "solution": "import base64\nimport json\nimport zlib\ndef task_func(data_dict):\n    # Serialize the dictionary to a JSON string\n    json_str = json.dumps(data_dict)\n    # Compress the JSON string using zlib\n    compressed_data = zlib.compress(json_str.encode('utf-8'))\n    # Encode the compressed data with base64\n    base64_str = base64.b64encode(compressed_data).decode('utf-8')\n    return base64_str", "raw_solution": "import base64\nimport json\nimport zlib\n\ndef task_func(data_dict):\n    # Serialize the dictionary to a JSON string\n    json_str = json.dumps(data_dict)\n    # Compress the JSON string using zlib\n    compressed_data = zlib.compress(json_str.encode('utf-8'))\n    # Encode the compressed data with base64\n    base64_str = base64.b64encode(compressed_data).decode('utf-8')\n    return base64_str\n```"}
{"task_id": "BigCodeBench/26", "solution": "import base64\nfrom cryptography.fernet import Fernet\ndef task_func(message, encryption_key):\n    f = Fernet(encryption_key)\n    encrypted_message = f.encrypt(message.encode())\n    return base64.b64encode(encrypted_message).decode()", "raw_solution": "import base64\nfrom cryptography.fernet import Fernet\n\ndef task_func(message, encryption_key):\n    f = Fernet(encryption_key)\n    encrypted_message = f.encrypt(message.encode())\n    return base64.b64encode(encrypted_message).decode()\n```"}
{"task_id": "BigCodeBench/27", "solution": "import json\nimport base64\nfrom datetime import datetime\ndef task_func(data: dict, DATE_FORMAT = \"%Y-%m-%d %H:%M:%S\") -> str:\n    data['timestamp'] = datetime.now().strftime(DATE_FORMAT)\n    return base64.b64encode(json.dumps(data).encode('ascii')).decode('ascii')", "raw_solution": "import json\nimport base64\nfrom datetime import datetime\n\ndef task_func(data: dict, DATE_FORMAT = \"%Y-%m-%d %H:%M:%S\") -> str:\n    data['timestamp'] = datetime.now().strftime(DATE_FORMAT)\n    return base64.b64encode(json.dumps(data).encode('ascii')).decode('ascii')\n```"}
{"task_id": "BigCodeBench/28", "solution": "import requests\nimport json\nimport base64\ndef task_func(data, url=\"http://your-api-url.com\"):\n    # Convert dictionary to JSON string\n    json_str = json.dumps(data)\n    # Encode JSON string in base64 format\n    base64_str = base64.b64encode(json_str.encode()).decode()\n    # Send POST request to API endpoint\n    response = requests.post(url, data={\"payload\": base64_str})\n    return response", "raw_solution": "import requests\nimport json\nimport base64\ndef task_func(data, url=\"http://your-api-url.com\"):\n    # Convert dictionary to JSON string\n    json_str = json.dumps(data)\n    # Encode JSON string in base64 format\n    base64_str = base64.b64encode(json_str.encode()).decode()\n    # Send POST request to API endpoint\n    response = requests.post(url, data={\"payload\": base64_str})\n    return response\n```"}
{"task_id": "BigCodeBench/29", "solution": "from sklearn.preprocessing import StandardScaler\nimport numpy as np\nimport base64\ndef task_func(data):\n    scaler = StandardScaler()\n    standardized_data = scaler.fit_transform(data)\n    base64_string = base64.b64encode(standardized_data).decode('utf-8')\n    return str(base64_string)", "raw_solution": "from sklearn.preprocessing import StandardScaler\nimport numpy as np\nimport base64\ndef task_func(data):\n    scaler = StandardScaler()\n    standardized_data = scaler.fit_transform(data)\n    base64_string = base64.b64encode(standardized_data).decode('utf-8')\n    return str(base64_string)\n```"}
{"task_id": "BigCodeBench/30", "solution": "import json\nimport os\nimport re\ndef task_func(\n    file_path,\n    attribute,\n    INPUT_JSON={\n        \"type\": \"object\",\n        \"properties\": {\n            \"name\": {\"type\": str},  \n            \"age\": {\"type\": int},   \n            \"email\": {\"type\": str}  \n        },\n        \"required\": [\"name\", \"age\", \"email\"]\n    },\n    EMAIL_REGEX=r\"^[a-z0-9]+[\\._]?[a-z0-9]+[@]\\w+[.]\\w{2,3}$\"):\n    if not os.path.exists(file_path):\n        raise ValueError(\"File does not exist\")\n    with open(file_path, 'r') as f:\n        data = json.load(f)\n    if attribute not in data:\n        raise ValueError(\"Required attribute is missing\")\n    if not isinstance(data[attribute], INPUT_JSON['properties'][attribute]['type']):\n        raise ValueError(\"Type does not match\")\n    if not re.match(EMAIL_REGEX, data[attribute]):\n        raise ValueError(\"Invalid email format\")\n    return data[attribute]", "raw_solution": "import json\nimport os\nimport re\ndef task_func(\n    file_path,\n    attribute,\n    INPUT_JSON={\n        \"type\": \"object\",\n        \"properties\": {\n            \"name\": {\"type\": str},  \n            \"age\": {\"type\": int},   \n            \"email\": {\"type\": str}  \n        },\n        \"required\": [\"name\", \"age\", \"email\"]\n    },\n    EMAIL_REGEX=r\"^[a-z0-9]+[\\._]?[a-z0-9]+[@]\\w+[.]\\w{2,3}$\"):\n    if not os.path.exists(file_path):\n        raise ValueError(\"File does not exist\")\n    with open(file_path, 'r') as f:\n        data = json.load(f)\n    if attribute not in data:\n        raise ValueError(\"Required attribute is missing\")\n    if not isinstance(data[attribute], INPUT_JSON['properties'][attribute]['type']):\n        raise ValueError(\"Type does not match\")\n    if not re.match(EMAIL_REGEX, data[attribute]):\n        raise ValueError(\"Invalid email format\")\n    return data[attribute]\n```"}
{"task_id": "BigCodeBench/31", "solution": "import nltk\nfrom string import punctuation\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nPUNCTUATION = set(punctuation)\ndef task_func(text):\n    # Remove punctuation from the text\n    text = ''.join([char for char in text if char not in PUNCTUATION])\n    # Split the text into words\n    words = text.split()\n    # Filter words that start with '$'\n    words = [word for word in words if word.startswith('$')]\n    # Count the frequency of each word\n    word_freq = nltk.FreqDist(words)\n    # Create a bar chart of the frequency of words beginning with the '$' character\n    ax = sns.barplot(x=word_freq.keys(), y=word_freq.values())\n    return ax", "raw_solution": "import nltk\nfrom string import punctuation\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n# Constants\nPUNCTUATION = set(punctuation)\ndef task_func(text):\n    # Remove punctuation from the text\n    text = ''.join([char for char in text if char not in PUNCTUATION])\n    # Split the text into words\n    words = text.split()\n    # Filter words that start with '$'\n    words = [word for word in words if word.startswith('$')]\n    # Count the frequency of each word\n    word_freq = nltk.FreqDist(words)\n    # Create a bar chart of the frequency of words beginning with the '$' character\n    ax = sns.barplot(x=word_freq.keys(), y=word_freq.values())\n    return ax\n```"}
{"task_id": "BigCodeBench/32", "solution": "import requests\nfrom bs4 import BeautifulSoup\ndef task_func(url, tag):\n    response = requests.get(url)\n    soup = BeautifulSoup(response.text, 'html.parser')\n    tag = soup.find(tag)\n    if tag:\n        return tag.get_text()\n    else:\n        return None", "raw_solution": "import requests\nfrom bs4 import BeautifulSoup\ndef task_func(url, tag):\n    response = requests.get(url)\n    soup = BeautifulSoup(response.text, 'html.parser')\n    tag = soup.find(tag)\n    if tag:\n        return tag.get_text()\n    else:\n        return None\n```"}
{"task_id": "BigCodeBench/33", "solution": "import numpy as np\nfrom functools import reduce", "raw_solution": "import numpy as np\nfrom functools import reduce\n\ndef task_func(list_of_pairs):\n    return np.array([reduce(lambda x, y: x * y, pair[1] for pair in list_of_pairs)])\n```"}
{"task_id": "BigCodeBench/34", "solution": "import re\nfrom wordcloud import WordCloud\nimport matplotlib.pyplot as plt\ndef task_func(text):\n    # Remove URLs from the text\n    text = re.sub(r'http\\S+', '', text)\n    \n    # Check if there are any words left after removing URLs\n    if not text:\n        raise ValueError(\"No words available to generate a word cloud after removing URLs.\")\n    \n    # Generate the word cloud\n    wordcloud = WordCloud(width=800, height=400, background_color='white').generate(text)\n    \n    # Plot the word cloud\n    plt.figure(figsize=(10, 5))\n    plt.imshow(wordcloud, interpolation='bilinear')\n    plt.axis('off')\n    plt.show()\n    \n    return wordcloud", "raw_solution": "import re\nfrom wordcloud import WordCloud\nimport matplotlib.pyplot as plt\n\ndef task_func(text):\n    # Remove URLs from the text\n    text = re.sub(r'http\\S+', '', text)\n    \n    # Check if there are any words left after removing URLs\n    if not text:\n        raise ValueError(\"No words available to generate a word cloud after removing URLs.\")\n    \n    # Generate the word cloud\n    wordcloud = WordCloud(width=800, height=400, background_color='white').generate(text)\n    \n    # Plot the word cloud\n    plt.figure(figsize=(10, 5))\n    plt.imshow(wordcloud, interpolation='bilinear')\n    plt.axis('off')\n    plt.show()\n    \n    return wordcloud\n```"}
{"task_id": "BigCodeBench/35", "solution": "import seaborn as sns\nimport matplotlib.pyplot as plt\ndef task_func(df, target_values=[1, 3, 4]):\n    df = df.replace({col: 0 for col in df.columns if col not in target_values})\n    for col in df.columns:\n        sns.histplot(df[col], kde=True, label=col)\n        plt.legend()\n        plt.show()", "raw_solution": "import seaborn as sns\nimport matplotlib.pyplot as plt\ndef task_func(df, target_values=[1, 3, 4]):\n    df = df.replace({col: 0 for col in df.columns if col not in target_values})\n    for col in df.columns:\n        sns.histplot(df[col], kde=True, label=col)\n        plt.legend()\n        plt.show()\n```"}
{"task_id": "BigCodeBench/36", "solution": "import numpy as np\nfrom scipy import stats\nimport matplotlib.pyplot as plt\ndef task_func(df):\n    # Replace all elements in DataFrame columns that do not exist in the TARGET_VALUES array with zeros\n    df = df.fillna(0)\n    \n    # Perform a Box-Cox transformation on each column (if data is not constant, add 1 to account for zeros)\n    df = df.apply(stats.boxcox, axis=0, cdf=True, floc=0)\n    \n    # Display the resulting KDE plots\n    fig, axes = plt.subplots(nrows=df.shape[1], ncols=1, figsize=(10, 10))\n    for i in range(df.shape[1]):\n        axes[i].plot(df.iloc[:, i])\n        axes[i].set_title(f'KDE plot of column {i}')\n    plt.show()\n    \n    return df, fig", "raw_solution": "import numpy as np\nfrom scipy import stats\nimport matplotlib.pyplot as plt\nTARGET_VALUES = np.array([1, 3, 4])\n\ndef task_func(df):\n    # Replace all elements in DataFrame columns that do not exist in the TARGET_VALUES array with zeros\n    df = df.fillna(0)\n    \n    # Perform a Box-Cox transformation on each column (if data is not constant, add 1 to account for zeros)\n    df = df.apply(stats.boxcox, axis=0, cdf=True, floc=0)\n    \n    # Display the resulting KDE plots\n    fig, axes = plt.subplots(nrows=df.shape[1], ncols=1, figsize=(10, 10))\n    for i in range(df.shape[1]):\n        axes[i].plot(df.iloc[:, i])\n        axes[i].set_title(f'KDE plot of column {i}')\n    plt.show()\n    \n    return df, fig\n```"}
{"task_id": "BigCodeBench/37", "solution": "from sklearn.ensemble import RandomForestClassifier\nimport seaborn as sns\nimport matplotlib.pyplot as plt\ndef task_func(df, target_column):\n    # Train a random forest classifier\n    rf = RandomForestClassifier(n_estimators=100)\n    rf.fit(df.drop(target_column, axis=1), df[target_column])\n    \n    # Get feature importances\n    feature_importances = rf.feature_importances_\n    \n    # Sort feature importances in descending order\n    sorted_indices = np.argsort(feature_importances)[::-1]\n    sorted_feature_importances = feature_importances[sorted_indices]\n    sorted_feature_names = df.drop(target_column, axis=1).columns[sorted_indices]\n    \n    # Plot the bar plot of feature importance\n    fig, ax = plt.subplots()\n    sns.barplot(x=sorted_feature_importances, y=sorted_feature_names, ax=ax)\n    ax.set_xlabel('Feature Importance Score')\n    ax.set_ylabel('Features')\n    ax.set_title('Visualizing Important Features')\n    \n    return rf, ax", "raw_solution": "from sklearn.ensemble import RandomForestClassifier\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\ndef task_func(df, target_column):\n    # Train a random forest classifier\n    rf = RandomForestClassifier(n_estimators=100)\n    rf.fit(df.drop(target_column, axis=1), df[target_column])\n    \n    # Get feature importances\n    feature_importances = rf.feature_importances_\n    \n    # Sort feature importances in descending order\n    sorted_indices = np.argsort(feature_importances)[::-1]\n    sorted_feature_importances = feature_importances[sorted_indices]\n    sorted_feature_names = df.drop(target_column, axis=1).columns[sorted_indices]\n    \n    # Plot the bar plot of feature importance\n    fig, ax = plt.subplots()\n    sns.barplot(x=sorted_feature_importances, y=sorted_feature_names, ax=ax)\n    ax.set_xlabel('Feature Importance Score')\n    ax.set_ylabel('Features')\n    ax.set_title('Visualizing Important Features')\n    \n    return rf, ax\n```"}
{"task_id": "BigCodeBench/38", "solution": "import pandas as pd\nfrom sklearn.preprocessing import StandardScaler\nimport matplotlib.pyplot as plt\nFEATURE_NAMES = [\"Feature 1\", \"Feature 2\", \"Feature 3\", \"Feature 4\", \"Feature 5\"]\ndef task_func(data_matrix):\n    # Standardize the data matrix\n    scaler = StandardScaler()\n    standardized_data = scaler.fit_transform(data_matrix)\n    # Calculate the mean of each row\n    means = standardized_data.mean(axis=1)\n    # Create a DataFrame with the standardized data and the mean of each row\n    df = pd.DataFrame(standardized_data, columns=FEATURE_NAMES)\n    df['Mean'] = means\n    # Plot the distribution of means\n    plt.hist(means, bins=30, edgecolor='black')\n    plt.title('Distribution of Means')\n    plt.xlabel('Mean')\n    plt.ylabel('Frequency')\n    return (df, plt.gca())", "raw_solution": "import pandas as pd\nfrom sklearn.preprocessing import StandardScaler\nimport matplotlib.pyplot as plt\n# Constants\nFEATURE_NAMES = [\"Feature 1\", \"Feature 2\", \"Feature 3\", \"Feature 4\", \"Feature 5\"]\ndef task_func(data_matrix):\n    # Standardize the data matrix\n    scaler = StandardScaler()\n    standardized_data = scaler.fit_transform(data_matrix)\n    # Calculate the mean of each row\n    means = standardized_data.mean(axis=1)\n    # Create a DataFrame with the standardized data and the mean of each row\n    df = pd.DataFrame(standardized_data, columns=FEATURE_NAMES)\n    df['Mean'] = means\n    # Plot the distribution of means\n    plt.hist(means, bins=30, edgecolor='black')\n    plt.title('Distribution of Means')\n    plt.xlabel('Mean')\n    plt.ylabel('Frequency')\n    return (df, plt.gca())\n```"}
{"task_id": "BigCodeBench/39", "solution": "import numpy as np\nfrom scipy.stats import ttest_1samp\nimport matplotlib.pyplot as plt\nALPHA = 0.05\ndef task_func(data_matrix):\n    # Calculate the mean value of each row\n    means = np.mean(data_matrix, axis=1)\n    \n    # Run a t-test from a sample against the population value\n    population_mean = np.mean(data_matrix)\n    t_stat, p_value = ttest_1samp(means, population_mean)\n    \n    # Record the mean values that differ significantly\n    significant_indices = np.where(p_value < ALPHA)[0]\n    \n    # Create a lineplot with the mean of rows in red\n    ax = plt.plot(means, label='Means')\n    \n    # Create a line plot with the significant_indices (those with a pvalue less than ALPHA) on the x-axis and the corresponding means on the y-axis. This plot should be blue. Its label is 'Significant Means'.\n    ax2 = plt.plot(significant_indices, means[significant_indices], 'b', label='Significant Means')\n    \n    # Create an horizontal line which represent the mean computed on the whole 2D matrix. It should be in green. Its label is 'Population Mean'.\n    plt.axhline(population_mean, color='g', label='Population Mean')\n    \n    # Show the plot\n    plt.legend()\n    plt.show()\n    \n    # Return the list of indices of the means that are significantly different from the population mean and the plot\n    return significant_indices, ax", "raw_solution": "import numpy as np\nfrom scipy.stats import ttest_1samp\nimport matplotlib.pyplot as plt\n# Constants\nALPHA = 0.05\n\ndef task_func(data_matrix):\n    # Calculate the mean value of each row\n    means = np.mean(data_matrix, axis=1)\n    \n    # Run a t-test from a sample against the population value\n    population_mean = np.mean(data_matrix)\n    t_stat, p_value = ttest_1samp(means, population_mean)\n    \n    # Record the mean values that differ significantly\n    significant_indices = np.where(p_value < ALPHA)[0]\n    \n    # Create a lineplot with the mean of rows in red\n    ax = plt.plot(means, label='Means')\n    \n    # Create a line plot with the significant_indices (those with a pvalue less than ALPHA) on the x-axis and the corresponding means on the y-axis. This plot should be blue. Its label is 'Significant Means'.\n    ax2 = plt.plot(significant_indices, means[significant_indices], 'b', label='Significant Means')\n    \n    # Create an horizontal line which represent the mean computed on the whole 2D matrix. It should be in green. Its label is 'Population Mean'.\n    plt.axhline(population_mean, color='g', label='Population Mean')\n    \n    # Show the plot\n    plt.legend()\n    plt.show()\n    \n    # Return the list of indices of the means that are significantly different from the population mean and the plot\n    return significant_indices, ax\n```"}
{"task_id": "BigCodeBench/40", "solution": "import pandas as pd\nimport seaborn as sns\nfrom scipy.stats import zscore\ndef task_func(data_matrix):\n    # Calculate Z-values\n    z_scores = zscore(data_matrix, axis=1)\n    \n    # Calculate mean value of each row\n    means = z_scores.mean(axis=1)\n    \n    # Create a DataFrame with Z-scores and mean\n    df = pd.DataFrame(z_scores, columns=data_matrix.columns)\n    df['Mean'] = means\n    \n    # Create a heatmap\n    sns.heatmap(df, annot=True, cmap='coolwarm')\n    \n    # Return the heatmap Axes object\n    return sns.plt.gca()", "raw_solution": "import pandas as pd\nimport seaborn as sns\nfrom scipy.stats import zscore\n\ndef task_func(data_matrix):\n    # Calculate Z-values\n    z_scores = zscore(data_matrix, axis=1)\n    \n    # Calculate mean value of each row\n    means = z_scores.mean(axis=1)\n    \n    # Create a DataFrame with Z-scores and mean\n    df = pd.DataFrame(z_scores, columns=data_matrix.columns)\n    df['Mean'] = means\n    \n    # Create a heatmap\n    sns.heatmap(df, annot=True, cmap='coolwarm')\n    \n    # Return the heatmap Axes object\n    return sns.plt.gca()\n```"}
{"task_id": "BigCodeBench/41", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nfrom scipy.stats import skew\ndef task_func(data_matrix):\n    # Calculate the skewness of each row\n    skewness = data_matrix.apply(lambda row: skew(row), axis=1)\n    # Create a DataFrame with the skewness\n    skewness_df = pd.DataFrame(skewness, columns=['Skewness'])\n    # Plot the distribution\n    plt.hist(skewness, bins=30, density=True)\n    plt.xlabel('Skewness')\n    plt.ylabel('Frequency')\n    plt.title('Distribution of Skewness')\n    plt.show()\n    return skewness_df, plt.gca()", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nfrom scipy.stats import skew\n\ndef task_func(data_matrix):\n    # Calculate the skewness of each row\n    skewness = data_matrix.apply(lambda row: skew(row), axis=1)\n    # Create a DataFrame with the skewness\n    skewness_df = pd.DataFrame(skewness, columns=['Skewness'])\n    # Plot the distribution\n    plt.hist(skewness, bins=30, density=True)\n    plt.xlabel('Skewness')\n    plt.ylabel('Frequency')\n    plt.title('Distribution of Skewness')\n    plt.show()\n    return skewness_df, plt.gca()\n```"}
{"task_id": "BigCodeBench/42", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.decomposition import PCA\ndef task_func(data_matrix, n_components=2):\n    pca = PCA(n_components=n_components)\n    pca.fit(data_matrix)\n    transformed_data = pca.transform(data_matrix)\n    means = pca.mean_\n    explained_variance = pca.explained_variance_ratio_\n    cumulative_variance = explained_variance.cumsum()\n    df = pd.DataFrame(transformed_data, columns=[f'Component {i+1}' for i in range(n_components)])\n    df['Mean'] = means\n    plt.plot(range(1, n_components+1), cumulative_variance)\n    plt.xlabel('Number of Components')\n    plt.ylabel('Cumulative Explained Variance')\n    plt.show()\n    return df, plt.gca()", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.decomposition import PCA\n\ndef task_func(data_matrix, n_components=2):\n    pca = PCA(n_components=n_components)\n    pca.fit(data_matrix)\n    transformed_data = pca.transform(data_matrix)\n    means = pca.mean_\n    explained_variance = pca.explained_variance_ratio_\n    cumulative_variance = explained_variance.cumsum()\n    df = pd.DataFrame(transformed_data, columns=[f'Component {i+1}' for i in range(n_components)])\n    df['Mean'] = means\n    plt.plot(range(1, n_components+1), cumulative_variance)\n    plt.xlabel('Number of Components')\n    plt.ylabel('Cumulative Explained Variance')\n    plt.show()\n    return df, plt.gca()\n```"}
{"task_id": "BigCodeBench/43", "solution": "import numpy as np\nimport seaborn as sns\ndef task_func(df):\n    df = df.fillna(df.mean())\n    stats = df.describe()\n    fig, axes = plt.subplots(1, len(stats.columns), figsize=(10, 5))\n    for i, col in enumerate(stats.columns):\n        sns.histplot(df[col], bins=10, ax=axes[i])\n    return stats, axes", "raw_solution": "import numpy as np\nimport seaborn as sns\ndef task_func(df):\n    df = df.fillna(df.mean())\n    stats = df.describe()\n    fig, axes = plt.subplots(1, len(stats.columns), figsize=(10, 5))\n    for i, col in enumerate(stats.columns):\n        sns.histplot(df[col], bins=10, ax=axes[i])\n    return stats, axes\n```"}
{"task_id": "BigCodeBench/44", "solution": "from sklearn.preprocessing import MinMaxScaler\nimport matplotlib.pyplot as plt\ndef task_func(df):\n    scaler = MinMaxScaler()\n    df = scaler.fit_transform(df)\n    fig, ax = plt.subplots()\n    ax.boxplot(df)\n    return df, ax", "raw_solution": "from sklearn.preprocessing import MinMaxScaler\nimport matplotlib.pyplot as plt\n\ndef task_func(df):\n    scaler = MinMaxScaler()\n    df = scaler.fit_transform(df)\n    fig, ax = plt.subplots()\n    ax.boxplot(df)\n    return df, ax\n```"}
{"task_id": "BigCodeBench/45", "solution": "import pandas as pd\nimport numpy as np\nfrom sklearn.decomposition import PCA\nimport seaborn as sns\nimport matplotlib.pyplot as plt\ndef task_func(df: pd.DataFrame):\n    # Exclude non-numeric columns\n    df = df.select_dtypes(include=['number'])\n    \n    # Replace missing values with column's average\n    df = df.fillna(df.mean())\n    \n    # Perform PCA\n    pca = PCA(n_components=2)\n    principal_components = pca.fit_transform(df)\n    \n    # Create a DataFrame with the first two principal components\n    principal_df = pd.DataFrame(data=principal_components, columns=['principal component 1', 'principal component 2'])\n    \n    # Draw a scatter plot of the first two main components\n    sns.scatterplot(x='principal component 1', y='principal component 2', data=principal_df)\n    plt.xlabel('principal component')\n    plt.ylabel('principal component 2')\n    \n    return principal_df, plt.gca()", "raw_solution": "import pandas as pd\nimport numpy as np\nfrom sklearn.decomposition import PCA\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\ndef task_func(df: pd.DataFrame):\n    # Exclude non-numeric columns\n    df = df.select_dtypes(include=['number'])\n    \n    # Replace missing values with column's average\n    df = df.fillna(df.mean())\n    \n    # Perform PCA\n    pca = PCA(n_components=2)\n    principal_components = pca.fit_transform(df)\n    \n    # Create a DataFrame with the first two principal components\n    principal_df = pd.DataFrame(data=principal_components, columns=['principal component 1', 'principal component 2'])\n    \n    # Draw a scatter plot of the first two main components\n    sns.scatterplot(x='principal component 1', y='principal component 2', data=principal_df)\n    plt.xlabel('principal component')\n    plt.ylabel('principal component 2')\n    \n    return principal_df, plt.gca()\n```"}
{"task_id": "BigCodeBench/46", "solution": "from scipy.stats import zscore\nimport matplotlib.pyplot as plt\ndef task_func(df):\n    z_scores = df.apply(zscore, axis=0, skipna=True)\n    z_scores = z_scores.fillna(df.mean())\n    fig, axes = plt.subplots(nrows=z_scores.shape[1], ncols=1, figsize=(10, 10))\n    for i, ax in enumerate(axes):\n        ax.hist(z_scores.iloc[:, i], bins=10)\n        ax.set_title(f'Column {i+1}')\n    return z_scores, axes", "raw_solution": "from scipy.stats import zscore\nimport matplotlib.pyplot as plt\n\ndef task_func(df):\n    z_scores = df.apply(zscore, axis=0, skipna=True)\n    z_scores = z_scores.fillna(df.mean())\n    fig, axes = plt.subplots(nrows=z_scores.shape[1], ncols=1, figsize=(10, 10))\n    for i, ax in enumerate(axes):\n        ax.hist(z_scores.iloc[:, i], bins=10)\n        ax.set_title(f'Column {i+1}')\n    return z_scores, axes\n```"}
{"task_id": "BigCodeBench/47", "solution": "from sklearn.preprocessing import StandardScaler\nimport seaborn as sns\nimport matplotlib.pyplot as plt\ndef task_func(df):\n    scaler = StandardScaler()\n    df = scaler.fit_transform(df)\n    corr = df.corr()\n    sns.heatmap(corr, annot=True, cmap='coolwarm')\n    plt.show()\n    return df, plt.gca()", "raw_solution": "from sklearn.preprocessing import StandardScaler\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\ndef task_func(df):\n    scaler = StandardScaler()\n    df = scaler.fit_transform(df)\n    corr = df.corr()\n    sns.heatmap(corr, annot=True, cmap='coolwarm')\n    plt.show()\n    return df, plt.gca()\n```"}
{"task_id": "BigCodeBench/48", "solution": "import time\nfrom datetime import datetime\nimport random\nimport matplotlib.pyplot as plt\nDATE_FORMAT = \"%Y-%m-%d %H:%M:%S\"\ndef task_func(n, output_path=None):\n    # Generate n random Unix timestamps\n    timestamps = [time.time() + random.random() for _ in range(n)]\n    # Convert timestamps to strings formatted as UTC DATE_FORMAT\n    formatted_timestamps = [datetime.utcfromtimestamp(ts).strftime(DATE_FORMAT) for ts in timestamps]\n    # Plot a histogram of the distribution of the generated timestamps\n    plt.hist(formatted_timestamps, bins=100)\n    if output_path:\n        plt.savefig(output_path)\n    else:\n        plt.show()", "raw_solution": "import time\nfrom datetime import datetime\nimport random\nimport matplotlib.pyplot as plt\n# Constants\nDATE_FORMAT = \"%Y-%m-%d %H:%M:%S\"\ndef task_func(n, output_path=None):\n    # Generate n random Unix timestamps\n    timestamps = [time.time() + random.random() for _ in range(n)]\n    # Convert timestamps to strings formatted as UTC DATE_FORMAT\n    formatted_timestamps = [datetime.utcfromtimestamp(ts).strftime(DATE_FORMAT) for ts in timestamps]\n    # Plot a histogram of the distribution of the generated timestamps\n    plt.hist(formatted_timestamps, bins=100)\n    if output_path:\n        plt.savefig(output_path)\n    else:\n        plt.show()\n```"}
{"task_id": "BigCodeBench/49", "solution": "from datetime import datetime\nimport pandas as pd\nimport matplotlib.pyplot as plt\ndef task_func(timestamps):\n    if len(timestamps) == 0:\n        raise ValueError(\"Input list of timestamps is empty.\")\n    df = pd.DataFrame({'Timestamp': timestamps, 'Datetime': [datetime.fromtimestamp(ts) for ts in timestamps]})\n    ax = df['Datetime'].hist(bins=10)\n    plt.show()\n    return df, ax", "raw_solution": "from datetime import datetime\nimport pandas as pd\nimport matplotlib.pyplot as plt\n# Constants\nDATE_FORMAT = \"%Y-%m-%d %H:%M:%S\"\ndef task_func(timestamps):\n    if len(timestamps) == 0:\n        raise ValueError(\"Input list of timestamps is empty.\")\n    df = pd.DataFrame({'Timestamp': timestamps, 'Datetime': [datetime.fromtimestamp(ts) for ts in timestamps]})\n    ax = df['Datetime'].hist(bins=10)\n    plt.show()\n    return df, ax\n```"}
{"task_id": "BigCodeBench/50", "solution": "from datetime import datetime\nimport pandas as pd\nimport pytz\nimport matplotlib.pyplot as plt\nDATE_FORMAT = \"%Y-%m-%d %H:%M:%S\"\nTIMEZONES = [\n    \"America/New_York\",\n    \"Europe/London\",\n    \"Asia/Shanghai\",\n    \"Asia/Tokyo\",\n    \"Australia/Sydney\",\n]\ndef task_func(timestamp):\n    # Convert Unix timestamp to datetime object\n    dt = datetime.fromtimestamp(timestamp)\n    # Create a pandas DataFrame\n    df = pd.DataFrame({\n        'Timezone': TIMEZONES,\n        'Datetime': [dt.astimezone(tz).strftime(DATE_FORMAT) for tz in TIMEZONES]\n    })\n    # Draw a bar chart\n    ax = df.plot(kind='bar', x='Timezone', y='Datetime', title=\"Datetime = f(Timezone)\")\n    plt.xlabel('Timezone')\n    plt.ylabel('Datetime')\n    plt.show()\n    return df, ax", "raw_solution": "from datetime import datetime\nimport pandas as pd\nimport pytz\nimport matplotlib.pyplot as plt\n# Constants\nDATE_FORMAT = \"%Y-%m-%d %H:%M:%S\"\nTIMEZONES = [\n    \"America/New_York\",\n    \"Europe/London\",\n    \"Asia/Shanghai\",\n    \"Asia/Tokyo\",\n    \"Australia/Sydney\",\n]\ndef task_func(timestamp):\n    # Convert Unix timestamp to datetime object\n    dt = datetime.fromtimestamp(timestamp)\n    # Create a pandas DataFrame\n    df = pd.DataFrame({\n        'Timezone': TIMEZONES,\n        'Datetime': [dt.astimezone(tz).strftime(DATE_FORMAT) for tz in TIMEZONES]\n    })\n    # Draw a bar chart\n    ax = df.plot(kind='bar', x='Timezone', y='Datetime', title=\"Datetime = f(Timezone)\")\n    plt.xlabel('Timezone')\n    plt.ylabel('Datetime')\n    plt.show()\n    return df, ax\n```"}
{"task_id": "BigCodeBench/51", "solution": "from sklearn.cluster import KMeans\nimport matplotlib.pyplot as plt\ndef task_func(df, age: int, height: int):\n    if len(df.columns) < 3:\n        df['Cluster'] = 0\n    else:\n        kmeans = KMeans(n_clusters=3, random_state=0).fit(df[['Age', 'Height']])\n        df['Cluster'] = kmeans.labels_\n    plt.scatter(df['Age'], df['Height'], c=df['Cluster'])\n    plt.xlabel('Age')\n    plt.ylabel('Height')\n    plt.title('KMeans Clustering based on Age and Height')\n    return df, plt.gca()", "raw_solution": "from sklearn.cluster import KMeans\nimport matplotlib.pyplot as plt\n\ndef task_func(df, age: int, height: int):\n    if len(df.columns) < 3:\n        df['Cluster'] = 0\n    else:\n        kmeans = KMeans(n_clusters=3, random_state=0).fit(df[['Age', 'Height']])\n        df['Cluster'] = kmeans.labels_\n    plt.scatter(df['Age'], df['Height'], c=df['Cluster'])\n    plt.xlabel('Age')\n    plt.ylabel('Height')\n    plt.title('KMeans Clustering based on Age and Height')\n    return df, plt.gca()\n```"}
{"task_id": "BigCodeBench/52", "solution": "import pandas as pd\nimport regex as re\nSTOPWORDS = [\"a\", \"an\", \"the\", \"in\", \"is\", \"are\"]\ndef task_func(text):\n    # Remove punctuation and convert to lowercase\n    text = re.sub(r'[^\\w\\s]', '', text).lower()\n    # Split text into words\n    words = text.split()\n    # Remove stopwords\n    words = [word for word in words if word not in STOPWORDS]\n    # Count word frequencies\n    word_freq = pd.Series(words).value_counts()\n    return word_freq", "raw_solution": "import pandas as pd\nimport regex as re\n# Constants\nSTOPWORDS = [\"a\", \"an\", \"the\", \"in\", \"is\", \"are\"]\ndef task_func(text):\n    # Remove punctuation and convert to lowercase\n    text = re.sub(r'[^\\w\\s]', '', text).lower()\n    # Split text into words\n    words = text.split()\n    # Remove stopwords\n    words = [word for word in words if word not in STOPWORDS]\n    # Count word frequencies\n    word_freq = pd.Series(words).value_counts()\n    return word_freq\n```"}
{"task_id": "BigCodeBench/53", "solution": "import pandas as pd\nimport regex as re\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nCOLUMN_NAMES = [\"Name\", \"Email\", \"Age\", \"Country\"]\ndef task_func(text):\n    data = re.findall(r\"Name: (.*?), Email: (.*?), Age: (.*?), Country: (.*?)($|\\n)\", text)\n    df = pd.DataFrame(data, columns=COLUMN_NAMES)\n    sns.histplot(df['Age'])\n    plt.show()", "raw_solution": "import pandas as pd\nimport regex as re\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nCOLUMN_NAMES = [\"Name\", \"Email\", \"Age\", \"Country\"]\ndef task_func(text):\n    data = re.findall(r\"Name: (.*?), Email: (.*?), Age: (.*?), Country: (.*?)($|\\n)\", text)\n    df = pd.DataFrame(data, columns=COLUMN_NAMES)\n    sns.histplot(df['Age'])\n    plt.show()\n```"}
{"task_id": "BigCodeBench/54", "solution": "import pandas as pd\nimport regex as re\nfrom sklearn.feature_extraction.text import CountVectorizer\ndef task_func(text):\n    # Remove empty sentences\n    text = re.sub(r'\\s*\\.\\s*', '.', text)\n    # Split text into sentences\n    sentences = text.split('.')\n    # Create document-term matrix\n    vectorizer = CountVectorizer()\n    X = vectorizer.fit_transform(sentences)\n    # Create DataFrame\n    df = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names_out())\n    return df", "raw_solution": "import pandas as pd\nimport regex as re\nfrom sklearn.feature_extraction.text import CountVectorizer\n\ndef task_func(text):\n    # Remove empty sentences\n    text = re.sub(r'\\s*\\.\\s*', '.', text)\n    # Split text into sentences\n    sentences = text.split('.')\n    # Create document-term matrix\n    vectorizer = CountVectorizer()\n    X = vectorizer.fit_transform(sentences)\n    # Create DataFrame\n    df = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names_out())\n    return df\n```"}
{"task_id": "BigCodeBench/55", "solution": "import re\nimport pandas as pd\nSTOPWORDS = [\"Those\", \"are\", \"the\", \"words\", \"to\", \"ignore\"]\ndef task_func(text):\n    sentences = re.split(r'[.!?]', text)\n    sentence_dict = {f'Sentence {i+1}': len([word for word in sentence.split() if word not in STOPWORDS]) for i, sentence in enumerate(sentences)}\n    return pd.Series(sentence_dict)", "raw_solution": "import re\nimport pandas as pd\nSTOPWORDS = [\"Those\", \"are\", \"the\", \"words\", \"to\", \"ignore\"]\ndef task_func(text):\n    sentences = re.split(r'[.!?]', text)\n    sentence_dict = {f'Sentence {i+1}': len([word for word in sentence.split() if word not in STOPWORDS]) for i, sentence in enumerate(sentences)}\n    return pd.Series(sentence_dict)\n```"}
{"task_id": "BigCodeBench/56", "solution": "import pandas as pd\nimport regex as re\ndef task_func(text):\n    # Extract data from text\n    data = re.findall(r'Score: (\\d+), Category: (.+)', text)\n    # Convert scores to integer\n    data = [[int(score), category] for score, category in data]\n    # Create DataFrame\n    df = pd.DataFrame(data, columns=['Score', 'Category'])\n    return df", "raw_solution": "import pandas as pd\nimport regex as re\n\ndef task_func(text):\n    # Extract data from text\n    data = re.findall(r'Score: (\\d+), Category: (.+)', text)\n    # Convert scores to integer\n    data = [[int(score), category] for score, category in data]\n    # Create DataFrame\n    df = pd.DataFrame(data, columns=['Score', 'Category'])\n    return df\n```"}
{"task_id": "BigCodeBench/57", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\ndef task_func(csv_file_path: str, title: str):\n    df = pd.read_csv(csv_file_path)\n    corr = df.corr().round(2)\n    sns.heatmap(corr, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5, square=True)\n    plt.title(title)\n    plt.show()\n    return corr, plt.gca()", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\ndef task_func(csv_file_path: str, title: str):\n    df = pd.read_csv(csv_file_path)\n    corr = df.corr().round(2)\n    sns.heatmap(corr, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5, square=True)\n    plt.title(title)\n    plt.show()\n    return corr, plt.gca()\n```"}
{"task_id": "BigCodeBench/58", "solution": "import numpy as np\nfrom scipy import stats\nimport matplotlib.pyplot as plt\ndef task_func(mu, sigma, num_samples):\n    # Generate a normal distribution\n    x = stats.norm.rvs(loc=mu, scale=sigma, size=num_samples)\n    \n    # Create a histogram of the samples\n    fig, ax = plt.subplots()\n    ax.hist(x, bins=30, density=True, alpha=0.6, color='g')\n    \n    # Plot the normal distribution curve\n    ax.plot(x, stats.norm.pdf(x, loc=mu, scale=sigma), 'r--', linewidth=2)\n    \n    # Set the plot title\n    ax.set_title('Normal Distribution')\n    \n    return fig", "raw_solution": "import numpy as np\nfrom scipy import stats\nimport matplotlib.pyplot as plt\n\ndef task_func(mu, sigma, num_samples):\n    # Generate a normal distribution\n    x = stats.norm.rvs(loc=mu, scale=sigma, size=num_samples)\n    \n    # Create a histogram of the samples\n    fig, ax = plt.subplots()\n    ax.hist(x, bins=30, density=True, alpha=0.6, color='g')\n    \n    # Plot the normal distribution curve\n    ax.plot(x, stats.norm.pdf(x, loc=mu, scale=sigma), 'r--', linewidth=2)\n    \n    # Set the plot title\n    ax.set_title('Normal Distribution')\n    \n    return fig\n```"}
{"task_id": "BigCodeBench/59", "solution": "import wikipedia\nfrom wordcloud import WordCloud\nimport matplotlib.pyplot as plt\ndef task_func(page_title):\n    try:\n        page = wikipedia.page(page_title)\n        text = page.content\n        wordcloud = WordCloud(width=800, height=400, background_color='white').generate(text)\n        plt.figure(figsize=(10, 5))\n        plt.imshow(wordcloud, interpolation='bilinear')\n        plt.axis('off')\n        plt.show()\n        return plt.axes()\n    except wikipedia.exceptions.PageError:\n        return None", "raw_solution": "import wikipedia\nfrom wordcloud import WordCloud\nimport matplotlib.pyplot as plt\n\ndef task_func(page_title):\n    try:\n        page = wikipedia.page(page_title)\n        text = page.content\n        wordcloud = WordCloud(width=800, height=400, background_color='white').generate(text)\n        plt.figure(figsize=(10, 5))\n        plt.imshow(wordcloud, interpolation='bilinear')\n        plt.axis('off')\n        plt.show()\n        return plt.axes()\n    except wikipedia.exceptions.PageError:\n        return None\n```"}
{"task_id": "BigCodeBench/60", "solution": "import json\nimport pandas as pd\ndef task_func(result, csv_file_path=\"test.csv\", json_file_path=\"test.json\"):\n    # Save the list of dictionaries to a CSV file\n    df = pd.DataFrame(result)\n    df.to_csv(csv_file_path, index=False)\n    \n    # Save the list of dictionaries to a JSON file\n    with open(json_file_path, 'w') as f:\n        json.dump(result, f)", "raw_solution": "import json\nimport pandas as pd\n\ndef task_func(result, csv_file_path=\"test.csv\", json_file_path=\"test.json\"):\n    # Save the list of dictionaries to a CSV file\n    df = pd.DataFrame(result)\n    df.to_csv(csv_file_path, index=False)\n    \n    # Save the list of dictionaries to a JSON file\n    with open(json_file_path, 'w') as f:\n        json.dump(result, f)\n```"}
{"task_id": "BigCodeBench/61", "solution": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom datetime import datetime\nPLOT_TITLE = 'Square root plot'\nX_LABEL = 'x'\nY_LABEL = 'sqrt(x)'\nTIME_FORMAT = '%Y-%m-%d %H:%M:%S'\ndef task_func(result):\n    # Extract the 'from_user' key from the input list of dictionaries\n    from_user = result['from_user']\n    # Calculate the square root of each value associated with the 'from_user' key\n    sqrt_values = np.sqrt(from_user)\n    # Round each square root value to 2 decimals\n    sqrt_values = np.round(sqrt_values, 2)\n    # Create a plot of the square root values\n    fig, ax = plt.subplots()\n    ax.plot(sqrt_values)\n    ax.set_title(PLOT_TITLE)\n    ax.set_xlabel(X_LABEL)\n    ax.set_ylabel(Y_LABEL)\n    # Annotate the plot with the current date and time\n    ax.annotate(datetime.now().strftime(TIME_FORMAT), xy=(0.5, 0.5), xytext=(0, 0), textcoords='offset points', ha='center', va='center')\n    return sqrt_values, ax", "raw_solution": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom datetime import datetime\n# Constants\nPLOT_TITLE = 'Square root plot'\nX_LABEL = 'x'\nY_LABEL = 'sqrt(x)'\nTIME_FORMAT = '%Y-%m-%d %H:%M:%S'\ndef task_func(result):\n    # Extract the 'from_user' key from the input list of dictionaries\n    from_user = result['from_user']\n    # Calculate the square root of each value associated with the 'from_user' key\n    sqrt_values = np.sqrt(from_user)\n    # Round each square root value to 2 decimals\n    sqrt_values = np.round(sqrt_values, 2)\n    # Create a plot of the square root values\n    fig, ax = plt.subplots()\n    ax.plot(sqrt_values)\n    ax.set_title(PLOT_TITLE)\n    ax.set_xlabel(X_LABEL)\n    ax.set_ylabel(Y_LABEL)\n    # Annotate the plot with the current date and time\n    ax.annotate(datetime.now().strftime(TIME_FORMAT), xy=(0.5, 0.5), xytext=(0, 0), textcoords='offset points', ha='center', va='center')\n    return sqrt_values, ax\n```"}
{"task_id": "BigCodeBench/62", "solution": "import random\nimport matplotlib.pyplot as plt\nimport seaborn as sns\ndef task_func(result, colors=['b', 'g', 'r', 'c', 'm', 'y', 'k']):\n    # Extract the \"from_user\" values from the result\n    from_users = [row['from_user'] for row in result]\n    \n    # Create a histogram of the \"from_user\" values\n    plt.hist(from_users, bins=10, color=random.choice(colors))\n    \n    # Show the histogram\n    plt.show()", "raw_solution": "import random\nimport matplotlib.pyplot as plt\nimport seaborn as sns\ndef task_func(result, colors=['b', 'g', 'r', 'c', 'm', 'y', 'k']):\n    # Extract the \"from_user\" values from the result\n    from_users = [row['from_user'] for row in result]\n    \n    # Create a histogram of the \"from_user\" values\n    plt.hist(from_users, bins=10, color=random.choice(colors))\n    \n    # Show the histogram\n    plt.show()\n```"}
{"task_id": "BigCodeBench/63", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\ndef task_func(car_dict):\n    df = pd.DataFrame.from_dict(car_dict, orient='index', columns=['Color'])\n    df.reset_index(inplace=True)\n    df.columns = ['Car', 'Color']\n    plt.figure(figsize=(10, 6))\n    plt.bar(df['Car'], df['Color'])\n    plt.title('Distribution of Vehicle Colors')\n    plt.xlabel('Car')\n    plt.ylabel('Color')\n    plt.xticks(rotation=45)\n    plt.show()\n    return df, plt.gca()", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\n\ndef task_func(car_dict):\n    df = pd.DataFrame.from_dict(car_dict, orient='index', columns=['Color'])\n    df.reset_index(inplace=True)\n    df.columns = ['Car', 'Color']\n    plt.figure(figsize=(10, 6))\n    plt.bar(df['Car'], df['Color'])\n    plt.title('Distribution of Vehicle Colors')\n    plt.xlabel('Car')\n    plt.ylabel('Color')\n    plt.xticks(rotation=45)\n    plt.show()\n    return df, plt.gca()\n```"}
{"task_id": "BigCodeBench/64", "solution": "import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nCOLUMNS = ['col1', 'col2', 'col3']\ndef task_func(data):\n    # Create a DataFrame from the input data\n    df = pd.DataFrame(data, columns=COLUMNS)\n    # Create a heatmap visualization\n    sns.heatmap(df.groupby(['col1', 'col2'])['col3'].value_counts().unstack())\n    # Return the DataFrame and the heatmap visualization\n    return df, plt.gca()", "raw_solution": "import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n# Constants\nCOLUMNS = ['col1', 'col2', 'col3']\ndef task_func(data):\n    # Create a DataFrame from the input data\n    df = pd.DataFrame(data, columns=COLUMNS)\n    # Create a heatmap visualization\n    sns.heatmap(df.groupby(['col1', 'col2'])['col3'].value_counts().unstack())\n    # Return the DataFrame and the heatmap visualization\n    return df, plt.gca()\n```"}
{"task_id": "BigCodeBench/65", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\ndef task_func(data):\n    df = pd.DataFrame(data)\n    x_label = '-'.join(df.columns[:-1])\n    y_label = df.columns[-1]\n    grouped = df.groupby(df.columns[:-1])\n    line_chart = grouped[y_label].mean().plot(kind='line')\n    plt.xlabel(x_label)\n    plt.ylabel(y_label)\n    return df, line_chart", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nCOLUMNS = ['col1', 'col2', 'col3']\n\ndef task_func(data):\n    df = pd.DataFrame(data)\n    x_label = '-'.join(df.columns[:-1])\n    y_label = df.columns[-1]\n    grouped = df.groupby(df.columns[:-1])\n    line_chart = grouped[y_label].mean().plot(kind='line')\n    plt.xlabel(x_label)\n    plt.ylabel(y_label)\n    return df, line_chart\n```"}
{"task_id": "BigCodeBench/66", "solution": "import pandas as pd\nimport seaborn as sns\nCOLUMNS = ['col1', 'col2', 'col3']\ndef task_func(data):\n    # Build a pandas DataFrame by using list of elements\n    df = pd.DataFrame(data, columns=COLUMNS)\n    # Create a new dataframe by grouping the values in the column 'col3' by ['col1', 'col2']\n    df_grouped = df.groupby(['col1', 'col2'])['col3'].value_counts().reset_index(name='count')\n    # Create a distribution plot of the 'col3' column of the previous dataframe using seaborn\n    ax = sns.histplot(df_grouped, x='col3', hue='col1', multiple='dodge', kde=True)\n    # Set the xlabel (label for the x-axis) to the 'col3'\n    ax.set_xlabel('col3')\n    return (df, ax)", "raw_solution": "import pandas as pd\nimport seaborn as sns\n# Constants\nCOLUMNS = ['col1', 'col2', 'col3']\ndef task_func(data):\n    # Build a pandas DataFrame by using list of elements\n    df = pd.DataFrame(data, columns=COLUMNS)\n    # Create a new dataframe by grouping the values in the column 'col3' by ['col1', 'col2']\n    df_grouped = df.groupby(['col1', 'col2'])['col3'].value_counts().reset_index(name='count')\n    # Create a distribution plot of the 'col3' column of the previous dataframe using seaborn\n    ax = sns.histplot(df_grouped, x='col3', hue='col1', multiple='dodge', kde=True)\n    # Set the xlabel (label for the x-axis) to the 'col3'\n    ax.set_xlabel('col3')\n    return (df, ax)\n```"}
{"task_id": "BigCodeBench/67", "solution": "import pandas as pd\nimport re\nimport os\ndef task_func(dir_path: str, pattern: str = '^EMP'):\n    files = os.listdir(dir_path)\n    files = [f for f in files if re.match(pattern, f)]\n    files = sorted(files, key=lambda x: os.path.getsize(os.path.join(dir_path, x)))\n    df = pd.DataFrame({'File': files, 'Size': [os.path.getsize(os.path.join(dir_path, f)) for f in files]})\n    return df", "raw_solution": "import pandas as pd\nimport re\nimport os\n\ndef task_func(dir_path: str, pattern: str = '^EMP'):\n    files = os.listdir(dir_path)\n    files = [f for f in files if re.match(pattern, f)]\n    files = sorted(files, key=lambda x: os.path.getsize(os.path.join(dir_path, x)))\n    df = pd.DataFrame({'File': files, 'Size': [os.path.getsize(os.path.join(dir_path, f)) for f in files]})\n    return df\n```"}
{"task_id": "BigCodeBench/68", "solution": "import pandas as pd\nimport seaborn as sns\ndef task_func(data='/path/to/data.csv', emp_prefix='EMP'):\n    df = pd.read_csv(data)\n    df = df[df['Employee ID'].str.startswith(emp_prefix)]\n    ax = sns.histplot(df['Age'])\n    return df, ax", "raw_solution": "import pandas as pd\nimport seaborn as sns\n\ndef task_func(data='/path/to/data.csv', emp_prefix='EMP'):\n    df = pd.read_csv(data)\n    df = df[df['Employee ID'].str.startswith(emp_prefix)]\n    ax = sns.histplot(df['Age'])\n    return df, ax\n```"}
{"task_id": "BigCodeBench/69", "solution": "import random\nimport matplotlib.pyplot as plt\nSALARY_RANGE = (20000, 100000)\ndef task_func(dict1):\n    # Get the number of employees in the department\n    num_employees = dict1['num_employees']\n    # Generate random salaries for each employee\n    salaries = [random.randint(SALARY_RANGE[0], SALARY_RANGE[1]) for _ in range(num_employees)]\n    # Create a histogram\n    plt.hist(salaries, bins=50, color='blue', edgecolor='black')\n    # Set the title and labels\n    plt.title('Salary Distribution in EMPXX Department')\n    plt.xlabel('Salary')\n    plt.ylabel('Number of Employees')\n    # Return the histogram\n    return plt.axes()", "raw_solution": "import random\nimport matplotlib.pyplot as plt\n# Constants\nSALARY_RANGE = (20000, 100000)\ndef task_func(dict1):\n    # Get the number of employees in the department\n    num_employees = dict1['num_employees']\n    # Generate random salaries for each employee\n    salaries = [random.randint(SALARY_RANGE[0], SALARY_RANGE[1]) for _ in range(num_employees)]\n    # Create a histogram\n    plt.hist(salaries, bins=50, color='blue', edgecolor='black')\n    # Set the title and labels\n    plt.title('Salary Distribution in EMPXX Department')\n    plt.xlabel('Salary')\n    plt.ylabel('Number of Employees')\n    # Return the histogram\n    return plt.axes()\n```"}
{"task_id": "BigCodeBench/70", "solution": "import pandas as pd\nimport json\nimport numpy as np\nCOLUMNS = ['email', 'list']\ndef task_func(json_file):\n    try:\n        with open(json_file, 'r') as f:\n            data = json.load(f)\n    except FileNotFoundError:\n        return pd.DataFrame(columns=COLUMNS), None\n    df = pd.DataFrame(columns=COLUMNS)\n    for email, list_ in data.items():\n        df = df.append({'email': email, 'list': list_, 'sum': np.sum(list_), 'mean': np.mean(list_)}, ignore_index=True)\n    return df, df['sum'].plot()", "raw_solution": "import pandas as pd\nimport json\nimport numpy as np\n# Constants\nCOLUMNS = ['email', 'list']\ndef task_func(json_file):\n    try:\n        with open(json_file, 'r') as f:\n            data = json.load(f)\n    except FileNotFoundError:\n        return pd.DataFrame(columns=COLUMNS), None\n    df = pd.DataFrame(columns=COLUMNS)\n    for email, list_ in data.items():\n        df = df.append({'email': email, 'list': list_, 'sum': np.sum(list_), 'mean': np.mean(list_)}, ignore_index=True)\n    return df, df['sum'].plot()\n```"}
{"task_id": "BigCodeBench/71", "solution": "import pandas as pd\nimport seaborn as sns\nimport numpy as np\nimport ast\ndef task_func(csv_file):\n    df = pd.read_csv(csv_file)\n    df['list'] = df['list'].apply(ast.literal_eval)\n    df['sum'] = df['list'].apply(sum)\n    df['mean'] = df['list'].apply(np.mean)\n    df['std'] = df['list'].apply(np.std)\n    sns.histplot(df['mean'])\n    return (df, sns.plt.gca())", "raw_solution": "import pandas as pd\nimport seaborn as sns\nimport numpy as np\nimport ast\n\ndef task_func(csv_file):\n    df = pd.read_csv(csv_file)\n    df['list'] = df['list'].apply(ast.literal_eval)\n    df['sum'] = df['list'].apply(sum)\n    df['mean'] = df['list'].apply(np.mean)\n    df['std'] = df['list'].apply(np.std)\n    sns.histplot(df['mean'])\n    return (df, sns.plt.gca())\n```"}
{"task_id": "BigCodeBench/72", "solution": "import pandas as pd\nimport os\nimport numpy as np\nimport ast\ndef task_func(directory):\n    # Get all CSV files in the directory\n    csv_files = [f for f in os.listdir(directory) if f.endswith('.csv')]\n    if not csv_files:\n        return None\n    # Get the file with the longest filename\n    longest_file = max(csv_files, key=len)\n    # Load the CSV file\n    df = pd.read_csv(os.path.join(directory, longest_file))\n    # Convert the 'list' column to a list\n    df['list'] = df['list'].apply(ast.literal_eval)\n    # Calculate the sum, mean, and median of the list associated with each e-mail\n    df['sum'] = df['list'].apply(sum)\n    df['mean'] = df['list'].apply(np.mean)\n    df['median'] = df['list'].apply(np.median)\n    # Draw a histogram of the median\n    ax = df['median'].hist()\n    return df, ax", "raw_solution": "import pandas as pd\nimport os\nimport numpy as np\nimport ast\ndef task_func(directory):\n    # Get all CSV files in the directory\n    csv_files = [f for f in os.listdir(directory) if f.endswith('.csv')]\n    if not csv_files:\n        return None\n    # Get the file with the longest filename\n    longest_file = max(csv_files, key=len)\n    # Load the CSV file\n    df = pd.read_csv(os.path.join(directory, longest_file))\n    # Convert the 'list' column to a list\n    df['list'] = df['list'].apply(ast.literal_eval)\n    # Calculate the sum, mean, and median of the list associated with each e-mail\n    df['sum'] = df['list'].apply(sum)\n    df['mean'] = df['list'].apply(np.mean)\n    df['median'] = df['list'].apply(np.median)\n    # Draw a histogram of the median\n    ax = df['median'].hist()\n    return df, ax\n```"}
{"task_id": "BigCodeBench/73", "solution": "import pandas as pd\nimport sqlite3\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport ast\ndef task_func(db_file):\n    # Load e-mail data from an SQLite database\n    conn = sqlite3.connect(db_file)\n    df = pd.read_sql_query(\"SELECT email, list FROM EmailData\", conn)\n    conn.close()\n    \n    # Convert the list column to a list\n    df['list'] = df['list'].apply(ast.literal_eval)\n    \n    # Calculate the sum, mean, and variance of the list associated with each e-mail\n    df['sum'] = df['list'].apply(sum)\n    df['mean'] = df['list'].apply(np.mean)\n    df['var'] = df['list'].apply(np.var)\n    \n    # Return the DataFrame and the matplotlib Axes object\n    return df, plt.bar(df['email'], df['sum'], label='Sum')", "raw_solution": "import pandas as pd\nimport sqlite3\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport ast\n\ndef task_func(db_file):\n    # Load e-mail data from an SQLite database\n    conn = sqlite3.connect(db_file)\n    df = pd.read_sql_query(\"SELECT email, list FROM EmailData\", conn)\n    conn.close()\n    \n    # Convert the list column to a list\n    df['list'] = df['list'].apply(ast.literal_eval)\n    \n    # Calculate the sum, mean, and variance of the list associated with each e-mail\n    df['sum'] = df['list'].apply(sum)\n    df['mean'] = df['list'].apply(np.mean)\n    df['var'] = df['list'].apply(np.var)\n    \n    # Return the DataFrame and the matplotlib Axes object\n    return df, plt.bar(df['email'], df['sum'], label='Sum')\n```"}
{"task_id": "BigCodeBench/74", "solution": "import socket\nimport requests\ndef task_func(host):\n    if host is None or host == '':\n        raise ValueError('Invalid host')\n    try:\n        ip = socket.gethostbyname(host)\n    except socket.gaierror:\n        raise ConnectionError('Failed to connect to the geolocation service')\n    try:\n        response = requests.get(f'https://ipinfo.io/{ip}')\n        response.raise_for_status()\n        return response.json()\n    except requests.exceptions.RequestException:\n        raise ConnectionError('Failed to fetch geolocation information')", "raw_solution": "import socket\nimport requests\n\ndef task_func(host):\n    if host is None or host == '':\n        raise ValueError('Invalid host')\n    try:\n        ip = socket.gethostbyname(host)\n    except socket.gaierror:\n        raise ConnectionError('Failed to connect to the geolocation service')\n    try:\n        response = requests.get(f'https://ipinfo.io/{ip}')\n        response.raise_for_status()\n        return response.json()\n    except requests.exceptions.RequestException:\n        raise ConnectionError('Failed to fetch geolocation information')\n```"}
{"task_id": "BigCodeBench/75", "solution": "import pandas as pd\nimport numpy as np\nimport itertools\nfrom datetime import datetime, timedelta\nimport seaborn as sns\ndef task_func(df, fruits=None, days=None, seed=None, sales_lower_bound=1, sales_upper_bound=50):\n    if not isinstance(df, pd.DataFrame):\n        raise TypeError('If \\'df\\' is not a pandas DataFrame.')\n    if df.empty:\n        raise ValueError('If \\'df\\' is not empty.')\n    if not isinstance(days, int):\n        raise ValueError('If \\'days\\' is not an integer.')\n    if not isinstance(fruits, list):\n        raise ValueError('If \\'fruits\\' is not a list.')\n    if not isinstance(seed, int):\n        raise ValueError('If \\'seed\\' is not an integer.')\n    if not isinstance(sales_lower_bound, int):\n        raise ValueError('If \\'sales_lower_bound\\' is not an integer.')\n    if not isinstance(sales_upper_bound, int):\n        raise ValueError('If \\'sales_upper_bound\\' is not an integer.')\n    if sales_lower_bound >= sales_upper_bound:\n        raise ValueError('If \\'sales_lower_bound\\' is not less than \\'sales_upper_bound\\'.')\n    if seed is not None:\n        np.random.seed(seed)\n    sales_data = []\n    for fruit in fruits:\n        for day in range(days):\n            sales_data.append((fruit, day, np.random.randint(sales_lower_bound, sales_upper_bound)))\n    df = pd.DataFrame(sales_data, columns=['fruit', 'day', 'sales'])\n    sns.boxplot(x='fruit', y='sales', data=df)\n    return df, sns.boxplot(x='fruit', y='sales', data=df)", "raw_solution": "import pandas as pd\nimport numpy as np\nimport itertools\nfrom datetime import datetime, timedelta\nimport seaborn as sns\n\ndef task_func(df, fruits=None, days=None, seed=None, sales_lower_bound=1, sales_upper_bound=50):\n    if not isinstance(df, pd.DataFrame):\n        raise TypeError('If \\'df\\' is not a pandas DataFrame.')\n    if df.empty:\n        raise ValueError('If \\'df\\' is not empty.')\n    if not isinstance(days, int):\n        raise ValueError('If \\'days\\' is not an integer.')\n    if not isinstance(fruits, list):\n        raise ValueError('If \\'fruits\\' is not a list.')\n    if not isinstance(seed, int):\n        raise ValueError('If \\'seed\\' is not an integer.')\n    if not isinstance(sales_lower_bound, int):\n        raise ValueError('If \\'sales_lower_bound\\' is not an integer.')\n    if not isinstance(sales_upper_bound, int):\n        raise ValueError('If \\'sales_upper_bound\\' is not an integer.')\n    if sales_lower_bound >= sales_upper_bound:\n        raise ValueError('If \\'sales_lower_bound\\' is not less than \\'sales_upper_bound\\'.')\n    if seed is not None:\n        np.random.seed(seed)\n    sales_data = []\n    for fruit in fruits:\n        for day in range(days):\n            sales_data.append((fruit, day, np.random.randint(sales_lower_bound, sales_upper_bound)))\n    df = pd.DataFrame(sales_data, columns=['fruit', 'day', 'sales'])\n    sns.boxplot(x='fruit', y='sales', data=df)\n    return df, sns.boxplot(x='fruit', y='sales', data=df)\n```"}
{"task_id": "BigCodeBench/76", "solution": "import random\nimport string\nfrom django.http import HttpResponse\ndef task_func(request, session_expire_time):\n    session_key = ''.join(random.choice(string.ascii_letters + string.digits) for _ in range(20))\n    if not (session_key.isalnum() and len(session_key) == 20):\n        raise ValueError(\"Session key does not contain both letters and digits or the session key length is not equal to 20.\")\n    response = HttpResponse(\"Session key generated successfully.\")\n    response.set_cookie('session_key', session_key, max_age=session_expire_time)\n    return response", "raw_solution": "import random\nimport string\nfrom django.http import HttpResponse\n\ndef task_func(request, session_expire_time):\n    session_key = ''.join(random.choice(string.ascii_letters + string.digits) for _ in range(20))\n    if not (session_key.isalnum() and len(session_key) == 20):\n        raise ValueError(\"Session key does not contain both letters and digits or the session key length is not equal to 20.\")\n    response = HttpResponse(\"Session key generated successfully.\")\n    response.set_cookie('session_key', session_key, max_age=session_expire_time)\n    return response\n```"}
{"task_id": "BigCodeBench/77", "solution": "import hashlib\nimport base64\nimport binascii\nfrom django.http import HttpResponseBadRequest, HttpResponse\ndef task_func(data):\n    if not isinstance(data, dict) or 'username' not in data or 'password' not in data:\n        return HttpResponseBadRequest('Bad Request')\n    username = data['username']\n    password = data['password']\n    if username != 'admin':\n        return HttpResponseBadRequest('Bad Request')\n    try:\n        password_hash = base64.b64decode(password)\n    except (UnicodeDecodeError, binascii.Error):\n        return HttpResponseBadRequest('Bad Request')\n    if hashlib.sha256('wrongpassword'.encode()).digest() != password_hash:\n        return HttpResponseBadRequest('Bad Request')\n    return HttpResponse('Login successful.', status=400)", "raw_solution": "import hashlib\nimport base64\nimport binascii\nfrom django.http import HttpResponseBadRequest, HttpResponse\n\ndef task_func(data):\n    if not isinstance(data, dict) or 'username' not in data or 'password' not in data:\n        return HttpResponseBadRequest('Bad Request')\n    username = data['username']\n    password = data['password']\n    if username != 'admin':\n        return HttpResponseBadRequest('Bad Request')\n    try:\n        password_hash = base64.b64decode(password)\n    except (UnicodeDecodeError, binascii.Error):\n        return HttpResponseBadRequest('Bad Request')\n    if hashlib.sha256('wrongpassword'.encode()).digest() != password_hash:\n        return HttpResponseBadRequest('Bad Request')\n    return HttpResponse('Login successful.', status=400)\n```"}
{"task_id": "BigCodeBench/78", "solution": "import csv\nimport io\nfrom django.http import HttpRequest, FileResponse\ndef task_func(request, header, csv_data):\n    # Create a CSV file in memory\n    csv_file = io.StringIO()\n    writer = csv.writer(csv_file)\n    writer.writerow(header)\n    writer.writerows(csv_data)\n    \n    # Create a FileResponse object with the CSV file\n    response = FileResponse(csv_file.getvalue().encode('utf-8'), content_type='text/csv')\n    response['Content-Disposition'] = f'attachment; filename=\"{header[0]}.csv\"'\n    \n    return response", "raw_solution": "import csv\nimport io\nfrom django.http import HttpRequest, FileResponse\n\ndef task_func(request, header, csv_data):\n    # Create a CSV file in memory\n    csv_file = io.StringIO()\n    writer = csv.writer(csv_file)\n    writer.writerow(header)\n    writer.writerows(csv_data)\n    \n    # Create a FileResponse object with the CSV file\n    response = FileResponse(csv_file.getvalue().encode('utf-8'), content_type='text/csv')\n    response['Content-Disposition'] = f'attachment; filename=\"{header[0]}.csv\"'\n    \n    return response\n```"}
{"task_id": "BigCodeBench/79", "solution": "import zipfile\nimport io\nfrom django.http import FileResponse, HttpRequest\nfrom django.conf import settings\ndef task_func(request, file_paths):\n    # Create a new zip file in memory\n    zip_buffer = io.BytesIO()\n    with zipfile.ZipFile(zip_buffer, 'w') as zipf:\n        # Add each file to the zip file\n        for file_path in file_paths:\n            zipf.write(file_path, os.path.basename(file_path))\n    # Create a FileResponse object with the zip file as an attachment\n    response = FileResponse(zip_buffer.getvalue(), content_type='application/zip')\n    response['Content-Disposition'] = f'attachment; filename=\"{settings.DEFAULT_FILE_STORAGE}\"'\n    return response", "raw_solution": "import zipfile\nimport io\nfrom django.http import FileResponse, HttpRequest\nfrom django.conf import settings\n\ndef task_func(request, file_paths):\n    # Create a new zip file in memory\n    zip_buffer = io.BytesIO()\n    with zipfile.ZipFile(zip_buffer, 'w') as zipf:\n        # Add each file to the zip file\n        for file_path in file_paths:\n            zipf.write(file_path, os.path.basename(file_path))\n    # Create a FileResponse object with the zip file as an attachment\n    response = FileResponse(zip_buffer.getvalue(), content_type='application/zip')\n    response['Content-Disposition'] = f'attachment; filename=\"{settings.DEFAULT_FILE_STORAGE}\"'\n    return response\n```"}
{"task_id": "BigCodeBench/80", "solution": "from flask import Flask, render_template, request\nimport json\nimport logging\ndef task_func(template_folder):\n    app = Flask(__name__, template_folder=template_folder)\n    @app.route('/', methods=['POST'])\n    def index():\n        data = request.get_json()\n        logging.info(json.dumps(data))\n        return render_template('index.html', data=data)\n    return app", "raw_solution": "from flask import Flask, render_template, request\nimport json\nimport logging\nlogging.basicConfig(filename=\"out.log\", level=logging.INFO)\ndef task_func(template_folder):\n    app = Flask(__name__, template_folder=template_folder)\n    @app.route('/', methods=['POST'])\n    def index():\n        data = request.get_json()\n        logging.info(json.dumps(data))\n        return render_template('index.html', data=data)\n    return app\n```"}
{"task_id": "BigCodeBench/81", "solution": "from flask import Flask\nfrom flask_restful import Resource, Api\nimport requests\ndef task_func(api_url, template_folder):\n    app = Flask(__name__)\n    api = Api(app)\n    app.config['TEMPLATES_FOLDER'] = template_folder\n    class Data(Resource):\n        def get(self):\n            response = requests.get(api_url)\n            return response.json()\n    api.add_resource(Data, '/data')\n    return app", "raw_solution": "from flask import Flask\nfrom flask_restful import Resource, Api\nimport requests\ndef task_func(api_url, template_folder):\n    app = Flask(__name__)\n    api = Api(app)\n    app.config['TEMPLATES_FOLDER'] = template_folder\n    class Data(Resource):\n        def get(self):\n            response = requests.get(api_url)\n            return response.json()\n    api.add_resource(Data, '/data')\n    return app\n```"}
{"task_id": "BigCodeBench/82", "solution": "from flask import Flask, render_template, redirect, url_for\nfrom flask_login import LoginManager, UserMixin, login_user, login_required, logout_user, current_user\nfrom flask_wtf import FlaskForm\nfrom wtforms import StringField, PasswordField, SubmitField\nfrom wtforms.validators import DataRequired, Length\nfrom werkzeug.security import generate_password_hash, check_password_hash\ndef task_func(secret_key, template_folder):\n    app = Flask(__name__)\n    app.config['SECRET_KEY'] = secret_key\n    app.config['LOGIN_DISABLED'] = False\n    app.config['LOGIN_REDIRECT_URL'] = url_for('login')\n    app.config['LOGIN_TEMPLATE'] = 'login.html'\n    app.config['LOGOUT_TEMPLATE'] = 'logout.html'\n    app.config['LOGIN_USER_TEMPLATE'] = 'login_user.html'\n    app.config['LOGIN_ERROR_TEMPLATE'] = 'login_error.html'\n    app.config['LOGIN_DISABLED_TEMPLATE'] = 'login_disabled.html'\n    app.config['LOGIN_DISABLED_REDIRECT_URL'] = url_for('login')\n    app.config['LOGIN_DISABLED_TEMPLATE'] = 'login_disabled.html'\n    app.config['LOGIN_DISABLED_REDIRECT_URL'] = url_for('login')\n    app.config['LOGIN_DISABLED_TEMPLATE'] = 'login_disabled.html'\n    app.config['LOGIN_DISABLED_REDIRECT_URL'] = url_for('login')\n    app.config['LOGIN_DISABLED_TEMPLATE'] = 'login_disabled.html'\n    app.config['LOGIN_DISABLED_REDIRECT_URL'] = url_for('login')\n    app.config['LOGIN_DISABLED_TEMPLATE'] = 'login_disabled.html'\n    app.config['LOGIN_DISABLED_REDIRECT_URL'] = url_for('login')\n    app.config['LOGIN_DISABLED_TEMPLATE'] = 'login_disabled.html'\n    app.config['LOGIN_DISABLED_REDIRECT_URL'] = url_for('login')\n    app.config['LOGIN_DISABLED_TEMPLATE'] = 'login_disabled.html'\n    app.config['LOGIN_DISABLED_REDIRECT_URL'] = url_for('login')\n    app.config['LOGIN_DISABLED_TEMPLATE'] = 'login_disabled.html'\n    app.config['LOGIN_DISABLED_REDIRECT_URL'] = url_for('login')\n    app.config['LOGIN_DISABLED_TEMPLATE'] = 'login_disabled.html'\n    app.config['LOGIN_DISABLED_REDIRECT_URL'] = url_for('login')\n    app.config['LOGIN_DISABLED_TEMPLATE'] = 'login_disabled.html'\n    app.config['LOGIN_DISABLED_REDIRECT_URL'] = url_for('login')\n    app.config['LOGIN_DISABLED_TEMPLATE'] = 'login_disabled.html'\n    app.config['LOGIN_DISABLED_REDIRECT_URL'] = url_for('login')\n    app.config['LOGIN_DISABLED_TEMPLATE'] = 'login_disabled.html'\n    app.config['LOGIN_DISABLED_REDIRECT_URL'] = url_for('login')\n    app.config['LOGIN_DISABLED_TEMPLATE'] = 'login_disabled.html'\n    app.config['LOGIN_DISABLED_REDIRECT_URL'] = url_for('login')\n    app.config['LOGIN_DISABLED_TEMPLATE'] = 'login_disabled.html'\n    app.config['LOGIN_DISABLED_REDIRECT_URL'] = url_for('login')\n    app.config['LOGIN_DISABLED_TEMPLATE'] = 'login_disabled.html'\n    app.config['LOGIN_DISABLED_REDIRECT_URL'] = url_for('login')\n    app.config['LOGIN_DISABLED_TEMPLATE'] = 'login_disabled.html'\n    app.config['LOGIN_DISABLED_REDIRECT_URL'] = url_for('login')\n    app.config['LOGIN_DISABLED_TEMPLATE'] = 'login_disabled.html'\n    app.config['LOGIN_DISABLED_REDIRECT_URL'] = url_for('login')\n    app.config['LOGIN_DISABLED_TEMPLATE'] = 'login_disabled.html'\n    app.config['LOGIN_DISABLED_REDIRECT_URL'] = url_for('login')\n    app.config['LOGIN_DISABLED_TEMPLATE'] = 'login_disabled.html'\n    app.config['LOGIN_DISABLED_REDIRECT_URL'] = url_for('login')\n    app.config['LOGIN_DISABLED_TEMPLATE'] = 'login_disabled.html'\n    app.config['LOGIN_DISABLED_REDIRECT_URL'] = url_for('login')\n    app.config['LOGIN_DISABLED_TEMPLATE'] = 'login_disabled.html'\n    app.config['LOGIN_DISABLED_REDIRECT_URL'] = url_for('login')\n    app.config['LOGIN_DISABLED_TEMPLATE'] = 'login_disabled.html'\n    app.config['LOGIN_DISABLED_REDIRECT_URL'] = url_for('login')\n    app.config['LOGIN_DISABLED_TEMPLATE'] = 'login_disabled.html'\n    app.config['LOGIN_DISABLED_REDIRECT_URL'] = url_for('login')\n    app.config['LOGIN_DISABLED_TEMPLATE'] = 'login_disabled.html'\n    app.config['LOGIN_DISABLED_REDIRECT_URL'] = url_for('login')\n    app.config['LOGIN_DISABLED_TEMPLATE'] = 'login_disabled.html'\n    app.config['LOGIN_DISABLED_REDIRECT_URL'] = url_for('login')\n    app.config['LOGIN_DISABLED_TEMPLATE'] = 'login_disabled.html'\n    app.config['LOGIN_DISABLED_REDIRECT_URL'] = url_for('login')\n    app.config['LOGIN_DISABLED_TEMPLATE'] = 'login_disabled.html'\n    app.config['LOGIN_DISABLED_REDIRECT_URL'] = url_for('login')\n    app.config['LOGIN_DISABLED_TEMPLATE'] = 'login_disabled.html'\n    app.config['LOGIN_DISABLED_REDIRECT_URL'] = url_for('login')\n    app.config['LOGIN_DISABLED_TEMPLATE'] = 'login_disabled.html'\n    app.config['LOGIN_DISABLED_REDIRECT_URL'] = url_for('login')\n    app.config['LOGIN_DISABLED_TEMPLATE'] = 'login_disabled.html'\n    app.config['LOGIN_DISABLED_REDIRECT_URL'] = url_for('login')\n    app.config['LOGIN_DISABLED_TEMPLATE'] = 'login_disabled.html'\n    app.config['LOGIN_DISABLED_REDIRECT_URL'] = url_for('login')\n    app.config['LOGIN_DISABLED_TEMPLATE'] = 'login_disabled.html'\n    app.config['LOGIN_DISABLED_REDIRECT_URL'] = url_for('login')\n    app.config['LOGIN_DISABLED_TEMPLATE'] = 'login_disabled.html'\n    app.config['LOGIN_DISABLED_REDIRECT_URL'] = url_for('login')\n    app.config['LOGIN_DISABLED_TEMPLATE'] = 'login_disabled.html'\n    app.config['LOGIN_DISABLED_REDIRECT_URL'] = url_for('login')\n    app.config['LOGIN_DISABLED_TEMPLATE'] = 'login_disabled.html'\n    app.config['LOGIN_DISABLED_REDIRECT_URL'] = url_for('login')\n    app.config['LOGIN_DISABLED_TEMPLATE'] = 'login_disabled.html'\n    app.config", "raw_solution": "from flask import Flask, render_template, redirect, url_for\nfrom flask_login import LoginManager, UserMixin, login_user, login_required, logout_user, current_user\nfrom flask_wtf import FlaskForm\nfrom wtforms import StringField, PasswordField, SubmitField\nfrom wtforms.validators import DataRequired, Length\nfrom werkzeug.security import generate_password_hash, check_password_hash\nclass LoginForm(FlaskForm):\n    username = StringField('Username', validators=[DataRequired(), Length(min=4, max=25)])\n    password = PasswordField('Password', validators=[DataRequired(), Length(min=8, max=80)])\n    submit = SubmitField('Log In')\nlogin_manager = LoginManager()\ndef task_func(secret_key, template_folder):\n    app = Flask(__name__)\n    app.config['SECRET_KEY'] = secret_key\n    app.config['LOGIN_DISABLED'] = False\n    app.config['LOGIN_REDIRECT_URL'] = url_for('login')\n    app.config['LOGIN_TEMPLATE'] = 'login.html'\n    app.config['LOGOUT_TEMPLATE'] = 'logout.html'\n    app.config['LOGIN_USER_TEMPLATE'] = 'login_user.html'\n    app.config['LOGIN_ERROR_TEMPLATE'] = 'login_error.html'\n    app.config['LOGIN_DISABLED_TEMPLATE'] = 'login_disabled.html'\n    app.config['LOGIN_DISABLED_REDIRECT_URL'] = url_for('login')\n    app.config['LOGIN_DISABLED_TEMPLATE'] = 'login_disabled.html'\n    app.config['LOGIN_DISABLED_REDIRECT_URL'] = url_for('login')\n    app.config['LOGIN_DISABLED_TEMPLATE'] = 'login_disabled.html'\n    app.config['LOGIN_DISABLED_REDIRECT_URL'] = url_for('login')\n    app.config['LOGIN_DISABLED_TEMPLATE'] = 'login_disabled.html'\n    app.config['LOGIN_DISABLED_REDIRECT_URL'] = url_for('login')\n    app.config['LOGIN_DISABLED_TEMPLATE'] = 'login_disabled.html'\n    app.config['LOGIN_DISABLED_REDIRECT_URL'] = url_for('login')\n    app.config['LOGIN_DISABLED_TEMPLATE'] = 'login_disabled.html'\n    app.config['LOGIN_DISABLED_REDIRECT_URL'] = url_for('login')\n    app.config['LOGIN_DISABLED_TEMPLATE'] = 'login_disabled.html'\n    app.config['LOGIN_DISABLED_REDIRECT_URL'] = url_for('login')\n    app.config['LOGIN_DISABLED_TEMPLATE'] = 'login_disabled.html'\n    app.config['LOGIN_DISABLED_REDIRECT_URL'] = url_for('login')\n    app.config['LOGIN_DISABLED_TEMPLATE'] = 'login_disabled.html'\n    app.config['LOGIN_DISABLED_REDIRECT_URL'] = url_for('login')\n    app.config['LOGIN_DISABLED_TEMPLATE'] = 'login_disabled.html'\n    app.config['LOGIN_DISABLED_REDIRECT_URL'] = url_for('login')\n    app.config['LOGIN_DISABLED_TEMPLATE'] = 'login_disabled.html'\n    app.config['LOGIN_DISABLED_REDIRECT_URL'] = url_for('login')\n    app.config['LOGIN_DISABLED_TEMPLATE'] = 'login_disabled.html'\n    app.config['LOGIN_DISABLED_REDIRECT_URL'] = url_for('login')\n    app.config['LOGIN_DISABLED_TEMPLATE'] = 'login_disabled.html'\n    app.config['LOGIN_DISABLED_REDIRECT_URL'] = url_for('login')\n    app.config['LOGIN_DISABLED_TEMPLATE'] = 'login_disabled.html'\n    app.config['LOGIN_DISABLED_REDIRECT_URL'] = url_for('login')\n    app.config['LOGIN_DISABLED_TEMPLATE'] = 'login_disabled.html'\n    app.config['LOGIN_DISABLED_REDIRECT_URL'] = url_for('login')\n    app.config['LOGIN_DISABLED_TEMPLATE'] = 'login_disabled.html'\n    app.config['LOGIN_DISABLED_REDIRECT_URL'] = url_for('login')\n    app.config['LOGIN_DISABLED_TEMPLATE'] = 'login_disabled.html'\n    app.config['LOGIN_DISABLED_REDIRECT_URL'] = url_for('login')\n    app.config['LOGIN_DISABLED_TEMPLATE'] = 'login_disabled.html'\n    app.config['LOGIN_DISABLED_REDIRECT_URL'] = url_for('login')\n    app.config['LOGIN_DISABLED_TEMPLATE'] = 'login_disabled.html'\n    app.config['LOGIN_DISABLED_REDIRECT_URL'] = url_for('login')\n    app.config['LOGIN_DISABLED_TEMPLATE'] = 'login_disabled.html'\n    app.config['LOGIN_DISABLED_REDIRECT_URL'] = url_for('login')\n    app.config['LOGIN_DISABLED_TEMPLATE'] = 'login_disabled.html'\n    app.config['LOGIN_DISABLED_REDIRECT_URL'] = url_for('login')\n    app.config['LOGIN_DISABLED_TEMPLATE'] = 'login_disabled.html'\n    app.config['LOGIN_DISABLED_REDIRECT_URL'] = url_for('login')\n    app.config['LOGIN_DISABLED_TEMPLATE'] = 'login_disabled.html'\n    app.config['LOGIN_DISABLED_REDIRECT_URL'] = url_for('login')\n    app.config['LOGIN_DISABLED_TEMPLATE'] = 'login_disabled.html'\n    app.config['LOGIN_DISABLED_REDIRECT_URL'] = url_for('login')\n    app.config['LOGIN_DISABLED_TEMPLATE'] = 'login_disabled.html'\n    app.config['LOGIN_DISABLED_REDIRECT_URL'] = url_for('login')\n    app.config['LOGIN_DISABLED_TEMPLATE'] = 'login_disabled.html'\n    app.config['LOGIN_DISABLED_REDIRECT_URL'] = url_for('login')\n    app.config['LOGIN_DISABLED_TEMPLATE'] = 'login_disabled.html'\n    app.config['LOGIN_DISABLED_REDIRECT_URL'] = url_for('login')\n    app.config['LOGIN_DISABLED_TEMPLATE'] = 'login_disabled.html'\n    app.config['LOGIN_DISABLED_REDIRECT_URL'] = url_for('login')\n    app.config['LOGIN_DISABLED_TEMPLATE'] = 'login_disabled.html'\n    app.config['LOGIN_DISABLED_REDIRECT_URL'] = url_for('login')\n    app.config['LOGIN_DISABLED_TEMPLATE'] = 'login_disabled.html'\n    app.config['LOGIN_DISABLED_REDIRECT_URL'] = url_for('login')\n    app.config['LOGIN_DISABLED_TEMPLATE'] = 'login_disabled.html'\n    app.config['LOGIN_DISABLED_REDIRECT_URL'] = url_for('login')\n    app.config['LOGIN_DISABLED_TEMPLATE'] = 'login_disabled.html'\n    app.config['LOGIN_DISABLED_REDIRECT_URL'] = url_for('login')\n    app.config['LOGIN_DISABLED_TEMPLATE'] = 'login_disabled.html'\n    app.config['LOGIN_DISABLED_REDIRECT_URL'] = url_for('login')\n    app.config['LOGIN_DISABLED_TEMPLATE'] = 'login_disabled.html'\n    app.config['LOGIN_DISABLED_REDIRECT_URL'] = url_for('login')\n    app.config['LOGIN_DISABLED_TEMPLATE'] = 'login_disabled.html'\n    app.config['LOGIN_DISABLED_REDIRECT_URL'] = url_for('login')\n    app.config['LOGIN_DISABLED_TEMPLATE'] = 'login_disabled.html'\n    app.config"}
{"task_id": "BigCodeBench/83", "solution": "from flask import Flask\nfrom flask_mail import Mail, Message\ndef task_func(smtp_server, smtp_port, smtp_user, smtp_password, template_folder):\n    app = Flask(__name__)\n    app.config['MAIL_SERVER'] = smtp_server\n    app.config['MAIL_PORT'] = smtp_port\n    app.config['MAIL_USERNAME'] = smtp_user\n    app.config['MAIL_PASSWORD'] = smtp_password\n    app.config['MAIL_USE_TLS'] = True\n    app.config['MAIL_USE_SSL'] = False\n    app.config['MAIL_DEFAULT_SENDER'] = smtp_user\n    app.config['TEMPLATES_FOLDER'] = template_folder\n    mail = Mail(app)\n    return app", "raw_solution": "from flask import Flask\nfrom flask_mail import Mail, Message\n\ndef task_func(smtp_server, smtp_port, smtp_user, smtp_password, template_folder):\n    app = Flask(__name__)\n    app.config['MAIL_SERVER'] = smtp_server\n    app.config['MAIL_PORT'] = smtp_port\n    app.config['MAIL_USERNAME'] = smtp_user\n    app.config['MAIL_PASSWORD'] = smtp_password\n    app.config['MAIL_USE_TLS'] = True\n    app.config['MAIL_USE_SSL'] = False\n    app.config['MAIL_DEFAULT_SENDER'] = smtp_user\n    app.config['TEMPLATES_FOLDER'] = template_folder\n    mail = Mail(app)\n    return app\n```"}
{"task_id": "BigCodeBench/84", "solution": "import numpy as np\nimport pandas as pd\ndef task_func(products, n_samples=100, sales_lower=50, sales_upper=200, profit_margin_min=0.1, profit_margin_max=0.5, random_seed=42):\n    if not isinstance(n_samples, int) or n_samples <= 0:\n        raise ValueError(\"n_samples must be a positive integer\")\n    if not isinstance(sales_lower, (int, float)) or not isinstance(sales_upper, (int, float)):\n        raise ValueError(\"sales_lower and sales_upper must be numeric\")\n    if not isinstance(profit_margin_min, (int, float)) or not isinstance(profit_margin_max, (int, float)):\n        raise ValueError(\"profit_margin_min and profit_margin_max must be numeric\")\n    if not isinstance(products, list) or not all(isinstance(product, str) for product in products):\n        raise TypeError(\"products must be a list of strings\")\n    if sales_lower > sales_upper:\n        raise ValueError(\"sales_lower must be less than or equal to sales_upper\")\n    np.random.seed(random_seed)\n    sales = np.random.randint(sales_lower, sales_upper, n_samples)\n    profits = np.random.uniform(profit_margin_min, profit_margin_max, n_samples)\n    df = pd.DataFrame({'product': products, 'sales': sales, 'profit': profits})\n    df = df.groupby('product')['profit'].sum().reset_index()\n    df = df.sort_values('profit', ascending=False)\n    return df", "raw_solution": "import numpy as np\nimport pandas as pd\ndef task_func(products, n_samples=100, sales_lower=50, sales_upper=200, profit_margin_min=0.1, profit_margin_max=0.5, random_seed=42):\n    if not isinstance(n_samples, int) or n_samples <= 0:\n        raise ValueError(\"n_samples must be a positive integer\")\n    if not isinstance(sales_lower, (int, float)) or not isinstance(sales_upper, (int, float)):\n        raise ValueError(\"sales_lower and sales_upper must be numeric\")\n    if not isinstance(profit_margin_min, (int, float)) or not isinstance(profit_margin_max, (int, float)):\n        raise ValueError(\"profit_margin_min and profit_margin_max must be numeric\")\n    if not isinstance(products, list) or not all(isinstance(product, str) for product in products):\n        raise TypeError(\"products must be a list of strings\")\n    if sales_lower > sales_upper:\n        raise ValueError(\"sales_lower must be less than or equal to sales_upper\")\n    np.random.seed(random_seed)\n    sales = np.random.randint(sales_lower, sales_upper, n_samples)\n    profits = np.random.uniform(profit_margin_min, profit_margin_max, n_samples)\n    df = pd.DataFrame({'product': products, 'sales': sales, 'profit': profits})\n    df = df.groupby('product')['profit'].sum().reset_index()\n    df = df.sort_values('profit', ascending=False)\n    return df\n```"}
{"task_id": "BigCodeBench/85", "solution": "import numpy as np\nimport pandas as pd\nfrom datetime import timedelta\nimport matplotlib.pyplot as plt\ndef task_func(start_date, end_date, random_seed=42):\n    if end_date < start_date:\n        raise ValueError('Invalid date range')\n    np.random.seed(random_seed)\n    dates = pd.date_range(start=start_date, end=end_date)\n    temperatures = np.random.uniform(-10, 40, len(dates))\n    humidities = np.random.uniform(20, 100, len(dates))\n    wind_speeds = np.random.uniform(0, 20, len(dates))\n    df = pd.DataFrame({'Date': dates, 'Temperature': temperatures, 'Humidity': humidities, 'Wind Speed': wind_speeds})\n    fig, ax = plt.subplots()\n    ax.plot(df['Date'], df['Temperature'], label='Temperature')\n    ax.plot(df['Date'], df['Humidity'], label='Humidity')\n    ax.plot(df['Date'], df['Wind Speed'], label='Wind Speed')\n    ax.legend()\n    return df, ax", "raw_solution": "import numpy as np\nimport pandas as pd\nfrom datetime import timedelta\nimport matplotlib.pyplot as plt\n\ndef task_func(start_date, end_date, random_seed=42):\n    if end_date < start_date:\n        raise ValueError('Invalid date range')\n    np.random.seed(random_seed)\n    dates = pd.date_range(start=start_date, end=end_date)\n    temperatures = np.random.uniform(-10, 40, len(dates))\n    humidities = np.random.uniform(20, 100, len(dates))\n    wind_speeds = np.random.uniform(0, 20, len(dates))\n    df = pd.DataFrame({'Date': dates, 'Temperature': temperatures, 'Humidity': humidities, 'Wind Speed': wind_speeds})\n    fig, ax = plt.subplots()\n    ax.plot(df['Date'], df['Temperature'], label='Temperature')\n    ax.plot(df['Date'], df['Humidity'], label='Humidity')\n    ax.plot(df['Date'], df['Wind Speed'], label='Wind Speed')\n    ax.legend()\n    return df, ax\n```"}
{"task_id": "BigCodeBench/86", "solution": "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\ndef task_func(students=[\"Alice\", \"Bob\", \"Charlie\", \"David\", \"Eve\"], seed=42):\n    np.random.seed(seed)\n    scores = np.random.randint(0, 100, size=len(students))\n    df = pd.DataFrame({'Student': students, 'Score': scores})\n    df = df.sort_values(by='Score')\n    fig, ax = plt.subplots()\n    ax.bar(df['Student'], df['Score'])\n    return df, ax", "raw_solution": "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndef task_func(students=[\"Alice\", \"Bob\", \"Charlie\", \"David\", \"Eve\"], seed=42):\n    np.random.seed(seed)\n    scores = np.random.randint(0, 100, size=len(students))\n    df = pd.DataFrame({'Student': students, 'Score': scores})\n    df = df.sort_values(by='Score')\n    fig, ax = plt.subplots()\n    ax.bar(df['Student'], df['Score'])\n    return df, ax\n```"}
{"task_id": "BigCodeBench/87", "solution": "import pandas as pd\nfrom random import choices, seed\ndef task_func(products, ratings, weights, random_seed=42):\n    seed(random_seed)\n    ratings = choices(ratings, weights=weights, k=len(products))\n    df = pd.DataFrame({'Product': products, 'Rating': ratings})\n    df = df.sort_values(by='Rating', ascending=False)\n    return df", "raw_solution": "import pandas as pd\nfrom random import choices, seed\n\ndef task_func(products, ratings, weights, random_seed=42):\n    seed(random_seed)\n    ratings = choices(ratings, weights=weights, k=len(products))\n    df = pd.DataFrame({'Product': products, 'Rating': ratings})\n    df = df.sort_values(by='Rating', ascending=False)\n    return df\n```"}
{"task_id": "BigCodeBench/88", "solution": "import numpy as np\nimport pandas as pd\nfrom datetime import datetime, timedelta\ndef task_func(start_date, end_date, seed=42):\n    np.random.seed(seed)\n    start_date = datetime.strptime(start_date, '%Y-%m-%d')\n    end_date = datetime.strptime(end_date, '%Y-%m-%d')\n    delta = end_date - start_date\n    dates = [start_date + timedelta(days=i) for i in range(delta.days + 1)]\n    sales = np.random.randint(0, 501, size=len(dates))\n    df = pd.DataFrame({'Date': dates, 'Sales': sales})\n    fig, ax = plt.subplots()\n    ax.plot(df['Date'], df['Sales'])\n    return df, ax", "raw_solution": "import numpy as np\nimport pandas as pd\nfrom datetime import datetime, timedelta\ndef task_func(start_date, end_date, seed=42):\n    np.random.seed(seed)\n    start_date = datetime.strptime(start_date, '%Y-%m-%d')\n    end_date = datetime.strptime(end_date, '%Y-%m-%d')\n    delta = end_date - start_date\n    dates = [start_date + timedelta(days=i) for i in range(delta.days + 1)]\n    sales = np.random.randint(0, 501, size=len(dates))\n    df = pd.DataFrame({'Date': dates, 'Sales': sales})\n    fig, ax = plt.subplots()\n    ax.plot(df['Date'], df['Sales'])\n    return df, ax\n```"}
{"task_id": "BigCodeBench/89", "solution": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy import stats\nfrom sklearn.preprocessing import StandardScaler\ndef task_func(data, column, outlier_z_score):\n    # Standardize the column\n    scaler = StandardScaler()\n    data[column] = scaler.fit_transform(data[column].values.reshape(-1, 1))\n    \n    # Calculate Z-scores\n    z_scores = stats.zscore(data[column])\n    \n    # Remove outliers\n    data = data[(np.abs(z_scores) < outlier_z_score).all(axis=1)]\n    \n    # Plot the data before and after outlier removal\n    plt.figure(figsize=(10, 5))\n    plt.subplot(1, 2, 1)\n    plt.scatter(data.index, data[column], color='blue')\n    plt.title('Data with Outliers')\n    plt.xlabel('Index')\n    plt.ylabel(column)\n    \n    plt.subplot(1, 2, 2)\n    plt.scatter(data.index, data[column], color='blue')\n    plt.title('Data without Outliers')\n    plt.xlabel('Index')\n    plt.ylabel(column)\n    \n    plt.show()\n    \n    return data, data.dropna(), np.where(np.abs(z_scores) > outlier_z_score)[0]", "raw_solution": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy import stats\nfrom sklearn.preprocessing import StandardScaler\n\ndef task_func(data, column, outlier_z_score):\n    # Standardize the column\n    scaler = StandardScaler()\n    data[column] = scaler.fit_transform(data[column].values.reshape(-1, 1))\n    \n    # Calculate Z-scores\n    z_scores = stats.zscore(data[column])\n    \n    # Remove outliers\n    data = data[(np.abs(z_scores) < outlier_z_score).all(axis=1)]\n    \n    # Plot the data before and after outlier removal\n    plt.figure(figsize=(10, 5))\n    plt.subplot(1, 2, 1)\n    plt.scatter(data.index, data[column], color='blue')\n    plt.title('Data with Outliers')\n    plt.xlabel('Index')\n    plt.ylabel(column)\n    \n    plt.subplot(1, 2, 2)\n    plt.scatter(data.index, data[column], color='blue')\n    plt.title('Data without Outliers')\n    plt.xlabel('Index')\n    plt.ylabel(column)\n    \n    plt.show()\n    \n    return data, data.dropna(), np.where(np.abs(z_scores) > outlier_z_score)[0]\n```"}
{"task_id": "BigCodeBench/90", "solution": "import numpy as np\nimport math\ndef task_func(data, target, k):\n    if not isinstance(k, int) or k < 0:\n        raise ValueError(\"k must be a non-negative integer\")\n    distances = []\n    for point in data:\n        lat1, lon1 = target\n        lat2, lon2 = point\n        dlat = math.radians(lat2 - lat1)\n        dlon = math.radians(lon2 - lon1)\n        a = math.sin(dlat / 2) ** 2 + math.cos(math.radians(lat1)) * math.cos(math.radians(lat2)) * math.sin(dlon / 2) ** 2\n        c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n        distance = 6371 * c\n        distances.append((distance, point))\n    distances.sort()\n    return [point for distance, point in distances[:k]]", "raw_solution": "import numpy as np\nimport math\ndef task_func(data, target, k):\n    if not isinstance(k, int) or k < 0:\n        raise ValueError(\"k must be a non-negative integer\")\n    distances = []\n    for point in data:\n        lat1, lon1 = target\n        lat2, lon2 = point\n        dlat = math.radians(lat2 - lat1)\n        dlon = math.radians(lon2 - lon1)\n        a = math.sin(dlat / 2) ** 2 + math.cos(math.radians(lat1)) * math.cos(math.radians(lat2)) * math.sin(dlon / 2) ** 2\n        c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n        distance = 6371 * c\n        distances.append((distance, point))\n    distances.sort()\n    return [point for distance, point in distances[:k]]\n```"}
{"task_id": "BigCodeBench/91", "solution": "from scipy.stats import linregress\nimport matplotlib.pyplot as plt\ndef task_func(data, column1, column2):\n    if column1 not in data.columns or column2 not in data.columns:\n        raise ValueError(\"If the specified columns do not exist in the DataFrame.\")\n    slope, intercept, r_value, p_value, std_err = linregress(data[column1], data[column2])\n    fig, ax = plt.subplots()\n    ax.scatter(data[column1], data[column2])\n    ax.plot(data[column1], slope * data[column1] + intercept, color='red')\n    ax.set_xlabel(column1)\n    ax.set_ylabel(column2)\n    return (slope, intercept, r_value, p_value, std_err), ax", "raw_solution": "from scipy.stats import linregress\nimport matplotlib.pyplot as plt\n\ndef task_func(data, column1, column2):\n    if column1 not in data.columns or column2 not in data.columns:\n        raise ValueError(\"If the specified columns do not exist in the DataFrame.\")\n    slope, intercept, r_value, p_value, std_err = linregress(data[column1], data[column2])\n    fig, ax = plt.subplots()\n    ax.scatter(data[column1], data[column2])\n    ax.plot(data[column1], slope * data[column1] + intercept, color='red')\n    ax.set_xlabel(column1)\n    ax.set_ylabel(column2)\n    return (slope, intercept, r_value, p_value, std_err), ax\n```"}
{"task_id": "BigCodeBench/92", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.cluster import KMeans\nfrom matplotlib.collections import PathCollection\ndef task_func(data, n_clusters=3):\n    if not isinstance(data, pd.DataFrame):\n        raise ValueError(\"If 'data' is not a pd.DataFrame.\")\n    if not isinstance(n_clusters, int) or n_clusters <= 1:\n        raise ValueError(\"If 'n_clusters' is not an integer greater than 1.\")\n    kmeans = KMeans(n_clusters=n_clusters)\n    kmeans.fit(data)\n    labels = kmeans.labels_\n    centroids = kmeans.cluster_centers_\n    fig, ax = plt.subplots()\n    scatter = ax.scatter(data.iloc[:, 0], data.iloc[:, 1], c=labels)\n    path_collection = PathCollection([Path(centroids)])\n    path_collection.set_facecolor('red')\n    path_collection.set_edgecolor('black')\n    ax.add_collection(path_collection)\n    ax.set_title('K-means Clustering')\n    ax.set_xlabel('Feature 1')\n    ax.set_ylabel('Feature 2')\n    plt.show()\n    return labels, ax", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.cluster import KMeans\nfrom matplotlib.collections import PathCollection\n\ndef task_func(data, n_clusters=3):\n    if not isinstance(data, pd.DataFrame):\n        raise ValueError(\"If 'data' is not a pd.DataFrame.\")\n    if not isinstance(n_clusters, int) or n_clusters <= 1:\n        raise ValueError(\"If 'n_clusters' is not an integer greater than 1.\")\n    kmeans = KMeans(n_clusters=n_clusters)\n    kmeans.fit(data)\n    labels = kmeans.labels_\n    centroids = kmeans.cluster_centers_\n    fig, ax = plt.subplots()\n    scatter = ax.scatter(data.iloc[:, 0], data.iloc[:, 1], c=labels)\n    path_collection = PathCollection([Path(centroids)])\n    path_collection.set_facecolor('red')\n    path_collection.set_edgecolor('black')\n    ax.add_collection(path_collection)\n    ax.set_title('K-means Clustering')\n    ax.set_xlabel('Feature 1')\n    ax.set_ylabel('Feature 2')\n    plt.show()\n    return labels, ax\n```"}
{"task_id": "BigCodeBench/93", "solution": "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.decomposition import PCA\ndef task_func(data, n_components=2):\n    if n_components <= 0:\n        raise ValueError(\"n_components must be a positive integer\")\n    pca = PCA(n_components=n_components)\n    transformed_data = pca.fit_transform(data)\n    return pd.DataFrame(transformed_data), plt.axes()", "raw_solution": "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.decomposition import PCA\ndef task_func(data, n_components=2):\n    if n_components <= 0:\n        raise ValueError(\"n_components must be a positive integer\")\n    pca = PCA(n_components=n_components)\n    transformed_data = pca.fit_transform(data)\n    return pd.DataFrame(transformed_data), plt.axes()\n```"}
{"task_id": "BigCodeBench/94", "solution": "import numpy as np\nfrom scipy.stats import norm\nimport matplotlib.pyplot as plt\ndef task_func(mean, std_dev, num_samples):\n    # Generate samples from a normal distribution\n    samples = norm.rvs(loc=mean, scale=std_dev, size=num_samples)\n    \n    # Calculate the PDF of the normal distribution\n    x = np.linspace(mean - 3 * std_dev, mean + 3 * std_dev, 300)\n    pdf = norm.pdf(x, loc=mean, scale=std_dev)\n    \n    # Plot the histogram and the PDF\n    fig, ax = plt.subplots()\n    ax.hist(samples, bins=30, density=True, alpha=0.6, color='g')\n    ax.plot(x, pdf, 'r', linewidth=2)\n    ax.set_title('Fit results: mean = %.2f, std = %.2f' % (mean, std_dev))\n    ax.set_xlabel('Value')\n    ax.set_ylabel('Density')\n    \n    return fig, samples", "raw_solution": "import numpy as np\nfrom scipy.stats import norm\nimport matplotlib.pyplot as plt\n\ndef task_func(mean, std_dev, num_samples):\n    # Generate samples from a normal distribution\n    samples = norm.rvs(loc=mean, scale=std_dev, size=num_samples)\n    \n    # Calculate the PDF of the normal distribution\n    x = np.linspace(mean - 3 * std_dev, mean + 3 * std_dev, 300)\n    pdf = norm.pdf(x, loc=mean, scale=std_dev)\n    \n    # Plot the histogram and the PDF\n    fig, ax = plt.subplots()\n    ax.hist(samples, bins=30, density=True, alpha=0.6, color='g')\n    ax.plot(x, pdf, 'r', linewidth=2)\n    ax.set_title('Fit results: mean = %.2f, std = %.2f' % (mean, std_dev))\n    ax.set_xlabel('Value')\n    ax.set_ylabel('Density')\n    \n    return fig, samples\n```"}
{"task_id": "BigCodeBench/95", "solution": "import pandas as pd\nfrom random import randint, uniform, seed\ndef task_func(categories=None, months=None, random_seed=42):\n    if categories is None or months is None or not isinstance(categories, list) or not isinstance(months, list) or len(categories) == 0 or len(months) == 0:\n        raise ValueError(\"Both 'categories' and 'months' must be provided as a list and cannot be empty.\")\n    seed(random_seed)\n    sales_data = []\n    for category in categories:\n        for month in months:\n            sales_data.append({'Month': month, 'Category': category, 'Sales': randint(100, 500) + uniform(0, 1)})\n    return pd.DataFrame(sales_data)", "raw_solution": "import pandas as pd\nfrom random import randint, uniform, seed\n\ndef task_func(categories=None, months=None, random_seed=42):\n    if categories is None or months is None or not isinstance(categories, list) or not isinstance(months, list) or len(categories) == 0 or len(months) == 0:\n        raise ValueError(\"Both 'categories' and 'months' must be provided as a list and cannot be empty.\")\n    seed(random_seed)\n    sales_data = []\n    for category in categories:\n        for month in months:\n            sales_data.append({'Month': month, 'Category': category, 'Sales': randint(100, 500) + uniform(0, 1)})\n    return pd.DataFrame(sales_data)\n```"}
{"task_id": "BigCodeBench/96", "solution": "import csv\nfrom collections import Counter\nimport operator\ndef task_func(csv_file, csv_delimiter):\n    with open(csv_file, newline='') as f:\n        reader = csv.reader(f, delimiter=csv_delimiter)\n        words = [word for row in reader for word in row]\n    word_counts = Counter(words)\n    sorted_word_counts = sorted(word_counts.items(), key=operator.itemgetter(1), reverse=True)\n    return sorted_word_counts", "raw_solution": "import csv\nfrom collections import Counter\nimport operator\n\ndef task_func(csv_file, csv_delimiter):\n    with open(csv_file, newline='') as f:\n        reader = csv.reader(f, delimiter=csv_delimiter)\n        words = [word for row in reader for word in row]\n    word_counts = Counter(words)\n    sorted_word_counts = sorted(word_counts.items(), key=operator.itemgetter(1), reverse=True)\n    return sorted_word_counts\n```"}
{"task_id": "BigCodeBench/97", "solution": "import math\nimport itertools\nfrom functools import reduce\ndef task_func(numbers):\n    result = 0\n    for r in range(1, len(numbers) + 1):\n        for combination in itertools.combinations(numbers, r):\n            product = reduce(lambda x, y: x * y, combination)\n            result += math.log(product)\n    return result", "raw_solution": "import math\nimport itertools\nfrom functools import reduce\ndef task_func(numbers):\n    result = 0\n    for r in range(1, len(numbers) + 1):\n        for combination in itertools.combinations(numbers, r):\n            product = reduce(lambda x, y: x * y, combination)\n            result += math.log(product)\n    return result\n```"}
{"task_id": "BigCodeBench/98", "solution": "import random\nimport string\nfrom collections import Counter\ndef task_func(num_strings, string_length):\n    # Generate a list of random strings\n    strings = [''.join(random.choice(string.ascii_lowercase) for _ in range(string_length)) for _ in range(num_strings)]\n    \n    # Count the frequency of each character across all strings\n    char_counts = Counter(''.join(strings))\n    \n    # Sort the characters by frequency in descending order\n    sorted_chars = sorted(char_counts.items(), key=lambda x: x[1], reverse=True)\n    \n    return sorted_chars", "raw_solution": "import random\nimport string\nfrom collections import Counter\n\ndef task_func(num_strings, string_length):\n    # Generate a list of random strings\n    strings = [''.join(random.choice(string.ascii_lowercase) for _ in range(string_length)) for _ in range(num_strings)]\n    \n    # Count the frequency of each character across all strings\n    char_counts = Counter(''.join(strings))\n    \n    # Sort the characters by frequency in descending order\n    sorted_chars = sorted(char_counts.items(), key=lambda x: x[1], reverse=True)\n    \n    return sorted_chars\n```"}
{"task_id": "BigCodeBench/99", "solution": "import matplotlib.pyplot as plt\nimport pandas as pd\nimport seaborn as sns\nfrom sklearn.datasets import load_iris\ndef task_func():\n    iris = load_iris()\n    df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n    df['species'] = iris.target_names[iris.target]\n    sns.pairplot(df, hue='species', palette='viridis', title='Iris Dataset Pair Plot', font='Arial')\n    plt.show()", "raw_solution": "import matplotlib.pyplot as plt\nimport pandas as pd\nimport seaborn as sns\nfrom sklearn.datasets import load_iris\n\ndef task_func():\n    iris = load_iris()\n    df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n    df['species'] = iris.target_names[iris.target]\n    sns.pairplot(df, hue='species', palette='viridis', title='Iris Dataset Pair Plot', font='Arial')\n    plt.show()\n```"}
{"task_id": "BigCodeBench/100", "solution": "import matplotlib.pyplot as plt\nimport pandas as pd\nimport random\nfrom datetime import datetime\ndef task_func(seed=42):\n    random.seed(seed)\n    dates = [datetime.now() - pd.Timedelta(days=i) for i in range(30)]\n    values = [random.random() for _ in range(30)]\n    df = pd.DataFrame({'Date': dates, 'Value': values})\n    fig, ax = plt.subplots()\n    ax.plot(df['Date'], df['Value'], label='Random Time Series Data')\n    ax.set_xlabel('Date')\n    ax.set_ylabel('Value')\n    ax.set_title('Random Time Series Data')\n    ax.legend()\n    return ax", "raw_solution": "import matplotlib.pyplot as plt\nimport pandas as pd\nimport random\nfrom datetime import datetime\n\ndef task_func(seed=42):\n    random.seed(seed)\n    dates = [datetime.now() - pd.Timedelta(days=i) for i in range(30)]\n    values = [random.random() for _ in range(30)]\n    df = pd.DataFrame({'Date': dates, 'Value': values})\n    fig, ax = plt.subplots()\n    ax.plot(df['Date'], df['Value'], label='Random Time Series Data')\n    ax.set_xlabel('Date')\n    ax.set_ylabel('Value')\n    ax.set_title('Random Time Series Data')\n    ax.legend()\n    return ax\n```"}
{"task_id": "BigCodeBench/101", "solution": "import matplotlib.pyplot as plt\nimport pandas as pd\nimport seaborn as sns\nimport numpy as np\ndef task_func(data_url=\"http://lib.stat.cmu.edu/datasets/boston\", seed=42):\n    np.random.seed(seed)\n    df = pd.read_csv(data_url)\n    corr = df.corr()\n    sns.heatmap(corr, annot=True, cmap='coolwarm')\n    plt.savefig('boston_heatmap.png')\n    return plt.gca()", "raw_solution": "import matplotlib.pyplot as plt\nimport pandas as pd\nimport seaborn as sns\nimport numpy as np\ndef task_func(data_url=\"http://lib.stat.cmu.edu/datasets/boston\", seed=42):\n    np.random.seed(seed)\n    df = pd.read_csv(data_url)\n    corr = df.corr()\n    sns.heatmap(corr, annot=True, cmap='coolwarm')\n    plt.savefig('boston_heatmap.png')\n    return plt.gca()\n```"}
{"task_id": "BigCodeBench/102", "solution": "import matplotlib.pyplot as plt\nimport seaborn as sns\nimport pandas as pd\nfrom sklearn.datasets import load_diabetes\ndef task_func():\n    sns.set(font='Arial')\n    diabetes = load_diabetes()\n    df = pd.DataFrame(diabetes.data, columns=diabetes.feature_names)\n    fig = sns.pairplot(df)\n    return fig, df", "raw_solution": "import matplotlib.pyplot as plt\nimport seaborn as sns\nimport pandas as pd\nfrom sklearn.datasets import load_diabetes\ndef task_func():\n    sns.set(font='Arial')\n    diabetes = load_diabetes()\n    df = pd.DataFrame(diabetes.data, columns=diabetes.feature_names)\n    fig = sns.pairplot(df)\n    return fig, df\n```"}
{"task_id": "BigCodeBench/103", "solution": "import matplotlib.pyplot as plt\nimport pandas as pd\ndef task_func(temperatures):\n    if not isinstance(temperatures, pd.DataFrame) or temperatures.empty:\n        raise ValueError(\"If the input DataFrame is not in the expected format or empty.\")\n    plt.figure(figsize=(10, 6))\n    plt.plot(temperatures['Date'], temperatures['Temperature (\u00b0C)'], marker='o', linestyle='-', color='b')\n    plt.xlabel('Date')\n    plt.ylabel('Temperature (\u00b0C)')\n    plt.title('Daily Temperatures in New York')\n    plt.xticks(rotation=45)\n    plt.tight_layout()\n    plt.show()\n    return plt.axes()", "raw_solution": "import matplotlib.pyplot as plt\nimport pandas as pd\n\ndef task_func(temperatures):\n    if not isinstance(temperatures, pd.DataFrame) or temperatures.empty:\n        raise ValueError(\"If the input DataFrame is not in the expected format or empty.\")\n    plt.figure(figsize=(10, 6))\n    plt.plot(temperatures['Date'], temperatures['Temperature (\u00b0C)'], marker='o', linestyle='-', color='b')\n    plt.xlabel('Date')\n    plt.ylabel('Temperature (\u00b0C)')\n    plt.title('Daily Temperatures in New York')\n    plt.xticks(rotation=45)\n    plt.tight_layout()\n    plt.show()\n    return plt.axes()\n```"}
{"task_id": "BigCodeBench/104", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nfrom itertools import cycle\ndef task_func(df, groups=['A', 'B', 'C', 'D', 'E']):\n    if not isinstance(df, pd.DataFrame) or 'Date' not in df.columns or 'Value' not in df.columns:\n        raise ValueError('If \\'df\\' is not a DataFrame or lacks required columns.')\n    fig, ax = plt.subplots()\n    for group in groups:\n        ax.scatter(df[df['Group'] == group]['Date'], df[df['Group'] == group]['Value'], label=group)\n    ax.set_title('Scatterplot of Values for Each Group Over Time')\n    ax.set_xlabel('Date (ordinal)')\n    ax.set_ylabel('Value')\n    ax.legend()\n    return ax", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nfrom itertools import cycle\n\ndef task_func(df, groups=['A', 'B', 'C', 'D', 'E']):\n    if not isinstance(df, pd.DataFrame) or 'Date' not in df.columns or 'Value' not in df.columns:\n        raise ValueError('If \\'df\\' is not a DataFrame or lacks required columns.')\n    fig, ax = plt.subplots()\n    for group in groups:\n        ax.scatter(df[df['Group'] == group]['Date'], df[df['Group'] == group]['Value'], label=group)\n    ax.set_title('Scatterplot of Values for Each Group Over Time')\n    ax.set_xlabel('Date (ordinal)')\n    ax.set_ylabel('Value')\n    ax.legend()\n    return ax\n```"}
{"task_id": "BigCodeBench/105", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\ndef task_func(df):\n    if df.empty:\n        raise ValueError(\"If the dataframe is empty\")\n    if 'date' not in df.columns:\n        raise ValueError(\"If required columns are missing\")\n    if not isinstance(df['date'], pd.DatetimeIndex):\n        raise ValueError(\"If 'date' column is not in datetime format\")\n    df['date'] = df['date'].ordinal()\n    corr_matrix = df.corr()\n    pair_grid = sns.pairplot(df)\n    pair_grid.fig.suptitle('Correlation Matrix')\n    return pair_grid.fig, pair_grid", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\ndef task_func(df):\n    if df.empty:\n        raise ValueError(\"If the dataframe is empty\")\n    if 'date' not in df.columns:\n        raise ValueError(\"If required columns are missing\")\n    if not isinstance(df['date'], pd.DatetimeIndex):\n        raise ValueError(\"If 'date' column is not in datetime format\")\n    df['date'] = df['date'].ordinal()\n    corr_matrix = df.corr()\n    pair_grid = sns.pairplot(df)\n    pair_grid.fig.suptitle('Correlation Matrix')\n    return pair_grid.fig, pair_grid\n```"}
{"task_id": "BigCodeBench/106", "solution": "import pandas as pd\nfrom sklearn.linear_model import LinearRegression\nimport matplotlib.pyplot as plt\ndef task_func(df):\n    if not isinstance(df, pd.DataFrame):\n        raise ValueError(\"If 'df' is not a valid DataFrame\")\n    if 'date' not in df.columns:\n        raise ValueError(\"Lacks the required columns\")\n    if not isinstance(df['date'][0], pd.Timestamp):\n        raise ValueError(\"If 'date' column is not in datetime format\")\n    df['date'] = df['date'].astype('int64')\n    X = df['date'].values.reshape(-1, 1)\n    y = df['value'].values\n    model = LinearRegression()\n    model.fit(X, y)\n    predictions = model.predict(X)\n    fig, ax = plt.subplots()\n    ax.plot(df['date'], df['value'], label='Original')\n    ax.plot(df['date'], predictions, label='Predicted')\n    ax.set_title('Value vs Date (Linear Regression Prediction)')\n    ax.set_xlabel('Date (ordinal)')\n    ax.set_ylabel('Value')\n    ax.legend()\n    return model, predictions, ax", "raw_solution": "import pandas as pd\nfrom sklearn.linear_model import LinearRegression\nimport matplotlib.pyplot as plt\n\ndef task_func(df):\n    if not isinstance(df, pd.DataFrame):\n        raise ValueError(\"If 'df' is not a valid DataFrame\")\n    if 'date' not in df.columns:\n        raise ValueError(\"Lacks the required columns\")\n    if not isinstance(df['date'][0], pd.Timestamp):\n        raise ValueError(\"If 'date' column is not in datetime format\")\n    df['date'] = df['date'].astype('int64')\n    X = df['date'].values.reshape(-1, 1)\n    y = df['value'].values\n    model = LinearRegression()\n    model.fit(X, y)\n    predictions = model.predict(X)\n    fig, ax = plt.subplots()\n    ax.plot(df['date'], df['value'], label='Original')\n    ax.plot(df['date'], predictions, label='Predicted')\n    ax.set_title('Value vs Date (Linear Regression Prediction)')\n    ax.set_xlabel('Date (ordinal)')\n    ax.set_ylabel('Value')\n    ax.legend()\n    return model, predictions, ax\n```"}
{"task_id": "BigCodeBench/107", "solution": "import pandas as pd\nfrom sklearn.cluster import KMeans\nimport matplotlib.pyplot as plt\ndef task_func(df, n_clusters=3, random_state=0):\n    if df.empty or 'date' not in df.columns or 'value' not in df.columns:\n        raise ValueError('If the DataFrame is empty or lacks required columns.')\n    df['date'] = pd.to_datetime(df['date'])\n    df['date'] = df['date'].map(pd.toordinal)\n    kmeans = KMeans(n_clusters=n_clusters, random_state=random_state)\n    kmeans.fit(df[['date', 'value']])\n    plt.scatter(df['date'], df['value'], c=kmeans.labels_)\n    plt.xlabel('Date (ordinal)')\n    plt.ylabel('Value')\n    plt.title('KMeans Clustering of Value vs Date')\n    return plt.gca()", "raw_solution": "import pandas as pd\nfrom sklearn.cluster import KMeans\nimport matplotlib.pyplot as plt\n\ndef task_func(df, n_clusters=3, random_state=0):\n    if df.empty or 'date' not in df.columns or 'value' not in df.columns:\n        raise ValueError('If the DataFrame is empty or lacks required columns.')\n    df['date'] = pd.to_datetime(df['date'])\n    df['date'] = df['date'].map(pd.toordinal)\n    kmeans = KMeans(n_clusters=n_clusters, random_state=random_state)\n    kmeans.fit(df[['date', 'value']])\n    plt.scatter(df['date'], df['value'], c=kmeans.labels_)\n    plt.xlabel('Date (ordinal)')\n    plt.ylabel('Value')\n    plt.title('KMeans Clustering of Value vs Date')\n    return plt.gca()\n```"}
{"task_id": "BigCodeBench/108", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nfrom statsmodels.tsa.seasonal import seasonal_decompose\ndef task_func(df, freq='D', decomposition_model='multiplicative'):\n    if not isinstance(df, pd.DataFrame):\n        raise ValueError('If \\'df\\' is not a DataFrame, lacks required columns, or contains invalid data types.')\n    if freq not in ['D', 'W', 'M', 'Q', 'A']:\n        raise ValueError('If \\'freq\\' is not a valid frequency string.')\n    if decomposition_model not in ['additive', 'multiplicative']:\n        raise ValueError('If \\'decomposition_model\\' is not \\'additive\\' or \\'multiplicative\\'.')\n    result = seasonal_decompose(df['value'], model=decomposition_model, freq=freq)\n    fig, axes = plt.subplots(4, 1, figsize=(10, 10))\n    result.trend.plot(ax=axes[0])\n    result.seasonal.plot(ax=axes[1])\n    result.resid.plot(ax=axes[2])\n    result.observed.plot(ax=axes[3])\n    plt.show()\n    return result, fig", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nfrom statsmodels.tsa.seasonal import seasonal_decompose\ndef task_func(df, freq='D', decomposition_model='multiplicative'):\n    if not isinstance(df, pd.DataFrame):\n        raise ValueError('If \\'df\\' is not a DataFrame, lacks required columns, or contains invalid data types.')\n    if freq not in ['D', 'W', 'M', 'Q', 'A']:\n        raise ValueError('If \\'freq\\' is not a valid frequency string.')\n    if decomposition_model not in ['additive', 'multiplicative']:\n        raise ValueError('If \\'decomposition_model\\' is not \\'additive\\' or \\'multiplicative\\'.')\n    result = seasonal_decompose(df['value'], model=decomposition_model, freq=freq)\n    fig, axes = plt.subplots(4, 1, figsize=(10, 10))\n    result.trend.plot(ax=axes[0])\n    result.seasonal.plot(ax=axes[1])\n    result.resid.plot(ax=axes[2])\n    result.observed.plot(ax=axes[3])\n    plt.show()\n    return result, fig\n```"}
{"task_id": "BigCodeBench/109", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\ndef task_func(df, items=None, locations=None):\n    if not isinstance(df, pd.DataFrame):\n        raise ValueError(\"df must be a DataFrame\")\n    if 'Item' not in df.columns or 'Location' not in df.columns:\n        raise ValueError(\"Item and Location columns must be present in df\")\n    if items is not None and not isinstance(items, list):\n        raise ValueError(\"items must be a list\")\n    if locations is not None and not isinstance(locations, list):\n        raise ValueError(\"locations must be a list\")\n    if items is not None:\n        df = df[df['Item'].isin(items)]\n    if locations is not None:\n        df = df[df['Location'].isin(locations)]\n    ax = df.groupby(['Item', 'Location']).size().unstack().plot(kind='bar', stacked=True)\n    ax.set_xlabel('Item')\n    ax.set_ylabel('Count')\n    ax.set_title('Distribution of Items Across Locations')\n    return ax", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\n\ndef task_func(df, items=None, locations=None):\n    if not isinstance(df, pd.DataFrame):\n        raise ValueError(\"df must be a DataFrame\")\n    if 'Item' not in df.columns or 'Location' not in df.columns:\n        raise ValueError(\"Item and Location columns must be present in df\")\n    if items is not None and not isinstance(items, list):\n        raise ValueError(\"items must be a list\")\n    if locations is not None and not isinstance(locations, list):\n        raise ValueError(\"locations must be a list\")\n    if items is not None:\n        df = df[df['Item'].isin(items)]\n    if locations is not None:\n        df = df[df['Location'].isin(locations)]\n    ax = df.groupby(['Item', 'Location']).size().unstack().plot(kind='bar', stacked=True)\n    ax.set_xlabel('Item')\n    ax.set_ylabel('Count')\n    ax.set_title('Distribution of Items Across Locations')\n    return ax\n```"}
{"task_id": "BigCodeBench/110", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\ndef task_func(df):\n    if not isinstance(df, pd.DataFrame) or 'Date' not in df.columns or 'Sales' not in df.columns or df.empty:\n        raise ValueError('If \\'df\\' is not a DataFrame or lacks \\'Date\\' or \\'Sales\\' columns, or has no data to plot.')\n    df['Date'] = pd.to_datetime(df['Date'])\n    df.set_index('Date', inplace=True)\n    ax = df['Sales'].plot()\n    ax.set_title('Daily Turnover Line Chart')\n    ax.set_xlabel('Date')\n    ax.set_ylabel('Sales')\n    plt.show()\n    return ax", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\n\ndef task_func(df):\n    if not isinstance(df, pd.DataFrame) or 'Date' not in df.columns or 'Sales' not in df.columns or df.empty:\n        raise ValueError('If \\'df\\' is not a DataFrame or lacks \\'Date\\' or \\'Sales\\' columns, or has no data to plot.')\n    df['Date'] = pd.to_datetime(df['Date'])\n    df.set_index('Date', inplace=True)\n    ax = df['Sales'].plot()\n    ax.set_title('Daily Turnover Line Chart')\n    ax.set_xlabel('Date')\n    ax.set_ylabel('Sales')\n    plt.show()\n    return ax\n```"}
{"task_id": "BigCodeBench/111", "solution": "import pandas as pd\nimport seaborn as sns\ndef task_func(df):\n    if not isinstance(df, pd.DataFrame) or 'Date' not in df.columns or 'Time' not in df.columns or 'Temperature' not in df.columns:\n        raise ValueError('If \\'df\\' is not a DataFrame or lacks \\'Date\\', \\'Time\\', or \\'Temperature\\' columns.')\n    sns.heatmap(df[['Date', 'Time', 'Temperature']], annot=True, fmt='.2f')\n    return sns.plt", "raw_solution": "import pandas as pd\nimport seaborn as sns\n\ndef task_func(df):\n    if not isinstance(df, pd.DataFrame) or 'Date' not in df.columns or 'Time' not in df.columns or 'Temperature' not in df.columns:\n        raise ValueError('If \\'df\\' is not a DataFrame or lacks \\'Date\\', \\'Time\\', or \\'Temperature\\' columns.')\n    sns.heatmap(df[['Date', 'Time', 'Temperature']], annot=True, fmt='.2f')\n    return sns.plt\n```"}
{"task_id": "BigCodeBench/112", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\ndef task_func(df):\n    if not isinstance(df, pd.DataFrame) or 'Status' not in df.columns:\n        raise ValueError('df is not a pandas DataFrame or does not contain the \"Status\" column')\n    status_counts = df['Status'].value_counts()\n    fig, ax = plt.subplots()\n    ax.pie(status_counts, labels=status_counts.index, autopct='%1.1f%%')\n    return ax", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\n\ndef task_func(df):\n    if not isinstance(df, pd.DataFrame) or 'Status' not in df.columns:\n        raise ValueError('df is not a pandas DataFrame or does not contain the \"Status\" column')\n    status_counts = df['Status'].value_counts()\n    fig, ax = plt.subplots()\n    ax.pie(status_counts, labels=status_counts.index, autopct='%1.1f%%')\n    return ax\n```"}
{"task_id": "BigCodeBench/113", "solution": "import json\nfrom collections import Counter\nimport random\ndef task_func(my_dict, keys):\n    if len(keys) != 10:\n        raise ValueError(\"If 'keys' does not contain exactly 10 unique elements.\")\n    for key in keys:\n        my_dict[key] = random.randint(1, 100)\n    with open('updated_dictionary.json', 'w') as f:\n        json.dump(my_dict, f)\n    with open('key_frequencies.txt', 'w') as f:\n        f.write(str(Counter(my_dict)))\n    return my_dict, 'updated_dictionary.json', 'key_frequencies.txt'", "raw_solution": "import json\nfrom collections import Counter\nimport random\n\ndef task_func(my_dict, keys):\n    if len(keys) != 10:\n        raise ValueError(\"If 'keys' does not contain exactly 10 unique elements.\")\n    for key in keys:\n        my_dict[key] = random.randint(1, 100)\n    with open('updated_dictionary.json', 'w') as f:\n        json.dump(my_dict, f)\n    with open('key_frequencies.txt', 'w') as f:\n        f.write(str(Counter(my_dict)))\n    return my_dict, 'updated_dictionary.json', 'key_frequencies.txt'\n```"}
{"task_id": "BigCodeBench/114", "solution": "import numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\ndef task_func(my_dict):\n    if not isinstance(my_dict['array'], np.ndarray):\n        raise TypeError('The value of the \\'array\\' key in my_dict is not a numpy array')\n    scaler = MinMaxScaler()\n    normalized_array = scaler.fit_transform(my_dict['array'].reshape(-1, 1))\n    my_dict['normalized_array'] = normalized_array.reshape(-1)\n    return my_dict", "raw_solution": "import numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\n\ndef task_func(my_dict):\n    if not isinstance(my_dict['array'], np.ndarray):\n        raise TypeError('The value of the \\'array\\' key in my_dict is not a numpy array')\n    scaler = MinMaxScaler()\n    normalized_array = scaler.fit_transform(my_dict['array'].reshape(-1, 1))\n    my_dict['normalized_array'] = normalized_array.reshape(-1)\n    return my_dict\n```"}
{"task_id": "BigCodeBench/115", "solution": "import numpy as np\nfrom scipy.stats import mode\nfrom scipy.stats import entropy\ndef task_func(numbers):\n    if len(numbers) == 0:\n        raise ValueError(\"Input list 'numbers' is empty\")\n    array = np.array(numbers)\n    mode_val, _ = mode(array)\n    entropy_val = entropy(array, base=2)\n    return {'mode': mode_val[0], 'entropy': entropy_val}", "raw_solution": "import numpy as np\nfrom scipy.stats import mode\nfrom scipy.stats import entropy\n\ndef task_func(numbers):\n    if len(numbers) == 0:\n        raise ValueError(\"Input list 'numbers' is empty\")\n    array = np.array(numbers)\n    mode_val, _ = mode(array)\n    entropy_val = entropy(array, base=2)\n    return {'mode': mode_val[0], 'entropy': entropy_val}\n```"}
{"task_id": "BigCodeBench/116", "solution": "import numpy as np\nimport matplotlib.pyplot as plt\ndef task_func(mu, sigma, sample_size):\n    # Generate a numpy array of random samples drawn from a normal distribution\n    samples = np.random.normal(mu, sigma, sample_size)\n    \n    # Plot the histogram of these samples\n    plt.hist(samples, bins=30, alpha=0.75, color='blue')\n    plt.xlabel('Sample values')\n    plt.ylabel('Frequency')\n    plt.title('Histogram of Generated Samples')\n    plt.show()\n    \n    return samples", "raw_solution": "import numpy as np\nimport matplotlib.pyplot as plt\n\ndef task_func(mu, sigma, sample_size):\n    # Generate a numpy array of random samples drawn from a normal distribution\n    samples = np.random.normal(mu, sigma, sample_size)\n    \n    # Plot the histogram of these samples\n    plt.hist(samples, bins=30, alpha=0.75, color='blue')\n    plt.xlabel('Sample values')\n    plt.ylabel('Frequency')\n    plt.title('Histogram of Generated Samples')\n    plt.show()\n    \n    return samples\n```"}
{"task_id": "BigCodeBench/117", "solution": "import pandas as pd\nimport numpy as np\nfrom random import choice, seed as set_seed\ndef task_func(num_of_students, seed=42, name_list=None, gender_list=None, age_range=(15, 20), score_range=(50, 100)):\n    if num_of_students <= 0:\n        raise ValueError(\"num_of_students must be positive\")\n    set_seed(seed)\n    if name_list is None:\n        name_list = [\"Alice\", \"Bob\", \"Charlie\", \"David\", \"Eve\", \"Frank\", \"Grace\", \"Hannah\", \"Ivy\", \"Jack\"]\n    if gender_list is None:\n        gender_list = [\"Male\", \"Female\"]\n    if age_range[0] > age_range[1]:\n        raise ValueError(\"age_range must be in ascending order\")\n    if score_range[0] > score_range[1]:\n        raise ValueError(\"score_range must be in ascending order\")\n    names = np.random.choice(name_list, num_of_students)\n    ages = np.random.randint(age_range[0], age_range[1] + 1, num_of_students)\n    genders = np.random.choice(gender_list, num_of_students)\n    scores = np.random.randint(score_range[0], score_range[1] + 1, num_of_students)\n    return pd.DataFrame({'Name': names, 'Age': ages, 'Gender': genders, 'Score': scores})", "raw_solution": "import pandas as pd\nimport numpy as np\nfrom random import choice, seed as set_seed\n\ndef task_func(num_of_students, seed=42, name_list=None, gender_list=None, age_range=(15, 20), score_range=(50, 100)):\n    if num_of_students <= 0:\n        raise ValueError(\"num_of_students must be positive\")\n    set_seed(seed)\n    if name_list is None:\n        name_list = [\"Alice\", \"Bob\", \"Charlie\", \"David\", \"Eve\", \"Frank\", \"Grace\", \"Hannah\", \"Ivy\", \"Jack\"]\n    if gender_list is None:\n        gender_list = [\"Male\", \"Female\"]\n    if age_range[0] > age_range[1]:\n        raise ValueError(\"age_range must be in ascending order\")\n    if score_range[0] > score_range[1]:\n        raise ValueError(\"score_range must be in ascending order\")\n    names = np.random.choice(name_list, num_of_students)\n    ages = np.random.randint(age_range[0], age_range[1] + 1, num_of_students)\n    genders = np.random.choice(gender_list, num_of_students)\n    scores = np.random.randint(score_range[0], score_range[1] + 1, num_of_students)\n    return pd.DataFrame({'Name': names, 'Age': ages, 'Gender': genders, 'Score': scores})\n```"}
{"task_id": "BigCodeBench/118", "solution": "import os\nimport shutil\ndef task_func(directory, backup_directory):\n    if not os.path.exists(backup_directory):\n        os.makedirs(backup_directory)\n    copied_files = []\n    for root, dirs, files in os.walk(directory):\n        for file in files:\n            if file.endswith('.json'):\n                file_path = os.path.join(root, file)\n                shutil.copy(file_path, backup_directory)\n                copied_files.append(file_path)\n    return copied_files", "raw_solution": "import os\nimport shutil\n\ndef task_func(directory, backup_directory):\n    if not os.path.exists(backup_directory):\n        os.makedirs(backup_directory)\n    copied_files = []\n    for root, dirs, files in os.walk(directory):\n        for file in files:\n            if file.endswith('.json'):\n                file_path = os.path.join(root, file)\n                shutil.copy(file_path, backup_directory)\n                copied_files.append(file_path)\n    return copied_files\n```"}
{"task_id": "BigCodeBench/119", "solution": "import numpy as np\nimport matplotlib.pyplot as plt\ndef task_func():\n    x = np.linspace(-10, 10, 400)\n    y = x**2\n    plt.plot(x, y)\n    plt.title('y = x^2')\n    plt.xlabel('x')\n    plt.ylabel('y')\n    plt.grid(True)\n    plt.show()", "raw_solution": "import numpy as np\nimport matplotlib.pyplot as plt\n\ndef task_func():\n    x = np.linspace(-10, 10, 400)\n    y = x**2\n    plt.plot(x, y)\n    plt.title('y = x^2')\n    plt.xlabel('x')\n    plt.ylabel('y')\n    plt.grid(True)\n    plt.show()\n```"}
{"task_id": "BigCodeBench/120", "solution": "import pandas as pd\nfrom datetime import datetime, timedelta\nfrom random import randint, seed as random_seed\ndef task_func(start_date=datetime(2020, 1, 1), end_date=datetime(2020, 12, 31), seed=42):\n    random_seed(seed)\n    if not isinstance(start_date, datetime) or not isinstance(end_date, datetime):\n        raise ValueError('start_date or end_date is not a datetime.datetime instance')\n    if start_date > end_date:\n        raise ValueError('start_date is later than end_date')\n    delta = end_date - start_date\n    num_days = delta.days + 1\n    dates = [start_date + timedelta(days=randint(0, num_days - 1)) for _ in range(num_days)]\n    return pd.Series(dates)", "raw_solution": "import pandas as pd\nfrom datetime import datetime, timedelta\nfrom random import randint, seed as random_seed\n\ndef task_func(start_date=datetime(2020, 1, 1), end_date=datetime(2020, 12, 31), seed=42):\n    random_seed(seed)\n    if not isinstance(start_date, datetime) or not isinstance(end_date, datetime):\n        raise ValueError('start_date or end_date is not a datetime.datetime instance')\n    if start_date > end_date:\n        raise ValueError('start_date is later than end_date')\n    delta = end_date - start_date\n    num_days = delta.days + 1\n    dates = [start_date + timedelta(days=randint(0, num_days - 1)) for _ in range(num_days)]\n    return pd.Series(dates)\n```"}
{"task_id": "BigCodeBench/121", "solution": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\ndef task_func(my_list, seed=42):\n    if not isinstance(my_list, list):\n        raise TypeError('my_list must be a list')\n    np.random.seed(seed)\n    sales_data = pd.DataFrame({\n        'Electronics': np.random.randint(10, 100, 10),\n        'Fashion': np.random.randint(10, 100, 10),\n        'Home & Kitchen': np.random.randint(10, 100, 10),\n        'Automotive': np.random.randint(10, 100, 10),\n        'Sports': np.random.randint(10, 100, 10)\n    })\n    my_list.append('12')\n    return sales_data, plt.bar(sales_data.index, sales_data.values)", "raw_solution": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef task_func(my_list, seed=42):\n    if not isinstance(my_list, list):\n        raise TypeError('my_list must be a list')\n    np.random.seed(seed)\n    sales_data = pd.DataFrame({\n        'Electronics': np.random.randint(10, 100, 10),\n        'Fashion': np.random.randint(10, 100, 10),\n        'Home & Kitchen': np.random.randint(10, 100, 10),\n        'Automotive': np.random.randint(10, 100, 10),\n        'Sports': np.random.randint(10, 100, 10)\n    })\n    my_list.append('12')\n    return sales_data, plt.bar(sales_data.index, sales_data.values)\n```"}
{"task_id": "BigCodeBench/122", "solution": "import numpy as np\nimport random\ndef task_func(my_list):\n    my_list.append(random.randint(0, 100))\n    return np.random.rand(sum(my_list))", "raw_solution": "import numpy as np\nimport random\n\ndef task_func(my_list):\n    my_list.append(random.randint(0, 100))\n    return np.random.rand(sum(my_list))\n```"}
{"task_id": "BigCodeBench/123", "solution": "import pandas as pd\nimport os\nimport glob\ndef task_func(my_list, file_dir='./data_files/', file_ext='.csv'):\n    if not isinstance(my_list, list):\n        raise TypeError('my_list is not a list')\n    if not os.path.exists(file_dir):\n        raise FileNotFoundError('no files are found in the specified directory')\n    file_list = glob.glob(os.path.join(file_dir, f'*{file_ext}'))\n    if len(file_list) == 0:\n        raise FileNotFoundError('no files are found in the specified directory')\n    df = pd.concat([pd.read_csv(file) for file in file_list])\n    return df", "raw_solution": "import pandas as pd\nimport os\nimport glob\n\ndef task_func(my_list, file_dir='./data_files/', file_ext='.csv'):\n    if not isinstance(my_list, list):\n        raise TypeError('my_list is not a list')\n    if not os.path.exists(file_dir):\n        raise FileNotFoundError('no files are found in the specified directory')\n    file_list = glob.glob(os.path.join(file_dir, f'*{file_ext}'))\n    if len(file_list) == 0:\n        raise FileNotFoundError('no files are found in the specified directory')\n    df = pd.concat([pd.read_csv(file) for file in file_list])\n    return df\n```"}
{"task_id": "BigCodeBench/124", "solution": "from random import randint, seed as random_seed\nimport time\nimport matplotlib.pyplot as plt\ndef task_func(my_list, size=100, seed=100):\n    if not isinstance(my_list, list):\n        raise TypeError('my_list is not a list')\n    if not all(isinstance(x, (int, float)) for x in my_list):\n        raise ValueError('my_list contains elements that are not numeric (int or float)')\n    random_seed(seed)\n    my_list.append(12)\n    size = sum(my_list)\n    size = min(size, 100)\n    size = max(size, 1)\n    random_numbers = [randint(1, 100) for _ in range(size)]\n    start_time = time.time()\n    plt.hist(random_numbers, bins=100)\n    plt.xlabel('Number')\n    plt.ylabel('Frequency')\n    plt.show()\n    return (time.time() - start_time, plt.gca())", "raw_solution": "from random import randint, seed as random_seed\nimport time\nimport matplotlib.pyplot as plt\n\ndef task_func(my_list, size=100, seed=100):\n    if not isinstance(my_list, list):\n        raise TypeError('my_list is not a list')\n    if not all(isinstance(x, (int, float)) for x in my_list):\n        raise ValueError('my_list contains elements that are not numeric (int or float)')\n    random_seed(seed)\n    my_list.append(12)\n    size = sum(my_list)\n    size = min(size, 100)\n    size = max(size, 1)\n    random_numbers = [randint(1, 100) for _ in range(size)]\n    start_time = time.time()\n    plt.hist(random_numbers, bins=100)\n    plt.xlabel('Number')\n    plt.ylabel('Frequency')\n    plt.show()\n    return (time.time() - start_time, plt.gca())\n```"}
{"task_id": "BigCodeBench/125", "solution": "from collections import defaultdict\nimport itertools\nimport json\nimport random\ndef task_func(LETTERS, n):\n    combinations = list(itertools.product(LETTERS, repeat=n))\n    letter_counts = defaultdict(int)\n    for combination in combinations:\n        for letter in combination:\n            letter_counts[letter] += 1\n    random_number = random.randint(0, 100)\n    file_name = f\"prefix_{random_number}.json\"\n    with open(file_name, \"w\") as f:\n        json.dump(letter_counts, f)\n    return file_name", "raw_solution": "from collections import defaultdict\nimport itertools\nimport json\nimport random\n\ndef task_func(LETTERS, n):\n    combinations = list(itertools.product(LETTERS, repeat=n))\n    letter_counts = defaultdict(int)\n    for combination in combinations:\n        for letter in combination:\n            letter_counts[letter] += 1\n    random_number = random.randint(0, 100)\n    file_name = f\"prefix_{random_number}.json\"\n    with open(file_name, \"w\") as f:\n        json.dump(letter_counts, f)\n    return file_name\n```"}
{"task_id": "BigCodeBench/126", "solution": "import pandas as pd\nfrom random import randint, seed as random_seed\nimport statistics\nimport numpy as np\ndef task_func(animals=None, seed=42):\n    random_seed(seed)\n    if animals is None:\n        animals = ['Lion', 'Tiger', 'Elephant', 'Giraffe', 'Zebra']\n    counts = []\n    for animal in animals:\n        counts.append([animal, randint(1, 100), randint(1, 100), randint(1, 100), randint(1, 100), randint(1, 100), randint(1, 100), randint(1, 100), randint(1, 100), randint(1, 100)])\n    df = pd.DataFrame(counts, columns=['Animal', 'Count 1', 'Count 2', 'Count 3', 'Count 4', 'Count 5', 'Count 6', 'Count 7', 'Count 8', 'Count 9'])\n    df['Mean'] = df.mean(axis=1)\n    df['Median'] = df.median(axis=1)\n    df['Standard Deviation'] = df.std(axis=1)\n    return df", "raw_solution": "import pandas as pd\nfrom random import randint, seed as random_seed\nimport statistics\nimport numpy as np\n\ndef task_func(animals=None, seed=42):\n    random_seed(seed)\n    if animals is None:\n        animals = ['Lion', 'Tiger', 'Elephant', 'Giraffe', 'Zebra']\n    counts = []\n    for animal in animals:\n        counts.append([animal, randint(1, 100), randint(1, 100), randint(1, 100), randint(1, 100), randint(1, 100), randint(1, 100), randint(1, 100), randint(1, 100), randint(1, 100)])\n    df = pd.DataFrame(counts, columns=['Animal', 'Count 1', 'Count 2', 'Count 3', 'Count 4', 'Count 5', 'Count 6', 'Count 7', 'Count 8', 'Count 9'])\n    df['Mean'] = df.mean(axis=1)\n    df['Median'] = df.median(axis=1)\n    df['Standard Deviation'] = df.std(axis=1)\n    return df\n```"}
{"task_id": "BigCodeBench/127", "solution": "import os\nimport shutil\nimport glob\nimport hashlib\ndef task_func(ROOT_DIR, DEST_DIR, SPECIFIC_HASH):\n    count = 0\n    for file in glob.glob(os.path.join(ROOT_DIR, '*')):\n        with open(file, 'rb') as f:\n            file_hash = hashlib.md5(f.read()).hexdigest()\n            if file_hash == SPECIFIC_HASH:\n                shutil.move(file, DEST_DIR)\n                count += 1\n    return count", "raw_solution": "import os\nimport shutil\nimport glob\nimport hashlib\n\ndef task_func(ROOT_DIR, DEST_DIR, SPECIFIC_HASH):\n    count = 0\n    for file in glob.glob(os.path.join(ROOT_DIR, '*')):\n        with open(file, 'rb') as f:\n            file_hash = hashlib.md5(f.read()).hexdigest()\n            if file_hash == SPECIFIC_HASH:\n                shutil.move(file, DEST_DIR)\n                count += 1\n    return count\n```"}
{"task_id": "BigCodeBench/128", "solution": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom random import randint\nimport math\ndef task_func(POINTS=100):\n    x = np.zeros(POINTS)\n    y = np.zeros(POINTS)\n    for i in range(POINTS):\n        direction = randint(0, 3)\n        if direction == 0:\n            x[i] = x[i-1] + 1\n            y[i] = y[i-1]\n        elif direction == 1:\n            x[i] = x[i-1] - 1\n            y[i] = y[i-1]\n        elif direction == 2:\n            x[i] = x[i-1]\n            y[i] = y[i-1] + 1\n        else:\n            x[i] = x[i-1]\n            y[i] = y[i-1] - 1\n    plt.plot(x, y)\n    plt.show()\n    return plt", "raw_solution": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom random import randint\nimport math\n\ndef task_func(POINTS=100):\n    x = np.zeros(POINTS)\n    y = np.zeros(POINTS)\n    for i in range(POINTS):\n        direction = randint(0, 3)\n        if direction == 0:\n            x[i] = x[i-1] + 1\n            y[i] = y[i-1]\n        elif direction == 1:\n            x[i] = x[i-1] - 1\n            y[i] = y[i-1]\n        elif direction == 2:\n            x[i] = x[i-1]\n            y[i] = y[i-1] + 1\n        else:\n            x[i] = x[i-1]\n            y[i] = y[i-1] - 1\n    plt.plot(x, y)\n    plt.show()\n    return plt\n```"}
{"task_id": "BigCodeBench/129", "solution": "import requests\nfrom bs4 import BeautifulSoup\nimport pandas as pd\ndef task_func(url='http://example.com'):\n    try:\n        response = requests.get(url)\n        response.raise_for_status()\n        soup = BeautifulSoup(response.content, 'html.parser')\n        table = soup.find('table')\n        if table is None:\n            raise ValueError('No table data found on the page')\n        headers = [th.text for th in table.find_all('th')]\n        rows = table.find_all('tr')\n        data = []\n        for row in rows:\n            cells = row.find_all(['td', 'th'])\n            row_data = [cell.text for cell in cells]\n            data.append(row_data)\n        df = pd.DataFrame(data, columns=headers)\n        return df\n    except requests.ConnectionError as e:\n        raise ConnectionError('ConnectionError: ' + str(e))\n    except requests.HTTPError as e:\n        raise requests.HTTPError('HTTPError: ' + str(e))\n    except ValueError as e:\n        raise ValueError('ValueError: ' + str(e))", "raw_solution": "import requests\nfrom bs4 import BeautifulSoup\nimport pandas as pd\n\ndef task_func(url='http://example.com'):\n    try:\n        response = requests.get(url)\n        response.raise_for_status()\n        soup = BeautifulSoup(response.content, 'html.parser')\n        table = soup.find('table')\n        if table is None:\n            raise ValueError('No table data found on the page')\n        headers = [th.text for th in table.find_all('th')]\n        rows = table.find_all('tr')\n        data = []\n        for row in rows:\n            cells = row.find_all(['td', 'th'])\n            row_data = [cell.text for cell in cells]\n            data.append(row_data)\n        df = pd.DataFrame(data, columns=headers)\n        return df\n    except requests.ConnectionError as e:\n        raise ConnectionError('ConnectionError: ' + str(e))\n    except requests.HTTPError as e:\n        raise requests.HTTPError('HTTPError: ' + str(e))\n    except ValueError as e:\n        raise ValueError('ValueError: ' + str(e))\n```"}
{"task_id": "BigCodeBench/130", "solution": "import base64\nimport binascii\nimport os\nimport hashlib\ndef task_func(hex_str, salt_size):\n    salt = os.urandom(salt_size)\n    salted_data = binascii.unhexlify(hex_str) + salt\n    hash = hashlib.sha256(salted_data).hexdigest()\n    return (base64.b64encode(salt).decode(), hash)", "raw_solution": "import base64\nimport binascii\nimport os\nimport hashlib\n\ndef task_func(hex_str, salt_size):\n    salt = os.urandom(salt_size)\n    salted_data = binascii.unhexlify(hex_str) + salt\n    hash = hashlib.sha256(salted_data).hexdigest()\n    return (base64.b64encode(salt).decode(), hash)\n```"}
{"task_id": "BigCodeBench/131", "solution": "import base64\nimport binascii\nimport os\nimport hashlib\ndef task_func(hex_str, salt_size):\n    salt = os.urandom(salt_size)\n    salted_data = binascii.unhexlify(hex_str) + salt\n    hash = hashlib.sha256(salted_data).hexdigest()\n    return (base64.b64encode(salt).decode('utf-8'), hash)", "raw_solution": "import base64\nimport binascii\nimport os\nimport hashlib\n\ndef task_func(hex_str, salt_size):\n    salt = os.urandom(salt_size)\n    salted_data = binascii.unhexlify(hex_str) + salt\n    hash = hashlib.sha256(salted_data).hexdigest()\n    return (base64.b64encode(salt).decode('utf-8'), hash)\n```"}
{"task_id": "BigCodeBench/132", "solution": "import binascii\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\ndef task_func(hex_str):\n    if not isinstance(hex_str, str):\n        raise ValueError(\"hex_str must be a string\")\n    if hex_str.startswith(\"\\\\x\"):\n        hex_str = hex_str[2:]\n    try:\n        bytes_obj = binascii.unhexlify(hex_str)\n    except binascii.Error:\n        raise ValueError(\"hex_str is not a valid hex string\")\n    byte_freq = np.bincount(bytes_obj)\n    df = pd.DataFrame({'Byte Value': bytes_obj, 'Frequency': byte_freq})\n    fig, ax = plt.subplots()\n    ax.bar(df['Byte Value'], df['Frequency'])\n    ax.set_xlabel('Byte Value')\n    ax.set_ylabel('Frequency')\n    return (df, ax)", "raw_solution": "import binascii\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\ndef task_func(hex_str):\n    if not isinstance(hex_str, str):\n        raise ValueError(\"hex_str must be a string\")\n    if hex_str.startswith(\"\\\\x\"):\n        hex_str = hex_str[2:]\n    try:\n        bytes_obj = binascii.unhexlify(hex_str)\n    except binascii.Error:\n        raise ValueError(\"hex_str is not a valid hex string\")\n    byte_freq = np.bincount(bytes_obj)\n    df = pd.DataFrame({'Byte Value': bytes_obj, 'Frequency': byte_freq})\n    fig, ax = plt.subplots()\n    ax.bar(df['Byte Value'], df['Frequency'])\n    ax.set_xlabel('Byte Value')\n    ax.set_ylabel('Frequency')\n    return (df, ax)\n```"}
{"task_id": "BigCodeBench/133", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import MinMaxScaler\ndef task_func(df):\n    if not isinstance(df, pd.DataFrame) or df.empty:\n        raise ValueError(\"If the input is not a DataFrame or if the DataFrame is empty.\")\n    scaler = MinMaxScaler()\n    df.iloc[:, -1] = scaler.fit_transform(df.iloc[:, -1].values.reshape(-1, 1))\n    plt.title('Normalized Data of ' + df.columns[-1])\n    plt.xlabel('Index')\n    plt.ylabel('Normalized Value')\n    plt.plot(df.index, df.iloc[:, -1])\n    plt.show()\n    return df, plt.gca()", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import MinMaxScaler\n\ndef task_func(df):\n    if not isinstance(df, pd.DataFrame) or df.empty:\n        raise ValueError(\"If the input is not a DataFrame or if the DataFrame is empty.\")\n    scaler = MinMaxScaler()\n    df.iloc[:, -1] = scaler.fit_transform(df.iloc[:, -1].values.reshape(-1, 1))\n    plt.title('Normalized Data of ' + df.columns[-1])\n    plt.xlabel('Index')\n    plt.ylabel('Normalized Value')\n    plt.plot(df.index, df.iloc[:, -1])\n    plt.show()\n    return df, plt.gca()\n```"}
{"task_id": "BigCodeBench/134", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\ndef task_func(df, bins=20):\n    if not isinstance(df, pd.DataFrame) or df.empty:\n        raise ValueError(\"If the input is not a DataFrame, or if the DataFrame is empty.\")\n    plt.hist(df.iloc[:, -1], bins=bins)\n    plt.title('Histogram of ' + df.columns[-1])\n    plt.xlabel('Value')\n    plt.ylabel('Frequency')\n    return plt", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\n\ndef task_func(df, bins=20):\n    if not isinstance(df, pd.DataFrame) or df.empty:\n        raise ValueError(\"If the input is not a DataFrame, or if the DataFrame is empty.\")\n    plt.hist(df.iloc[:, -1], bins=bins)\n    plt.title('Histogram of ' + df.columns[-1])\n    plt.xlabel('Value')\n    plt.ylabel('Frequency')\n    return plt\n```"}
{"task_id": "BigCodeBench/135", "solution": "import numpy as np\nimport pandas as pd\nfrom sklearn.impute import SimpleImputer\nimport seaborn as sns\nimport matplotlib.pyplot as plt\ndef task_func(df):\n    if not isinstance(df, pd.DataFrame) or df.empty:\n        raise ValueError(\"If the input is not a DataFrame or has no columns.\")\n    imputer = SimpleImputer(strategy='mean')\n    df.iloc[:, -1] = imputer.fit_transform(df.iloc[:, -1].values.reshape(-1, 1))\n    ax = sns.boxplot(x=df.iloc[:, -1])\n    return df, ax", "raw_solution": "import numpy as np\nimport pandas as pd\nfrom sklearn.impute import SimpleImputer\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\ndef task_func(df):\n    if not isinstance(df, pd.DataFrame) or df.empty:\n        raise ValueError(\"If the input is not a DataFrame or has no columns.\")\n    imputer = SimpleImputer(strategy='mean')\n    df.iloc[:, -1] = imputer.fit_transform(df.iloc[:, -1].values.reshape(-1, 1))\n    ax = sns.boxplot(x=df.iloc[:, -1])\n    return df, ax\n```"}
{"task_id": "BigCodeBench/136", "solution": "import pandas as pd\nfrom sklearn.decomposition import PCA\nimport matplotlib.pyplot as plt\ndef task_func(df):\n    if not isinstance(df, pd.DataFrame) or df.empty:\n        raise ValueError(\"If the input is not a DataFrame, or if the DataFrame is empty.\")\n    pca = PCA(n_components=2)\n    principalComponents = pca.fit_transform(df)\n    principalDf = pd.DataFrame(data=principalComponents, columns=['Principal Component 1', 'Principal Component 2'])\n    plt.figure(figsize=(8, 8))\n    plt.scatter(principalDf['Principal Component 1'], principalDf['Principal Component 2'], c=df['target'], cmap='viridis')\n    plt.title('2 Component PCA')\n    plt.xlabel('Principal Component 1')\n    plt.ylabel('Principal Component 2')\n    plt.show()\n    return principalDf, plt.gca()", "raw_solution": "import pandas as pd\nfrom sklearn.decomposition import PCA\nimport matplotlib.pyplot as plt\n\ndef task_func(df):\n    if not isinstance(df, pd.DataFrame) or df.empty:\n        raise ValueError(\"If the input is not a DataFrame, or if the DataFrame is empty.\")\n    pca = PCA(n_components=2)\n    principalComponents = pca.fit_transform(df)\n    principalDf = pd.DataFrame(data=principalComponents, columns=['Principal Component 1', 'Principal Component 2'])\n    plt.figure(figsize=(8, 8))\n    plt.scatter(principalDf['Principal Component 1'], principalDf['Principal Component 2'], c=df['target'], cmap='viridis')\n    plt.title('2 Component PCA')\n    plt.xlabel('Principal Component 1')\n    plt.ylabel('Principal Component 2')\n    plt.show()\n    return principalDf, plt.gca()\n```"}
{"task_id": "BigCodeBench/137", "solution": "import pandas as pd\nfrom scipy.stats import skew\ndef task_func(df):\n    if not isinstance(df, pd.DataFrame) or len(df.columns) == 0:\n        raise ValueError(\"If the input is not a DataFrame or has no columns.\")\n    return skew(df.iloc[:, -1])", "raw_solution": "import pandas as pd\nfrom scipy.stats import skew\n\ndef task_func(df):\n    if not isinstance(df, pd.DataFrame) or len(df.columns) == 0:\n        raise ValueError(\"If the input is not a DataFrame or has no columns.\")\n    return skew(df.iloc[:, -1])\n```"}
{"task_id": "BigCodeBench/138", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\ndef task_func(df, letters=list('ABCDEFGHIJKLMNOPQRSTUVWXYZ')):\n    if not isinstance(df, pd.DataFrame) or 'Letters' not in df.columns:\n        raise ValueError('If \\'df\\' is not a DataFrame or lacks the \\'Letters\\' column.')\n    letter_freq = df['Letters'].value_counts()\n    plt.bar(letter_freq.index, letter_freq.values)\n    plt.xlabel('Letters')\n    plt.ylabel('Frequency')\n    plt.title('Letter Frequency')\n    return plt", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\n\ndef task_func(df, letters=list('ABCDEFGHIJKLMNOPQRSTUVWXYZ')):\n    if not isinstance(df, pd.DataFrame) or 'Letters' not in df.columns:\n        raise ValueError('If \\'df\\' is not a DataFrame or lacks the \\'Letters\\' column.')\n    letter_freq = df['Letters'].value_counts()\n    plt.bar(letter_freq.index, letter_freq.values)\n    plt.xlabel('Letters')\n    plt.ylabel('Frequency')\n    plt.title('Letter Frequency')\n    return plt\n```"}
{"task_id": "BigCodeBench/139", "solution": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\ndef task_func(df):\n    if not isinstance(df, pd.DataFrame) or df.empty:\n        raise ValueError(\"If the input is not a non-empty DataFrame or if there are no numeric columns in the DataFrame.\")\n    numeric_columns = df.select_dtypes(include=[np.number]).columns\n    if not numeric_columns:\n        raise ValueError(\"If the input is not a non-empty DataFrame or if there are no numeric columns in the DataFrame.\")\n    plots = []\n    for column in numeric_columns:\n        plt.figure()\n        plt.hist(df[column], bins=30)\n        plt.title(column)\n        plt.xlabel('Value')\n        plt.ylabel('Frequency')\n        plt.show()\n        plots.append(plt.gca())\n    return plots", "raw_solution": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef task_func(df):\n    if not isinstance(df, pd.DataFrame) or df.empty:\n        raise ValueError(\"If the input is not a non-empty DataFrame or if there are no numeric columns in the DataFrame.\")\n    numeric_columns = df.select_dtypes(include=[np.number]).columns\n    if not numeric_columns:\n        raise ValueError(\"If the input is not a non-empty DataFrame or if there are no numeric columns in the DataFrame.\")\n    plots = []\n    for column in numeric_columns:\n        plt.figure()\n        plt.hist(df[column], bins=30)\n        plt.title(column)\n        plt.xlabel('Value')\n        plt.ylabel('Frequency')\n        plt.show()\n        plots.append(plt.gca())\n    return plots\n```"}
{"task_id": "BigCodeBench/140", "solution": "import pandas as pd\nfrom sklearn.preprocessing import StandardScaler\ndef task_func(df, cols):\n    if not isinstance(df, pd.DataFrame):\n        raise ValueError('df is not a DataFrame')\n    if not isinstance(cols, list):\n        raise ValueError('cols is not a list')\n    if not all(col in df.columns for col in cols):\n        raise ValueError('columns in cols don\\'t exist in df')\n    scaler = StandardScaler()\n    df[cols] = scaler.fit_transform(df[cols])\n    return df", "raw_solution": "import pandas as pd\nfrom sklearn.preprocessing import StandardScaler\n\ndef task_func(df, cols):\n    if not isinstance(df, pd.DataFrame):\n        raise ValueError('df is not a DataFrame')\n    if not isinstance(cols, list):\n        raise ValueError('cols is not a list')\n    if not all(col in df.columns for col in cols):\n        raise ValueError('columns in cols don\\'t exist in df')\n    scaler = StandardScaler()\n    df[cols] = scaler.fit_transform(df[cols])\n    return df\n```"}
{"task_id": "BigCodeBench/141", "solution": "import numpy as np\nimport pandas as pd\nimport statistics\ndef task_func(rows, columns=['A', 'B', 'C', 'D', 'E', 'F'], seed=42):\n    if rows <= 0:\n        raise ValueError('If \\'rows\\' is not a positive integer greater than 0.')\n    np.random.seed(seed)\n    df = pd.DataFrame(np.random.randint(1, 101, (rows, len(columns))), columns=columns)\n    means = df.mean()\n    medians = df.median()\n    return df, means.to_dict(), medians.to_dict()", "raw_solution": "import numpy as np\nimport pandas as pd\nimport statistics\ndef task_func(rows, columns=['A', 'B', 'C', 'D', 'E', 'F'], seed=42):\n    if rows <= 0:\n        raise ValueError('If \\'rows\\' is not a positive integer greater than 0.')\n    np.random.seed(seed)\n    df = pd.DataFrame(np.random.randint(1, 101, (rows, len(columns))), columns=columns)\n    means = df.mean()\n    medians = df.median()\n    return df, means.to_dict(), medians.to_dict()\n```"}
{"task_id": "BigCodeBench/142", "solution": "import numpy as np\nimport matplotlib.pyplot as plt\ndef task_func():\n    x = np.linspace(0, 2 * np.pi, 1000)\n    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n    ax1.plot(x, np.sin(x), label='Sine function')\n    ax1.set_title('Sine function')\n    ax1.set_xlabel('x')\n    ax1.set_ylabel('sin(x)')\n    ax1.legend()\n    ax2.plot(x, np.cos(x), label='Cosine function')\n    ax2.set_title('Cosine function')\n    ax2.set_xlabel('x')\n    ax2.set_ylabel('cos(x)')\n    ax2.legend()\n    return fig, np.array([ax1, ax2])", "raw_solution": "import numpy as np\nimport matplotlib.pyplot as plt\n\ndef task_func():\n    x = np.linspace(0, 2 * np.pi, 1000)\n    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n    ax1.plot(x, np.sin(x), label='Sine function')\n    ax1.set_title('Sine function')\n    ax1.set_xlabel('x')\n    ax1.set_ylabel('sin(x)')\n    ax1.legend()\n    ax2.plot(x, np.cos(x), label='Cosine function')\n    ax2.set_title('Cosine function')\n    ax2.set_xlabel('x')\n    ax2.set_ylabel('cos(x)')\n    ax2.legend()\n    return fig, np.array([ax1, ax2])\n```"}
{"task_id": "BigCodeBench/143", "solution": "import numpy as np\nimport matplotlib.pyplot as plt\ndef task_func():\n    x = np.linspace(-10, 10, 100)\n    y = 2 * x + 1\n    plt.plot(x, y, label='y=2x+1')\n    plt.scatter(2, 5, color='green', label='x=2')\n    plt.title('Solution of the equation y=2x+1 at x=2')\n    plt.xlabel('x')\n    plt.ylabel('y')\n    plt.legend()\n    plt.show()", "raw_solution": "import numpy as np\nimport matplotlib.pyplot as plt\n\ndef task_func():\n    x = np.linspace(-10, 10, 100)\n    y = 2 * x + 1\n    plt.plot(x, y, label='y=2x+1')\n    plt.scatter(2, 5, color='green', label='x=2')\n    plt.title('Solution of the equation y=2x+1 at x=2')\n    plt.xlabel('x')\n    plt.ylabel('y')\n    plt.legend()\n    plt.show()\n```"}
{"task_id": "BigCodeBench/144", "solution": "import ipaddress\nimport requests\ndef task_func(ip_range, timeout):\n    try:\n        ip_network = ipaddress.ip_network(ip_range)\n    except ValueError:\n        raise ValueError('Invalid IP range provided')\n    active_ips = []\n    for ip in ip_network:\n        try:\n            response = requests.get(f'http://{ip}', timeout=timeout)\n            if response.status_code == 200:\n                active_ips.append(ip)\n        except requests.exceptions.RequestException:\n            continue\n    return active_ips", "raw_solution": "import ipaddress\nimport requests\n\ndef task_func(ip_range, timeout):\n    try:\n        ip_network = ipaddress.ip_network(ip_range)\n    except ValueError:\n        raise ValueError('Invalid IP range provided')\n    active_ips = []\n    for ip in ip_network:\n        try:\n            response = requests.get(f'http://{ip}', timeout=timeout)\n            if response.status_code == 200:\n                active_ips.append(ip)\n        except requests.exceptions.RequestException:\n            continue\n    return active_ips\n```"}
{"task_id": "BigCodeBench/145", "solution": "import csv\nfrom ipaddress import IPv4Network\ndef task_func(ip_range, csv_path):\n    network = IPv4Network(ip_range)\n    with open(csv_path, 'w', newline='') as file:\n        writer = csv.writer(file)\n        for ip in network:\n            writer.writerow([str(ip)])\n    return csv_path", "raw_solution": "import csv\nfrom ipaddress import IPv4Network\n\ndef task_func(ip_range, csv_path):\n    network = IPv4Network(ip_range)\n    with open(csv_path, 'w', newline='') as file:\n        writer = csv.writer(file)\n        for ip in network:\n            writer.writerow([str(ip)])\n    return csv_path\n```"}
{"task_id": "BigCodeBench/146", "solution": "import subprocess\nfrom ipaddress import IPv4Network\ndef task_func(ip_range):\n    try:\n        network = IPv4Network(ip_range)\n        active_ips = {}\n        for ip in network:\n            ping_result = subprocess.run(['ping', '-c', '1', str(ip)], capture_output=True, text=True)\n            if ping_result.returncode == 0:\n                active_ips[str(ip)] = True\n            else:\n                active_ips[str(ip)] = False\n        return active_ips\n    except subprocess.CalledProcessError:\n        raise", "raw_solution": "import subprocess\nfrom ipaddress import IPv4Network\n\ndef task_func(ip_range):\n    try:\n        network = IPv4Network(ip_range)\n        active_ips = {}\n        for ip in network:\n            ping_result = subprocess.run(['ping', '-c', '1', str(ip)], capture_output=True, text=True)\n            if ping_result.returncode == 0:\n                active_ips[str(ip)] = True\n            else:\n                active_ips[str(ip)] = False\n        return active_ips\n    except subprocess.CalledProcessError:\n        raise\n```"}
{"task_id": "BigCodeBench/147", "solution": "import socket\nfrom ipaddress import IPv4Network\nfrom threading import Thread\ndef task_func(ip_range, port):\n    ip_network = IPv4Network(ip_range)\n    result = {}\n    for ip in ip_network:\n        try:\n            sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n            sock.settimeout(1)\n            result[ip] = sock.connect_ex((str(ip), port)) == 0\n        except socket.error:\n            result[ip] = False\n        finally:\n            sock.close()\n    return result", "raw_solution": "import socket\nfrom ipaddress import IPv4Network\nfrom threading import Thread\n\ndef task_func(ip_range, port):\n    ip_network = IPv4Network(ip_range)\n    result = {}\n    for ip in ip_network:\n        try:\n            sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n            sock.settimeout(1)\n            result[ip] = sock.connect_ex((str(ip), port)) == 0\n        except socket.error:\n            result[ip] = False\n        finally:\n            sock.close()\n    return result\n```"}
{"task_id": "BigCodeBench/148", "solution": "import pandas as pd\nfrom sklearn.preprocessing import LabelEncoder\ndef task_func(df: pd.DataFrame, column_name: str) -> pd.DataFrame:\n    le = LabelEncoder()\n    df[column_name] = le.fit_transform(df[column_name])\n    return df", "raw_solution": "import pandas as pd\nfrom sklearn.preprocessing import LabelEncoder\n\ndef task_func(df: pd.DataFrame, column_name: str) -> pd.DataFrame:\n    le = LabelEncoder()\n    df[column_name] = le.fit_transform(df[column_name])\n    return df\n```"}
{"task_id": "BigCodeBench/149", "solution": "import pandas as pd\nimport numpy as np\nDEFAULT_COLUMNS = ['Element', 'Count']\ndef task_func(elements, include_index=False):\n    df = pd.DataFrame(columns=DEFAULT_COLUMNS)\n    for i, element in enumerate(elements):\n        df.loc[i] = [element, len(element)]\n    if include_index:\n        df['Index'] = range(len(elements))\n    return df", "raw_solution": "import pandas as pd\nimport numpy as np\nDEFAULT_COLUMNS = ['Element', 'Count']\ndef task_func(elements, include_index=False):\n    df = pd.DataFrame(columns=DEFAULT_COLUMNS)\n    for i, element in enumerate(elements):\n        df.loc[i] = [element, len(element)]\n    if include_index:\n        df['Index'] = range(len(elements))\n    return df\n```"}
{"task_id": "BigCodeBench/150", "solution": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\ndef task_func(product_dict, product_keys):\n    # Create a DataFrame from the product dictionary\n    df = pd.DataFrame(product_dict, index=product_keys)\n    # Calculate the profit for each product\n    df['Profit'] = df['Quantity'] * df['Price']\n    # Calculate the average price and profit for all considered products\n    avg_price = df['Price'].mean()\n    avg_profit = df['Profit'].mean()\n    # Plot a bar chart of the profit for each product\n    ax = df['Profit'].plot(kind='bar')\n    ax.set_xlabel('Product')\n    ax.set_ylabel('Profit')\n    ax.set_title('Profit Report')\n    return (df, ax)", "raw_solution": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef task_func(product_dict, product_keys):\n    # Create a DataFrame from the product dictionary\n    df = pd.DataFrame(product_dict, index=product_keys)\n    # Calculate the profit for each product\n    df['Profit'] = df['Quantity'] * df['Price']\n    # Calculate the average price and profit for all considered products\n    avg_price = df['Price'].mean()\n    avg_profit = df['Profit'].mean()\n    # Plot a bar chart of the profit for each product\n    ax = df['Profit'].plot(kind='bar')\n    ax.set_xlabel('Product')\n    ax.set_ylabel('Profit')\n    ax.set_title('Profit Report')\n    return (df, ax)\n```"}
{"task_id": "BigCodeBench/151", "solution": "import pandas as pd\nfrom sklearn.preprocessing import MinMaxScaler\ndef task_func(data_dict, data_keys):\n    if not data_keys:\n        raise ValueError(\"If no keys in `data_keys` are found in `data_dict`.\")\n    df = pd.DataFrame(data_dict)\n    scaler = MinMaxScaler()\n    df_scaled = scaler.fit_transform(df[data_keys])\n    fig, ax = plt.subplots()\n    ax.plot(df_scaled)\n    return df_scaled, ax", "raw_solution": "import pandas as pd\nfrom sklearn.preprocessing import MinMaxScaler\n\ndef task_func(data_dict, data_keys):\n    if not data_keys:\n        raise ValueError(\"If no keys in `data_keys` are found in `data_dict`.\")\n    df = pd.DataFrame(data_dict)\n    scaler = MinMaxScaler()\n    df_scaled = scaler.fit_transform(df[data_keys])\n    fig, ax = plt.subplots()\n    ax.plot(df_scaled)\n    return df_scaled, ax\n```"}
{"task_id": "BigCodeBench/152", "solution": "import pandas as pd\nimport numpy as np\nfrom random import randint\nSTUDENTS = ['Joe', 'Amy', 'Mark', 'Sara', 'John', 'Emily', 'Zoe', 'Matt']\nCOURSES = ['Math', 'Physics', 'Chemistry', 'Biology', 'English', 'History', 'Geography', 'Computer Science']\ndef task_func():\n    # Generate random grades for each student across each course\n    grades = np.random.uniform(0, 100, (len(STUDENTS), len(COURSES)))\n    # Calculate average grade for each student\n    avg_grades = np.mean(grades, axis=1)\n    # Create DataFrame\n    df = pd.DataFrame({'Student': STUDENTS, 'Course': COURSES, 'Grade': grades, 'Average Grade': avg_grades})\n    return df", "raw_solution": "import pandas as pd\nimport numpy as np\nfrom random import randint\n# Constants\nSTUDENTS = ['Joe', 'Amy', 'Mark', 'Sara', 'John', 'Emily', 'Zoe', 'Matt']\nCOURSES = ['Math', 'Physics', 'Chemistry', 'Biology', 'English', 'History', 'Geography', 'Computer Science']\n\ndef task_func():\n    # Generate random grades for each student across each course\n    grades = np.random.uniform(0, 100, (len(STUDENTS), len(COURSES)))\n    # Calculate average grade for each student\n    avg_grades = np.mean(grades, axis=1)\n    # Create DataFrame\n    df = pd.DataFrame({'Student': STUDENTS, 'Course': COURSES, 'Grade': grades, 'Average Grade': avg_grades})\n    return df\n```"}
{"task_id": "BigCodeBench/153", "solution": "import pandas as pd\nfrom sklearn.preprocessing import LabelEncoder\ndef task_func(data):\n    le = LabelEncoder()\n    data['Encoded'] = le.fit_transform(data['Category'])\n    return pd.DataFrame({'Category': data['Category'], 'Encoded': data['Encoded']})", "raw_solution": "import pandas as pd\nfrom sklearn.preprocessing import LabelEncoder\n\ndef task_func(data):\n    le = LabelEncoder()\n    data['Encoded'] = le.fit_transform(data['Category'])\n    return pd.DataFrame({'Category': data['Category'], 'Encoded': data['Encoded']})\n```"}
{"task_id": "BigCodeBench/154", "solution": "import re\nimport os\nimport glob\nimport mimetypes\ndef task_func(directory, file_pattern, suffix):\n    file_types = {}\n    for file in glob.glob(os.path.join(directory, file_pattern + '*' + suffix)):\n        file_types[file] = mimetypes.guess_type(file)[0]\n    return file_types", "raw_solution": "import re\nimport os\nimport glob\nimport mimetypes\ndef task_func(directory, file_pattern, suffix):\n    file_types = {}\n    for file in glob.glob(os.path.join(directory, file_pattern + '*' + suffix)):\n        file_types[file] = mimetypes.guess_type(file)[0]\n    return file_types\n```"}
{"task_id": "BigCodeBench/155", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\ndef task_func(data):\n    # Compute the average of each row\n    averages = data.mean(axis=1)\n    # Append the averages as a new column\n    data['Average'] = averages\n    # Plot the averages against their respective row indices\n    plt.plot(data.index, data['Average'])\n    plt.xlabel('Row Index')\n    plt.ylabel('Average')\n    plt.show()\n    return data, plt.gca()", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\n# Constants\nCOLUMN_NAMES = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H']\ndef task_func(data):\n    # Compute the average of each row\n    averages = data.mean(axis=1)\n    # Append the averages as a new column\n    data['Average'] = averages\n    # Plot the averages against their respective row indices\n    plt.plot(data.index, data['Average'])\n    plt.xlabel('Row Index')\n    plt.ylabel('Average')\n    plt.show()\n    return data, plt.gca()\n```"}
{"task_id": "BigCodeBench/156", "solution": "import pandas as pd\nfrom sklearn.preprocessing import MinMaxScaler\nimport matplotlib.pyplot as plt\ndef task_func(data):\n    scaler = MinMaxScaler()\n    normalized_data = scaler.fit_transform(data)\n    average_data = normalized_data.mean(axis=1)\n    df = pd.DataFrame(normalized_data, columns=data.columns)\n    df['Average'] = average_data\n    plt.figure(figsize=(10, 5))\n    plt.bar(df.index, average_data)\n    plt.xlabel('Index')\n    plt.ylabel('Average')\n    plt.title('Average of each row')\n    plt.show()\n    return df", "raw_solution": "import pandas as pd\nfrom sklearn.preprocessing import MinMaxScaler\nimport matplotlib.pyplot as plt\n\ndef task_func(data):\n    scaler = MinMaxScaler()\n    normalized_data = scaler.fit_transform(data)\n    average_data = normalized_data.mean(axis=1)\n    df = pd.DataFrame(normalized_data, columns=data.columns)\n    df['Average'] = average_data\n    plt.figure(figsize=(10, 5))\n    plt.bar(df.index, average_data)\n    plt.xlabel('Index')\n    plt.ylabel('Average')\n    plt.title('Average of each row')\n    plt.show()\n    return df\n```"}
{"task_id": "BigCodeBench/157", "solution": "import pandas as pd\nimport seaborn as sns\ndef task_func(data):\n    if not isinstance(data, pd.DataFrame) or not data.shape[1] == 1:\n        raise ValueError(\"If the input data is not a 2D array or if it contains non-numeric data.\")\n    data['Average'] = data.mean(axis=1)\n    corr_matrix = data.corr()\n    sns.heatmap(corr_matrix, annot=True)\n    return data, sns.plt.gca()", "raw_solution": "import pandas as pd\nimport seaborn as sns\n\ndef task_func(data):\n    if not isinstance(data, pd.DataFrame) or not data.shape[1] == 1:\n        raise ValueError(\"If the input data is not a 2D array or if it contains non-numeric data.\")\n    data['Average'] = data.mean(axis=1)\n    corr_matrix = data.corr()\n    sns.heatmap(corr_matrix, annot=True)\n    return data, sns.plt.gca()\n```"}
{"task_id": "BigCodeBench/158", "solution": "import json\nimport urllib.request\nimport urllib.parse\nimport gzip\ndef task_func(url_str, file_path):\n    # Fetch JSON data from the given URL\n    response = urllib.request.urlopen(url_str)\n    data = response.read()\n    \n    # Decode the JSON-formatted data\n    data = json.loads(data.decode('utf-8'))\n    \n    # Compress the data into a gzip file\n    with gzip.open(file_path, 'wb') as f:\n        f.write(json.dumps(data).encode('utf-8'))\n    \n    return file_path", "raw_solution": "import json\nimport urllib.request\nimport urllib.parse\nimport gzip\n\ndef task_func(url_str, file_path):\n    # Fetch JSON data from the given URL\n    response = urllib.request.urlopen(url_str)\n    data = response.read()\n    \n    # Decode the JSON-formatted data\n    data = json.loads(data.decode('utf-8'))\n    \n    # Compress the data into a gzip file\n    with gzip.open(file_path, 'wb') as f:\n        f.write(json.dumps(data).encode('utf-8'))\n    \n    return file_path\n```"}
{"task_id": "BigCodeBench/159", "solution": "import struct\nimport io\nimport gzip\ndef task_func(newArray):\n    # Pack the array elements into bytes\n    packed_data = struct.pack('f' * len(newArray), *newArray)\n    # Compress the packed data using gzip\n    compressed_data = gzip.compress(packed_data)\n    return compressed_data", "raw_solution": "import struct\nimport io\nimport gzip\n\ndef task_func(newArray):\n    # Pack the array elements into bytes\n    packed_data = struct.pack('f' * len(newArray), *newArray)\n    # Compress the packed data using gzip\n    compressed_data = gzip.compress(packed_data)\n    return compressed_data\n```"}
{"task_id": "BigCodeBench/160", "solution": "import pandas as pd\nimport seaborn as sns\nfrom scipy import stats\ndef task_func(data):\n    if data.shape[1] != 8:\n        raise ValueError(\"The input data does not have exactly eight columns.\")\n    # Compute the average of each row\n    data['Average'] = data.mean(axis=1)\n    # Plot the distribution of these averages\n    sns.distplot(data['Average'])\n    # Evaluate their normality\n    p_value = stats.normaltest(data['Average']).pvalue\n    return data, sns.distplot(data['Average']), p_value", "raw_solution": "import pandas as pd\nimport seaborn as sns\nfrom scipy import stats\n# Constants\nCOLUMN_NAMES = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H']\ndef task_func(data):\n    if data.shape[1] != 8:\n        raise ValueError(\"The input data does not have exactly eight columns.\")\n    # Compute the average of each row\n    data['Average'] = data.mean(axis=1)\n    # Plot the distribution of these averages\n    sns.distplot(data['Average'])\n    # Evaluate their normality\n    p_value = stats.normaltest(data['Average']).pvalue\n    return data, sns.distplot(data['Average']), p_value\n```"}
{"task_id": "BigCodeBench/161", "solution": "import re\nimport pandas as pd\nfrom datetime import datetime\ndef task_func(log_file):\n    # Read the log file\n    with open(log_file, 'r') as f:\n        log_data = f.read()\n    \n    # Extract the log entries\n    log_entries = re.findall(r'(\\w+): \\[(\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2})\\] - (.+)', log_data)\n    \n    # Check if any valid log entries are found\n    if not log_entries:\n        raise ValueError('No valid log entries found')\n    \n    # Create a pandas DataFrame from the log entries\n    df = pd.DataFrame(log_entries, columns=['Type', 'Timestamp', 'Message'])\n    \n    # Convert the Timestamp column to datetime\n    df['Timestamp'] = pd.to_datetime(df['Timestamp'])\n    \n    # Save the DataFrame to a CSV file\n    csv_file = log_file.replace('.log', '.csv')\n    df.to_csv(csv_file, index=False)\n    \n    # Return the file path to the newly created CSV file\n    return csv_file", "raw_solution": "import re\nimport pandas as pd\nfrom datetime import datetime\n\ndef task_func(log_file):\n    # Read the log file\n    with open(log_file, 'r') as f:\n        log_data = f.read()\n    \n    # Extract the log entries\n    log_entries = re.findall(r'(\\w+): \\[(\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2})\\] - (.+)', log_data)\n    \n    # Check if any valid log entries are found\n    if not log_entries:\n        raise ValueError('No valid log entries found')\n    \n    # Create a pandas DataFrame from the log entries\n    df = pd.DataFrame(log_entries, columns=['Type', 'Timestamp', 'Message'])\n    \n    # Convert the Timestamp column to datetime\n    df['Timestamp'] = pd.to_datetime(df['Timestamp'])\n    \n    # Save the DataFrame to a CSV file\n    csv_file = log_file.replace('.log', '.csv')\n    df.to_csv(csv_file, index=False)\n    \n    # Return the file path to the newly created CSV file\n    return csv_file\n```"}
{"task_id": "BigCodeBench/162", "solution": "import re\nimport matplotlib.pyplot as plt\nimport numpy as np\ndef task_func(text, rwidth=0.8):\n    words = re.findall(r'\\b\\w+\\b', text)\n    if not words:\n        return plt.axes()\n    word_lengths = [len(word) for word in words]\n    plt.hist(word_lengths, bins=np.arange(min(word_lengths), max(word_lengths) + 1), rwidth=rwidth)\n    return plt.axes()", "raw_solution": "import re\nimport matplotlib.pyplot as plt\nimport numpy as np\ndef task_func(text, rwidth=0.8):\n    words = re.findall(r'\\b\\w+\\b', text)\n    if not words:\n        return plt.axes()\n    word_lengths = [len(word) for word in words]\n    plt.hist(word_lengths, bins=np.arange(min(word_lengths), max(word_lengths) + 1), rwidth=rwidth)\n    return plt.axes()\n```"}
{"task_id": "BigCodeBench/163", "solution": "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\ndef task_func(rows=5, cols=5):\n    if rows > cols:\n        raise ValueError(\"If the number of columns exceeds the number of available categories.\")\n    data = np.random.rand(rows, cols)\n    df = pd.DataFrame(data, columns=[f\"Category {i+1}\" for i in range(cols)])\n    ax = df.plot(kind=\"bar\", stacked=True)\n    plt.show()\n    return ax", "raw_solution": "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndef task_func(rows=5, cols=5):\n    if rows > cols:\n        raise ValueError(\"If the number of columns exceeds the number of available categories.\")\n    data = np.random.rand(rows, cols)\n    df = pd.DataFrame(data, columns=[f\"Category {i+1}\" for i in range(cols)])\n    ax = df.plot(kind=\"bar\", stacked=True)\n    plt.show()\n    return ax\n```"}
{"task_id": "BigCodeBench/164", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\ndef task_func(num_labels=5, data_range=(0, 1)):\n    labels = np.random.choice(np.arange(num_labels), size=num_labels)\n    data = np.random.uniform(data_range[0], data_range[1], size=(num_labels, 10))\n    fig, ax = plt.subplots()\n    for i in range(num_labels):\n        ax.bar(labels[i], data[i], label=labels[i])\n    ax.set_title('Stacked Bar Chart')\n    ax.set_xlabel('Labels')\n    ax.set_ylabel('Data')\n    ax.legend()\n    return fig", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\n\ndef task_func(num_labels=5, data_range=(0, 1)):\n    labels = np.random.choice(np.arange(num_labels), size=num_labels)\n    data = np.random.uniform(data_range[0], data_range[1], size=(num_labels, 10))\n    fig, ax = plt.subplots()\n    for i in range(num_labels):\n        ax.bar(labels[i], data[i], label=labels[i])\n    ax.set_title('Stacked Bar Chart')\n    ax.set_xlabel('Labels')\n    ax.set_ylabel('Data')\n    ax.legend()\n    return fig\n```"}
{"task_id": "BigCodeBench/165", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nfrom random import randint\ndef task_func(num_rows=5, rand_range=(0, 100)):\n    # Create a DataFrame with random integer values within a specified range for categories 'A' through 'E'\n    df = pd.DataFrame({'Category': ['A', 'B', 'C', 'D', 'E'] * num_rows, 'Value': [randint(*rand_range) for _ in range(num_rows * 5)]})\n    \n    # Visualize this data with a stacked bar chart\n    df.groupby('Category')['Value'].sum().plot(kind='bar', stacked=True)\n    \n    # Return the matplotlib Figure object containing the plotted data\n    return plt.gcf()", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nfrom random import randint\n\ndef task_func(num_rows=5, rand_range=(0, 100)):\n    # Create a DataFrame with random integer values within a specified range for categories 'A' through 'E'\n    df = pd.DataFrame({'Category': ['A', 'B', 'C', 'D', 'E'] * num_rows, 'Value': [randint(*rand_range) for _ in range(num_rows * 5)]})\n    \n    # Visualize this data with a stacked bar chart\n    df.groupby('Category')['Value'].sum().plot(kind='bar', stacked=True)\n    \n    # Return the matplotlib Figure object containing the plotted data\n    return plt.gcf()\n```"}
{"task_id": "BigCodeBench/166", "solution": "import pandas as pd\nfrom datetime import datetime\nimport holidays\ndef task_func(start_date=datetime(2023, 1, 1), end_date=datetime(2023, 12, 31), country='US'):\n    if not isinstance(start_date, datetime) or start_date > end_date:\n        raise ValueError(\"start_date must be a datetime object and be before end_date\")\n    if not isinstance(end_date, datetime) or end_date < start_date:\n        raise ValueError(\"end_date must be a datetime object and be after start_date\")\n    country_holidays = holidays.CountryHoliday(country, years=[start_date.year, end_date.year])\n    business_days = []\n    for day in pd.date_range(start=start_date, end=end_date):\n        if day.weekday() < 5 and day not in country_holidays:\n            business_days.append(day)\n    return business_days", "raw_solution": "import pandas as pd\nfrom datetime import datetime\nimport holidays\n\ndef task_func(start_date=datetime(2023, 1, 1), end_date=datetime(2023, 12, 31), country='US'):\n    if not isinstance(start_date, datetime) or start_date > end_date:\n        raise ValueError(\"start_date must be a datetime object and be before end_date\")\n    if not isinstance(end_date, datetime) or end_date < start_date:\n        raise ValueError(\"end_date must be a datetime object and be after start_date\")\n    country_holidays = holidays.CountryHoliday(country, years=[start_date.year, end_date.year])\n    business_days = []\n    for day in pd.date_range(start=start_date, end=end_date):\n        if day.weekday() < 5 and day not in country_holidays:\n            business_days.append(day)\n    return business_days\n```"}
{"task_id": "BigCodeBench/167", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nfrom random import randint\ndef task_func(num_types=5, integer_range=(0, 100)):\n    # Generate random integer values across a specified number of categories\n    data = pd.DataFrame({\n        'category': [f'category_{i}' for i in range(num_types)],\n        'value': [randint(*integer_range) for _ in range(num_types)]\n    })\n    \n    # Visualize these data as a horizontal stacked bar chart\n    fig, ax = plt.subplots()\n    data.plot(kind='barh', x='category', y='value', ax=ax)\n    \n    return fig, ax", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nfrom random import randint\n\ndef task_func(num_types=5, integer_range=(0, 100)):\n    # Generate random integer values across a specified number of categories\n    data = pd.DataFrame({\n        'category': [f'category_{i}' for i in range(num_types)],\n        'value': [randint(*integer_range) for _ in range(num_types)]\n    })\n    \n    # Visualize these data as a horizontal stacked bar chart\n    fig, ax = plt.subplots()\n    data.plot(kind='barh', x='category', y='value', ax=ax)\n    \n    return fig, ax\n```"}
{"task_id": "BigCodeBench/168", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\ndef task_func(num_groups=5, data_size=5, labels=None):\n    if labels is None:\n        labels = ['Group ' + str(i) for i in range(num_groups)]\n    data = np.random.rand(num_groups, data_size)\n    df = pd.DataFrame(data, columns=labels)\n    fig, ax = plt.subplots()\n    df.plot(kind='bar', stacked=True, ax=ax)\n    plt.savefig('test_plot.png')\n    return fig, df, 'test_plot.png'", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\n\ndef task_func(num_groups=5, data_size=5, labels=None):\n    if labels is None:\n        labels = ['Group ' + str(i) for i in range(num_groups)]\n    data = np.random.rand(num_groups, data_size)\n    df = pd.DataFrame(data, columns=labels)\n    fig, ax = plt.subplots()\n    df.plot(kind='bar', stacked=True, ax=ax)\n    plt.savefig('test_plot.png')\n    return fig, df, 'test_plot.png'\n```"}
{"task_id": "BigCodeBench/169", "solution": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.ndimage import gaussian_filter\ndef task_func(image, sigma=2):\n    if sigma <= 0:\n        raise ValueError(\"If sigma is non-positive.\")\n    if not isinstance(image, np.ndarray):\n        raise TypeError(\"If the input is not a numpy array.\")\n    filtered_image = gaussian_filter(image, sigma=sigma)\n    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n    ax1.imshow(image, cmap='gray')\n    ax1.set_title('Original')\n    ax2.imshow(filtered_image, cmap='gray')\n    ax2.set_title('Filtered')\n    plt.show()\n    return ax, filtered_image", "raw_solution": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.ndimage import gaussian_filter\ndef task_func(image, sigma=2):\n    if sigma <= 0:\n        raise ValueError(\"If sigma is non-positive.\")\n    if not isinstance(image, np.ndarray):\n        raise TypeError(\"If the input is not a numpy array.\")\n    filtered_image = gaussian_filter(image, sigma=sigma)\n    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n    ax1.imshow(image, cmap='gray')\n    ax1.set_title('Original')\n    ax2.imshow(filtered_image, cmap='gray')\n    ax2.set_title('Filtered')\n    plt.show()\n    return ax, filtered_image\n```"}
{"task_id": "BigCodeBench/170", "solution": "import pandas as pd\nimport requests\nfrom io import StringIO\ndef task_func(csv_url, sort_by_column=\"title\"):\n    try:\n        response = requests.get(csv_url)\n        response.raise_for_status()\n        data = StringIO(response.text)\n        df = pd.read_csv(data)\n        df = df.sort_values(by=sort_by_column)\n        return df\n    except requests.exceptions.HTTPError as e:\n        raise Exception(\"Exception: If the response status code is not 200.\")", "raw_solution": "import pandas as pd\nimport requests\nfrom io import StringIO\n\ndef task_func(csv_url, sort_by_column=\"title\"):\n    try:\n        response = requests.get(csv_url)\n        response.raise_for_status()\n        data = StringIO(response.text)\n        df = pd.read_csv(data)\n        df = df.sort_values(by=sort_by_column)\n        return df\n    except requests.exceptions.HTTPError as e:\n        raise Exception(\"Exception: If the response status code is not 200.\")\n```"}
{"task_id": "BigCodeBench/171", "solution": "import random\nimport pandas as pd\nimport collections\nVEGETABLES = ['Carrot', 'Potato', 'Tomato', 'Cabbage', 'Spinach']\ndef task_func(vegetable_dict, seed=0):\n    random.seed(seed)\n    # Reverse the dictionary to map vegetables to people\n    people_dict = {v: k for k, v in vegetable_dict.items()}\n    # Assign random counts to vegetables\n    counts = {v: random.randint(1, 10) for v in VEGETABLES}\n    # Calculate the total counts\n    total_counts = sum(counts.values())\n    # Create a dictionary to map each vegetable to a person from the input\n    vegetable_to_person = {v: people_dict[v] for v in VEGETABLES}\n    # Create a DataFrame with columns for vegetable names, their random counts,\n    # and their percentage occurrence within the total counts\n    df = pd.DataFrame({\n        'Vegetable': VEGETABLES,\n        'Count': counts.values(),\n        'Percentage': [c / total_counts for c in counts.values()]\n    })\n    return df", "raw_solution": "import random\nimport pandas as pd\nimport collections\n# Constants\nVEGETABLES = ['Carrot', 'Potato', 'Tomato', 'Cabbage', 'Spinach']\ndef task_func(vegetable_dict, seed=0):\n    random.seed(seed)\n    # Reverse the dictionary to map vegetables to people\n    people_dict = {v: k for k, v in vegetable_dict.items()}\n    # Assign random counts to vegetables\n    counts = {v: random.randint(1, 10) for v in VEGETABLES}\n    # Calculate the total counts\n    total_counts = sum(counts.values())\n    # Create a dictionary to map each vegetable to a person from the input\n    vegetable_to_person = {v: people_dict[v] for v in VEGETABLES}\n    # Create a DataFrame with columns for vegetable names, their random counts,\n    # and their percentage occurrence within the total counts\n    df = pd.DataFrame({\n        'Vegetable': VEGETABLES,\n        'Count': counts.values(),\n        'Percentage': [c / total_counts for c in counts.values()]\n    })\n    return df\n```"}
{"task_id": "BigCodeBench/172", "solution": "import json\nfrom datetime import datetime\ndef task_func(json_data):\n    utc_datetime = json_data['utc_datetime']\n    date = datetime.strptime(utc_datetime, '%Y-%m-%dT%H:%M:%SZ')\n    return date.weekday() >= 5", "raw_solution": "import json\nfrom datetime import datetime\n\ndef task_func(json_data):\n    utc_datetime = json_data['utc_datetime']\n    date = datetime.strptime(utc_datetime, '%Y-%m-%dT%H:%M:%SZ')\n    return date.weekday() >= 5\n```"}
{"task_id": "BigCodeBench/173", "solution": "import numpy as np\nimport pandas as pd\ndef task_func(country_dict):\n    countries = list(country_dict.keys())\n    gdp_values = np.random.randint(1000000000, 100000000000, size=len(countries))\n    df = pd.DataFrame(gdp_values, index=countries, columns=['GDP'])\n    return df", "raw_solution": "import numpy as np\nimport pandas as pd\n\ndef task_func(country_dict):\n    countries = list(country_dict.keys())\n    gdp_values = np.random.randint(1000000000, 100000000000, size=len(countries))\n    df = pd.DataFrame(gdp_values, index=countries, columns=['GDP'])\n    return df\n```"}
{"task_id": "BigCodeBench/174", "solution": "import pandas as pd\nimport numpy as np\ndef task_func(data, key, min_value, max_value):\n    if not isinstance(data, pd.DataFrame):\n        raise Exception(\"The function will raise an error if the input data is not pandas DataFrame\")\n    data[key] = np.random.uniform(min_value, max_value, data.shape[0])\n    return data", "raw_solution": "import pandas as pd\nimport numpy as np\n\ndef task_func(data, key, min_value, max_value):\n    if not isinstance(data, pd.DataFrame):\n        raise Exception(\"The function will raise an error if the input data is not pandas DataFrame\")\n    data[key] = np.random.uniform(min_value, max_value, data.shape[0])\n    return data\n```"}
{"task_id": "BigCodeBench/175", "solution": "import re\nimport matplotlib.pyplot as plt\ndef task_func(df):\n    if df.empty or 'Title' not in df.columns or 'Views' not in df.columns or 'Likes' not in df.columns:\n        return plt.subplots()\n    titles = df['Title'].str.lower()\n    titles = titles.str.contains('how|what', regex=True)\n    if not titles.any():\n        return plt.subplots()\n    like_ratio = df.loc[titles, 'Likes'] / df.loc[titles, 'Views']\n    plt.bar(like_ratio.index, like_ratio)\n    plt.xlabel('Video Title')\n    plt.ylabel('Like Ratio')\n    plt.title('Video Titles Containing \"how\" or \"what\" and Their Like Ratios')\n    return plt.subplots()", "raw_solution": "import re\nimport matplotlib.pyplot as plt\n\ndef task_func(df):\n    if df.empty or 'Title' not in df.columns or 'Views' not in df.columns or 'Likes' not in df.columns:\n        return plt.subplots()\n    titles = df['Title'].str.lower()\n    titles = titles.str.contains('how|what', regex=True)\n    if not titles.any():\n        return plt.subplots()\n    like_ratio = df.loc[titles, 'Likes'] / df.loc[titles, 'Views']\n    plt.bar(like_ratio.index, like_ratio)\n    plt.xlabel('Video Title')\n    plt.ylabel('Like Ratio')\n    plt.title('Video Titles Containing \"how\" or \"what\" and Their Like Ratios')\n    return plt.subplots()\n```"}
{"task_id": "BigCodeBench/176", "solution": "import re\nimport socket\ndef task_func(ip_addresses: list) -> dict:\n    ip_to_hostname = {}\n    for ip in ip_addresses:\n        try:\n            hostname = socket.gethostbyaddr(ip)[0]\n            ip_to_hostname[ip] = hostname\n        except socket.herror:\n            ip_to_hostname[ip] = None\n    return ip_to_hostname", "raw_solution": "import re\nimport socket\n\ndef task_func(ip_addresses: list) -> dict:\n    ip_to_hostname = {}\n    for ip in ip_addresses:\n        try:\n            hostname = socket.gethostbyaddr(ip)[0]\n            ip_to_hostname[ip] = hostname\n        except socket.herror:\n            ip_to_hostname[ip] = None\n    return ip_to_hostname\n```"}
{"task_id": "BigCodeBench/177", "solution": "import re\nimport nltk\nfrom string import punctuation\ndef task_func(df):\n    if df.empty or 'Title' not in df.columns or 'Content' not in df.columns:\n        raise ValueError(\"DataFrame is empty or does not contain the necessary columns 'Title' and 'Content'\")\n    df['Title'] = df['Title'].str.lower()\n    df['Content'] = df['Content'].str.lower()\n    df['Content'] = df['Content'].str.replace('[^\\w\\s]', '')\n    words = nltk.word_tokenize(df['Content'])\n    words = [word for word in words if word not in punctuation]\n    word_freq = nltk.FreqDist(words)\n    return dict(word_freq)", "raw_solution": "import re\nimport nltk\nfrom string import punctuation\ndef task_func(df):\n    if df.empty or 'Title' not in df.columns or 'Content' not in df.columns:\n        raise ValueError(\"DataFrame is empty or does not contain the necessary columns 'Title' and 'Content'\")\n    df['Title'] = df['Title'].str.lower()\n    df['Content'] = df['Content'].str.lower()\n    df['Content'] = df['Content'].str.replace('[^\\w\\s]', '')\n    words = nltk.word_tokenize(df['Content'])\n    words = [word for word in words if word not in punctuation]\n    word_freq = nltk.FreqDist(words)\n    return dict(word_freq)\n```"}
{"task_id": "BigCodeBench/178", "solution": "import re\nimport json\nIP_REGEX = r'[0-9]+(?:\\.[0-9]+){3}'\ndef task_func(ip_address):\n    # Check if the provided IP address is valid\n    if not re.match(IP_REGEX, ip_address):\n        return 'Invalid IP address received'\n    # Return the public IP address\n    return ip_address", "raw_solution": "import re\nimport json\n# Constants\nIP_REGEX = r'[0-9]+(?:\\.[0-9]+){3}'\ndef task_func(ip_address):\n    # Check if the provided IP address is valid\n    if not re.match(IP_REGEX, ip_address):\n        return 'Invalid IP address received'\n    # Return the public IP address\n    return ip_address\n```"}
{"task_id": "BigCodeBench/179", "solution": "import re\nimport matplotlib.pyplot as plt\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nimport numpy as np\ndef task_func(df):\n    if 'Title' not in df.columns or 'Content' not in df.columns:\n        return plt.figure()\n    df['Title'] = df['Title'].str.lower()\n    df['Content'] = df['Content'].str.lower()\n    df['Title'] = df['Title'].str.replace(r'\\W+', ' ')\n    df['Content'] = df['Content'].str.replace(r'\\W+', ' ')\n    df['Title'] = df['Title'].str.split()\n    df['Content'] = df['Content'].str.split()\n    df['Title'] = df['Title'].apply(lambda x: [word for word in x if 'how' in word or 'what' in word])\n    df['Content'] = df['Content'].apply(lambda x: [word for word in x if 'how' in word or 'what' in word])\n    df['Title'] = df['Title'].apply(lambda x: ' '.join(x))\n    df['Content'] = df['Content'].apply(lambda x: ' '.join(x))\n    df['Title'] = df['Title'].str.replace(r'\\s+', ' ')\n    df['Content'] = df['Content'].str.replace(r'\\s+', ' ')\n    df['Title'] = df['Title'].str.split()\n    df['Content'] = df['Content'].str.split()\n    df['Title'] = df['Title'].apply(lambda x: [word for word in x if 'how' in word or 'what' in word])\n    df['Content'] = df['Content'].apply(lambda x: [word for word in x if 'how' in word or 'what' in word])\n    df['Title'] = df['Title'].apply(lambda x: ' '.join(x))\n    df['Content'] = df['Content'].apply(lambda x: ' '.join(x))\n    df['Title'] = df['Title'].str.replace(r'\\s+', ' ')\n    df['Content'] = df['Content'].str.replace(r'\\s+', ' ')\n    df['Title'] = df['Title'].str.split()\n    df['Content'] = df['Content'].str.split()\n    df['Title'] = df['Title'].apply(lambda x: [word for word in x if 'how' in word or 'what' in word])\n    df['Content'] = df['Content'].apply(lambda x: [word for word in x if 'how' in word or 'what' in word])\n    df['Title'] = df['Title'].apply(lambda x: ' '.join(x))\n    df['Content'] = df['Content'].apply(lambda x: ' '.join(x))\n    df['Title'] = df['Title'].str.replace(r'\\s+', ' ')\n    df['Content'] = df['Content'].str.replace(r'\\s+', ' ')\n    df['Title'] = df['Title'].str.split()\n    df['Content'] = df['Content'].str.split()\n    df['Title'] = df['Title'].apply(lambda x: [word for word in x if 'how' in word or 'what' in word])\n    df['Content'] = df['Content'].apply(lambda x: [word for word in x if 'how' in word or 'what' in word])\n    df['Title'] = df['Title'].apply(lambda x: ' '.join(x))\n    df['Content'] = df['Content'].apply(lambda x: ' '.join(x))\n    df['Title'] = df['Title'].str.replace(r'\\s+', ' ')\n    df['Content'] = df['Content'].str.replace(r'\\s+', ' ')\n    df['Title'] = df['Title'].str.split()\n    df['Content'] = df['Content'].str.split()\n    df['Title'] = df['Title'].apply(lambda x: [word for word in x if 'how' in word or 'what' in word])\n    df['Content'] = df['Content'].apply(lambda x: [word for word in x if 'how' in word or 'what' in word])\n    df['Title'] = df['Title'].apply(lambda x: ' '.join(x))\n    df['Content'] = df['Content'].apply(lambda x: ' '.join(x))\n    df['Title'] = df['Title'].str.replace(r'\\s+', ' ')\n    df['Content'] = df['Content'].str.replace(r'\\s+', ' ')\n    df['Title'] = df['Title'].str.split()\n    df['Content'] = df['Content'].str.split()\n    df['Title'] = df['Title'].apply(lambda x: [word for word in x if 'how' in word or 'what' in word])\n    df['Content'] = df['Content'].apply(lambda x: [word for word in x if 'how' in word or 'what' in word])\n    df['Title'] = df['Title'].apply(lambda x: ' '.join(x))\n    df['Content'] = df['Content'].apply(lambda x: ' '.join(x))\n    df['Title'] = df['Title'].str.replace(r'\\s+', ' ')\n    df['Content'] = df['Content'].str.replace(r'\\s+', ' ')\n    df['Title'] = df['Title'].str.split()\n    df['Content'] = df['Content'].str.split()\n    df['Title'] = df['Title'].apply(lambda x: [word for word in x if 'how' in word or 'what' in word])\n    df['Content'] = df['Content'].apply(lambda x: [word for word in x if 'how' in word or 'what' in word])\n    df['Title'] = df['Title'].apply(lambda x: ' '.join(x))\n    df['Content'] = df['Content'].apply(lambda x: ' '.join(x))\n    df['Title'] = df['Title'].str.replace(r'\\s+', ' ')\n    df['Content'] = df['Content'].str.replace(r'\\s+', ' ')", "raw_solution": "import re\nimport matplotlib.pyplot as plt\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nimport numpy as np\ndef task_func(df):\n    if 'Title' not in df.columns or 'Content' not in df.columns:\n        return plt.figure()\n    df['Title'] = df['Title'].str.lower()\n    df['Content'] = df['Content'].str.lower()\n    df['Title'] = df['Title'].str.replace(r'\\W+', ' ')\n    df['Content'] = df['Content'].str.replace(r'\\W+', ' ')\n    df['Title'] = df['Title'].str.split()\n    df['Content'] = df['Content'].str.split()\n    df['Title'] = df['Title'].apply(lambda x: [word for word in x if 'how' in word or 'what' in word])\n    df['Content'] = df['Content'].apply(lambda x: [word for word in x if 'how' in word or 'what' in word])\n    df['Title'] = df['Title'].apply(lambda x: ' '.join(x))\n    df['Content'] = df['Content'].apply(lambda x: ' '.join(x))\n    df['Title'] = df['Title'].str.replace(r'\\s+', ' ')\n    df['Content'] = df['Content'].str.replace(r'\\s+', ' ')\n    df['Title'] = df['Title'].str.split()\n    df['Content'] = df['Content'].str.split()\n    df['Title'] = df['Title'].apply(lambda x: [word for word in x if 'how' in word or 'what' in word])\n    df['Content'] = df['Content'].apply(lambda x: [word for word in x if 'how' in word or 'what' in word])\n    df['Title'] = df['Title'].apply(lambda x: ' '.join(x))\n    df['Content'] = df['Content'].apply(lambda x: ' '.join(x))\n    df['Title'] = df['Title'].str.replace(r'\\s+', ' ')\n    df['Content'] = df['Content'].str.replace(r'\\s+', ' ')\n    df['Title'] = df['Title'].str.split()\n    df['Content'] = df['Content'].str.split()\n    df['Title'] = df['Title'].apply(lambda x: [word for word in x if 'how' in word or 'what' in word])\n    df['Content'] = df['Content'].apply(lambda x: [word for word in x if 'how' in word or 'what' in word])\n    df['Title'] = df['Title'].apply(lambda x: ' '.join(x))\n    df['Content'] = df['Content'].apply(lambda x: ' '.join(x))\n    df['Title'] = df['Title'].str.replace(r'\\s+', ' ')\n    df['Content'] = df['Content'].str.replace(r'\\s+', ' ')\n    df['Title'] = df['Title'].str.split()\n    df['Content'] = df['Content'].str.split()\n    df['Title'] = df['Title'].apply(lambda x: [word for word in x if 'how' in word or 'what' in word])\n    df['Content'] = df['Content'].apply(lambda x: [word for word in x if 'how' in word or 'what' in word])\n    df['Title'] = df['Title'].apply(lambda x: ' '.join(x))\n    df['Content'] = df['Content'].apply(lambda x: ' '.join(x))\n    df['Title'] = df['Title'].str.replace(r'\\s+', ' ')\n    df['Content'] = df['Content'].str.replace(r'\\s+', ' ')\n    df['Title'] = df['Title'].str.split()\n    df['Content'] = df['Content'].str.split()\n    df['Title'] = df['Title'].apply(lambda x: [word for word in x if 'how' in word or 'what' in word])\n    df['Content'] = df['Content'].apply(lambda x: [word for word in x if 'how' in word or 'what' in word])\n    df['Title'] = df['Title'].apply(lambda x: ' '.join(x))\n    df['Content'] = df['Content'].apply(lambda x: ' '.join(x))\n    df['Title'] = df['Title'].str.replace(r'\\s+', ' ')\n    df['Content'] = df['Content'].str.replace(r'\\s+', ' ')\n    df['Title'] = df['Title'].str.split()\n    df['Content'] = df['Content'].str.split()\n    df['Title'] = df['Title'].apply(lambda x: [word for word in x if 'how' in word or 'what' in word])\n    df['Content'] = df['Content'].apply(lambda x: [word for word in x if 'how' in word or 'what' in word])\n    df['Title'] = df['Title'].apply(lambda x: ' '.join(x))\n    df['Content'] = df['Content'].apply(lambda x: ' '.join(x))\n    df['Title'] = df['Title'].str.replace(r'\\s+', ' ')\n    df['Content'] = df['Content'].str.replace(r'\\s+', ' ')\n    df['Title'] = df['Title'].str.split()\n    df['Content'] = df['Content'].str.split()\n    df['Title'] = df['Title'].apply(lambda x: [word for word in x if 'how' in word or 'what' in word])\n    df['Content'] = df['Content'].apply(lambda x: [word for word in x if 'how' in word or 'what' in word])\n    df['Title'] = df['Title'].apply(lambda x: ' '.join(x))\n    df['Content'] = df['Content'].apply(lambda x: ' '.join(x))\n    df['Title'] = df['Title'].str.replace(r'\\s+', ' ')\n    df['Content'] = df['Content'].str.replace(r'\\s+', ' ')\n    df['Title"}
{"task_id": "BigCodeBench/180", "solution": "from PIL import Image\nimport numpy as np\nfrom skimage.transform import resize\nimport matplotlib.pyplot as plt\nimport os\ndef task_func(img_path, scale_factors=[0.5, 0.75, 1.5, 2.0]):\n    if not os.path.exists(img_path):\n        raise FileNotFoundError(\"File not found\")\n    img = Image.open(img_path)\n    img = np.array(img)\n    scaled_images = []\n    for scale_factor in scale_factors:\n        scaled_img = resize(img, (int(img.shape[0] * scale_factor), int(img.shape[1] * scale_factor)))\n        fig, ax = plt.subplots()\n        ax.imshow(scaled_img)\n        ax.axis('off')\n        scaled_images.append((ax, scaled_img))\n    return scaled_images", "raw_solution": "from PIL import Image\nimport numpy as np\nfrom skimage.transform import resize\nimport matplotlib.pyplot as plt\nimport os\n\ndef task_func(img_path, scale_factors=[0.5, 0.75, 1.5, 2.0]):\n    if not os.path.exists(img_path):\n        raise FileNotFoundError(\"File not found\")\n    img = Image.open(img_path)\n    img = np.array(img)\n    scaled_images = []\n    for scale_factor in scale_factors:\n        scaled_img = resize(img, (int(img.shape[0] * scale_factor), int(img.shape[1] * scale_factor)))\n        fig, ax = plt.subplots()\n        ax.imshow(scaled_img)\n        ax.axis('off')\n        scaled_images.append((ax, scaled_img))\n    return scaled_images\n```"}
{"task_id": "BigCodeBench/181", "solution": "from django.http import HttpResponse\nfrom django.conf import settings\nimport random\nimport time\ndef task_func(data, min_delay, max_delay):\n    # Simulate network latency\n    time.sleep(random.uniform(min_delay, max_delay))\n    # Create a JSON response\n    response = HttpResponse(json.dumps(data), content_type='application/json')\n    return response", "raw_solution": "from django.http import HttpResponse\nfrom django.conf import settings\nimport random\nimport time\n\ndef task_func(data, min_delay, max_delay):\n    # Simulate network latency\n    time.sleep(random.uniform(min_delay, max_delay))\n    # Create a JSON response\n    response = HttpResponse(json.dumps(data), content_type='application/json')\n    return response\n```"}
{"task_id": "BigCodeBench/182", "solution": "import re\nfrom sklearn.cluster import KMeans\nfrom sklearn.feature_extraction.text import CountVectorizer\ndef task_func(df):\n    # Filter articles by keywords\n    df = df[df['title'].str.contains('how|what', case=False)]\n    \n    # Vectorize content\n    vectorizer = CountVectorizer()\n    X = vectorizer.fit_transform(df['content'])\n    \n    # Perform KMeans clustering\n    kmeans = KMeans(n_clusters=3, random_state=0)\n    y = kmeans.fit_predict(X)\n    \n    return y.tolist()", "raw_solution": "import re\nfrom sklearn.cluster import KMeans\nfrom sklearn.feature_extraction.text import CountVectorizer\ndef task_func(df):\n    # Filter articles by keywords\n    df = df[df['title'].str.contains('how|what', case=False)]\n    \n    # Vectorize content\n    vectorizer = CountVectorizer()\n    X = vectorizer.fit_transform(df['content'])\n    \n    # Perform KMeans clustering\n    kmeans = KMeans(n_clusters=3, random_state=0)\n    y = kmeans.fit_predict(X)\n    \n    return y.tolist()\n```"}
{"task_id": "BigCodeBench/183", "solution": "from django.http import HttpResponse\nimport uuid\ndef task_func(data):\n    response = HttpResponse(data, content_type='application/json')\n    response['X-Request-UUID'] = str(uuid.uuid4())\n    return response", "raw_solution": "from django.http import HttpResponse\nimport uuid\n\ndef task_func(data):\n    response = HttpResponse(data, content_type='application/json')\n    response['X-Request-UUID'] = str(uuid.uuid4())\n    return response\n```"}
{"task_id": "BigCodeBench/184", "solution": "import pandas as pd\nimport re\nfrom sklearn.feature_extraction.text import CountVectorizer\nSTOPWORDS = ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'your', 'yours', 'yourself',\n             'yourselves', 'he', 'him', 'his', 'himself', 'she', 'her', 'hers', 'herself', 'it', 'its', 'itself',\n             'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', 'these',\n             'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do',\n             'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while',\n             'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before',\n             'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again',\n             'further', 'then', 'once']\ndef task_func(dataframe, text_column):\n    # Remove stopwords, numbers, and punctuation\n    dataframe[text_column] = dataframe[text_column].apply(lambda x: re.sub(r'\\b(' + '|'.join(STOPWORDS) + r')\\b', '', x))\n    dataframe[text_column] = dataframe[text_column].apply(lambda x: re.sub(r'\\d+', '', x))\n    dataframe[text_column] = dataframe[text_column].apply(lambda x: re.sub(r'[^\\w\\s]', '', x))\n    # Vectorize text\n    vectorizer = CountVectorizer()\n    vectorized_data = vectorizer.fit_transform(dataframe[text_column])\n    # Convert to DataFrame\n    word_counts = pd.DataFrame(vectorized_data.toarray(), columns=vectorizer.get_feature_names_out())\n    return word_counts", "raw_solution": "import pandas as pd\nimport re\nfrom sklearn.feature_extraction.text import CountVectorizer\n# Constants\nSTOPWORDS = ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'your', 'yours', 'yourself',\n             'yourselves', 'he', 'him', 'his', 'himself', 'she', 'her', 'hers', 'herself', 'it', 'its', 'itself',\n             'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', 'these',\n             'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do',\n             'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while',\n             'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before',\n             'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again',\n             'further', 'then', 'once']\ndef task_func(dataframe, text_column):\n    # Remove stopwords, numbers, and punctuation\n    dataframe[text_column] = dataframe[text_column].apply(lambda x: re.sub(r'\\b(' + '|'.join(STOPWORDS) + r')\\b', '', x))\n    dataframe[text_column] = dataframe[text_column].apply(lambda x: re.sub(r'\\d+', '', x))\n    dataframe[text_column] = dataframe[text_column].apply(lambda x: re.sub(r'[^\\w\\s]', '', x))\n    # Vectorize text\n    vectorizer = CountVectorizer()\n    vectorized_data = vectorizer.fit_transform(dataframe[text_column])\n    # Convert to DataFrame\n    word_counts = pd.DataFrame(vectorized_data.toarray(), columns=vectorizer.get_feature_names_out())\n    return word_counts\n```"}
{"task_id": "BigCodeBench/185", "solution": "import pandas as pd\nimport numpy as np\nimport folium\ndef task_func(dic={'Lon': (-180, 180), 'Lat': (-90, 90)}, cities=['New York', 'London', 'Beijing', 'Tokyo', 'Sydney']):\n    if not all(key in dic for key in ['Lon', 'Lat']):\n        raise ValueError('If \\'Lon\\' or \\'Lat\\' keys are missing in the dictionary, or if their values are not tuples.')\n    if not all(isinstance(value, tuple) for value in dic.values()):\n        raise ValueError('If \\'Lon\\' or \\'Lat\\' keys are missing in the dictionary, or if their values are not tuples.')\n    lon_range, lat_range = dic['Lon'], dic['Lat']\n    lon = np.random.uniform(lon_range[0], lon_range[1], len(cities))\n    lat = np.random.uniform(lat_range[0], lat_range[1], len(cities))\n    df = pd.DataFrame({'City': cities, 'Longitude': lon, 'Latitude': lat})\n    map = folium.Map(location=[np.mean(df['Latitude']), np.mean(df['Longitude'])], zoom_start=5)\n    for index, row in df.iterrows():\n        folium.Marker([row['Latitude'], row['Longitude']], popup=row['City']).add_to(map)\n    return map, df", "raw_solution": "import pandas as pd\nimport numpy as np\nimport folium\n\ndef task_func(dic={'Lon': (-180, 180), 'Lat': (-90, 90)}, cities=['New York', 'London', 'Beijing', 'Tokyo', 'Sydney']):\n    if not all(key in dic for key in ['Lon', 'Lat']):\n        raise ValueError('If \\'Lon\\' or \\'Lat\\' keys are missing in the dictionary, or if their values are not tuples.')\n    if not all(isinstance(value, tuple) for value in dic.values()):\n        raise ValueError('If \\'Lon\\' or \\'Lat\\' keys are missing in the dictionary, or if their values are not tuples.')\n    lon_range, lat_range = dic['Lon'], dic['Lat']\n    lon = np.random.uniform(lon_range[0], lon_range[1], len(cities))\n    lat = np.random.uniform(lat_range[0], lat_range[1], len(cities))\n    df = pd.DataFrame({'City': cities, 'Longitude': lon, 'Latitude': lat})\n    map = folium.Map(location=[np.mean(df['Latitude']), np.mean(df['Longitude'])], zoom_start=5)\n    for index, row in df.iterrows():\n        folium.Marker([row['Latitude'], row['Longitude']], popup=row['City']).add_to(map)\n    return map, df\n```"}
{"task_id": "BigCodeBench/186", "solution": "from geopy.distance import geodesic\nimport folium\ndef task_func(dic):\n    if not dic:\n        raise ValueError(\"If the input dictionary is empty.\")\n    map = folium.Map(location=[0, 0], zoom_start=2)\n    for i in dic:\n        for j in dic:\n            if i != j:\n                folium.Marker([dic[i][0], dic[i][1]]).add_to(map)\n                folium.Marker([dic[j][0], dic[j][1]]).add_to(map)\n                distance = geodesic(dic[i], dic[j]).kilometers\n                folium.PolyLine([[dic[i][0], dic[i][1]], [dic[j][0], dic[j][1]]], color='red').add_to(map)\n    return map, dic", "raw_solution": "from geopy.distance import geodesic\nimport folium\n\ndef task_func(dic):\n    if not dic:\n        raise ValueError(\"If the input dictionary is empty.\")\n    map = folium.Map(location=[0, 0], zoom_start=2)\n    for i in dic:\n        for j in dic:\n            if i != j:\n                folium.Marker([dic[i][0], dic[i][1]]).add_to(map)\n                folium.Marker([dic[j][0], dic[j][1]]).add_to(map)\n                distance = geodesic(dic[i], dic[j]).kilometers\n                folium.PolyLine([[dic[i][0], dic[i][1]], [dic[j][0], dic[j][1]]], color='red').add_to(map)\n    return map, dic\n```"}
{"task_id": "BigCodeBench/187", "solution": "import numpy as np\nimport geopandas as gpd\nfrom shapely.geometry import Point\ndef task_func(dic={'Lon': (-180, 180), 'Lat': (-90, 90)}, cities=['New York', 'London', 'Beijing', 'Tokyo', 'Sydney']):\n    if 'Lon' not in dic or 'Lat' not in dic:\n        raise ValueError('If \\'Lon\\' or \\'Lat\\' keys are missing in the dictionary, or if their values are not tuples.')\n    lon_range = dic['Lon']\n    lat_range = dic['Lat']\n    lon = np.random.uniform(lon_range[0], lon_range[1], len(cities))\n    lat = np.random.uniform(lat_range[0], lat_range[1], len(cities))\n    coordinates = [Point((lon[i], lat[i])) for i in range(len(cities))]\n    gdf = gpd.GeoDataFrame({'City': cities, 'Coordinates': coordinates})\n    return gdf", "raw_solution": "import numpy as np\nimport geopandas as gpd\nfrom shapely.geometry import Point\n\ndef task_func(dic={'Lon': (-180, 180), 'Lat': (-90, 90)}, cities=['New York', 'London', 'Beijing', 'Tokyo', 'Sydney']):\n    if 'Lon' not in dic or 'Lat' not in dic:\n        raise ValueError('If \\'Lon\\' or \\'Lat\\' keys are missing in the dictionary, or if their values are not tuples.')\n    lon_range = dic['Lon']\n    lat_range = dic['Lat']\n    lon = np.random.uniform(lon_range[0], lon_range[1], len(cities))\n    lat = np.random.uniform(lat_range[0], lat_range[1], len(cities))\n    coordinates = [Point((lon[i], lat[i])) for i in range(len(cities))]\n    gdf = gpd.GeoDataFrame({'City': cities, 'Coordinates': coordinates})\n    return gdf\n```"}
{"task_id": "BigCodeBench/188", "solution": "import pandas as pd\nimport folium\nfrom geopy.geocoders import Photon\ndef task_func(dic):\n    geolocator = Photon(user_agent=\"geoapiExercises\")\n    locations = []\n    for key, value in dic.items():\n        if isinstance(value, str):\n            location = geolocator.geocode(value)\n            if location:\n                locations.append((key, location.latitude, location.longitude))\n        else:\n            locations.append((key, value[0], value[1]))\n    map = folium.Map(location=[0, 0], zoom_start=2)\n    for key, lat, lon in locations:\n        folium.Marker([lat, lon], popup=key).add_to(map)\n    return map", "raw_solution": "import pandas as pd\nimport folium\nfrom geopy.geocoders import Photon\n\ndef task_func(dic):\n    geolocator = Photon(user_agent=\"geoapiExercises\")\n    locations = []\n    for key, value in dic.items():\n        if isinstance(value, str):\n            location = geolocator.geocode(value)\n            if location:\n                locations.append((key, location.latitude, location.longitude))\n        else:\n            locations.append((key, value[0], value[1]))\n    map = folium.Map(location=[0, 0], zoom_start=2)\n    for key, lat, lon in locations:\n        folium.Marker([lat, lon], popup=key).add_to(map)\n    return map\n```"}
{"task_id": "BigCodeBench/189", "solution": "import re\nimport json\nimport requests\ndef task_func(data_url: str) -> list:\n    try:\n        response = requests.get(data_url)\n        response.raise_for_status()\n        data = json.loads(response.text)\n        names = re.findall(r'(?<!\\[)[\\w\\s]+(?!\\])', json.dumps(data))\n        return names\n    except requests.exceptions.RequestException as e:\n        return \"Invalid url input\"", "raw_solution": "import re\nimport json\nimport requests\n\ndef task_func(data_url: str) -> list:\n    try:\n        response = requests.get(data_url)\n        response.raise_for_status()\n        data = json.loads(response.text)\n        names = re.findall(r'(?<!\\[)[\\w\\s]+(?!\\])', json.dumps(data))\n        return names\n    except requests.exceptions.RequestException as e:\n        return \"Invalid url input\"\n```"}
{"task_id": "BigCodeBench/190", "solution": "import sqlite3\nimport pandas as pd\nimport csv\nfrom io import StringIO\nDATABASE_NAME = 'test.db'\nTABLE_NAME = 'test_table'\ndef task_func(csv_input):\n    # Create a new database connection\n    conn = sqlite3.connect(DATABASE_NAME)\n    cursor = conn.cursor()\n\n    # Create a new table or replace an existing one\n    cursor.execute(f'''\n        CREATE TABLE IF NOT EXISTS {TABLE_NAME} (\n            id INTEGER PRIMARY KEY,\n            name TEXT,\n            age INTEGER\n        )\n    ''')\n\n    # Insert data into the table\n    if isinstance(csv_input, str):\n        csv_input = StringIO(csv_input)\n    reader = csv.DictReader(csv_input)\n    for row in reader:\n        cursor.execute(f'''\n            INSERT INTO {TABLE_NAME} (id, name, age) VALUES (?, ?, ?)\n        ''', (row['id'], row['name'], row['age']))\n\n    # Commit the changes and close the connection\n    conn.commit()\n    conn.close()\n\n    # Query the table and return the data as a DataFrame\n    conn = sqlite3.connect(DATABASE_NAME)\n    cursor = conn.cursor()\n    cursor.execute(f'''\n        SELECT * FROM {TABLE_NAME}\n    ''')\n    df = pd.DataFrame(cursor.fetchall(), columns=[desc[0] for desc in cursor.description])\n    conn.close()\n\n    return df", "raw_solution": "import sqlite3\nimport pandas as pd\nimport csv\nfrom io import StringIO\n\n# Constants\nDATABASE_NAME = 'test.db'\nTABLE_NAME = 'test_table'\n\ndef task_func(csv_input):\n    # Create a new database connection\n    conn = sqlite3.connect(DATABASE_NAME)\n    cursor = conn.cursor()\n\n    # Create a new table or replace an existing one\n    cursor.execute(f'''\n        CREATE TABLE IF NOT EXISTS {TABLE_NAME} (\n            id INTEGER PRIMARY KEY,\n            name TEXT,\n            age INTEGER\n        )\n    ''')\n\n    # Insert data into the table\n    if isinstance(csv_input, str):\n        csv_input = StringIO(csv_input)\n    reader = csv.DictReader(csv_input)\n    for row in reader:\n        cursor.execute(f'''\n            INSERT INTO {TABLE_NAME} (id, name, age) VALUES (?, ?, ?)\n        ''', (row['id'], row['name'], row['age']))\n\n    # Commit the changes and close the connection\n    conn.commit()\n    conn.close()\n\n    # Query the table and return the data as a DataFrame\n    conn = sqlite3.connect(DATABASE_NAME)\n    cursor = conn.cursor()\n    cursor.execute(f'''\n        SELECT * FROM {TABLE_NAME}\n    ''')\n    df = pd.DataFrame(cursor.fetchall(), columns=[desc[0] for desc in cursor.description])\n    conn.close()\n\n    return df\n```"}
{"task_id": "BigCodeBench/191", "solution": "import random\nfrom scipy import stats\ndef task_func(animals, mean):\n    # Generate a random number of customers following a Poisson distribution\n    num_customers = stats.poisson.rvs(mean)\n    \n    # Initialize a dictionary to store the sales\n    sales = {}\n    \n    # Simulate sales for each customer\n    for i in range(num_customers):\n        # Randomly select an animal type\n        animal_type = random.choice(animals)\n        \n        # Increment the sales count for the selected animal type\n        if animal_type in sales:\n            sales[animal_type] += 1\n        else:\n            sales[animal_type] = 1\n    \n    # Return the summary of the sales\n    return sales", "raw_solution": "import random\nfrom scipy import stats\n\ndef task_func(animals, mean):\n    # Generate a random number of customers following a Poisson distribution\n    num_customers = stats.poisson.rvs(mean)\n    \n    # Initialize a dictionary to store the sales\n    sales = {}\n    \n    # Simulate sales for each customer\n    for i in range(num_customers):\n        # Randomly select an animal type\n        animal_type = random.choice(animals)\n        \n        # Increment the sales count for the selected animal type\n        if animal_type in sales:\n            sales[animal_type] += 1\n        else:\n            sales[animal_type] = 1\n    \n    # Return the summary of the sales\n    return sales\n```"}
{"task_id": "BigCodeBench/192", "solution": "import re\nimport smtplib\nTEXT = \"Josie Smith [3996 COLLEGE AVENUE, SOMETOWN, MD 21003]Mugsy Dog Smith [2560 OAK ST, GLENMEADE, WI 14098]\"\nRECEPIENT_ADDRESS = \"names@gmail.com\"\nSMTP_SERVER = \"smtp.gmail.com\"\nSMTP_PORT = 587\nEMAIL_ADDRESS = \"your.email@gmail.com\"\nEMAIL_PASSWORD = \"your.password\"\ndef task_func(text=TEXT, smtp_server=SMTP_SERVER, smtp_port=SMTP_PORT, email_address=EMAIL_ADDRESS, email_password=EMAIL_PASSWORD, recepient_address=RECEPIENT_ADDRESS, smtp=None):\n    # Extract all names from the text\n    names = re.findall(r'\\b[A-Za-z\\s]+\\b', text)\n    # Create the email message\n    message = f\"Subject: Extracted Names\\n\\n{names[0]}\\n{names[1]}\"\n    # Connect to the SMTP server and send the email\n    with smtplib.SMTP(smtp_server, smtp_port) as server:\n        server.starttls()\n        server.login(email_address, email_password)\n        server.sendmail(email_address, recepient_address, message)\n    # Return the list of extracted names\n    return names", "raw_solution": "import re\nimport smtplib\n# Constants\nTEXT = \"Josie Smith [3996 COLLEGE AVENUE, SOMETOWN, MD 21003]Mugsy Dog Smith [2560 OAK ST, GLENMEADE, WI 14098]\"\nRECEPIENT_ADDRESS = \"names@gmail.com\"\nSMTP_SERVER = \"smtp.gmail.com\"\nSMTP_PORT = 587\nEMAIL_ADDRESS = \"your.email@gmail.com\"\nEMAIL_PASSWORD = \"your.password\"\ndef task_func(text=TEXT, smtp_server=SMTP_SERVER, smtp_port=SMTP_PORT, email_address=EMAIL_ADDRESS, email_password=EMAIL_PASSWORD, recepient_address=RECEPIENT_ADDRESS, smtp=None):\n    # Extract all names from the text\n    names = re.findall(r'\\b[A-Za-z\\s]+\\b', text)\n    # Create the email message\n    message = f\"Subject: Extracted Names\\n\\n{names[0]}\\n{names[1]}\"\n    # Connect to the SMTP server and send the email\n    with smtplib.SMTP(smtp_server, smtp_port) as server:\n        server.starttls()\n        server.login(email_address, email_password)\n        server.sendmail(email_address, recepient_address, message)\n    # Return the list of extracted names\n    return names\n```"}
{"task_id": "BigCodeBench/193", "solution": "import pandas as pd\nimport numpy as np\nfrom random import choice\nDATA_TYPES = [str, int, float, list, tuple, dict, set]\ndef task_func(rows, columns):\n    df = pd.DataFrame(columns=['col' + str(i) for i in range(columns)])\n    for i in range(rows):\n        for j in range(columns):\n            data_type = choice(DATA_TYPES)\n            if data_type == str:\n                df.at[i, 'col' + str(j)] = ''.join(np.random.choice('abcdefghijklmnopqrstuvwxyz', 5))\n            elif data_type == int:\n                df.at[i, 'col' + str(j)] = np.random.randint(0, 10)\n            elif data_type == float:\n                df.at[i, 'col' + str(j)] = float(np.random.randint(0, 10))\n            elif data_type == list:\n                df.at[i, 'col' + str(j)] = np.random.choice(range(1, 6), np.random.randint(1, 6))\n            elif data_type == tuple:\n                df.at[i, 'col' + str(j)] = tuple(np.random.choice(range(1, 6), np.random.randint(1, 6)))\n            elif data_type == dict:\n                df.at[i, 'col' + str(j)] = {np.random.randint(0, 10): np.random.randint(0, 10) for _ in range(np.random.randint(1, 6))}\n            elif data_type == set:\n                df.at[i, 'col' + str(j)] = set(np.random.choice(range(1, 6), np.random.randint(1, 6)))\n    return df", "raw_solution": "import pandas as pd\nimport numpy as np\nfrom random import choice\n# Constants\nDATA_TYPES = [str, int, float, list, tuple, dict, set]\n\ndef task_func(rows, columns):\n    df = pd.DataFrame(columns=['col' + str(i) for i in range(columns)])\n    for i in range(rows):\n        for j in range(columns):\n            data_type = choice(DATA_TYPES)\n            if data_type == str:\n                df.at[i, 'col' + str(j)] = ''.join(np.random.choice('abcdefghijklmnopqrstuvwxyz', 5))\n            elif data_type == int:\n                df.at[i, 'col' + str(j)] = np.random.randint(0, 10)\n            elif data_type == float:\n                df.at[i, 'col' + str(j)] = float(np.random.randint(0, 10))\n            elif data_type == list:\n                df.at[i, 'col' + str(j)] = np.random.choice(range(1, 6), np.random.randint(1, 6))\n            elif data_type == tuple:\n                df.at[i, 'col' + str(j)] = tuple(np.random.choice(range(1, 6), np.random.randint(1, 6)))\n            elif data_type == dict:\n                df.at[i, 'col' + str(j)] = {np.random.randint(0, 10): np.random.randint(0, 10) for _ in range(np.random.randint(1, 6))}\n            elif data_type == set:\n                df.at[i, 'col' + str(j)] = set(np.random.choice(range(1, 6), np.random.randint(1, 6)))\n    return df\n```"}
{"task_id": "BigCodeBench/194", "solution": "import numpy as np\nimport matplotlib.pyplot as plt\nBAR_COLOR = ['blue', 'green', 'red', 'cyan', 'magenta', 'yellow', 'black']\ndef task_func(data_size):\n    # Generate random numeric data\n    data = np.random.rand(data_size)\n    \n    # Select a random color from the predefined list\n    color = np.random.choice(BAR_COLOR)\n    \n    # Create a histogram of the data\n    plt.hist(data, bins=10, color=color)\n    \n    # Show the histogram\n    plt.show()\n    \n    # Return the generated data and the selected color\n    return data, color", "raw_solution": "import numpy as np\nimport matplotlib.pyplot as plt\n# Constants\nBAR_COLOR = ['blue', 'green', 'red', 'cyan', 'magenta', 'yellow', 'black']\n\ndef task_func(data_size):\n    # Generate random numeric data\n    data = np.random.rand(data_size)\n    \n    # Select a random color from the predefined list\n    color = np.random.choice(BAR_COLOR)\n    \n    # Create a histogram of the data\n    plt.hist(data, bins=10, color=color)\n    \n    # Show the histogram\n    plt.show()\n    \n    # Return the generated data and the selected color\n    return data, color\n```"}
{"task_id": "BigCodeBench/195", "solution": "import subprocess\nimport platform\nimport time\ndef task_func(url):\n    # Check if the operating system is Windows\n    if platform.system() == 'Windows':\n        # Use the start function to open the web page in the default web browser\n        subprocess.Popen(['start', url], shell=True)\n    else:\n        # Use the webbrowser module to open the web page in the default web browser\n        import webbrowser\n        webbrowser.open(url)\n    # Return the return code of the subprocess\n    return subprocess.call(['tasklist', '/FI', 'IMAGENAME eq chrome.exe'])", "raw_solution": "import subprocess\nimport platform\nimport time\n\ndef task_func(url):\n    # Check if the operating system is Windows\n    if platform.system() == 'Windows':\n        # Use the start function to open the web page in the default web browser\n        subprocess.Popen(['start', url], shell=True)\n    else:\n        # Use the webbrowser module to open the web page in the default web browser\n        import webbrowser\n        webbrowser.open(url)\n    # Return the return code of the subprocess\n    return subprocess.call(['tasklist', '/FI', 'IMAGENAME eq chrome.exe'])\n```"}
{"task_id": "BigCodeBench/196", "solution": "import random\nimport seaborn as sns\nimport numpy as np\nfrom matplotlib import pyplot as plt\ndef task_func(length, range_limit=100, seed=0):\n    if range_limit <= 1:\n        raise ValueError(\"If range_limit is less than or equal to 1.\")\n    random.seed(seed)\n    random_numbers = [random.randint(0, range_limit - 1) for _ in range(length)]\n    random_numbers.sort()\n    sns.histplot(random_numbers)\n    plt.show()\n    return (plt.gca(), random_numbers)", "raw_solution": "import random\nimport seaborn as sns\nimport numpy as np\nfrom matplotlib import pyplot as plt\n\ndef task_func(length, range_limit=100, seed=0):\n    if range_limit <= 1:\n        raise ValueError(\"If range_limit is less than or equal to 1.\")\n    random.seed(seed)\n    random_numbers = [random.randint(0, range_limit - 1) for _ in range(length)]\n    random_numbers.sort()\n    sns.histplot(random_numbers)\n    plt.show()\n    return (plt.gca(), random_numbers)\n```"}
{"task_id": "BigCodeBench/197", "solution": "import heapq\nimport math\nimport matplotlib.pyplot as plt\ndef task_func(l1, l2, N=10):\n    # Calculate the differences between the respective elements of the lists\n    differences = [abs(x - y) for x, y in zip(l1, l2)]\n    # Sort the differences in descending order\n    differences.sort(reverse=True)\n    # Take the square of the differences\n    squared_differences = [x ** 2 for x in differences]\n    # Take the square root of the squared differences\n    sqrt_differences = [math.sqrt(x) for x in squared_differences]\n    # Get the N biggest differences\n    biggest_differences = heapq.nlargest(N, sqrt_differences)\n    # Plot the differences\n    plt.plot(biggest_differences)\n    # Return the plotted values as a matplotlib Axes object\n    return plt.gca()", "raw_solution": "import heapq\nimport math\nimport matplotlib.pyplot as plt\ndef task_func(l1, l2, N=10):\n    # Calculate the differences between the respective elements of the lists\n    differences = [abs(x - y) for x, y in zip(l1, l2)]\n    # Sort the differences in descending order\n    differences.sort(reverse=True)\n    # Take the square of the differences\n    squared_differences = [x ** 2 for x in differences]\n    # Take the square root of the squared differences\n    sqrt_differences = [math.sqrt(x) for x in squared_differences]\n    # Get the N biggest differences\n    biggest_differences = heapq.nlargest(N, sqrt_differences)\n    # Plot the differences\n    plt.plot(biggest_differences)\n    # Return the plotted values as a matplotlib Axes object\n    return plt.gca()\n```"}
{"task_id": "BigCodeBench/198", "solution": "import numpy as np\nimport bisect\nimport statistics\nimport matplotlib.pyplot as plt\ndef task_func(data, value):\n    if len(data) == 0:\n        return np.array([]), 0\n    avg = statistics.mean(data)\n    greater_than_avg = [x for x in data if x > avg]\n    count = len(greater_than_avg)\n    sorted_data = np.sort(data)\n    plt.hist(sorted_data, bins=20)\n    plt.show()\n    return np.array(greater_than_avg), count", "raw_solution": "import numpy as np\nimport bisect\nimport statistics\nimport matplotlib.pyplot as plt\n\ndef task_func(data, value):\n    if len(data) == 0:\n        return np.array([]), 0\n    avg = statistics.mean(data)\n    greater_than_avg = [x for x in data if x > avg]\n    count = len(greater_than_avg)\n    sorted_data = np.sort(data)\n    plt.hist(sorted_data, bins=20)\n    plt.show()\n    return np.array(greater_than_avg), count\n```"}
{"task_id": "BigCodeBench/199", "solution": "import pandas as pd\nimport pytz\nfrom datetime import datetime\nfrom random import randint, seed as set_seed\ndef task_func(\n    utc_datetime,\n    cities=['New York', 'London', 'Beijing', 'Tokyo', 'Sydney'],\n    weather_conditions=['Sunny', 'Cloudy', 'Rainy', 'Snowy', 'Stormy'],\n    timezones={\n        'New York': 'America/New_York',\n        'London': 'Europe/London',\n        'Beijing': 'Asia/Shanghai',\n        'Tokyo': 'Asia/Tokyo',\n        'Sydney': 'Australia/Sydney'\n    },\n    seed=42\n):\n    set_seed(seed)\n    df = pd.DataFrame()\n    for city in cities:\n        local_time = utc_datetime.astimezone(pytz.timezone(timezones[city]))\n        weather_condition = weather_conditions[randint(0, len(weather_conditions) - 1)]\n        df = df.append({\n            'City': city,\n            'Local Time': local_time.strftime('%Y-%m-%d %H:%M:%S %Z'),\n            'Weather Condition': weather_condition\n        }, ignore_index=True)\n    return df", "raw_solution": "import pandas as pd\nimport pytz\nfrom datetime import datetime\nfrom random import randint, seed as set_seed\n\ndef task_func(\n    utc_datetime,\n    cities=['New York', 'London', 'Beijing', 'Tokyo', 'Sydney'],\n    weather_conditions=['Sunny', 'Cloudy', 'Rainy', 'Snowy', 'Stormy'],\n    timezones={\n        'New York': 'America/New_York',\n        'London': 'Europe/London',\n        'Beijing': 'Asia/Shanghai',\n        'Tokyo': 'Asia/Tokyo',\n        'Sydney': 'Australia/Sydney'\n    },\n    seed=42\n):\n    set_seed(seed)\n    df = pd.DataFrame()\n    for city in cities:\n        local_time = utc_datetime.astimezone(pytz.timezone(timezones[city]))\n        weather_condition = weather_conditions[randint(0, len(weather_conditions) - 1)]\n        df = df.append({\n            'City': city,\n            'Local Time': local_time.strftime('%Y-%m-%d %H:%M:%S %Z'),\n            'Weather Condition': weather_condition\n        }, ignore_index=True)\n    return df\n```"}
{"task_id": "BigCodeBench/200", "solution": "import random\nimport bisect\nimport statistics\nimport matplotlib.pyplot as plt\ndef task_func(n, value):\n    # Generate 'n' random numbers between 0 and 1\n    numbers = [random.random() for _ in range(n)]\n    \n    # Find numbers greater than the average of all generated numbers\n    average = statistics.mean(numbers)\n    greater_than_average = [num for num in numbers if num > average]\n    \n    # Count how many are greater than or equal to a specified value\n    count = bisect.bisect_right(greater_than_average, value)\n    \n    # Plot the sorted numbers\n    plt.hist(greater_than_average, bins=100)\n    plt.title('Sorted numbers greater than the average')\n    plt.xlabel('Number')\n    plt.ylabel('Frequency')\n    plt.show()\n    \n    return greater_than_average, count", "raw_solution": "import random\nimport bisect\nimport statistics\nimport matplotlib.pyplot as plt\n\ndef task_func(n, value):\n    # Generate 'n' random numbers between 0 and 1\n    numbers = [random.random() for _ in range(n)]\n    \n    # Find numbers greater than the average of all generated numbers\n    average = statistics.mean(numbers)\n    greater_than_average = [num for num in numbers if num > average]\n    \n    # Count how many are greater than or equal to a specified value\n    count = bisect.bisect_right(greater_than_average, value)\n    \n    # Plot the sorted numbers\n    plt.hist(greater_than_average, bins=100)\n    plt.title('Sorted numbers greater than the average')\n    plt.xlabel('Number')\n    plt.ylabel('Frequency')\n    plt.show()\n    \n    return greater_than_average, count\n```"}
{"task_id": "BigCodeBench/201", "solution": "import bisect\nimport statistics\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\ndef task_func(df, column, value):\n    if column not in df.columns:\n        raise ValueError(\"Column does not exist in the DataFrame\")\n    if not isinstance(value, (int, float)):\n        raise ValueError(\"Value is not a number\")\n    avg = statistics.mean(df[column])\n    greater_than_avg = df[column] > avg\n    greater_than_value = df[column] > value\n    return (greater_than_avg, np.sum(greater_than_value), plt.hist(df[column], bins=20))", "raw_solution": "import bisect\nimport statistics\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\n\ndef task_func(df, column, value):\n    if column not in df.columns:\n        raise ValueError(\"Column does not exist in the DataFrame\")\n    if not isinstance(value, (int, float)):\n        raise ValueError(\"Value is not a number\")\n    avg = statistics.mean(df[column])\n    greater_than_avg = df[column] > avg\n    greater_than_value = df[column] > value\n    return (greater_than_avg, np.sum(greater_than_value), plt.hist(df[column], bins=20))\n```"}
{"task_id": "BigCodeBench/202", "solution": "import re\nimport json\nfrom collections import Counter\ndef task_func(json_str, top_n=10):\n    # Parse the JSON string\n    json_dict = json.loads(json_str)\n    \n    # Extract all URLs from the JSON dict\n    urls = re.findall(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', json_str)\n    \n    # Count the number of times each URL appears\n    url_counts = Counter(urls)\n    \n    # Return the top n URLs\n    return dict(url_counts.most_common(top_n))", "raw_solution": "import re\nimport json\nfrom collections import Counter\n\ndef task_func(json_str, top_n=10):\n    # Parse the JSON string\n    json_dict = json.loads(json_str)\n    \n    # Extract all URLs from the JSON dict\n    urls = re.findall(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', json_str)\n    \n    # Count the number of times each URL appears\n    url_counts = Counter(urls)\n    \n    # Return the top n URLs\n    return dict(url_counts.most_common(top_n))\n```"}
{"task_id": "BigCodeBench/203", "solution": "import json\nimport smtplib\nSMTP_SERVER = \"smtp.gmail.com\"\nSMTP_PORT = 587\nEMAIL_ADDRESS = \"your.email@gmail.com\"\nEMAIL_PASSWORD = \"your.password\"\ndef task_func(input_data=None, smtp_server=SMTP_SERVER, smtp_port=SMTP_PORT, email_address=EMAIL_ADDRESS, email_password=EMAIL_PASSWORD, smtp=None):\n    if not input_data:\n        return []\n    data = json.loads(input_data)\n    if not data:\n        return []\n    names = []\n    for item in data:\n        if \"email\" in item and \"name\" in item:\n            names.append(item[\"name\"])\n    if not names:\n        return []", "raw_solution": "import json\nimport smtplib\n# Constants\nSMTP_SERVER = \"smtp.gmail.com\"\nSMTP_PORT = 587\nEMAIL_ADDRESS = \"your.email@gmail.com\"\nEMAIL_PASSWORD = \"your.password\"\ndef task_func(input_data=None, smtp_server=SMTP_SERVER, smtp_port=SMTP_PORT, email_address=EMAIL_ADDRESS, email_password=EMAIL_PASSWORD, smtp=None):\n    if not input_data:\n        return []\n    data = json.loads(input_data)\n    if not data:\n        return []\n    names = []\n    for item in data:\n        if \"email\" in item and \"name\" in item:\n            names.append(item[\"name\"])\n    if not names:\n        return []\n    message = f\"Subject: Extracted Names\\n\\n{'\\n'.join(names)}\"\n    with smtplib.SMTP(smtp_server, smtp_port) as server:\n        server.starttls()\n        server.login(email_address, email_password)\n        server.sendmail(email_address, email_address, message)\n    return names\n```"}
{"task_id": "BigCodeBench/204", "solution": "import numpy as np\nfrom collections import Counter\nimport matplotlib.pyplot as plt\ndef task_func(L):\n    mean = np.mean(L)\n    median = np.median(L)\n    mode = Counter(L).most_common(1)[0][0]\n    std_dev = np.std(L)\n    plot = plt.hist(L, bins=10)\n    return {'mean': mean, 'median': median, 'mode': mode, 'std_dev': std_dev, 'plot': plot}", "raw_solution": "import numpy as np\nfrom collections import Counter\nimport matplotlib.pyplot as plt\n\ndef task_func(L):\n    mean = np.mean(L)\n    median = np.median(L)\n    mode = Counter(L).most_common(1)[0][0]\n    std_dev = np.std(L)\n    plot = plt.hist(L, bins=10)\n    return {'mean': mean, 'median': median, 'mode': mode, 'std_dev': std_dev, 'plot': plot}\n```"}
{"task_id": "BigCodeBench/205", "solution": "import subprocess\nfrom multiprocessing import Pool\ndef execute_command(command):\n    process = subprocess.Popen(command, stdout=subprocess.PIPE, stderr=subprocess.PIPE, shell=True)\n    output, _ = process.communicate()\n    return output\ndef task_func(commands):\n    if not commands:\n        return []\n    with Pool() as pool:\n        outputs = pool.map(execute_command, commands)\n    return outputs", "raw_solution": "import subprocess\nfrom multiprocessing import Pool\n\ndef execute_command(command):\n    process = subprocess.Popen(command, stdout=subprocess.PIPE, stderr=subprocess.PIPE, shell=True)\n    output, _ = process.communicate()\n    return output\n\ndef task_func(commands):\n    if not commands:\n        return []\n    with Pool() as pool:\n        outputs = pool.map(execute_command, commands)\n    return outputs\n```"}
{"task_id": "BigCodeBench/206", "solution": "import csv\nimport json\nimport os\ndef task_func(file_name):\n    if not os.path.exists(file_name):\n        raise FileNotFoundError(\"File does not exist\")\n    with open(file_name, newline='') as csvfile:\n        reader = csv.DictReader(csvfile)\n        data = [row for row in reader]\n    with open(file_name.replace('.csv', '.json'), 'w') as jsonfile:\n        json.dump(data, jsonfile)\n    return file_name.replace('.csv', '.json')", "raw_solution": "import csv\nimport json\nimport os\ndef task_func(file_name):\n    if not os.path.exists(file_name):\n        raise FileNotFoundError(\"File does not exist\")\n    with open(file_name, newline='') as csvfile:\n        reader = csv.DictReader(csvfile)\n        data = [row for row in reader]\n    with open(file_name.replace('.csv', '.json'), 'w') as jsonfile:\n        json.dump(data, jsonfile)\n    return file_name.replace('.csv', '.json')\n```"}
{"task_id": "BigCodeBench/207", "solution": "import re\nimport requests\ndef task_func(input):\n    # Extract the API endpoint from the input string\n    endpoint = re.search(r'https?://\\S+', input).group()\n    # Send a GET request to the endpoint\n    response = requests.get(endpoint)\n    # Return the response data in JSON format\n    return response.json()", "raw_solution": "import re\nimport requests\ndef task_func(input):\n    # Extract the API endpoint from the input string\n    endpoint = re.search(r'https?://\\S+', input).group()\n    # Send a GET request to the endpoint\n    response = requests.get(endpoint)\n    # Return the response data in JSON format\n    return response.json()\n```"}
{"task_id": "BigCodeBench/208", "solution": "import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\ndef task_func(elements, seed=0):\n    if not isinstance(elements, int) or elements <= 0:\n        raise ValueError(\"If elements is not a positive integer.\")\n    np.random.seed(seed)\n    steps = np.random.choice([-1, 1], size=elements)\n    walk = np.cumsum(steps)\n    stats = {\n        \"count\": len(walk),\n        \"mean\": np.mean(walk),\n        \"std\": np.std(walk),\n        \"min\": np.min(walk),\n        \"5th\": np.percentile(walk, 5),\n        \"25th\": np.percentile(walk, 25),\n        \"median\": np.median(walk),\n        \"75th\": np.percentile(walk, 75),\n        \"95th\": np.percentile(walk, 95),\n        \"max\": np.max(walk)\n    }\n    fig, ax = plt.subplots()\n    ax.plot(walk)\n    ax.set_title(\"Random Walk\")\n    ax.set_xlabel(\"Steps\")\n    ax.set_ylabel(\"Position\")\n    return stats, ax", "raw_solution": "import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\ndef task_func(elements, seed=0):\n    if not isinstance(elements, int) or elements <= 0:\n        raise ValueError(\"If elements is not a positive integer.\")\n    np.random.seed(seed)\n    steps = np.random.choice([-1, 1], size=elements)\n    walk = np.cumsum(steps)\n    stats = {\n        \"count\": len(walk),\n        \"mean\": np.mean(walk),\n        \"std\": np.std(walk),\n        \"min\": np.min(walk),\n        \"5th\": np.percentile(walk, 5),\n        \"25th\": np.percentile(walk, 25),\n        \"median\": np.median(walk),\n        \"75th\": np.percentile(walk, 75),\n        \"95th\": np.percentile(walk, 95),\n        \"max\": np.max(walk)\n    }\n    fig, ax = plt.subplots()\n    ax.plot(walk)\n    ax.set_title(\"Random Walk\")\n    ax.set_xlabel(\"Steps\")\n    ax.set_ylabel(\"Position\")\n    return stats, ax\n```"}
{"task_id": "BigCodeBench/209", "solution": "import numpy as np\nfrom operator import itemgetter\nimport matplotlib.pyplot as plt\ndef task_func(data):\n    # Create a scatter plot of the data\n    plt.scatter(data[:, 0], data[:, 1])\n    \n    # Find the tuple with the maximum value at index 1\n    max_tuple = max(data, key=itemgetter(1))\n    \n    # Highlight the tuple with the maximum value at index 1\n    plt.scatter(max_tuple[0], max_tuple[1], color='red', marker='x')\n    \n    # Set the title, x-axis label, y-axis label, and legend\n    plt.title('Max Tuple Highlighted')\n    plt.xlabel('x')\n    plt.ylabel('y')\n    plt.legend(['Data', 'Max Tuple'])\n    \n    # Return the Axes object of the plot\n    return plt.axes()", "raw_solution": "import numpy as np\nfrom operator import itemgetter\nimport matplotlib.pyplot as plt\n\ndef task_func(data):\n    # Create a scatter plot of the data\n    plt.scatter(data[:, 0], data[:, 1])\n    \n    # Find the tuple with the maximum value at index 1\n    max_tuple = max(data, key=itemgetter(1))\n    \n    # Highlight the tuple with the maximum value at index 1\n    plt.scatter(max_tuple[0], max_tuple[1], color='red', marker='x')\n    \n    # Set the title, x-axis label, y-axis label, and legend\n    plt.title('Max Tuple Highlighted')\n    plt.xlabel('x')\n    plt.ylabel('y')\n    plt.legend(['Data', 'Max Tuple'])\n    \n    # Return the Axes object of the plot\n    return plt.axes()\n```"}
{"task_id": "BigCodeBench/210", "solution": "import collections\nfrom operator import itemgetter\nimport matplotlib.pyplot as plt\ndef task_func(data):\n    letter_counts = collections.Counter(data)\n    max_value = max(letter_counts.values())\n    max_letter = max(letter_counts.items(), key=itemgetter(1))[0]\n    fig, ax = plt.subplots()\n    ax.bar(letter_counts.keys(), letter_counts.values())\n    ax.set_title('Letter Counts with Max Value Letter Highlighted')\n    ax.set_xlabel('Letter')\n    ax.set_ylabel('Count')\n    ax.legend(['Letter Counts', max_letter])\n    ax.text(max_letter, max_value, max_letter, ha='center', va='bottom', fontsize=12)\n    return ax", "raw_solution": "import collections\nfrom operator import itemgetter\nimport matplotlib.pyplot as plt\n\ndef task_func(data):\n    letter_counts = collections.Counter(data)\n    max_value = max(letter_counts.values())\n    max_letter = max(letter_counts.items(), key=itemgetter(1))[0]\n    fig, ax = plt.subplots()\n    ax.bar(letter_counts.keys(), letter_counts.values())\n    ax.set_title('Letter Counts with Max Value Letter Highlighted')\n    ax.set_xlabel('Letter')\n    ax.set_ylabel('Count')\n    ax.legend(['Letter Counts', max_letter])\n    ax.text(max_letter, max_value, max_letter, ha='center', va='bottom', fontsize=12)\n    return ax\n```"}
{"task_id": "BigCodeBench/211", "solution": "import requests\nimport os\nimport zipfile\ndef task_func(url, destination_directory, headers=None):\n    response = requests.get(url, headers=headers)\n    if response.status_code != 200:\n        raise Exception('Failed to download file')\n    with zipfile.ZipFile(io.BytesIO(response.content)) as zip_ref:\n        zip_ref.extractall(destination_directory)\n    extracted_files = [f for f in os.listdir(destination_directory) if os.path.isfile(os.path.join(destination_directory, f))]\n    return extracted_files", "raw_solution": "import requests\nimport os\nimport zipfile\ndef task_func(url, destination_directory, headers=None):\n    response = requests.get(url, headers=headers)\n    if response.status_code != 200:\n        raise Exception('Failed to download file')\n    with zipfile.ZipFile(io.BytesIO(response.content)) as zip_ref:\n        zip_ref.extractall(destination_directory)\n    extracted_files = [f for f in os.listdir(destination_directory) if os.path.isfile(os.path.join(destination_directory, f))]\n    return extracted_files\n```"}
{"task_id": "BigCodeBench/212", "solution": "import numpy as np\nfrom operator import itemgetter\nimport matplotlib.pyplot as plt\ndef task_func(data):\n    x = data[:, 0]\n    y = data[:, 1]\n    max_y = max(y)\n    max_y_index = y.tolist().index(max_y)\n    plt.scatter(x, y)\n    plt.title('Points with Max Y Point Highlighted')\n    plt.xlabel('x')\n    plt.ylabel('y')\n    plt.scatter(x[max_y_index], y[max_y_index], color='red')\n    axes = plt.gca()\n    return axes, (x[max_y_index], y[max_y_index])", "raw_solution": "import numpy as np\nfrom operator import itemgetter\nimport matplotlib.pyplot as plt\n\ndef task_func(data):\n    x = data[:, 0]\n    y = data[:, 1]\n    max_y = max(y)\n    max_y_index = y.tolist().index(max_y)\n    plt.scatter(x, y)\n    plt.title('Points with Max Y Point Highlighted')\n    plt.xlabel('x')\n    plt.ylabel('y')\n    plt.scatter(x[max_y_index], y[max_y_index], color='red')\n    axes = plt.gca()\n    return axes, (x[max_y_index], y[max_y_index])\n```"}
{"task_id": "BigCodeBench/213", "solution": "import time\nimport random\nimport matplotlib.pyplot as plt\nfrom scipy.stats import kurtosis\ndef task_func(intervals=100, seed=0):\n    random.seed(seed)\n    time.sleep(1)\n    x = [random.random() for _ in range(intervals)]\n    plt.plot(x)\n    plt.show()\n    return plt.gca(), kurtosis(x)", "raw_solution": "import time\nimport random\nimport matplotlib.pyplot as plt\nfrom scipy.stats import kurtosis\ndef task_func(intervals=100, seed=0):\n    random.seed(seed)\n    time.sleep(1)\n    x = [random.random() for _ in range(intervals)]\n    plt.plot(x)\n    plt.show()\n    return plt.gca(), kurtosis(x)\n```"}
{"task_id": "BigCodeBench/214", "solution": "import random\nimport numpy as np\nimport cv2\nimport matplotlib.pyplot as plt\ndef task_func(seed=42, image_size=(100, 100, 3), range_low=0, range_high=255):\n    if range_low >= range_high:\n        raise ValueError(\"If range_low is not less than range_high.\")\n    random.seed(seed)\n    image = np.random.randint(range_low, range_high, image_size)\n    ax = plt.subplot(111)\n    ax.imshow(image)\n    ax.set_title(\"Random RGB Image\")\n    plt.show()\n    return ax, image", "raw_solution": "import random\nimport numpy as np\nimport cv2\nimport matplotlib.pyplot as plt\n\ndef task_func(seed=42, image_size=(100, 100, 3), range_low=0, range_high=255):\n    if range_low >= range_high:\n        raise ValueError(\"If range_low is not less than range_high.\")\n    random.seed(seed)\n    image = np.random.randint(range_low, range_high, image_size)\n    ax = plt.subplot(111)\n    ax.imshow(image)\n    ax.set_title(\"Random RGB Image\")\n    plt.show()\n    return ax, image\n```"}
{"task_id": "BigCodeBench/215", "solution": "import requests\nimport json\nimport pandas as pd\nimport seaborn as sns\nHEADERS = {\n    'accept': 'application/json'\n}\ndef task_func(url, parameters):\n    try:\n        response = requests.get(url, headers=HEADERS, params=parameters)\n        response.raise_for_status()\n        data = response.json()\n        df = pd.DataFrame(data)\n        sns.heatmap(df.corr(), annot=True)\n        return df, sns.plt.gca()\n    except requests.exceptions.RequestException as e:\n        raise Exception(\"This function will raise a general Expection if the url is invalid, empty data, invalid data, and url cannot be accessed.\")", "raw_solution": "import requests\nimport json\nimport pandas as pd\nimport seaborn as sns\n# Constants\nHEADERS = {\n    'accept': 'application/json'\n}\ndef task_func(url, parameters):\n    try:\n        response = requests.get(url, headers=HEADERS, params=parameters)\n        response.raise_for_status()\n        data = response.json()\n        df = pd.DataFrame(data)\n        sns.heatmap(df.corr(), annot=True)\n        return df, sns.plt.gca()\n    except requests.exceptions.RequestException as e:\n        raise Exception(\"This function will raise a general Expection if the url is invalid, empty data, invalid data, and url cannot be accessed.\")\n```"}
{"task_id": "BigCodeBench/216", "solution": "import pandas as pd\nimport os\nimport json\nfrom collections import Counter\ndef task_func(json_dir_path, word_count):\n    # Initialize a list to store the most common words and their counts\n    most_common_words = []\n    \n    # Loop through all the files in the directory\n    for filename in os.listdir(json_dir_path):\n        # Check if the file is a JSON file\n        if filename.endswith('.json'):\n            # Open the JSON file\n            with open(os.path.join(json_dir_path, filename), 'r') as f:\n                # Load the JSON data\n                data = json.load(f)\n                \n                # Extract the text content from the JSON data\n                text = data['text']\n                \n                # Split the text into words\n                words = text.split()\n                \n                # Count the frequency of each word\n                word_counts = Counter(words)\n                \n                # Get the most common words and their counts\n                most_common = word_counts.most_common(word_count)\n                \n                # Add the most common words and their counts to the list\n                most_common_words.extend(most_common)\n    \n    # Return the list of most common words and their counts\n    return most_common_words", "raw_solution": "import pandas as pd\nimport os\nimport json\nfrom collections import Counter\ndef task_func(json_dir_path, word_count):\n    # Initialize a list to store the most common words and their counts\n    most_common_words = []\n    \n    # Loop through all the files in the directory\n    for filename in os.listdir(json_dir_path):\n        # Check if the file is a JSON file\n        if filename.endswith('.json'):\n            # Open the JSON file\n            with open(os.path.join(json_dir_path, filename), 'r') as f:\n                # Load the JSON data\n                data = json.load(f)\n                \n                # Extract the text content from the JSON data\n                text = data['text']\n                \n                # Split the text into words\n                words = text.split()\n                \n                # Count the frequency of each word\n                word_counts = Counter(words)\n                \n                # Get the most common words and their counts\n                most_common = word_counts.most_common(word_count)\n                \n                # Add the most common words and their counts to the list\n                most_common_words.extend(most_common)\n    \n    # Return the list of most common words and their counts\n    return most_common_words\n```"}
{"task_id": "BigCodeBench/217", "solution": "import numpy as np\nfrom scipy import stats\nimport matplotlib.pyplot as plt\ndef task_func(mu=0, sigma=1, sample_size=1000, seed=0):\n    np.random.seed(seed)\n    sample = np.random.normal(mu, sigma, sample_size)\n    ax = plt.hist(sample, bins=50, density=True)\n    x = np.linspace(mu - 3*sigma, mu + 3*sigma, 1000)\n    y = stats.norm.pdf(x, mu, sigma)\n    ax.plot(x, y, 'r')\n    ax.set_title('Normal Distribution with $\\\\mu = %0.2f, \\\\sigma = %0.2f$' % (mu, sigma))\n    return ax, np.mean(sample), np.std(sample)", "raw_solution": "import numpy as np\nfrom scipy import stats\nimport matplotlib.pyplot as plt\n\ndef task_func(mu=0, sigma=1, sample_size=1000, seed=0):\n    np.random.seed(seed)\n    sample = np.random.normal(mu, sigma, sample_size)\n    ax = plt.hist(sample, bins=50, density=True)\n    x = np.linspace(mu - 3*sigma, mu + 3*sigma, 1000)\n    y = stats.norm.pdf(x, mu, sigma)\n    ax.plot(x, y, 'r')\n    ax.set_title('Normal Distribution with $\\\\mu = %0.2f, \\\\sigma = %0.2f$' % (mu, sigma))\n    return ax, np.mean(sample), np.std(sample)\n```"}
{"task_id": "BigCodeBench/218", "solution": "import pandas as pd\nfrom sklearn.preprocessing import StandardScaler\nFEATURES = ['feature1', 'feature2', 'feature3', 'feature4', 'feature5']\nTARGET = 'target'\ndef task_func(df, dict_mapping, plot_histogram=False):\n    if not isinstance(df, pd.DataFrame):\n        raise ValueError(\"The input df is not a DataFrame.\")\n    if not set(FEATURES).issubset(df.columns) or not set([TARGET]).issubset(df.columns):\n        raise ValueError(\"The function will raise ValueError if the FEATURES and TARGET columns not in the input DataFrame.\")\n    df[FEATURES] = df[FEATURES].replace(dict_mapping)\n    scaler = StandardScaler()\n    df[FEATURES] = scaler.fit_transform(df[FEATURES])\n    if plot_histogram:\n        df[TARGET].hist()\n    return df, None", "raw_solution": "import pandas as pd\nfrom sklearn.preprocessing import StandardScaler\n# Constants\nFEATURES = ['feature1', 'feature2', 'feature3', 'feature4', 'feature5']\nTARGET = 'target'\ndef task_func(df, dict_mapping, plot_histogram=False):\n    if not isinstance(df, pd.DataFrame):\n        raise ValueError(\"The input df is not a DataFrame.\")\n    if not set(FEATURES).issubset(df.columns) or not set([TARGET]).issubset(df.columns):\n        raise ValueError(\"The function will raise ValueError if the FEATURES and TARGET columns not in the input DataFrame.\")\n    df[FEATURES] = df[FEATURES].replace(dict_mapping)\n    scaler = StandardScaler()\n    df[FEATURES] = scaler.fit_transform(df[FEATURES])\n    if plot_histogram:\n        df[TARGET].hist()\n    return df, None\n```"}
{"task_id": "BigCodeBench/219", "solution": "import math\nimport statistics\nimport numpy as np\ndef task_func(input_list):\n    # Sort the input list in ascending order based on the degree value of its elements\n    sorted_list = sorted(input_list, key=lambda x: x[0])\n    \n    # Calculate the mean, median, and mode of the sorted list\n    mean = statistics.mean(sorted_list)\n    median = statistics.median(sorted_list)\n    mode = statistics.mode(sorted_list)\n    \n    # Calculate the magnitude of the fast fourier transform of the degree values upto the nearest integer\n    fft = np.fft.fft(sorted_list)\n    magnitude = np.abs(fft)\n    magnitude = np.round(magnitude)\n    \n    # Return the results as a tuple\n    return (mean, median, mode, magnitude)", "raw_solution": "import math\nimport statistics\nimport numpy as np\ndef task_func(input_list):\n    # Sort the input list in ascending order based on the degree value of its elements\n    sorted_list = sorted(input_list, key=lambda x: x[0])\n    \n    # Calculate the mean, median, and mode of the sorted list\n    mean = statistics.mean(sorted_list)\n    median = statistics.median(sorted_list)\n    mode = statistics.mode(sorted_list)\n    \n    # Calculate the magnitude of the fast fourier transform of the degree values upto the nearest integer\n    fft = np.fft.fft(sorted_list)\n    magnitude = np.abs(fft)\n    magnitude = np.round(magnitude)\n    \n    # Return the results as a tuple\n    return (mean, median, mode, magnitude)\n```"}
{"task_id": "BigCodeBench/220", "solution": "from random import choice\nimport turtle\nimport time\ndef task_func(colors):\n    turtle.speed(0)\n    turtle.bgcolor(\"white\")\n    turtle.pensize(2)\n    turtle.hideturtle()\n    for i in range(5):\n        color = choice(colors)\n        turtle.color(color)\n        turtle.begin_fill()\n        for j in range(4):\n            turtle.forward(100)\n            turtle.right(90)\n        turtle.end_fill()\n        time.sleep(1)\n    turtle.done()", "raw_solution": "from random import choice\nimport turtle\nimport time\n\ndef task_func(colors):\n    turtle.speed(0)\n    turtle.bgcolor(\"white\")\n    turtle.pensize(2)\n    turtle.hideturtle()\n    for i in range(5):\n        color = choice(colors)\n        turtle.color(color)\n        turtle.begin_fill()\n        for j in range(4):\n            turtle.forward(100)\n            turtle.right(90)\n        turtle.end_fill()\n        time.sleep(1)\n    turtle.done()\n```"}
{"task_id": "BigCodeBench/221", "solution": "import numpy as np\nfrom scipy import stats\nFEATURES = ['feature1', 'feature2', 'feature3', 'feature4', 'feature5']\ndef task_func(df, dct):\n    # Check if the input is valid\n    if 'feature1' not in df.columns:\n        return \"Invalid input\"\n    # Replace certain values in the DataFrame based on the provided dictionary mapping\n    for key, value in dct.items():\n        df[key] = df[key].replace(value)\n    # Calculate and return the mean, median, mode, and variance for each feature\n    stats_dict = {}\n    for feature in FEATURES:\n        stats_dict[feature] = {\n            'mean': np.mean(df[feature]),\n            'median': np.median(df[feature]),\n            'mode': stats.mode(df[feature])[0][0],\n            'variance': np.var(df[feature])\n        }\n    return stats_dict", "raw_solution": "import numpy as np\nfrom scipy import stats\n# Constants\nFEATURES = ['feature1', 'feature2', 'feature3', 'feature4', 'feature5']\n\ndef task_func(df, dct):\n    # Check if the input is valid\n    if 'feature1' not in df.columns:\n        return \"Invalid input\"\n    # Replace certain values in the DataFrame based on the provided dictionary mapping\n    for key, value in dct.items():\n        df[key] = df[key].replace(value)\n    # Calculate and return the mean, median, mode, and variance for each feature\n    stats_dict = {}\n    for feature in FEATURES:\n        stats_dict[feature] = {\n            'mean': np.mean(df[feature]),\n            'median': np.median(df[feature]),\n            'mode': stats.mode(df[feature])[0][0],\n            'variance': np.var(df[feature])\n        }\n    return stats_dict\n```"}
{"task_id": "BigCodeBench/222", "solution": "import math\nimport numpy as np\nimport matplotlib.pyplot as plt\ndef task_func(list_input):\n    list_input.sort(key=lambda x: x[1])\n    cumulative_sum = np.cumsum([x[0] for x in list_input])\n    plt.plot(cumulative_sum)\n    plt.show()\n    return cumulative_sum, plt.gca()", "raw_solution": "import math\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef task_func(list_input):\n    list_input.sort(key=lambda x: x[1])\n    cumulative_sum = np.cumsum([x[0] for x in list_input])\n    plt.plot(cumulative_sum)\n    plt.show()\n    return cumulative_sum, plt.gca()\n```"}
{"task_id": "BigCodeBench/223", "solution": "import pandas as pd\nfrom sklearn.preprocessing import LabelEncoder\ndef task_func(df, dct, columns=None):\n    if not isinstance(df, pd.DataFrame):\n        raise ValueError(\"The input df is not a DataFrame.\")\n    if columns is None:\n        columns = dct.keys()\n    for col in columns:\n        if col in dct:\n            if dct[col] == 'replace':\n                df[col] = df[col].replace(dct[col])\n            elif dct[col] == 'encode':\n                le = LabelEncoder()\n                df[col] = le.fit_transform(df[col])\n            elif dct[col] == 'standardize':\n                df[col] = (df[col] - df[col].mean()) / df[col].std()\n    return df", "raw_solution": "import pandas as pd\nfrom sklearn.preprocessing import LabelEncoder\n\ndef task_func(df, dct, columns=None):\n    if not isinstance(df, pd.DataFrame):\n        raise ValueError(\"The input df is not a DataFrame.\")\n    if columns is None:\n        columns = dct.keys()\n    for col in columns:\n        if col in dct:\n            if dct[col] == 'replace':\n                df[col] = df[col].replace(dct[col])\n            elif dct[col] == 'encode':\n                le = LabelEncoder()\n                df[col] = le.fit_transform(df[col])\n            elif dct[col] == 'standardize':\n                df[col] = (df[col] - df[col].mean()) / df[col].std()\n    return df\n```"}
{"task_id": "BigCodeBench/224", "solution": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.fft import fft\ndef task_func(range_start=-10, range_end=10, step=0.1):\n    gen = ((x, np.sin(x), np.cos(x), np.abs(np.sin(x) - np.cos(x))) for x in np.arange(range_start, range_end, step))\n    ax = plt.plot()\n    for x, sin_x, cos_x, diff in gen:\n        ax.plot(x, sin_x, label='sin(x)')\n        ax.plot(x, cos_x, label='cos(x)')\n        ax.plot(x, diff, label='abs(sin(x) - cos(x))')\n    ax.legend()\n    plt.show()\n    fft_diff = fft(diff)\n    mean = np.abs(np.mean(fft_diff))\n    median = np.abs(np.median(fft_diff))\n    return (gen, ax, mean, median)", "raw_solution": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.fft import fft\n\ndef task_func(range_start=-10, range_end=10, step=0.1):\n    gen = ((x, np.sin(x), np.cos(x), np.abs(np.sin(x) - np.cos(x))) for x in np.arange(range_start, range_end, step))\n    ax = plt.plot()\n    for x, sin_x, cos_x, diff in gen:\n        ax.plot(x, sin_x, label='sin(x)')\n        ax.plot(x, cos_x, label='cos(x)')\n        ax.plot(x, diff, label='abs(sin(x) - cos(x))')\n    ax.legend()\n    plt.show()\n    fft_diff = fft(diff)\n    mean = np.abs(np.mean(fft_diff))\n    median = np.abs(np.median(fft_diff))\n    return (gen, ax, mean, median)\n```"}
{"task_id": "BigCodeBench/225", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\ndef task_func(df, dct, columns=None, plot_histograms=False):\n    if not isinstance(df, pd.DataFrame):\n        raise ValueError(\"The function will raise a ValueError is input df is not a DataFrame.\")\n    if columns is None:\n        columns = df.columns\n    for col in columns:\n        if col in dct:\n            df[col] = df[col].map(dct)\n    if plot_histograms:\n        for col in columns:\n            plt.hist(df[col], bins=20)\n            plt.show()\n    return df", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\n\ndef task_func(df, dct, columns=None, plot_histograms=False):\n    if not isinstance(df, pd.DataFrame):\n        raise ValueError(\"The function will raise a ValueError is input df is not a DataFrame.\")\n    if columns is None:\n        columns = df.columns\n    for col in columns:\n        if col in dct:\n            df[col] = df[col].map(dct)\n    if plot_histograms:\n        for col in columns:\n            plt.hist(df[col], bins=20)\n            plt.show()\n    return df\n```"}
{"task_id": "BigCodeBench/226", "solution": "import numpy as np\nimport math\nimport matplotlib.pyplot as plt\ndef task_func(range_start=0, range_end=10, step=0.1):\n    gen = ((x, math.exp(x)) for x in np.arange(range_start, range_end, step))\n    plt.plot(np.arange(range_start, range_end, step), [y for x, y in gen])\n    plt.show()\n    return gen, plt.gca()", "raw_solution": "import numpy as np\nimport math\nimport matplotlib.pyplot as plt\n\ndef task_func(range_start=0, range_end=10, step=0.1):\n    gen = ((x, math.exp(x)) for x in np.arange(range_start, range_end, step))\n    plt.plot(np.arange(range_start, range_end, step), [y for x, y in gen])\n    plt.show()\n    return gen, plt.gca()\n```"}
{"task_id": "BigCodeBench/227", "solution": "import numpy as np\nimport os\nimport soundfile as sf\nimport librosa\nimport matplotlib.pyplot as plt\ndef task_func(L, M, N, audio_file):\n    if not os.path.exists(audio_file):\n        raise FileNotFoundError(\"The specified audio file does not exist.\")\n    data, sr = sf.read(audio_file)\n    data = data / np.max(np.abs(data))\n    data = librosa.stft(data, n_fft=2048, hop_length=512)\n    data = np.abs(data)\n    data = 20 * np.log10(data)\n    data = np.clip(data, -100, 100)\n    data = data.reshape(M, N)\n    plt.figure(figsize=(10, 10))\n    plt.imshow(data, aspect='auto', origin='lower', cmap='jet', extent=[0, N, 0, M])\n    plt.colorbar(label='SPL (dB)')\n    plt.xlabel('Time (samples)')\n    plt.ylabel('Frequency (Hz)')\n    plt.title('Spectrogram')\n    plt.show()\n    return data, plt.gcf()", "raw_solution": "import numpy as np\nimport os\nimport soundfile as sf\nimport librosa\nimport matplotlib.pyplot as plt\n\ndef task_func(L, M, N, audio_file):\n    if not os.path.exists(audio_file):\n        raise FileNotFoundError(\"The specified audio file does not exist.\")\n    data, sr = sf.read(audio_file)\n    data = data / np.max(np.abs(data))\n    data = librosa.stft(data, n_fft=2048, hop_length=512)\n    data = np.abs(data)\n    data = 20 * np.log10(data)\n    data = np.clip(data, -100, 100)\n    data = data.reshape(M, N)\n    plt.figure(figsize=(10, 10))\n    plt.imshow(data, aspect='auto', origin='lower', cmap='jet', extent=[0, N, 0, M])\n    plt.colorbar(label='SPL (dB)')\n    plt.xlabel('Time (samples)')\n    plt.ylabel('Frequency (Hz)')\n    plt.title('Spectrogram')\n    plt.show()\n    return data, plt.gcf()\n```"}
{"task_id": "BigCodeBench/228", "solution": "import pandas as pd\nimport numpy as np\ndef task_func(df, dct):\n    if not isinstance(df, pd.DataFrame):\n        raise ValueError(\"This function will raise a ValueError is input df is not a DataFrame.\")\n    df = df.replace(dct)\n    corr_matrix = df.corr(method='pearson')\n    return corr_matrix", "raw_solution": "import pandas as pd\nimport numpy as np\n# Constants\nCOLUMNS = ['column1', 'column2', 'column3', 'column4', 'column5']\ndef task_func(df, dct):\n    if not isinstance(df, pd.DataFrame):\n        raise ValueError(\"This function will raise a ValueError is input df is not a DataFrame.\")\n    df = df.replace(dct)\n    corr_matrix = df.corr(method='pearson')\n    return corr_matrix\n```"}
{"task_id": "BigCodeBench/229", "solution": "import json\nimport random\nfrom datetime import datetime, timedelta\nUSERS = ['Alice', 'Bob', 'Charlie', 'Dave', 'Eve']\ndef task_func(file_path, num_entries, seed=None):\n    if seed is not None:\n        random.seed(seed)\n    # Generate random user activity data\n    data = []\n    for i in range(num_entries):\n        user = random.choice(USERS)\n        action = random.choice(['login', 'logout', 'view', 'edit'])\n        timestamp = datetime.now() - timedelta(minutes=random.randint(0, 60))\n        data.append({'user': user, 'action': action, 'timestamp': timestamp})\n    # Write data to JSON file\n    with open(file_path, 'w') as f:\n        json.dump(data, f, indent=4)\n    return file_path", "raw_solution": "import json\nimport random\nfrom datetime import datetime, timedelta\n# Constants\nUSERS = ['Alice', 'Bob', 'Charlie', 'Dave', 'Eve']\ndef task_func(file_path, num_entries, seed=None):\n    if seed is not None:\n        random.seed(seed)\n    # Generate random user activity data\n    data = []\n    for i in range(num_entries):\n        user = random.choice(USERS)\n        action = random.choice(['login', 'logout', 'view', 'edit'])\n        timestamp = datetime.now() - timedelta(minutes=random.randint(0, 60))\n        data.append({'user': user, 'action': action, 'timestamp': timestamp})\n    # Write data to JSON file\n    with open(file_path, 'w') as f:\n        json.dump(data, f, indent=4)\n    return file_path\n```"}
{"task_id": "BigCodeBench/230", "solution": "import matplotlib.pyplot as plt\nimport pandas as pd\nimport seaborn as sns\ndef task_func(df):\n    if not isinstance(df, pd.DataFrame):\n        return \"Invalid input\"\n    df = df.drop_duplicates(subset=['Name'])\n    sns.histplot(df['Score'], kde=True, color='blue', label='Histogram of Scores')\n    plt.title('Histogram of Scores')\n    plt.legend()\n    sns.boxplot(x='Country', y='Score', data=df, color='red', label='Boxplot of Scores by Country')\n    plt.title('Boxplot of Scores by Country')\n    plt.legend()\n    plt.show()\n    return plt.gcf()", "raw_solution": "import matplotlib.pyplot as plt\nimport pandas as pd\nimport seaborn as sns\n# Constants\nCOLUMNS = ['Name', 'Age', 'Country', 'Score']\ndef task_func(df):\n    if not isinstance(df, pd.DataFrame):\n        return \"Invalid input\"\n    df = df.drop_duplicates(subset=['Name'])\n    sns.histplot(df['Score'], kde=True, color='blue', label='Histogram of Scores')\n    plt.title('Histogram of Scores')\n    plt.legend()\n    sns.boxplot(x='Country', y='Score', data=df, color='red', label='Boxplot of Scores by Country')\n    plt.title('Boxplot of Scores by Country')\n    plt.legend()\n    plt.show()\n    return plt.gcf()\n```"}
{"task_id": "BigCodeBench/231", "solution": "import numpy as np\nimport scipy.stats as stats\nimport matplotlib.pyplot as plt\nimport random\nfrom matplotlib.axes import Axes\ndef task_func(obj_list) -> Axes:\n    if not obj_list:\n        mu = 0\n        std = 0\n    else:\n        mu = np.mean([obj.value for obj in obj_list])\n        std = np.std([obj.value for obj in obj_list])\n    x = np.linspace(mu - 3 * std, mu + 3 * std, 100)\n    y = stats.norm.pdf(x, mu, std)\n    fig, ax = plt.subplots()\n    ax.plot(x, y)\n    ax.set_xlabel('Value')\n    ax.set_ylabel('Probability Density')\n    ax.set_title('Custom Normal Distribution Curve')\n    return ax", "raw_solution": "import numpy as np\nimport scipy.stats as stats\nimport matplotlib.pyplot as plt\nimport random\nfrom matplotlib.axes import Axes\nclass ValueObject:\n    value = 0\n    def __init__(self, mu=0, std=1, seed=77):\n        random.seed(seed)\n        self.value = random.gauss(mu, std)\ndef task_func(obj_list) -> Axes:\n    if not obj_list:\n        mu = 0\n        std = 0\n    else:\n        mu = np.mean([obj.value for obj in obj_list])\n        std = np.std([obj.value for obj in obj_list])\n    x = np.linspace(mu - 3 * std, mu + 3 * std, 100)\n    y = stats.norm.pdf(x, mu, std)\n    fig, ax = plt.subplots()\n    ax.plot(x, y)\n    ax.set_xlabel('Value')\n    ax.set_ylabel('Probability Density')\n    ax.set_title('Custom Normal Distribution Curve')\n    return ax\n```"}
{"task_id": "BigCodeBench/232", "solution": "import pandas as pd\nimport collections\ndef task_func(df):\n    if not isinstance(df, pd.DataFrame):\n        raise ValueError(\"Input df is not a DataFrame.\")\n    df = df.drop_duplicates(subset=['Customer Name'])\n    total_sales = df['Sales'].sum()\n    most_popular_category = collections.Counter(df['Category']).most_common(1)[0][0]\n    return {'Total Sales': total_sales, 'Most Popular Category': most_popular_category}", "raw_solution": "import pandas as pd\nimport collections\n\ndef task_func(df):\n    if not isinstance(df, pd.DataFrame):\n        raise ValueError(\"Input df is not a DataFrame.\")\n    df = df.drop_duplicates(subset=['Customer Name'])\n    total_sales = df['Sales'].sum()\n    most_popular_category = collections.Counter(df['Category']).most_common(1)[0][0]\n    return {'Total Sales': total_sales, 'Most Popular Category': most_popular_category}\n```"}
{"task_id": "BigCodeBench/233", "solution": "import random\nimport matplotlib.pyplot as plt\ndef task_func(obj_list, attr, num_bins=30, seed=0):\n    random.seed(seed)\n    attr_values = [getattr(obj, attr) for obj in obj_list]\n    plt.hist(attr_values, bins=num_bins, edgecolor='black')\n    plt.title('Histogram of attribute values')\n    plt.xlabel('Attribute Value')\n    plt.ylabel('Count')\n    return plt", "raw_solution": "import random\nimport matplotlib.pyplot as plt\n# Sample data\nclass Object:\n    value = 0\n    def __init__(self, value=None):\n        if value is None:\n            self.value = random.gauss(0, 1)\n        else:\n            self.value = value\ndef task_func(obj_list, attr, num_bins=30, seed=0):\n    random.seed(seed)\n    attr_values = [getattr(obj, attr) for obj in obj_list]\n    plt.hist(attr_values, bins=num_bins, edgecolor='black')\n    plt.title('Histogram of attribute values')\n    plt.xlabel('Attribute Value')\n    plt.ylabel('Count')\n    return plt\n```"}
{"task_id": "BigCodeBench/234", "solution": "import pandas as pd\nfrom scipy import stats\nimport matplotlib.pyplot as plt\ndef task_func(df):\n    if not isinstance(df, pd.DataFrame):\n        raise ValueError(\"The function will raise a ValueError is input df is not a DataFrame.\")\n    df = df.drop_duplicates(subset=['name'])\n    slope, intercept, r_value, p_value, std_err = stats.linregress(df['age'], df['score'])\n    plt.plot(df['age'], df['score'], 'o')\n    plt.plot(df['age'], slope * df['age'] + intercept, 'r')\n    plt.title('Linear Regression')\n    plt.xlabel('Age')\n    plt.ylabel('Score')\n    return plt, plt.gca()", "raw_solution": "import pandas as pd\nfrom scipy import stats\nimport matplotlib.pyplot as plt\n\ndef task_func(df):\n    if not isinstance(df, pd.DataFrame):\n        raise ValueError(\"The function will raise a ValueError is input df is not a DataFrame.\")\n    df = df.drop_duplicates(subset=['name'])\n    slope, intercept, r_value, p_value, std_err = stats.linregress(df['age'], df['score'])\n    plt.plot(df['age'], df['score'], 'o')\n    plt.plot(df['age'], slope * df['age'] + intercept, 'r')\n    plt.title('Linear Regression')\n    plt.xlabel('Age')\n    plt.ylabel('Score')\n    return plt, plt.gca()\n```"}
{"task_id": "BigCodeBench/235", "solution": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom statsmodels.formula.api import ols\ndef task_func(mu, sigma, seed=0, num_samples=1000, num_bins=30):\n    np.random.seed(seed)\n    x = np.random.normal(mu, sigma, num_samples)\n    fig, ax = plt.subplots()\n    ax.hist(x, bins=num_bins, density=True, alpha=0.5, color='blue')\n    pdf = np.exp(-(x - mu)**2 / (2 * sigma**2)) / (sigma * np.sqrt(2 * np.pi))\n    ax.plot(x, pdf, color='red')\n    y = np.linspace(mu - 3 * sigma, mu + 3 * sigma, 1000)\n    model = ols('y ~ 1', data={'y': y}).fit()\n    ax.plot(y, model.fittedvalues, color='green')\n    return ax", "raw_solution": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom statsmodels.formula.api import ols\ndef task_func(mu, sigma, seed=0, num_samples=1000, num_bins=30):\n    np.random.seed(seed)\n    x = np.random.normal(mu, sigma, num_samples)\n    fig, ax = plt.subplots()\n    ax.hist(x, bins=num_bins, density=True, alpha=0.5, color='blue')\n    pdf = np.exp(-(x - mu)**2 / (2 * sigma**2)) / (sigma * np.sqrt(2 * np.pi))\n    ax.plot(x, pdf, color='red')\n    y = np.linspace(mu - 3 * sigma, mu + 3 * sigma, 1000)\n    model = ols('y ~ 1', data={'y': y}).fit()\n    ax.plot(y, model.fittedvalues, color='green')\n    return ax\n```"}
{"task_id": "BigCodeBench/236", "solution": "import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score\ndef task_func(df, test_size=0.2, random_state=42):\n    if not isinstance(df, pd.DataFrame):\n        raise ValueError(\"The function will raise a ValueError is input df is not a DataFrame.\")\n    df.drop_duplicates(subset=['Name'], inplace=True)\n    X = df[['Age', 'Score']]\n    y = df['Category']\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n    clf = RandomForestClassifier(n_estimators=100, random_state=random_state)\n    clf.fit(X_train, y_train)\n    y_pred = clf.predict(X_test)\n    return accuracy_score(y_test, y_pred)", "raw_solution": "import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score\n\ndef task_func(df, test_size=0.2, random_state=42):\n    if not isinstance(df, pd.DataFrame):\n        raise ValueError(\"The function will raise a ValueError is input df is not a DataFrame.\")\n    df.drop_duplicates(subset=['Name'], inplace=True)\n    X = df[['Age', 'Score']]\n    y = df['Category']\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n    clf = RandomForestClassifier(n_estimators=100, random_state=random_state)\n    clf.fit(X_train, y_train)\n    y_pred = clf.predict(X_test)\n    return accuracy_score(y_test, y_pred)\n```"}
{"task_id": "BigCodeBench/237", "solution": "import numpy as np\nfrom sklearn.decomposition import PCA\nimport matplotlib.pyplot as plt\ndef task_func(data, save_plot=False, plot_path=None):\n    if save_plot and plot_path is None:\n        raise ValueError(\"If save_plot is True but plot_path is not provided.\")\n    coordinates_2d = np.zeros((len(data), 2))\n    for i, obj in enumerate(data):\n        coordinates_2d[i] = obj['3D_coordinates']\n    pca = PCA(n_components=2)\n    coordinates_2d = pca.fit_transform(coordinates_2d)\n    if save_plot:\n        fig, ax = plt.subplots()\n        ax.scatter(coordinates_2d[:, 0], coordinates_2d[:, 1])\n        plt.savefig(plot_path)\n        return coordinates_2d, ax\n    else:\n        return coordinates_2d", "raw_solution": "import numpy as np\nfrom sklearn.decomposition import PCA\nimport matplotlib.pyplot as plt\n\ndef task_func(data, save_plot=False, plot_path=None):\n    if save_plot and plot_path is None:\n        raise ValueError(\"If save_plot is True but plot_path is not provided.\")\n    coordinates_2d = np.zeros((len(data), 2))\n    for i, obj in enumerate(data):\n        coordinates_2d[i] = obj['3D_coordinates']\n    pca = PCA(n_components=2)\n    coordinates_2d = pca.fit_transform(coordinates_2d)\n    if save_plot:\n        fig, ax = plt.subplots()\n        ax.scatter(coordinates_2d[:, 0], coordinates_2d[:, 1])\n        plt.savefig(plot_path)\n        return coordinates_2d, ax\n    else:\n        return coordinates_2d\n```"}
{"task_id": "BigCodeBench/238", "solution": "import matplotlib\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import StandardScaler\ndef task_func(df):\n    # Standardize 'Age' and 'Score' columns\n    scaler = StandardScaler()\n    df[['Age', 'Score']] = scaler.fit_transform(df[['Age', 'Score']])\n    \n    # Remove duplicate entries based on 'Name'\n    df.drop_duplicates(subset='Name', inplace=True)\n    \n    # Plot a scatter plot of these standardized values\n    fig, ax = plt.subplots()\n    ax.scatter(df['Age (standardized)'], df['Score (standardized)'])\n    ax.set_title('Scatter Plot of Standardized Age and Score')\n    ax.set_xlabel('Age (standardized)')\n    ax.set_ylabel('Score (standardized)')\n    \n    return df, ax", "raw_solution": "import matplotlib\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import StandardScaler\ndef task_func(df):\n    # Standardize 'Age' and 'Score' columns\n    scaler = StandardScaler()\n    df[['Age', 'Score']] = scaler.fit_transform(df[['Age', 'Score']])\n    \n    # Remove duplicate entries based on 'Name'\n    df.drop_duplicates(subset='Name', inplace=True)\n    \n    # Plot a scatter plot of these standardized values\n    fig, ax = plt.subplots()\n    ax.scatter(df['Age (standardized)'], df['Score (standardized)'])\n    ax.set_title('Scatter Plot of Standardized Age and Score')\n    ax.set_xlabel('Age (standardized)')\n    ax.set_ylabel('Score (standardized)')\n    \n    return df, ax\n```"}
{"task_id": "BigCodeBench/239", "solution": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy import stats\ndef task_func(original):\n    # Extract numeric values\n    numeric_values = [item[0] for item in original]\n    \n    # Compute basic statistics\n    mean = np.mean(numeric_values)\n    std_dev = np.std(numeric_values)\n    min_val = np.min(numeric_values)\n    max_val = np.max(numeric_values)\n    \n    # Generate a histogram with an overlaid PDF\n    fig, ax = plt.subplots()\n    ax.hist(numeric_values, density=True, alpha=0.6, bins='auto')\n    x = np.linspace(min_val, max_val, 100)\n    y = stats.norm.pdf(x, mean, std_dev)\n    ax.plot(x, y, 'r')\n    ax.set_xlabel('Numeric Values')\n    ax.set_ylabel('Frequency')\n    ax.set_title('Histogram with Overlaid PDF')\n    \n    return np.array(numeric_values), {'mean': mean, 'std_dev': std_dev, 'min_val': min_val, 'max_val': max_val}, ax", "raw_solution": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy import stats\n\ndef task_func(original):\n    # Extract numeric values\n    numeric_values = [item[0] for item in original]\n    \n    # Compute basic statistics\n    mean = np.mean(numeric_values)\n    std_dev = np.std(numeric_values)\n    min_val = np.min(numeric_values)\n    max_val = np.max(numeric_values)\n    \n    # Generate a histogram with an overlaid PDF\n    fig, ax = plt.subplots()\n    ax.hist(numeric_values, density=True, alpha=0.6, bins='auto')\n    x = np.linspace(min_val, max_val, 100)\n    y = stats.norm.pdf(x, mean, std_dev)\n    ax.plot(x, y, 'r')\n    ax.set_xlabel('Numeric Values')\n    ax.set_ylabel('Frequency')\n    ax.set_title('Histogram with Overlaid PDF')\n    \n    return np.array(numeric_values), {'mean': mean, 'std_dev': std_dev, 'min_val': min_val, 'max_val': max_val}, ax\n```"}
{"task_id": "BigCodeBench/240", "solution": "import pandas as pd\nfrom random import uniform\ndef task_func(n_data_points=1000, min_value=0.0, max_value=10.0, column_name='Value'):\n    data = [uniform(min_value, max_value) for _ in range(n_data_points)]\n    df = pd.DataFrame(data, columns=[column_name])\n    df[column_name] = df[column_name].round(3)\n    return df", "raw_solution": "import pandas as pd\nfrom random import uniform\n\ndef task_func(n_data_points=1000, min_value=0.0, max_value=10.0, column_name='Value'):\n    data = [uniform(min_value, max_value) for _ in range(n_data_points)]\n    df = pd.DataFrame(data, columns=[column_name])\n    df[column_name] = df[column_name].round(3)\n    return df\n```"}
{"task_id": "BigCodeBench/241", "solution": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn import preprocessing\ndef task_func(original):\n    np_array = np.array(original)\n    normalized_array = preprocessing.normalize(np_array)\n    fig, ax = plt.subplots()\n    ax.plot(original, label='Original')\n    ax.plot(normalized_array, label='Normalized')\n    ax.set_title('Original vs. Normalized Data')\n    ax.legend()\n    return np_array, normalized_array, ax", "raw_solution": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn import preprocessing\n\ndef task_func(original):\n    np_array = np.array(original)\n    normalized_array = preprocessing.normalize(np_array)\n    fig, ax = plt.subplots()\n    ax.plot(original, label='Original')\n    ax.plot(normalized_array, label='Normalized')\n    ax.set_title('Original vs. Normalized Data')\n    ax.legend()\n    return np_array, normalized_array, ax\n```"}
{"task_id": "BigCodeBench/242", "solution": "import cv2\nimport matplotlib.pyplot as plt\nimport numpy as np\ndef task_func(image_path, kernel_size):\n    if not isinstance(kernel_size, int) or kernel_size <= 0:\n        raise ValueError(\"kernel_size must be a positive integer\")\n    if not cv2.imread(image_path):\n        raise FileNotFoundError(\"File not found\")\n    img = cv2.imread(image_path)\n    blurred = cv2.GaussianBlur(img, (kernel_size, kernel_size), 0)\n    fig, (ax1, ax2) = plt.subplots(1, 2)\n    ax1.imshow(img)\n    ax1.set_title(\"Original Image\")\n    ax2.imshow(blurred)\n    ax2.set_title(\"Blurred Image\")\n    plt.show()\n    return blurred, ax1, ax2", "raw_solution": "import cv2\nimport matplotlib.pyplot as plt\nimport numpy as np\n\ndef task_func(image_path, kernel_size):\n    if not isinstance(kernel_size, int) or kernel_size <= 0:\n        raise ValueError(\"kernel_size must be a positive integer\")\n    if not cv2.imread(image_path):\n        raise FileNotFoundError(\"File not found\")\n    img = cv2.imread(image_path)\n    blurred = cv2.GaussianBlur(img, (kernel_size, kernel_size), 0)\n    fig, (ax1, ax2) = plt.subplots(1, 2)\n    ax1.imshow(img)\n    ax1.set_title(\"Original Image\")\n    ax2.imshow(blurred)\n    ax2.set_title(\"Blurred Image\")\n    plt.show()\n    return blurred, ax1, ax2\n```"}
{"task_id": "BigCodeBench/243", "solution": "import pandas as pd\nimport random\nN_DATA_POINTS = 10000\nMIN_VALUE = 0.0\nMAX_VALUE = 10.0\ndef task_func(n_data_points=N_DATA_POINTS):\n    if n_data_points == 0:\n        return pd.DataFrame(columns=['Value'])\n    else:\n        data = [random.uniform(MIN_VALUE, MAX_VALUE) for _ in range(n_data_points)]\n        return pd.DataFrame(data, columns=['Value'])", "raw_solution": "import pandas as pd\nimport random\n# Constants\nN_DATA_POINTS = 10000\nMIN_VALUE = 0.0\nMAX_VALUE = 10.0\ndef task_func(n_data_points=N_DATA_POINTS):\n    if n_data_points == 0:\n        return pd.DataFrame(columns=['Value'])\n    else:\n        data = [random.uniform(MIN_VALUE, MAX_VALUE) for _ in range(n_data_points)]\n        return pd.DataFrame(data, columns=['Value'])\n```"}
{"task_id": "BigCodeBench/244", "solution": "import numpy as np\nfrom scipy.fft import fft\nfrom matplotlib import pyplot as plt\ndef task_func(original):\n    if len(original) == 0:\n        return np.array([]), None\n    original_array = np.array(original)\n    fft_data = fft(original_array)\n    magnitude = np.abs(fft_data)\n    axes = plt.hist(magnitude)\n    return original_array, fft_data, axes", "raw_solution": "import numpy as np\nfrom scipy.fft import fft\nfrom matplotlib import pyplot as plt\n\ndef task_func(original):\n    if len(original) == 0:\n        return np.array([]), None\n    original_array = np.array(original)\n    fft_data = fft(original_array)\n    magnitude = np.abs(fft_data)\n    axes = plt.hist(magnitude)\n    return original_array, fft_data, axes\n```"}
{"task_id": "BigCodeBench/245", "solution": "import pandas as pd\nimport random\nfrom scipy import stats\ndef task_func(n_data_points=5000, min_value=0.0, max_value=10.0):\n    # Generate a random dataset of floating-point numbers within a specified range\n    data = [random.uniform(min_value, max_value) for _ in range(n_data_points)]\n    \n    # Truncate each value to 3 decimal places\n    data = [round(x, 3) for x in data]\n    \n    # Calculate statistical measures (mean, median, mode)\n    mean = round(sum(data) / len(data), 3)\n    median = round(stats.median(data), 3)\n    mode = round(stats.mode(data)[0][0], 3)\n    \n    # Return the results as a dictionary\n    return {'mean': mean, 'median': median, 'mode': mode}", "raw_solution": "import pandas as pd\nimport random\nfrom scipy import stats\n\ndef task_func(n_data_points=5000, min_value=0.0, max_value=10.0):\n    # Generate a random dataset of floating-point numbers within a specified range\n    data = [random.uniform(min_value, max_value) for _ in range(n_data_points)]\n    \n    # Truncate each value to 3 decimal places\n    data = [round(x, 3) for x in data]\n    \n    # Calculate statistical measures (mean, median, mode)\n    mean = round(sum(data) / len(data), 3)\n    median = round(stats.median(data), 3)\n    mode = round(stats.mode(data)[0][0], 3)\n    \n    # Return the results as a dictionary\n    return {'mean': mean, 'median': median, 'mode': mode}\n```"}
{"task_id": "BigCodeBench/246", "solution": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.fft import fft\nANGLES = np.arange(0, 2*np.pi, 0.01)\ndef task_func(n_waves, seed=0):\n    if n_waves < 1:\n        return [], [], None\n    np.random.seed(seed)\n    waves = [np.sin(angle) for angle in ANGLES]\n    mixed_signal = np.sum(waves, axis=0)\n    fft_data = fft(mixed_signal)\n    plt.hist(np.abs(fft_data), bins=100)\n    plt.show()\n    return waves, fft_data, plt.gca()", "raw_solution": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.fft import fft\nANGLES = np.arange(0, 2*np.pi, 0.01)\ndef task_func(n_waves, seed=0):\n    if n_waves < 1:\n        return [], [], None\n    np.random.seed(seed)\n    waves = [np.sin(angle) for angle in ANGLES]\n    mixed_signal = np.sum(waves, axis=0)\n    fft_data = fft(mixed_signal)\n    plt.hist(np.abs(fft_data), bins=100)\n    plt.show()\n    return waves, fft_data, plt.gca()\n```"}
{"task_id": "BigCodeBench/247", "solution": "import pandas as pd\nimport random\nfrom sklearn.preprocessing import StandardScaler\ndef task_func(n_data_points=5000, min_value=0.0, max_value=10.0):\n    if max_value < min_value:\n        raise ValueError(\"max_value must be greater than or equal to min_value\")\n    data = [random.uniform(min_value, max_value) for _ in range(n_data_points)]\n    data = [round(x, 3) for x in data]\n    scaler = StandardScaler()\n    scaler.fit([data])\n    normalized_data = scaler.transform([data])\n    normalized_data = [round(x[0], 3) for x in normalized_data]\n    df = pd.DataFrame({f\"Normalized Value\": normalized_data})\n    return df", "raw_solution": "import pandas as pd\nimport random\nfrom sklearn.preprocessing import StandardScaler\n# Constants\nN_DATA_POINTS = 5000\nMIN_VALUE = 0.0\nMAX_VALUE = 10.0\ndef task_func(n_data_points=5000, min_value=0.0, max_value=10.0):\n    if max_value < min_value:\n        raise ValueError(\"max_value must be greater than or equal to min_value\")\n    data = [random.uniform(min_value, max_value) for _ in range(n_data_points)]\n    data = [round(x, 3) for x in data]\n    scaler = StandardScaler()\n    scaler.fit([data])\n    normalized_data = scaler.transform([data])\n    normalized_data = [round(x[0], 3) for x in normalized_data]\n    df = pd.DataFrame({f\"Normalized Value\": normalized_data})\n    return df\n```"}
{"task_id": "BigCodeBench/248", "solution": "import numpy as np\nimport matplotlib.pyplot as plt\nimport itertools\ndef task_func(data_list):\n    if not data_list:\n        raise ValueError(\"If the data_list is empty.\")\n    x, y = zip(*data_list)\n    plt.plot(x, y)\n    plt.show()", "raw_solution": "import numpy as np\nimport matplotlib.pyplot as plt\nimport itertools\n\ndef task_func(data_list):\n    if not data_list:\n        raise ValueError(\"If the data_list is empty.\")\n    x, y = zip(*data_list)\n    plt.plot(x, y)\n    plt.show()\n```"}
{"task_id": "BigCodeBench/249", "solution": "import pandas as pd\nimport random\nfrom sklearn.model_selection import train_test_split\ndef task_func(n_data_points=10000, min_value=0.0, max_value=10.0, test_size=0.2):\n    # Generate random set of floating-point numbers within a specified range\n    data = pd.DataFrame({'Value': [random.uniform(min_value, max_value) for _ in range(n_data_points)]})\n    \n    # Truncate each value to 3 decimal places\n    data['Value'] = data['Value'].round(3)\n    \n    # Divide the data into train and test sets based on a given test size\n    train, test = train_test_split(data, test_size=test_size, random_state=42)\n    \n    return (train, test)", "raw_solution": "import pandas as pd\nimport random\nfrom sklearn.model_selection import train_test_split\n\ndef task_func(n_data_points=10000, min_value=0.0, max_value=10.0, test_size=0.2):\n    # Generate random set of floating-point numbers within a specified range\n    data = pd.DataFrame({'Value': [random.uniform(min_value, max_value) for _ in range(n_data_points)]})\n    \n    # Truncate each value to 3 decimal places\n    data['Value'] = data['Value'].round(3)\n    \n    # Divide the data into train and test sets based on a given test size\n    train, test = train_test_split(data, test_size=test_size, random_state=42)\n    \n    return (train, test)\n```"}
{"task_id": "BigCodeBench/250", "solution": "import numpy as np\nimport itertools\nimport json\ndef task_func(data_list, json_file_name=\"mean_values.json\"):\n    mean_values = {}\n    for i, values in enumerate(data_list):\n        mean_values[f\"Position {i+1}\"] = np.mean(values)\n    with open(json_file_name, \"w\") as f:\n        json.dump(mean_values, f)\n    return mean_values", "raw_solution": "import numpy as np\nimport itertools\nimport json\ndef task_func(data_list, json_file_name=\"mean_values.json\"):\n    mean_values = {}\n    for i, values in enumerate(data_list):\n        mean_values[f\"Position {i+1}\"] = np.mean(values)\n    with open(json_file_name, \"w\") as f:\n        json.dump(mean_values, f)\n    return mean_values\n```"}
{"task_id": "BigCodeBench/251", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\ndef task_func(data):\n    if not isinstance(data, pd.DataFrame):\n        raise ValueError(\"The function will raise ValueError if the input data is not a DataFrame.\")\n    fig, ax = plt.subplots()\n    ax.pie(data['job'], labels=data['name'], autopct='%1.1f%%')\n    return fig", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\n\ndef task_func(data):\n    if not isinstance(data, pd.DataFrame):\n        raise ValueError(\"The function will raise ValueError if the input data is not a DataFrame.\")\n    fig, ax = plt.subplots()\n    ax.pie(data['job'], labels=data['name'], autopct='%1.1f%%')\n    return fig\n```"}
{"task_id": "BigCodeBench/252", "solution": "import matplotlib.pyplot as plt\nfrom itertools import zip_longest\nCOLORS = ['red', 'green', 'blue', 'yellow', 'purple']\ndef task_func(data, labels):\n    # Check if the number of data series is more than the number of colors\n    if len(data) > len(COLORS):\n        # If so, cycle through the colors\n        colors = COLORS * (len(data) // len(COLORS) + 1)\n    else:\n        # Otherwise, use the predefined colors\n        colors = COLORS[:len(data)]\n    \n    # Check if the number of data series is more than the number of labels\n    if len(data) > len(labels):\n        # If so, use 'black' for the missing labels\n        labels = labels + ['black'] * (len(data) - len(labels))\n    \n    # Create the plot\n    fig, ax = plt.subplots()\n    for d, l, c in zip_longest(data, labels, colors):\n        ax.plot(d, label=l, color=c)\n    \n    # Add a legend\n    ax.legend()\n    \n    # Return the Axes object of the plot\n    return ax", "raw_solution": "import matplotlib.pyplot as plt\nfrom itertools import zip_longest\n# Constants\nCOLORS = ['red', 'green', 'blue', 'yellow', 'purple']\n\ndef task_func(data, labels):\n    # Check if the number of data series is more than the number of colors\n    if len(data) > len(COLORS):\n        # If so, cycle through the colors\n        colors = COLORS * (len(data) // len(COLORS) + 1)\n    else:\n        # Otherwise, use the predefined colors\n        colors = COLORS[:len(data)]\n    \n    # Check if the number of data series is more than the number of labels\n    if len(data) > len(labels):\n        # If so, use 'black' for the missing labels\n        labels = labels + ['black'] * (len(data) - len(labels))\n    \n    # Create the plot\n    fig, ax = plt.subplots()\n    for d, l, c in zip_longest(data, labels, colors):\n        ax.plot(d, label=l, color=c)\n    \n    # Add a legend\n    ax.legend()\n    \n    # Return the Axes object of the plot\n    return ax\n```"}
{"task_id": "BigCodeBench/253", "solution": "import numpy as np\nimport random\nCOLORS = ['b', 'g', 'r', 'c', 'm', 'y', 'k']\ndef task_func(ax):\n    # Generate random sine wave function\n    x = np.linspace(0, 2 * np.pi, 100)\n    y = np.sin(x)\n    # Set random color\n    color = random.choice(COLORS)\n    # Set random position for radial labels\n    theta = random.uniform(0, 2 * np.pi)\n    ax.plot(x, y, color=color, label=f'Random sine wave (color: {color}, theta: {theta})')\n    ax.legend()\n    return color", "raw_solution": "import numpy as np\nimport random\n# Constants\nCOLORS = ['b', 'g', 'r', 'c', 'm', 'y', 'k']\ndef task_func(ax):\n    # Generate random sine wave function\n    x = np.linspace(0, 2 * np.pi, 100)\n    y = np.sin(x)\n    # Set random color\n    color = random.choice(COLORS)\n    # Set random position for radial labels\n    theta = random.uniform(0, 2 * np.pi)\n    ax.plot(x, y, color=color, label=f'Random sine wave (color: {color}, theta: {theta})')\n    ax.legend()\n    return color\n```"}
{"task_id": "BigCodeBench/254", "solution": "import json\nimport math\ndef task_func(decimal_value, precision=2):\n    sqrt = math.sqrt(decimal_value)\n    return json.dumps(sqrt, precision=precision)", "raw_solution": "import json\nimport math\ndef task_func(decimal_value, precision=2):\n    sqrt = math.sqrt(decimal_value)\n    return json.dumps(sqrt, precision=precision)\n```"}
{"task_id": "BigCodeBench/255", "solution": "import matplotlib\nimport numpy as np\nFUNCTIONS = [np.sin, np.cos, np.tan]\ndef task_func(ax, func_index):\n    if not isinstance(ax, matplotlib.axes._axes.Axes):\n        raise ValueError(\"This function will raise a ValueError if the input ax is not and Axes.\")\n    ax.plot(np.linspace(0, 2 * np.pi, 100), FUNCTIONS[func_index](np.linspace(0, 2 * np.pi, 100)))\n    ax.set_rticks(np.arange(0, 5, 1))\n    ax.set_rlabel_position(45)\n    ax.set_title(\"Polar Diagram of Sine, Cosine, and Tangent\")\n    return ax", "raw_solution": "import matplotlib\nimport numpy as np\n# Constants\nFUNCTIONS = [np.sin, np.cos, np.tan]\ndef task_func(ax, func_index):\n    if not isinstance(ax, matplotlib.axes._axes.Axes):\n        raise ValueError(\"This function will raise a ValueError if the input ax is not and Axes.\")\n    ax.plot(np.linspace(0, 2 * np.pi, 100), FUNCTIONS[func_index](np.linspace(0, 2 * np.pi, 100)))\n    ax.set_rticks(np.arange(0, 5, 1))\n    ax.set_rlabel_position(45)\n    ax.set_title(\"Polar Diagram of Sine, Cosine, and Tangent\")\n    return ax\n```"}
{"task_id": "BigCodeBench/256", "solution": "import json\nimport random\nimport hashlib\nfrom datetime import datetime\ndef task_func(utc_datetime, salt='salt', password_length=10, seed=0):\n    if not isinstance(utc_datetime, datetime):\n        raise ValueError('utc_datetime is not a datetime object')\n    if not isinstance(salt, str):\n        raise ValueError('salt is not a string')\n    random.seed(seed)\n    password = ''.join(random.choices('abcdefghijklmnopqrstuvwxyz0123456789', k=password_length))\n    hashed_password = hashlib.sha256((salt + password).encode()).hexdigest()\n    return json.dumps({'hashed_password': hashed_password})", "raw_solution": "import json\nimport random\nimport hashlib\nfrom datetime import datetime\n\ndef task_func(utc_datetime, salt='salt', password_length=10, seed=0):\n    if not isinstance(utc_datetime, datetime):\n        raise ValueError('utc_datetime is not a datetime object')\n    if not isinstance(salt, str):\n        raise ValueError('salt is not a string')\n    random.seed(seed)\n    password = ''.join(random.choices('abcdefghijklmnopqrstuvwxyz0123456789', k=password_length))\n    hashed_password = hashlib.sha256((salt + password).encode()).hexdigest()\n    return json.dumps({'hashed_password': hashed_password})\n```"}
{"task_id": "BigCodeBench/257", "solution": "import numpy as np\nimport math\ndef task_func(ax, num_turns):\n    # Calculate the number of radial ticks\n    num_ticks = num_turns * 45\n    # Calculate the radius of the spiral\n    radius = 10\n    # Calculate the angle increment for each tick\n    angle_increment = 2 * math.pi / num_ticks\n    # Calculate the coordinates of the spiral\n    theta = np.arange(0, 2 * math.pi, angle_increment)\n    x = radius * np.cos(theta)\n    y = radius * np.sin(theta)\n    # Plot the spiral\n    ax.plot(x, y)\n    # Set the radial ticks\n    ax.set_rticks(np.arange(0, radius + 1, 1))\n    # Set the radial tick labels\n    ax.set_rlabel('Radius')\n    # Set the radial tick labels to be in degrees\n    ax.set_rlabel('Radius (degrees)', labelpad=15)\n    # Set the radial tick labels to be in radians\n    ax.set_rlabel('Radius (radians)', labelpad=15)\n    # Set the radial tick labels to be in degrees\n    ax.set_rlabel('Radius (degrees)', labelpad=15)\n    # Set the radial tick labels to be in radians\n    ax.set_rlabel('Radius (radians)', labelpad=15)\n    # Set the radial tick labels to be in degrees\n    ax.set_rlabel('Radius (degrees)', labelpad=15)\n    # Set the radial tick labels to be in radians\n    ax.set_rlabel('Radius (radians)', labelpad=15)\n    # Set the radial tick labels to be in degrees\n    ax.set_rlabel('Radius (degrees)', labelpad=15)\n    # Set the radial tick labels to be in radians\n    ax.set_rlabel('Radius (radians)', labelpad=15)\n    # Set the radial tick labels to be in degrees\n    ax.set_rlabel('Radius (degrees)', labelpad=15)\n    # Set the radial tick labels to be in radians\n    ax.set_rlabel('Radius (radians)', labelpad=15)\n    # Set the radial tick labels to be in degrees\n    ax.set_rlabel('Radius (degrees)', labelpad=15)\n    # Set the radial tick labels to be in radians\n    ax.set_rlabel('Radius (radians)', labelpad=15)\n    # Set the radial tick labels to be in degrees\n    ax.set_rlabel('Radius (degrees)', labelpad=15)\n    # Set the radial tick labels to be in radians\n    ax.set_rlabel('Radius (radians)', labelpad=15)\n    # Set the radial tick labels to be in degrees\n    ax.set_rlabel('Radius (degrees)', labelpad=15)\n    # Set the radial tick labels to be in radians\n    ax.set_rlabel('Radius (radians)', labelpad=15)\n    # Set the radial tick labels to be in degrees\n    ax.set_rlabel('Radius (degrees)', labelpad=15)\n    # Set the radial tick labels to be in radians\n    ax.set_rlabel('Radius (radians)', labelpad=15)\n    # Set the radial tick labels to be in degrees\n    ax.set_rlabel('Radius (degrees)', labelpad=15)\n    # Set the radial tick labels to be in radians\n    ax.set_rlabel('Radius (radians)', labelpad=15)\n    # Set the radial tick labels to be in degrees\n    ax.set_rlabel('Radius (degrees)', labelpad=15)\n    # Set the radial tick labels to be in radians\n    ax.set_rlabel('Radius (radians)', labelpad=15)\n    # Set the radial tick labels to be in degrees\n    ax.set_rlabel('Radius (degrees)', labelpad=15)\n    # Set the radial tick labels to be in radians\n    ax.set_rlabel('Radius (radians)', labelpad=15)\n    # Set the radial tick labels to be in degrees\n    ax.set_rlabel('Radius (degrees)', labelpad=15)\n    # Set the radial tick labels to be in radians\n    ax.set_rlabel('Radius (degrees)', labelpad=15)\n    # Set the radial tick labels to be in radians\n    ax.set_rlabel('Radius (degrees)', labelpad=15)\n    # Set the radial tick labels to be in radians\n    ax.set_rlabel('Radius (degrees)', labelpad=15)\n    # Set the radial tick labels to be in radians\n    ax.set_rlabel('Radius (degrees)', labelpad=15)\n    # Set the radial tick labels to be in radians\n    ax.set_rlabel('Radius (degrees)', labelpad=15)\n    # Set the radial tick labels to be in radians\n    ax.set_rlabel('Radius (degrees)', labelpad=15)\n    # Set the radial tick labels to be in radians\n    ax.set_rlabel('Radius (degrees)', labelpad=15)\n    # Set the radial tick labels to be in radians\n    ax.set_rlabel('Radius (degrees)', labelpad=15)\n    # Set the radial tick labels to be in radians\n    ax.set_rlabel('Radius (degrees)', labelpad=15)\n    # Set the radial tick labels to be in radians\n    ax.set_rlabel('Radius (degrees)', labelpad=15)\n    # Set the radial tick labels to be in radians\n    ax.set_rlabel('Radius (degrees)', labelpad=15)\n    # Set the radial tick labels to be in radians\n    ax.set_rlabel('Radius (degrees)', labelpad=15)\n    # Set the radial tick labels to be in radians\n    ax.set_rlabel('Radius (degrees)', labelpad=15)\n    # Set the radial tick labels to be in radians\n    ax.set_rlabel('Radius (degrees)', labelpad=15)", "raw_solution": "import numpy as np\nimport math\ndef task_func(ax, num_turns):\n    # Calculate the number of radial ticks\n    num_ticks = num_turns * 45\n    # Calculate the radius of the spiral\n    radius = 10\n    # Calculate the angle increment for each tick\n    angle_increment = 2 * math.pi / num_ticks\n    # Calculate the coordinates of the spiral\n    theta = np.arange(0, 2 * math.pi, angle_increment)\n    x = radius * np.cos(theta)\n    y = radius * np.sin(theta)\n    # Plot the spiral\n    ax.plot(x, y)\n    # Set the radial ticks\n    ax.set_rticks(np.arange(0, radius + 1, 1))\n    # Set the radial tick labels\n    ax.set_rlabel('Radius')\n    # Set the radial tick labels to be in degrees\n    ax.set_rlabel('Radius (degrees)', labelpad=15)\n    # Set the radial tick labels to be in radians\n    ax.set_rlabel('Radius (radians)', labelpad=15)\n    # Set the radial tick labels to be in degrees\n    ax.set_rlabel('Radius (degrees)', labelpad=15)\n    # Set the radial tick labels to be in radians\n    ax.set_rlabel('Radius (radians)', labelpad=15)\n    # Set the radial tick labels to be in degrees\n    ax.set_rlabel('Radius (degrees)', labelpad=15)\n    # Set the radial tick labels to be in radians\n    ax.set_rlabel('Radius (radians)', labelpad=15)\n    # Set the radial tick labels to be in degrees\n    ax.set_rlabel('Radius (degrees)', labelpad=15)\n    # Set the radial tick labels to be in radians\n    ax.set_rlabel('Radius (radians)', labelpad=15)\n    # Set the radial tick labels to be in degrees\n    ax.set_rlabel('Radius (degrees)', labelpad=15)\n    # Set the radial tick labels to be in radians\n    ax.set_rlabel('Radius (radians)', labelpad=15)\n    # Set the radial tick labels to be in degrees\n    ax.set_rlabel('Radius (degrees)', labelpad=15)\n    # Set the radial tick labels to be in radians\n    ax.set_rlabel('Radius (radians)', labelpad=15)\n    # Set the radial tick labels to be in degrees\n    ax.set_rlabel('Radius (degrees)', labelpad=15)\n    # Set the radial tick labels to be in radians\n    ax.set_rlabel('Radius (radians)', labelpad=15)\n    # Set the radial tick labels to be in degrees\n    ax.set_rlabel('Radius (degrees)', labelpad=15)\n    # Set the radial tick labels to be in radians\n    ax.set_rlabel('Radius (radians)', labelpad=15)\n    # Set the radial tick labels to be in degrees\n    ax.set_rlabel('Radius (degrees)', labelpad=15)\n    # Set the radial tick labels to be in radians\n    ax.set_rlabel('Radius (radians)', labelpad=15)\n    # Set the radial tick labels to be in degrees\n    ax.set_rlabel('Radius (degrees)', labelpad=15)\n    # Set the radial tick labels to be in radians\n    ax.set_rlabel('Radius (radians)', labelpad=15)\n    # Set the radial tick labels to be in degrees\n    ax.set_rlabel('Radius (degrees)', labelpad=15)\n    # Set the radial tick labels to be in radians\n    ax.set_rlabel('Radius (radians)', labelpad=15)\n    # Set the radial tick labels to be in degrees\n    ax.set_rlabel('Radius (degrees)', labelpad=15)\n    # Set the radial tick labels to be in radians\n    ax.set_rlabel('Radius (radians)', labelpad=15)\n    # Set the radial tick labels to be in degrees\n    ax.set_rlabel('Radius (degrees)', labelpad=15)\n    # Set the radial tick labels to be in radians\n    ax.set_rlabel('Radius (degrees)', labelpad=15)\n    # Set the radial tick labels to be in radians\n    ax.set_rlabel('Radius (degrees)', labelpad=15)\n    # Set the radial tick labels to be in radians\n    ax.set_rlabel('Radius (degrees)', labelpad=15)\n    # Set the radial tick labels to be in radians\n    ax.set_rlabel('Radius (degrees)', labelpad=15)\n    # Set the radial tick labels to be in radians\n    ax.set_rlabel('Radius (degrees)', labelpad=15)\n    # Set the radial tick labels to be in radians\n    ax.set_rlabel('Radius (degrees)', labelpad=15)\n    # Set the radial tick labels to be in radians\n    ax.set_rlabel('Radius (degrees)', labelpad=15)\n    # Set the radial tick labels to be in radians\n    ax.set_rlabel('Radius (degrees)', labelpad=15)\n    # Set the radial tick labels to be in radians\n    ax.set_rlabel('Radius (degrees)', labelpad=15)\n    # Set the radial tick labels to be in radians\n    ax.set_rlabel('Radius (degrees)', labelpad=15)\n    # Set the radial tick labels to be in radians\n    ax.set_rlabel('Radius (degrees)', labelpad=15)\n    # Set the radial tick labels to be in radians\n    ax.set_rlabel('Radius (degrees)', labelpad=15)\n    # Set the radial tick labels to be in radians\n    ax.set_rlabel('Radius (degrees)', labelpad=15)\n    # Set the radial tick labels to be in radians\n    ax.set_rlabel('Radius (degrees)', labelpad=15)\n   "}
{"task_id": "BigCodeBench/258", "solution": "import json\nimport random\nDATA = [\n    {'name': 'John', 'age': 30, 'city': 'New York'},\n    {'name': 'Peter', 'age': 35, 'city': 'London'},\n    {'name': 'Susan', 'age': 25, 'city': 'Sydney'},\n    {'name': 'Alice', 'age': 28, 'city': 'Paris'},\n    {'name': 'Bob', 'age': 40, 'city': 'Tokyo'},\n    {'name': 'Charlie', 'age': 22, 'city': 'Beijing'},\n    {'name': 'David', 'age': 33, 'city': 'Mumbai'},\n    {'name': 'Eve', 'age': 27, 'city': 'Berlin'},\n    {'name': 'Frank', 'age': 32, 'city': 'Moscow'},\n    {'name': 'Grace', 'age': 29, 'city': 'Rome'}\n]\ndef task_func(utc_datetime, seed=0):\n    random.seed(seed)\n    person = random.choice(DATA)\n    person['utc_datetime'] = utc_datetime\n    return json.dumps(person)", "raw_solution": "import json\nimport random\n# Constants\nDATA = [\n    {'name': 'John', 'age': 30, 'city': 'New York'},\n    {'name': 'Peter', 'age': 35, 'city': 'London'},\n    {'name': 'Susan', 'age': 25, 'city': 'Sydney'},\n    {'name': 'Alice', 'age': 28, 'city': 'Paris'},\n    {'name': 'Bob', 'age': 40, 'city': 'Tokyo'},\n    {'name': 'Charlie', 'age': 22, 'city': 'Beijing'},\n    {'name': 'David', 'age': 33, 'city': 'Mumbai'},\n    {'name': 'Eve', 'age': 27, 'city': 'Berlin'},\n    {'name': 'Frank', 'age': 32, 'city': 'Moscow'},\n    {'name': 'Grace', 'age': 29, 'city': 'Rome'}\n]\n\ndef task_func(utc_datetime, seed=0):\n    random.seed(seed)\n    person = random.choice(DATA)\n    person['utc_datetime'] = utc_datetime\n    return json.dumps(person)\n```"}
{"task_id": "BigCodeBench/259", "solution": "import matplotlib\nimport numpy as np\ndef task_func(ax, num_points):\n    if not isinstance(ax, matplotlib.axes._axes.Axes):\n        raise ValueError(\"This function will raise a ValueError if the input ax is not and Axes.\")\n    if num_points < 0:\n        raise ValueError(\"This function will raise a ValueError if it is use the negative number as num_points.\")\n    theta = np.linspace(0, 2 * np.pi, num_points)\n    r = np.random.rand(num_points)\n    ax.plot(r * np.cos(theta), r * np.sin(theta))\n    ax.set_xticks(np.linspace(0, 1, 11))\n    ax.set_xticklabels(np.linspace(0, 10, 11))\n    ax.set_yticks(np.linspace(0, 1, 11))\n    ax.set_yticklabels(np.linspace(0, 10, 11))\n    return ax", "raw_solution": "import matplotlib\nimport numpy as np\ndef task_func(ax, num_points):\n    if not isinstance(ax, matplotlib.axes._axes.Axes):\n        raise ValueError(\"This function will raise a ValueError if the input ax is not and Axes.\")\n    if num_points < 0:\n        raise ValueError(\"This function will raise a ValueError if it is use the negative number as num_points.\")\n    theta = np.linspace(0, 2 * np.pi, num_points)\n    r = np.random.rand(num_points)\n    ax.plot(r * np.cos(theta), r * np.sin(theta))\n    ax.set_xticks(np.linspace(0, 1, 11))\n    ax.set_xticklabels(np.linspace(0, 10, 11))\n    ax.set_yticks(np.linspace(0, 1, 11))\n    ax.set_yticklabels(np.linspace(0, 10, 11))\n    return ax\n```"}
{"task_id": "BigCodeBench/260", "solution": "import json\nimport os\nimport glob\nKEY = 'mynewkey'\nVALUE = 'mynewvalue'\ndef task_func(directory):\n    # Initialize the count of updated files\n    updated_files = 0\n    # Iterate over all JSON files in the directory\n    for file_path in glob.glob(os.path.join(directory, '*.json')):\n        # Open the file and load its contents\n        with open(file_path, 'r') as file:\n            data = json.load(file)\n        # Check if the key already exists in the JSON data\n        if KEY not in data:\n            # Add the new key-value pair if it doesn't exist\n            data[KEY] = VALUE\n            # Save the updated JSON data back to the file\n            with open(file_path, 'w') as file:\n                json.dump(data, file, indent=4)\n            # Increment the count of updated files\n            updated_files += 1\n    # Return the count of updated files\n    return updated_files", "raw_solution": "import json\nimport os\nimport glob\n# Constants\nKEY = 'mynewkey'\nVALUE = 'mynewvalue'\ndef task_func(directory):\n    # Initialize the count of updated files\n    updated_files = 0\n    # Iterate over all JSON files in the directory\n    for file_path in glob.glob(os.path.join(directory, '*.json')):\n        # Open the file and load its contents\n        with open(file_path, 'r') as file:\n            data = json.load(file)\n        # Check if the key already exists in the JSON data\n        if KEY not in data:\n            # Add the new key-value pair if it doesn't exist\n            data[KEY] = VALUE\n            # Save the updated JSON data back to the file\n            with open(file_path, 'w') as file:\n                json.dump(data, file, indent=4)\n            # Increment the count of updated files\n            updated_files += 1\n    # Return the count of updated files\n    return updated_files\n```"}
{"task_id": "BigCodeBench/261", "solution": "import matplotlib.pyplot as plt\nimport numpy as np\ndef task_func(ax, radius):\n    if radius < 0:\n        raise ValueError(\"Radius cannot be negative\")\n    if not isinstance(ax, plt.Axes):\n        raise TypeError(\"ax must be a polar plot\")\n    theta = np.linspace(0, 2 * np.pi, 100)\n    r = radius * np.ones_like(theta)\n    ax.plot(theta, r, color='blue')\n    ax.set_rticks(np.arange(0, radius + 1, 1))\n    return ax", "raw_solution": "import matplotlib.pyplot as plt\nimport numpy as np\n\ndef task_func(ax, radius):\n    if radius < 0:\n        raise ValueError(\"Radius cannot be negative\")\n    if not isinstance(ax, plt.Axes):\n        raise TypeError(\"ax must be a polar plot\")\n    theta = np.linspace(0, 2 * np.pi, 100)\n    r = radius * np.ones_like(theta)\n    ax.plot(theta, r, color='blue')\n    ax.set_rticks(np.arange(0, radius + 1, 1))\n    return ax\n```"}
{"task_id": "BigCodeBench/262", "solution": "import collections\nimport seaborn as sns\nimport matplotlib.pyplot as plt\ndef task_func(dictionary, new_key, new_value):\n    dictionary[new_key] = new_value\n    sns.histplot(dictionary.values())\n    plt.show()\n    return dictionary, plt.gca()", "raw_solution": "import collections\nimport seaborn as sns\nimport matplotlib.pyplot as plt\ndef task_func(dictionary, new_key, new_value):\n    dictionary[new_key] = new_value\n    sns.histplot(dictionary.values())\n    plt.show()\n    return dictionary, plt.gca()\n```"}
{"task_id": "BigCodeBench/263", "solution": "import os\nimport glob\nimport shutil\nimport time\ndef task_func(my_path: str, days_old: int) -> str:\n    # Create archive directory if it doesn't exist\n    archive_dir = os.path.join(my_path, 'archive')\n    if not os.path.exists(archive_dir):\n        os.makedirs(archive_dir)\n    # Get current time\n    now = time.time()\n    # Get list of files in the directory\n    files = glob.glob(os.path.join(my_path, '*'))\n    # Loop through files\n    for file in files:\n        # Check if file is a directory\n        if os.path.isdir(file):\n            continue\n        # Get file modification time\n        mod_time = os.path.getmtime(file)\n        # Check if file is older than 'days_old'\n        if now - mod_time > days_old * 24 * 60 * 60:\n            # Move file to archive directory\n            shutil.move(file, os.path.join(archive_dir, os.path.basename(file)))\n    # Return path of archive directory\n    return archive_dir", "raw_solution": "import os\nimport glob\nimport shutil\nimport time\n# Constants\nFILE_EXTENSIONS = ['.txt', '.csv', '.xlsx', '.docx', '.pdf']\ndef task_func(my_path: str, days_old: int) -> str:\n    # Create archive directory if it doesn't exist\n    archive_dir = os.path.join(my_path, 'archive')\n    if not os.path.exists(archive_dir):\n        os.makedirs(archive_dir)\n    # Get current time\n    now = time.time()\n    # Get list of files in the directory\n    files = glob.glob(os.path.join(my_path, '*'))\n    # Loop through files\n    for file in files:\n        # Check if file is a directory\n        if os.path.isdir(file):\n            continue\n        # Get file modification time\n        mod_time = os.path.getmtime(file)\n        # Check if file is older than 'days_old'\n        if now - mod_time > days_old * 24 * 60 * 60:\n            # Move file to archive directory\n            shutil.move(file, os.path.join(archive_dir, os.path.basename(file)))\n    # Return path of archive directory\n    return archive_dir\n```"}
{"task_id": "BigCodeBench/264", "solution": "import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\ndef task_func(dictionary, key, value, n=100, bins=30, seed=0):\n    if not isinstance(value, (int, float)):\n        raise ValueError(\"The provided value is not a number.\")\n    np.random.seed(seed)\n    dataset = np.random.normal(value, value, n)\n    updated_dict = dictionary.copy()\n    updated_dict[key] = value\n    return updated_dict, pd.Series(dataset), plt.hist(dataset, bins=bins)", "raw_solution": "import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\ndef task_func(dictionary, key, value, n=100, bins=30, seed=0):\n    if not isinstance(value, (int, float)):\n        raise ValueError(\"The provided value is not a number.\")\n    np.random.seed(seed)\n    dataset = np.random.normal(value, value, n)\n    updated_dict = dictionary.copy()\n    updated_dict[key] = value\n    return updated_dict, pd.Series(dataset), plt.hist(dataset, bins=bins)\n```"}
{"task_id": "BigCodeBench/265", "solution": "import collections\nimport json\nimport os\ndef task_func(data, json_file_name='data.json'):\n    data['a'] = 1\n    freq = collections.Counter(data.values())\n    with open(json_file_name, 'w') as f:\n        json.dump({'data': data, 'freq': freq}, f)\n    return os.path.abspath(json_file_name)", "raw_solution": "import collections\nimport json\nimport os\ndef task_func(data, json_file_name='data.json'):\n    data['a'] = 1\n    freq = collections.Counter(data.values())\n    with open(json_file_name, 'w') as f:\n        json.dump({'data': data, 'freq': freq}, f)\n    return os.path.abspath(json_file_name)\n```"}
{"task_id": "BigCodeBench/266", "solution": "import os\nimport os.path\nimport csv\nimport collections\nFILE_NAME = 'file_sizes.csv'\ndef task_func(my_path):\n    # Get all files in the directory\n    files = os.listdir(my_path)\n    # Create a dictionary to store file sizes\n    file_sizes = collections.defaultdict(int)\n    # Iterate over all files\n    for file in files:\n        # Get the full path of the file\n        file_path = os.path.join(my_path, file)\n        # Check if the file is a regular file\n        if os.path.isfile(file_path):\n            # Get the file size\n            file_size = os.path.getsize(file_path)\n            # Add the file size to the dictionary\n            file_sizes[file] = file_size\n    # Write the file sizes to a CSV file\n    with open(FILE_NAME, 'w', newline='') as f:\n        writer = csv.writer(f)\n        # Write the header row\n        writer.writerow(['File', 'Size (bytes)'])\n        # Write the data rows\n        for file, size in file_sizes.items():\n            writer.writerow([file, size])\n    # Return the path of the CSV file\n    return FILE_NAME", "raw_solution": "import os\nimport os.path\nimport csv\nimport collections\n# Constants\nFILE_NAME = 'file_sizes.csv'\ndef task_func(my_path):\n    # Get all files in the directory\n    files = os.listdir(my_path)\n    # Create a dictionary to store file sizes\n    file_sizes = collections.defaultdict(int)\n    # Iterate over all files\n    for file in files:\n        # Get the full path of the file\n        file_path = os.path.join(my_path, file)\n        # Check if the file is a regular file\n        if os.path.isfile(file_path):\n            # Get the file size\n            file_size = os.path.getsize(file_path)\n            # Add the file size to the dictionary\n            file_sizes[file] = file_size\n    # Write the file sizes to a CSV file\n    with open(FILE_NAME, 'w', newline='') as f:\n        writer = csv.writer(f)\n        # Write the header row\n        writer.writerow(['File', 'Size (bytes)'])\n        # Write the data rows\n        for file, size in file_sizes.items():\n            writer.writerow([file, size])\n    # Return the path of the CSV file\n    return FILE_NAME\n```"}
{"task_id": "BigCodeBench/267", "solution": "import numpy as np\nfrom scipy import fftpack\nimport matplotlib.pyplot as plt\ndef task_func(data, sample_rate=8000):\n    data['a'] = 1\n    signal = np.array(data.values())\n    fft = fftpack.fft(signal)\n    plt.plot(np.abs(fft))\n    plt.title('FFT of the signal')\n    return fft, plt.gca()", "raw_solution": "import numpy as np\nfrom scipy import fftpack\nimport matplotlib.pyplot as plt\n\ndef task_func(data, sample_rate=8000):\n    data['a'] = 1\n    signal = np.array(data.values())\n    fft = fftpack.fft(signal)\n    plt.plot(np.abs(fft))\n    plt.title('FFT of the signal')\n    return fft, plt.gca()\n```"}
{"task_id": "BigCodeBench/268", "solution": "import collections\nimport random\nLETTERS = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j']\ndef task_func(n_keys, n_values):\n    # Generate a list of keys\n    keys = random.sample(LETTERS, n_keys)\n    # Generate a list of values\n    values = list(range(1, n_values + 1))\n    # Create a dictionary with the generated keys and values\n    dict = collections.OrderedDict(zip(keys, values))\n    return dict", "raw_solution": "import collections\nimport random\n# Constants\nLETTERS = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j']\ndef task_func(n_keys, n_values):\n    # Generate a list of keys\n    keys = random.sample(LETTERS, n_keys)\n    # Generate a list of values\n    values = list(range(1, n_values + 1))\n    # Create a dictionary with the generated keys and values\n    dict = collections.OrderedDict(zip(keys, values))\n    return dict\n```"}
{"task_id": "BigCodeBench/269", "solution": "import numpy as np\nfrom scipy import stats\nfrom sklearn.preprocessing import MinMaxScaler\nimport matplotlib.pyplot as plt\ndef task_func(data_dict):\n    data_dict['a'] = 1\n    mean = np.mean(data_dict.values())\n    median = np.median(data_dict.values())\n    mode = stats.mode(data_dict.values())[0][0]\n    data_dict['mean'] = round(mean, 2)\n    data_dict['median'] = median\n    data_dict['mode'] = mode\n    scaler = MinMaxScaler(feature_range=(0, 1))\n    normalized_values = scaler.fit_transform(np.array(data_dict.values()).reshape(-1, 1))\n    normalized_values = normalized_values.flatten()\n    fig, ax = plt.subplots()\n    ax.hist(normalized_values, bins=30, edgecolor='black')\n    ax.set_title('Histogram of Normalized Values')\n    ax.set_xlabel('Value')\n    ax.set_ylabel('Frequency')\n    return (data_dict, {'mean': mean, 'median': median, 'mode': mode}, ax)", "raw_solution": "import numpy as np\nfrom scipy import stats\nfrom sklearn.preprocessing import MinMaxScaler\nimport matplotlib.pyplot as plt\n\ndef task_func(data_dict):\n    data_dict['a'] = 1\n    mean = np.mean(data_dict.values())\n    median = np.median(data_dict.values())\n    mode = stats.mode(data_dict.values())[0][0]\n    data_dict['mean'] = round(mean, 2)\n    data_dict['median'] = median\n    data_dict['mode'] = mode\n    scaler = MinMaxScaler(feature_range=(0, 1))\n    normalized_values = scaler.fit_transform(np.array(data_dict.values()).reshape(-1, 1))\n    normalized_values = normalized_values.flatten()\n    fig, ax = plt.subplots()\n    ax.hist(normalized_values, bins=30, edgecolor='black')\n    ax.set_title('Histogram of Normalized Values')\n    ax.set_xlabel('Value')\n    ax.set_ylabel('Frequency')\n    return (data_dict, {'mean': mean, 'median': median, 'mode': mode}, ax)\n```"}
{"task_id": "BigCodeBench/270", "solution": "import re\nfrom collections import Counter\ndef task_func(sentence):\n    words = re.findall(r'\\b\\w+\\b', sentence)\n    return dict(Counter(words))", "raw_solution": "import re\nfrom collections import Counter\ndef task_func(sentence):\n    words = re.findall(r'\\b\\w+\\b', sentence)\n    return dict(Counter(words))\n```"}
{"task_id": "BigCodeBench/271", "solution": "import random\nimport string\nimport hashlib\nimport time\ndef task_func(data_dict: dict, seed=0) -> dict:\n    random.seed(seed)\n    salt = ''.join(random.choices(string.ascii_lowercase, k=5))\n    for key, value in data_dict.items():\n        data_dict[key] = hashlib.sha256((value + salt).encode()).hexdigest()\n    data_dict['timestamp'] = int(time.time())\n    return data_dict", "raw_solution": "import random\nimport string\nimport hashlib\nimport time\ndef task_func(data_dict: dict, seed=0) -> dict:\n    random.seed(seed)\n    salt = ''.join(random.choices(string.ascii_lowercase, k=5))\n    for key, value in data_dict.items():\n        data_dict[key] = hashlib.sha256((value + salt).encode()).hexdigest()\n    data_dict['timestamp'] = int(time.time())\n    return data_dict\n```"}
{"task_id": "BigCodeBench/272", "solution": "import cgi\nimport http.server\nimport json", "raw_solution": "import cgi\nimport http.server\nimport json\n\nclass MyHandler(http.server.BaseHTTPRequestHandler):\n    def do_POST(self):\n        content_length = int(self.headers['Content-Length'])\n        post_data = self.rfile.read(content_length)\n        data = json.loads(post_data.decode('utf-8'))\n        if 'data' not in data:\n            self.send_response(400)\n            self.send_header('Content-type', 'application/json')\n            self.end_headers()\n            self.wfile.write(json.dumps({\"status\": \"error\", \"message\": \"No data received\"}).encode('utf-8'))\n            return\n        if self.headers['Content-Type'] != 'application/json':\n            self.send_response(400)\n            self.send_header('Content-type', 'application/json')\n            self.end_headers()\n            self.wfile.write(json.dumps({\"status\": \"error\", \"message\": \"Content-Type header is not application/json\"}).encode('utf-8'))\n            return\n        self.send_response(200)\n        self.send_header('Content-type', 'application/json')\n        self.end_headers()\n        self.wfile.write(json.dumps({\"status\": \"success\", \"message\": \"Data received successfully.\"}).encode('utf-8'))\n```"}
{"task_id": "BigCodeBench/273", "solution": "import cgi\nimport http.server\nimport json\nSUCCESS_RESPONSE = {\n    'status': 'success',\n    'message': 'Data received successfully.'\n}\nERROR_RESPONSE = {\n    'status': 'error',\n    'message': 'Invalid data received.'\n}\ndef task_func():\n    form = cgi.FieldStorage()\n    if 'content-type' not in form:\n        return ERROR_RESPONSE\n    if form['content-type'].value != 'application/json':\n        return ERROR_RESPONSE\n    try:\n        data = json.loads(form.getvalue('data'))\n    except json.JSONDecodeError:\n        return ERROR_RESPONSE\n    if 'data' not in data:\n        return ERROR_RESPONSE\n    return SUCCESS_RESPONSE", "raw_solution": "import cgi\nimport http.server\nimport json\nSUCCESS_RESPONSE = {\n    'status': 'success',\n    'message': 'Data received successfully.'\n}\nERROR_RESPONSE = {\n    'status': 'error',\n    'message': 'Invalid data received.'\n}\ndef task_func():\n    form = cgi.FieldStorage()\n    if 'content-type' not in form:\n        return ERROR_RESPONSE\n    if form['content-type'].value != 'application/json':\n        return ERROR_RESPONSE\n    try:\n        data = json.loads(form.getvalue('data'))\n    except json.JSONDecodeError:\n        return ERROR_RESPONSE\n    if 'data' not in data:\n        return ERROR_RESPONSE\n    return SUCCESS_RESPONSE\n```"}
{"task_id": "BigCodeBench/274", "solution": "import cgi\nimport http.server\nimport smtplib\nfrom email.mime.text import MIMEText\nimport json\ndef task_func(smtp_server, smtp_port, smtp_username, smtp_password):\n    class EmailHandler(http.server.BaseHTTPRequestHandler):\n        def do_POST(self):\n            content_length = int(self.headers['Content-Length'])\n            post_data = self.rfile.read(content_length)\n            try:\n                email_data = json.loads(post_data)\n            except json.JSONDecodeError:\n                self.send_response(400)\n                self.end_headers()\n                return\n            if 'subject' not in email_data or 'message' not in email_data or 'to' not in email_data:\n                self.send_response(400)\n                self.end_headers()\n                return\n            try:\n                msg = MIMEText(email_data['message'])\n                msg['Subject'] = email_data['subject']\n                msg['To'] = email_data['to']\n                server = smtplib.SMTP(smtp_server, smtp_port)\n                server.starttls()\n                server.login(smtp_username, smtp_password)\n                server.sendmail(smtp_username, email_data['to'], msg.as_string())\n                server.quit()\n                self.send_response(200)\n                self.end_headers()\n            except smtplib.SMTPAuthenticationError:\n                self.send_response(535)\n                self.end_headers()\n            except Exception as e:\n                self.send_response(500)\n                self.end_headers()\n                self.wfile.write(str(e).encode())\n    return EmailHandler", "raw_solution": "import cgi\nimport http.server\nimport smtplib\nfrom email.mime.text import MIMEText\nimport json\ndef task_func(smtp_server, smtp_port, smtp_username, smtp_password):\n    class EmailHandler(http.server.BaseHTTPRequestHandler):\n        def do_POST(self):\n            content_length = int(self.headers['Content-Length'])\n            post_data = self.rfile.read(content_length)\n            try:\n                email_data = json.loads(post_data)\n            except json.JSONDecodeError:\n                self.send_response(400)\n                self.end_headers()\n                return\n            if 'subject' not in email_data or 'message' not in email_data or 'to' not in email_data:\n                self.send_response(400)\n                self.end_headers()\n                return\n            try:\n                msg = MIMEText(email_data['message'])\n                msg['Subject'] = email_data['subject']\n                msg['To'] = email_data['to']\n                server = smtplib.SMTP(smtp_server, smtp_port)\n                server.starttls()\n                server.login(smtp_username, smtp_password)\n                server.sendmail(smtp_username, email_data['to'], msg.as_string())\n                server.quit()\n                self.send_response(200)\n                self.end_headers()\n            except smtplib.SMTPAuthenticationError:\n                self.send_response(535)\n                self.end_headers()\n            except Exception as e:\n                self.send_response(500)\n                self.end_headers()\n                self.wfile.write(str(e).encode())\n    return EmailHandler\n```"}
{"task_id": "BigCodeBench/275", "solution": "import numpy as np\nfrom itertools import combinations\ndef task_func(n):\n    if n < 1:\n        raise ValueError(\"This function will raise Value Error if the input n is less than 1.\")\n    return list(combinations(range(1, n+1), 2))", "raw_solution": "import numpy as np\nfrom itertools import combinations\n\ndef task_func(n):\n    if n < 1:\n        raise ValueError(\"This function will raise Value Error if the input n is less than 1.\")\n    return list(combinations(range(1, n+1), 2))\n```"}
{"task_id": "BigCodeBench/276", "solution": "import numpy as np\nfrom scipy import stats\nimport matplotlib.pyplot as plt\ndef task_func(matrix):\n    # Calculate the distribution of the maximum values of each row\n    max_values = np.max(matrix, axis=1)\n    # Record the histogram and the estimate of the core density of the distribution\n    hist, bins = np.histogram(max_values, bins=100)\n    density = stats.gaussian_kde(hist)\n    # Return the skew, kurtosis, and the histogram plot\n    skew = stats.skew(max_values)\n    kurtosis = stats.kurtosis(max_values)\n    return skew, kurtosis, plt.plot(bins, density(bins))", "raw_solution": "import numpy as np\nfrom scipy import stats\nimport matplotlib.pyplot as plt\n\ndef task_func(matrix):\n    # Calculate the distribution of the maximum values of each row\n    max_values = np.max(matrix, axis=1)\n    # Record the histogram and the estimate of the core density of the distribution\n    hist, bins = np.histogram(max_values, bins=100)\n    density = stats.gaussian_kde(hist)\n    # Return the skew, kurtosis, and the histogram plot\n    skew = stats.skew(max_values)\n    kurtosis = stats.kurtosis(max_values)\n    return skew, kurtosis, plt.plot(bins, density(bins))\n```"}
{"task_id": "BigCodeBench/277", "solution": "import random\nfrom itertools import combinations\nimport math\ndef task_func(n):\n    if n < 2:\n        return None\n    points = [(random.random(), random.random()) for _ in range(n)]\n    closest_pair = None\n    for p1, p2 in combinations(points, 2):\n        distance = math.sqrt((p1[0] - p2[0])**2 + (p1[1] - p2[1])**2)\n        if closest_pair is None or distance < closest_pair[0]:\n            closest_pair = (distance, (p1, p2))\n    return closest_pair[1]", "raw_solution": "import random\nfrom itertools import combinations\nimport math\ndef task_func(n):\n    if n < 2:\n        return None\n    points = [(random.random(), random.random()) for _ in range(n)]\n    closest_pair = None\n    for p1, p2 in combinations(points, 2):\n        distance = math.sqrt((p1[0] - p2[0])**2 + (p1[1] - p2[1])**2)\n        if closest_pair is None or distance < closest_pair[0]:\n            closest_pair = (distance, (p1, p2))\n    return closest_pair[1]\n```"}
{"task_id": "BigCodeBench/278", "solution": "import numpy as np\nfrom sympy import symbols, solve\ndef task_func(precision=2, seed=0):\n    np.random.seed(seed)\n    a = np.random.randint(-10, 11)\n    b = np.random.randint(-10, 11)\n    c = np.random.randint(-10, 11)\n    x = symbols('x')\n    eq = a * x**2 + b * x + c\n    sol = solve(eq, x)\n    sol = [round(sol[i], precision) + 0j for i in range(len(sol))]\n    return sol", "raw_solution": "import numpy as np\nfrom sympy import symbols, solve\n\ndef task_func(precision=2, seed=0):\n    np.random.seed(seed)\n    a = np.random.randint(-10, 11)\n    b = np.random.randint(-10, 11)\n    c = np.random.randint(-10, 11)\n    x = symbols('x')\n    eq = a * x**2 + b * x + c\n    sol = solve(eq, x)\n    sol = [round(sol[i], precision) + 0j for i in range(len(sol))]\n    return sol\n```"}
{"task_id": "BigCodeBench/279", "solution": "import random\nfrom collections import Counter\nCARDS = ['2', '3', '4', '5', '6', '7', '8', '9', '10', 'J', 'Q', 'K', 'A']\ndef task_func(x=1):\n    hands = []\n    for _ in range(x):\n        hand = random.sample(CARDS, 5)\n        hands.append(hand)\n    counter = Counter(hand)\n    return hands, counter", "raw_solution": "import random\nfrom collections import Counter\n\n# Constants\nCARDS = ['2', '3', '4', '5', '6', '7', '8', '9', '10', 'J', 'Q', 'K', 'A']\n\ndef task_func(x=1):\n    hands = []\n    for _ in range(x):\n        hand = random.sample(CARDS, 5)\n        hands.append(hand)\n    counter = Counter(hand)\n    return hands, counter\n```"}
{"task_id": "BigCodeBench/280", "solution": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.fft import fft\ndef task_func(signal, precision=2, seed=777):\n    np.random.seed(seed)\n    signal = np.random.rand(len(signal))\n    signal = np.round(signal, precision)\n    fft_result = fft(signal)\n    fig, (ax1, ax2) = plt.subplots(2, 1)\n    ax1.plot(signal)\n    ax1.set_title('Original Signal')\n    ax2.plot(np.abs(fft_result))\n    ax2.set_title('Transformed Signal')\n    plt.show()\n    return fft_result, (ax1, ax2)", "raw_solution": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.fft import fft\n\ndef task_func(signal, precision=2, seed=777):\n    np.random.seed(seed)\n    signal = np.random.rand(len(signal))\n    signal = np.round(signal, precision)\n    fft_result = fft(signal)\n    fig, (ax1, ax2) = plt.subplots(2, 1)\n    ax1.plot(signal)\n    ax1.set_title('Original Signal')\n    ax2.plot(np.abs(fft_result))\n    ax2.set_title('Transformed Signal')\n    plt.show()\n    return fft_result, (ax1, ax2)\n```"}
{"task_id": "BigCodeBench/281", "solution": "import re\nimport os\nfrom collections import Counter\ndef task_func(folder_path: str) -> dict:\n    ip_count = Counter()\n    for root, dirs, files in os.walk(folder_path):\n        for file in files:\n            if file.endswith('.log'):\n                file_path = os.path.join(root, file)\n                with open(file_path, 'r') as f:\n                    for line in f:\n                        ip = re.search(r'\\b(?:[0-9]{1,3}\\.){3}[0-9]{1,3}\\b', line)\n                        if ip:\n                            ip_count[ip.group()] += 1\n    return dict(ip_count)", "raw_solution": "import re\nimport os\nfrom collections import Counter\n\ndef task_func(folder_path: str) -> dict:\n    ip_count = Counter()\n    for root, dirs, files in os.walk(folder_path):\n        for file in files:\n            if file.endswith('.log'):\n                file_path = os.path.join(root, file)\n                with open(file_path, 'r') as f:\n                    for line in f:\n                        ip = re.search(r'\\b(?:[0-9]{1,3}\\.){3}[0-9]{1,3}\\b', line)\n                        if ip:\n                            ip_count[ip.group()] += 1\n    return dict(ip_count)\n```"}
{"task_id": "BigCodeBench/282", "solution": "import matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\nimport numpy as np\nimport cv2\nimport os\ndef task_func(file_path, onpick):\n    if not os.path.exists(file_path):\n        raise FileNotFoundError(\"File not found\")\n    img = cv2.imread(file_path)\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    img = cv2.resize(img, (100, 100))\n    img = np.array(img)\n    img = img.reshape((100, 100, 3))\n    img = img.astype(np.float32)\n    img = img / 255.0\n    img = np.transpose(img, (2, 0, 1))\n    img = np.expand_dims(img, axis=0)\n    fig = plt.figure()\n    ax = fig.add_subplot(111, projection='3d')\n    ax.scatter(img[0, 0, 0], img[0, 0, 1], img[0, 0, 2], c='r', marker='o')\n    def onpick(event):\n        if event.artist == ax.scatter:\n            x, y, z = event.artist.get_offsets()[event.ind[0]]\n            print(f\"Selected point: ({x}, {y}, {z})\")\n            onpick_func(x, y, z)\n    ax.set_xlabel('Red')\n    ax.set_ylabel('Green')\n    ax.set_zlabel('Blue')\n    ax.set_xlim(0, 1)\n    ax.set_ylim(0, 1)\n    ax.set_zlim(0, 1)\n    ax.set_xticks(np.arange(0, 1.1, 0.1))\n    ax.set_yticks(np.arange(0, 1.1, 0.1))\n    ax.set_zticks(np.arange(0, 1.1, 0.1))\n    ax.set_xticklabels(np.arange(0, 1.1, 0.1))\n    ax.set_yticklabels(np.arange(0, 1.1, 0.1))\n    ax.set_zticklabels(np.arange(0, 1.1, 0.1))\n    ax.set_title('Color Histogram')\n    ax.set_xlabel('Red')\n    ax.set_ylabel('Green')\n    ax.set_zlabel('Blue')\n    ax.set_xlim(0, 1)\n    ax.set_ylim(0, 1)\n    ax.set_zlim(0, 1)\n    ax.set_xticks(np.arange(0, 1.1, 0.1))\n    ax.set_yticks(np.arange(0, 1.1, 0.1))\n    ax.set_zticks(np.arange(0, 1.1, 0.1))\n    ax.set_xticklabels(np.arange(0, 1.1, 0.1))\n    ax.set_yticklabels(np.arange(0, 1.1, 0.1))\n    ax.set_zticklabels(np.arange(0, 1.1, 0.1))\n    ax.set_title('Color Histogram')\n    ax.set_xlabel('Red')\n    ax.set_ylabel('Green')\n    ax.set_zlabel('Blue')\n    ax.set_xlim(0, 1)\n    ax.set_ylim(0, 1)\n    ax.set_zlim(0, 1)\n    ax.set_xticks(np.arange(0, 1.1, 0.1))\n    ax.set_yticks(np.arange(0, 1.1, 0.1))\n    ax.set_zticks(np.arange(0, 1.1, 0.1))\n    ax.set_xticklabels(np.arange(0, 1.1, 0.1))\n    ax.set_yticklabels(np.arange(0, 1.1, 0.1))\n    ax.set_zticklabels(np.arange(0, 1.1, 0.1))\n    ax.set_title('Color Histogram')\n    ax.set_xlabel('Red')\n    ax.set_ylabel('Green')\n    ax.set_zlabel('Blue')\n    ax.set_xlim(0, 1)\n    ax.set_ylim(0, 1)\n    ax.set_zlim(0, 1)\n    ax.set_xticks(np.arange(0, 1.1, 0.1))\n    ax.set_yticks(np.arange(0, 1.1, 0.1))\n    ax.set_zticks(np.arange(0, 1.1, 0.1))\n    ax.set_xticklabels(np.arange(0, 1.1, 0.1))\n    ax.set_yticklabels(np.arange(0, 1.1, 0.1))\n    ax.set_zticklabels(np.arange(0, 1.1, 0.1))\n    ax.set_title('Color Histogram')\n    ax.set_xlabel('Red')\n    ax.set_ylabel('Green')\n    ax.set_zlabel('Blue')\n    ax.set_xlim(0, 1)\n    ax.set_ylim(0, 1)\n    ax.set_zlim(0, 1)\n    ax.set_xticks(np.arange(0, 1.1, 0.1))\n    ax.set_yticks(np.arange(0, 1.1, 0.1))\n    ax.set_zticks(np.arange(0, 1.1, 0.1))\n    ax.set_xticklabels(np.arange(0, 1.1, 0.1))\n    ax.set_yticklabels(np.arange(0, 1.1, 0.1))\n    ax.set_zticklabels(np.arange(0, 1.1, 0.1))\n    ax.set_title('Color Histogram')\n    ax.set_xlabel('Red')\n    ax.set_ylabel('Green')\n    ax.set_zlabel('Blue')\n    ax.set_xlim(0, 1)\n    ax.set_ylim(0, 1)\n    ax.set_zlim(0, 1)", "raw_solution": "import matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\nimport numpy as np\nimport cv2\nimport os\ndef task_func(file_path, onpick):\n    if not os.path.exists(file_path):\n        raise FileNotFoundError(\"File not found\")\n    img = cv2.imread(file_path)\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    img = cv2.resize(img, (100, 100))\n    img = np.array(img)\n    img = img.reshape((100, 100, 3))\n    img = img.astype(np.float32)\n    img = img / 255.0\n    img = np.transpose(img, (2, 0, 1))\n    img = np.expand_dims(img, axis=0)\n    fig = plt.figure()\n    ax = fig.add_subplot(111, projection='3d')\n    ax.scatter(img[0, 0, 0], img[0, 0, 1], img[0, 0, 2], c='r', marker='o')\n    def onpick(event):\n        if event.artist == ax.scatter:\n            x, y, z = event.artist.get_offsets()[event.ind[0]]\n            print(f\"Selected point: ({x}, {y}, {z})\")\n            onpick_func(x, y, z)\n    ax.set_xlabel('Red')\n    ax.set_ylabel('Green')\n    ax.set_zlabel('Blue')\n    ax.set_xlim(0, 1)\n    ax.set_ylim(0, 1)\n    ax.set_zlim(0, 1)\n    ax.set_xticks(np.arange(0, 1.1, 0.1))\n    ax.set_yticks(np.arange(0, 1.1, 0.1))\n    ax.set_zticks(np.arange(0, 1.1, 0.1))\n    ax.set_xticklabels(np.arange(0, 1.1, 0.1))\n    ax.set_yticklabels(np.arange(0, 1.1, 0.1))\n    ax.set_zticklabels(np.arange(0, 1.1, 0.1))\n    ax.set_title('Color Histogram')\n    ax.set_xlabel('Red')\n    ax.set_ylabel('Green')\n    ax.set_zlabel('Blue')\n    ax.set_xlim(0, 1)\n    ax.set_ylim(0, 1)\n    ax.set_zlim(0, 1)\n    ax.set_xticks(np.arange(0, 1.1, 0.1))\n    ax.set_yticks(np.arange(0, 1.1, 0.1))\n    ax.set_zticks(np.arange(0, 1.1, 0.1))\n    ax.set_xticklabels(np.arange(0, 1.1, 0.1))\n    ax.set_yticklabels(np.arange(0, 1.1, 0.1))\n    ax.set_zticklabels(np.arange(0, 1.1, 0.1))\n    ax.set_title('Color Histogram')\n    ax.set_xlabel('Red')\n    ax.set_ylabel('Green')\n    ax.set_zlabel('Blue')\n    ax.set_xlim(0, 1)\n    ax.set_ylim(0, 1)\n    ax.set_zlim(0, 1)\n    ax.set_xticks(np.arange(0, 1.1, 0.1))\n    ax.set_yticks(np.arange(0, 1.1, 0.1))\n    ax.set_zticks(np.arange(0, 1.1, 0.1))\n    ax.set_xticklabels(np.arange(0, 1.1, 0.1))\n    ax.set_yticklabels(np.arange(0, 1.1, 0.1))\n    ax.set_zticklabels(np.arange(0, 1.1, 0.1))\n    ax.set_title('Color Histogram')\n    ax.set_xlabel('Red')\n    ax.set_ylabel('Green')\n    ax.set_zlabel('Blue')\n    ax.set_xlim(0, 1)\n    ax.set_ylim(0, 1)\n    ax.set_zlim(0, 1)\n    ax.set_xticks(np.arange(0, 1.1, 0.1))\n    ax.set_yticks(np.arange(0, 1.1, 0.1))\n    ax.set_zticks(np.arange(0, 1.1, 0.1))\n    ax.set_xticklabels(np.arange(0, 1.1, 0.1))\n    ax.set_yticklabels(np.arange(0, 1.1, 0.1))\n    ax.set_zticklabels(np.arange(0, 1.1, 0.1))\n    ax.set_title('Color Histogram')\n    ax.set_xlabel('Red')\n    ax.set_ylabel('Green')\n    ax.set_zlabel('Blue')\n    ax.set_xlim(0, 1)\n    ax.set_ylim(0, 1)\n    ax.set_zlim(0, 1)\n    ax.set_xticks(np.arange(0, 1.1, 0.1))\n    ax.set_yticks(np.arange(0, 1.1, 0.1))\n    ax.set_zticks(np.arange(0, 1.1, 0.1))\n    ax.set_xticklabels(np.arange(0, 1.1, 0.1))\n    ax.set_yticklabels(np.arange(0, 1.1, 0.1))\n    ax.set_zticklabels(np.arange(0, 1.1, 0.1))\n    ax.set_title('Color Histogram')\n    ax.set_xlabel('Red')\n    ax.set_ylabel('Green')\n    ax.set_zlabel('Blue')\n    ax.set_xlim(0, 1)\n    ax.set_ylim(0, 1)\n    ax.set_zlim(0, 1)\n    ax.set_xticks(np.arange(0, 1"}
{"task_id": "BigCodeBench/283", "solution": "import os\nimport json\nfrom collections import Counter\ndef task_func(json_files_path='./json_files/', key='name'):\n    result = {}\n    for filename in os.listdir(json_files_path):\n        if filename.endswith('.json'):\n            with open(os.path.join(json_files_path, filename), 'r') as f:\n                data = json.load(f)\n                if key in data:\n                    result[data[key]] = result.get(data[key], 0) + 1\n    return result", "raw_solution": "import os\nimport json\nfrom collections import Counter\n\ndef task_func(json_files_path='./json_files/', key='name'):\n    result = {}\n    for filename in os.listdir(json_files_path):\n        if filename.endswith('.json'):\n            with open(os.path.join(json_files_path, filename), 'r') as f:\n                data = json.load(f)\n                if key in data:\n                    result[data[key]] = result.get(data[key], 0) + 1\n    return result\n```"}
{"task_id": "BigCodeBench/284", "solution": "import mechanize\nfrom bs4 import BeautifulSoup\nfrom urllib.parse import urljoin\ndef task_func(url):\n    br = mechanize.Browser()\n    br.open(url)\n    soup = BeautifulSoup(br.response().read(), 'html.parser')\n    links = [urljoin(url, a['href']) for a in soup.find_all('a')]\n    return links", "raw_solution": "import mechanize\nfrom bs4 import BeautifulSoup\nfrom urllib.parse import urljoin\n\ndef task_func(url):\n    br = mechanize.Browser()\n    br.open(url)\n    soup = BeautifulSoup(br.response().read(), 'html.parser')\n    links = [urljoin(url, a['href']) for a in soup.find_all('a')]\n    return links\n```"}
{"task_id": "BigCodeBench/285", "solution": "import mechanize\nfrom bs4 import BeautifulSoup\ndef task_func(url, form_id, data):\n    br = mechanize.Browser()\n    br.open(url)\n    br.select_form(form_id)\n    for key, value in data.items():\n        br.form[key] = value\n    br.submit()\n    soup = BeautifulSoup(br.response().read(), 'html.parser')\n    if soup.title is None:\n        return 'No Title'\n    else:\n        return soup.title.string", "raw_solution": "import mechanize\nfrom bs4 import BeautifulSoup\n\ndef task_func(url, form_id, data):\n    br = mechanize.Browser()\n    br.open(url)\n    br.select_form(form_id)\n    for key, value in data.items():\n        br.form[key] = value\n    br.submit()\n    soup = BeautifulSoup(br.response().read(), 'html.parser')\n    if soup.title is None:\n        return 'No Title'\n    else:\n        return soup.title.string\n```"}
{"task_id": "BigCodeBench/286", "solution": "from collections import Counter\nimport os\nimport csv\ndef task_func(output_file, test_directory):\n    if not os.path.exists(test_directory):\n        return 0\n    word_counts = Counter()\n    for file_name in os.listdir(test_directory):\n        if file_name.endswith('.txt'):\n            file_path = os.path.join(test_directory, file_name)\n            with open(file_path, 'r', encoding='utf-8') as file:\n                for line in file:\n                    words = line.split()\n                    word_counts.update(words)\n    with open(output_file, 'w', newline='', encoding='utf-8') as file:\n        writer = csv.writer(file)\n        writer.writerow(['Word', 'Count'])\n        for word, count in word_counts.items():\n            writer.writerow([word, count])\n    return sum(word_counts.values())", "raw_solution": "from collections import Counter\nimport os\nimport csv\n# Constants\nFILE_DIR = './yourdictfiles/'\ndef task_func(output_file, test_directory):\n    if not os.path.exists(test_directory):\n        return 0\n    word_counts = Counter()\n    for file_name in os.listdir(test_directory):\n        if file_name.endswith('.txt'):\n            file_path = os.path.join(test_directory, file_name)\n            with open(file_path, 'r', encoding='utf-8') as file:\n                for line in file:\n                    words = line.split()\n                    word_counts.update(words)\n    with open(output_file, 'w', newline='', encoding='utf-8') as file:\n        writer = csv.writer(file)\n        writer.writerow(['Word', 'Count'])\n        for word, count in word_counts.items():\n            writer.writerow([word, count])\n    return sum(word_counts.values())\n```"}
{"task_id": "BigCodeBench/287", "solution": "from collections import Counter\nimport os\nimport json\ndef task_func(filename, directory):\n    # Initialize a counter to count the number of words in each .txt file\n    word_count = Counter()\n    \n    # Loop through all files in the specified directory\n    for root, dirs, files in os.walk(directory):\n        for file in files:\n            # Check if the file is a .txt file\n            if file.endswith('.txt'):\n                # Construct the full path to the .txt file\n                file_path = os.path.join(root, file)\n                \n                # Open the .txt file and read its contents\n                with open(file_path, 'r') as f:\n                    # Split the contents into words and count them\n                    words = f.read().split()\n                    word_count.update(words)\n    \n    # Calculate the total number of words\n    total_words = sum(word_count.values())\n    \n    # Export the counts to a JSON file\n    with open('word_counts.json', 'w') as f:\n        json.dump(word_count, f)\n    \n    # Return the total number of words\n    return total_words", "raw_solution": "from collections import Counter\nimport os\nimport json\n\ndef task_func(filename, directory):\n    # Initialize a counter to count the number of words in each .txt file\n    word_count = Counter()\n    \n    # Loop through all files in the specified directory\n    for root, dirs, files in os.walk(directory):\n        for file in files:\n            # Check if the file is a .txt file\n            if file.endswith('.txt'):\n                # Construct the full path to the .txt file\n                file_path = os.path.join(root, file)\n                \n                # Open the .txt file and read its contents\n                with open(file_path, 'r') as f:\n                    # Split the contents into words and count them\n                    words = f.read().split()\n                    word_count.update(words)\n    \n    # Calculate the total number of words\n    total_words = sum(word_count.values())\n    \n    # Export the counts to a JSON file\n    with open('word_counts.json', 'w') as f:\n        json.dump(word_count, f)\n    \n    # Return the total number of words\n    return total_words\n```"}
{"task_id": "BigCodeBench/288", "solution": "import collections\nimport json\nimport os\ndef task_func(directory_path: str) -> dict:\n    count_dict = collections.defaultdict(int)\n    for filename in os.listdir(directory_path):\n        if filename.endswith('.json'):\n            with open(os.path.join(directory_path, filename), 'r') as f:\n                data = json.load(f)\n                for key in data:\n                    count_dict[key] += 1\n    return dict(count_dict)", "raw_solution": "import collections\nimport json\nimport os\n\ndef task_func(directory_path: str) -> dict:\n    count_dict = collections.defaultdict(int)\n    for filename in os.listdir(directory_path):\n        if filename.endswith('.json'):\n            with open(os.path.join(directory_path, filename), 'r') as f:\n                data = json.load(f)\n                for key in data:\n                    count_dict[key] += 1\n    return dict(count_dict)\n```"}
{"task_id": "BigCodeBench/289", "solution": "import tensorflow as tf\nfrom sklearn.model_selection import KFold\nfrom sklearn.preprocessing import MinMaxScaler\ndef task_func(X, y, n_splits, batch_size, epochs):\n    scaler = MinMaxScaler()\n    X = scaler.fit_transform(X)\n    y = tf.keras.utils.to_categorical(y)\n    model = tf.keras.Sequential([\n        tf.keras.layers.Dense(20, activation='relu', input_shape=(X.shape[1],)),\n        tf.keras.layers.Dense(1, activation='sigmoid')\n    ])\n    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n    kfold = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n    history = []\n    for train_index, test_index in kfold.split(X):\n        X_train, X_test = X[train_index], X[test_index]\n        y_train, y_test = y[train_index], y[test_index]\n        model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(X_test, y_test))\n        history.append(model.history)\n    return history", "raw_solution": "import tensorflow as tf\nfrom sklearn.model_selection import KFold\nfrom sklearn.preprocessing import MinMaxScaler\ndef task_func(X, y, n_splits, batch_size, epochs):\n    scaler = MinMaxScaler()\n    X = scaler.fit_transform(X)\n    y = tf.keras.utils.to_categorical(y)\n    model = tf.keras.Sequential([\n        tf.keras.layers.Dense(20, activation='relu', input_shape=(X.shape[1],)),\n        tf.keras.layers.Dense(1, activation='sigmoid')\n    ])\n    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n    kfold = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n    history = []\n    for train_index, test_index in kfold.split(X):\n        X_train, X_test = X[train_index], X[test_index]\n        y_train, y_test = y[train_index], y[test_index]\n        model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(X_test, y_test))\n        history.append(model.history)\n    return history\n```"}
{"task_id": "BigCodeBench/290", "solution": "import nltk\nfrom collections import Counter\nimport os\nfrom nltk.corpus import stopwords\nSTOPWORDS = set(stopwords.words('english'))\ndef task_func(directory_path):\n    # Initialize a counter to store unique words\n    word_count = Counter()\n    \n    # Walk through all files in the directory\n    for root, dirs, files in os.walk(directory_path):\n        for file in files:\n            # Check if the file is a .txt file\n            if file.endswith('.txt'):\n                # Open the file and read its contents\n                with open(os.path.join(root, file), 'r') as f:\n                    text = f.read()\n                \n                # Split the text into words\n                words = text.split()\n                \n                # Remove stop words and non-alphabetic characters\n                words = [word.lower() for word in words if word.isalpha() and word not in STOPWORDS]\n                \n                # Update the word count\n                word_count.update(words)\n    \n    # Return the total count of unique non-stop words\n    return len(word_count)", "raw_solution": "import nltk\nnltk.download('stopwords')\nfrom collections import Counter\nimport os\nfrom nltk.corpus import stopwords\n\n# Constants\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(directory_path):\n    # Initialize a counter to store unique words\n    word_count = Counter()\n    \n    # Walk through all files in the directory\n    for root, dirs, files in os.walk(directory_path):\n        for file in files:\n            # Check if the file is a .txt file\n            if file.endswith('.txt'):\n                # Open the file and read its contents\n                with open(os.path.join(root, file), 'r') as f:\n                    text = f.read()\n                \n                # Split the text into words\n                words = text.split()\n                \n                # Remove stop words and non-alphabetic characters\n                words = [word.lower() for word in words if word.isalpha() and word not in STOPWORDS]\n                \n                # Update the word count\n                word_count.update(words)\n    \n    # Return the total count of unique non-stop words\n    return len(word_count)\n```"}
{"task_id": "BigCodeBench/291", "solution": "import matplotlib.pyplot as plt\nimport numpy as np\nimport seaborn as sns\ndef task_func(mu, sigma, seed=0):\n    np.random.seed(seed)\n    data = np.random.normal(mu, sigma, 1000)\n    sns.histplot(data, kde=True, color='blue')\n    plt.colorbar(label='Density')\n    plt.xlabel('Value')\n    plt.ylabel('Frequency')\n    plt.title('Normal Distribution')\n    return plt.gca()", "raw_solution": "import matplotlib.pyplot as plt\nimport numpy as np\nimport seaborn as sns\ndef task_func(mu, sigma, seed=0):\n    np.random.seed(seed)\n    data = np.random.normal(mu, sigma, 1000)\n    sns.histplot(data, kde=True, color='blue')\n    plt.colorbar(label='Density')\n    plt.xlabel('Value')\n    plt.ylabel('Frequency')\n    plt.title('Normal Distribution')\n    return plt.gca()\n```"}
{"task_id": "BigCodeBench/292", "solution": "import pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\ndef task_func(df):\n    scaler = MinMaxScaler()\n    df['Age'] = scaler.fit_transform(df['Age'].values.reshape(-1, 1))\n    df['Income'] = scaler.fit_transform(df['Income'].values.reshape(-1, 1))\n    income_hist = df['Income'].hist()\n    return (df, income_hist)", "raw_solution": "import pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\n\ndef task_func(df):\n    scaler = MinMaxScaler()\n    df['Age'] = scaler.fit_transform(df['Age'].values.reshape(-1, 1))\n    df['Income'] = scaler.fit_transform(df['Income'].values.reshape(-1, 1))\n    income_hist = df['Income'].hist()\n    return (df, income_hist)\n```"}
{"task_id": "BigCodeBench/293", "solution": "import itertools\nimport numpy as np\nimport matplotlib.pyplot as plt\ndef task_func(elements, subset_size):\n    # Generate all subsets of the given size\n    subsets = list(itertools.combinations(elements, subset_size))\n    \n    # Calculate the sums of the subsets\n    sums = [sum(subset) for subset in subsets]\n    \n    # Draw a histogram of the sums of the subsets\n    fig, ax = plt.subplots()\n    ax.hist(sums, bins=20)\n    ax.set_title('Histogram of Subset Sums')\n    ax.set_xlabel('Sum')\n    ax.set_ylabel('Frequency')\n    \n    # Return the Axes object of the plotted histogram and the combinations of the subsets and their sums\n    return ax, subsets, sums", "raw_solution": "import itertools\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef task_func(elements, subset_size):\n    # Generate all subsets of the given size\n    subsets = list(itertools.combinations(elements, subset_size))\n    \n    # Calculate the sums of the subsets\n    sums = [sum(subset) for subset in subsets]\n    \n    # Draw a histogram of the sums of the subsets\n    fig, ax = plt.subplots()\n    ax.hist(sums, bins=20)\n    ax.set_title('Histogram of Subset Sums')\n    ax.set_xlabel('Sum')\n    ax.set_ylabel('Frequency')\n    \n    # Return the Axes object of the plotted histogram and the combinations of the subsets and their sums\n    return ax, subsets, sums\n```"}
{"task_id": "BigCodeBench/294", "solution": "import pandas as pd\nfrom sklearn.preprocessing import StandardScaler\ndef task_func(df):\n    if 'id' not in df.columns or 'age' not in df.columns or 'income' not in df.columns:\n        raise ValueError(\"This function will raise ValueError if the DataFrame does not have the 'id', 'age', and 'income' columns.\")\n    scaler = StandardScaler()\n    df[['age', 'income']] = scaler.fit_transform(df[['age', 'income']])\n    return df", "raw_solution": "import pandas as pd\nfrom sklearn.preprocessing import StandardScaler\n\ndef task_func(df):\n    if 'id' not in df.columns or 'age' not in df.columns or 'income' not in df.columns:\n        raise ValueError(\"This function will raise ValueError if the DataFrame does not have the 'id', 'age', and 'income' columns.\")\n    scaler = StandardScaler()\n    df[['age', 'income']] = scaler.fit_transform(df[['age', 'income']])\n    return df\n```"}
{"task_id": "BigCodeBench/295", "solution": "import itertools\nimport statistics\ndef task_func(elements, subset_size):\n    # Generate all subsets of the given size\n    subsets = list(itertools.combinations(elements, subset_size))\n    # Calculate the sum of each subset\n    subset_sums = [sum(subset) for subset in subsets]\n    # Calculate the mean, median, and mode of the sums of the subsets\n    mean = statistics.mean(subset_sums)\n    median = statistics.median(subset_sums)\n    mode = statistics.mode(subset_sums)\n    # Return the results in a dictionary\n    return {'mean': mean, 'median': median, 'mode': mode}", "raw_solution": "import itertools\nimport statistics\n\n# Refined function after importing required libraries\ndef task_func(elements, subset_size):\n    # Generate all subsets of the given size\n    subsets = list(itertools.combinations(elements, subset_size))\n    # Calculate the sum of each subset\n    subset_sums = [sum(subset) for subset in subsets]\n    # Calculate the mean, median, and mode of the sums of the subsets\n    mean = statistics.mean(subset_sums)\n    median = statistics.median(subset_sums)\n    mode = statistics.mode(subset_sums)\n    # Return the results in a dictionary\n    return {'mean': mean, 'median': median, 'mode': mode}\n```"}
{"task_id": "BigCodeBench/296", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\ndef task_func(df):\n    if not isinstance(df, pd.DataFrame):\n        raise ValueError(\"The function will raise a ValueError is input df is not a DataFrame.\")\n    counts = df['value'].value_counts()\n    ax = counts.plot(kind='bar')\n    ax.set_title('Value Distribution')\n    ax.set_xlabel('Value')\n    ax.set_ylabel('Count')\n    return ax", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\n\ndef task_func(df):\n    if not isinstance(df, pd.DataFrame):\n        raise ValueError(\"The function will raise a ValueError is input df is not a DataFrame.\")\n    counts = df['value'].value_counts()\n    ax = counts.plot(kind='bar')\n    ax.set_title('Value Distribution')\n    ax.set_xlabel('Value')\n    ax.set_ylabel('Count')\n    return ax\n```"}
{"task_id": "BigCodeBench/297", "solution": "import itertools\nimport collections\ndef task_func(elements, subset_size):\n    subsets = list(itertools.combinations(elements, subset_size))\n    sums = [sum(subset) for subset in subsets]\n    counts = collections.Counter(sums)\n    return dict(counts)", "raw_solution": "import itertools\nimport collections\ndef task_func(elements, subset_size):\n    subsets = list(itertools.combinations(elements, subset_size))\n    sums = [sum(subset) for subset in subsets]\n    counts = collections.Counter(sums)\n    return dict(counts)\n```"}
{"task_id": "BigCodeBench/298", "solution": "import pandas as pd\nfrom sklearn.preprocessing import StandardScaler\nimport matplotlib.pyplot as plt\ndef task_func(df, plot=False):\n    if 'Date' not in df.columns or 'Value' not in df.columns:\n        raise KeyError(\"This function will raise KeyError if the DataFrame does not have the 'Date' and 'Value' columns.\")\n    df['Date'] = pd.to_datetime(df['Date'])\n    df.set_index('Date', inplace=True)\n    scaler = StandardScaler()\n    scaled_values = scaler.fit_transform(df['Value'].values.reshape(-1, 1))\n    df_scaled = pd.DataFrame(scaled_values, columns=['Scaled Value'])\n    df_scaled = df_scaled.join(df.drop('Value', axis=1))\n    if plot:\n        df_scaled.plot(kind='bar', title='Scaled Values Over Time', xlabel='Date', ylabel='Scaled Value')\n        plt.show()\n    return df_scaled", "raw_solution": "import pandas as pd\nfrom sklearn.preprocessing import StandardScaler\nimport matplotlib.pyplot as plt\n# Constants\nCOLUMNS = ['Date', 'Value']\ndef task_func(df, plot=False):\n    if 'Date' not in df.columns or 'Value' not in df.columns:\n        raise KeyError(\"This function will raise KeyError if the DataFrame does not have the 'Date' and 'Value' columns.\")\n    df['Date'] = pd.to_datetime(df['Date'])\n    df.set_index('Date', inplace=True)\n    scaler = StandardScaler()\n    scaled_values = scaler.fit_transform(df['Value'].values.reshape(-1, 1))\n    df_scaled = pd.DataFrame(scaled_values, columns=['Scaled Value'])\n    df_scaled = df_scaled.join(df.drop('Value', axis=1))\n    if plot:\n        df_scaled.plot(kind='bar', title='Scaled Values Over Time', xlabel='Date', ylabel='Scaled Value')\n        plt.show()\n    return df_scaled\n```"}
{"task_id": "BigCodeBench/299", "solution": "import itertools\nimport math\nfrom pandas import Series\ndef task_func(elements, subset_size, top_n=2):\n    if subset_size > len(elements):\n        return 1\n    elif subset_size == 0:\n        return 1\n    else:\n        subsets = list(itertools.combinations(elements, subset_size))\n        subset_sums = [sum(subset) for subset in subsets]\n        subset_sums.sort(reverse=True)\n        return math.prod(subset_sums[:top_n]), Series(subset_sums[:top_n])", "raw_solution": "import itertools\nimport math\nfrom pandas import Series\n\ndef task_func(elements, subset_size, top_n=2):\n    if subset_size > len(elements):\n        return 1\n    elif subset_size == 0:\n        return 1\n    else:\n        subsets = list(itertools.combinations(elements, subset_size))\n        subset_sums = [sum(subset) for subset in subsets]\n        subset_sums.sort(reverse=True)\n        return math.prod(subset_sums[:top_n]), Series(subset_sums[:top_n])\n```"}
{"task_id": "BigCodeBench/300", "solution": "import pandas as pd\nfrom scipy.stats import zscore\nimport matplotlib.pyplot as plt\ndef task_func(df):\n    if 'Date' not in df.columns or 'Value' not in df.columns:\n        raise KeyError(\"This function will raise KeyError if the DataFrame does not have the 'Date' and 'Value' columns.\")\n    df['Date'] = pd.to_datetime(df['Date'])\n    df['Z-Score'] = df['Value'].apply(lambda x: zscore(x))\n    df = df.drop(columns=['Value'])\n    fig, ax = plt.subplots()\n    ax.boxplot(df['Z-Score'], vert=False)\n    ax.set_title('Z-Scores Over Time')\n    ax.set_xlabel('Date')\n    ax.set_ylabel('Z-Score')\n    return df, fig", "raw_solution": "import pandas as pd\nfrom scipy.stats import zscore\nimport matplotlib.pyplot as plt\n\ndef task_func(df):\n    if 'Date' not in df.columns or 'Value' not in df.columns:\n        raise KeyError(\"This function will raise KeyError if the DataFrame does not have the 'Date' and 'Value' columns.\")\n    df['Date'] = pd.to_datetime(df['Date'])\n    df['Z-Score'] = df['Value'].apply(lambda x: zscore(x))\n    df = df.drop(columns=['Value'])\n    fig, ax = plt.subplots()\n    ax.boxplot(df['Z-Score'], vert=False)\n    ax.set_title('Z-Scores Over Time')\n    ax.set_xlabel('Date')\n    ax.set_ylabel('Z-Score')\n    return df, fig\n```"}
{"task_id": "BigCodeBench/301", "solution": "import pytz\nimport numpy as np\nfrom dateutil.parser import parse\nimport math\nSOLAR_CYCLE_YEARS = np.array([1986, 1996, 2008, 2019])\ndef task_func(date_str, from_tz, to_tz):\n    date = parse(date_str)\n    from_tz = pytz.timezone(from_tz)\n    to_tz = pytz.timezone(to_tz)\n    date = date.astimezone(from_tz)\n    year = date.year\n    if year < SOLAR_CYCLE_YEARS[0] or year > SOLAR_CYCLE_YEARS[-1]:\n        raise ValueError(\"Date is not within the solar cycle years\")\n    year_diff = year - SOLAR_CYCLE_YEARS[0]\n    solar_activity = math.cos((year_diff - 1) * 2 * math.pi / 11)\n    return solar_activity", "raw_solution": "import pytz\nimport numpy as np\nfrom dateutil.parser import parse\nimport math\nSOLAR_CYCLE_YEARS = np.array([1986, 1996, 2008, 2019])\ndef task_func(date_str, from_tz, to_tz):\n    date = parse(date_str)\n    from_tz = pytz.timezone(from_tz)\n    to_tz = pytz.timezone(to_tz)\n    date = date.astimezone(from_tz)\n    year = date.year\n    if year < SOLAR_CYCLE_YEARS[0] or year > SOLAR_CYCLE_YEARS[-1]:\n        raise ValueError(\"Date is not within the solar cycle years\")\n    year_diff = year - SOLAR_CYCLE_YEARS[0]\n    solar_activity = math.cos((year_diff - 1) * 2 * math.pi / 11)\n    return solar_activity\n```"}
{"task_id": "BigCodeBench/302", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\ndef task_func(df, plot=False):\n    if df.empty or df['Value'].isnull().any():\n        raise ValueError(\"DataFrame input is empty or have invalid 'Value'\")\n    df['Value'] = df['Value'].apply(lambda x: x if isinstance(x, list) else [x])\n    df = pd.concat([df.drop('Value', axis=1), df['Value'].apply(pd.Series)], axis=1)\n    corr = df.corr()\n    if plot:\n        sns.heatmap(corr, annot=True, cmap='coolwarm')\n        plt.title('Correlation Heatmap')\n        plt.show()\n    return corr", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n# Constants\nCOLUMNS = ['Date', 'Value']\ndef task_func(df, plot=False):\n    if df.empty or df['Value'].isnull().any():\n        raise ValueError(\"DataFrame input is empty or have invalid 'Value'\")\n    df['Value'] = df['Value'].apply(lambda x: x if isinstance(x, list) else [x])\n    df = pd.concat([df.drop('Value', axis=1), df['Value'].apply(pd.Series)], axis=1)\n    corr = df.corr()\n    if plot:\n        sns.heatmap(corr, annot=True, cmap='coolwarm')\n        plt.title('Correlation Heatmap')\n        plt.show()\n    return corr\n```"}
{"task_id": "BigCodeBench/303", "solution": "import pytz\nimport numpy as np\nfrom dateutil.parser import parse\nimport math\nMOON_PHASES_YEARS = np.array([1987, 1994, 2001, 2008, 2015, 2022])\ndef task_func(date_str, from_tz, to_tz):\n    # Parse the input date string\n    date = parse(date_str)\n    \n    # Convert the date to UTC\n    date = date.astimezone(pytz.utc)\n    \n    # Get the year of the date\n    year = date.year\n    \n    # Find the reference year for the moon phases\n    ref_year = MOON_PHASES_YEARS[np.argmin(np.abs(year - MOON_PHASES_YEARS))]\n    \n    # Calculate the moon phase\n    phase = (year - ref_year) / 7\n    \n    # Convert the phase to a float between 0 and 1\n    phase = (phase + 1) / 2\n    \n    return phase", "raw_solution": "import pytz\nimport numpy as np\nfrom dateutil.parser import parse\nimport math\nMOON_PHASES_YEARS = np.array([1987, 1994, 2001, 2008, 2015, 2022])\n\ndef task_func(date_str, from_tz, to_tz):\n    # Parse the input date string\n    date = parse(date_str)\n    \n    # Convert the date to UTC\n    date = date.astimezone(pytz.utc)\n    \n    # Get the year of the date\n    year = date.year\n    \n    # Find the reference year for the moon phases\n    ref_year = MOON_PHASES_YEARS[np.argmin(np.abs(year - MOON_PHASES_YEARS))]\n    \n    # Calculate the moon phase\n    phase = (year - ref_year) / 7\n    \n    # Convert the phase to a float between 0 and 1\n    phase = (phase + 1) / 2\n    \n    return phase\n```"}
{"task_id": "BigCodeBench/304", "solution": "import pandas as pd\nfrom sklearn.decomposition import PCA\nimport matplotlib.pyplot as plt\ndef task_func(df):\n    if df.empty:\n        return 0, 0\n    df = df.explode('numbers')\n    df['numbers'] = df['numbers'].astype(float)\n    pca = PCA()\n    pca.fit(df['numbers'].values.reshape(-1, 1))\n    explained_variance_ratio = pca.explained_variance_ratio_\n    ax = plt.bar(range(len(explained_variance_ratio)), explained_variance_ratio)\n    plt.title('Explained Variance Ratio of Principal Components')\n    plt.xlabel('Principal Component')\n    plt.ylabel('Explained Variance Ratio')\n    plt.show()\n    return explained_variance_ratio, ax", "raw_solution": "import pandas as pd\nfrom sklearn.decomposition import PCA\nimport matplotlib.pyplot as plt\n\ndef task_func(df):\n    if df.empty:\n        return 0, 0\n    df = df.explode('numbers')\n    df['numbers'] = df['numbers'].astype(float)\n    pca = PCA()\n    pca.fit(df['numbers'].values.reshape(-1, 1))\n    explained_variance_ratio = pca.explained_variance_ratio_\n    ax = plt.bar(range(len(explained_variance_ratio)), explained_variance_ratio)\n    plt.title('Explained Variance Ratio of Principal Components')\n    plt.xlabel('Principal Component')\n    plt.ylabel('Explained Variance Ratio')\n    plt.show()\n    return explained_variance_ratio, ax\n```"}
{"task_id": "BigCodeBench/305", "solution": "from collections import Counter\nimport itertools\nimport random\nALPHABET = 'abcdefghijklmnopqrstuvwxyz'\ndef task_func(list_of_lists, seed=0):\n    random.seed(seed)\n    if not list_of_lists:\n        list_of_lists = [random.sample(ALPHABET, 10)]\n    counter = Counter(itertools.chain(*list_of_lists))\n    return counter", "raw_solution": "from collections import Counter\nimport itertools\nimport random\n\n# Constants\nALPHABET = 'abcdefghijklmnopqrstuvwxyz'\n\ndef task_func(list_of_lists, seed=0):\n    random.seed(seed)\n    if not list_of_lists:\n        list_of_lists = [random.sample(ALPHABET, 10)]\n    counter = Counter(itertools.chain(*list_of_lists))\n    return counter\n```"}
{"task_id": "BigCodeBench/306", "solution": "import os\nimport logging\ndef task_func(directory):\n    if not os.path.exists(directory):\n        raise FileNotFoundError(\"The specified directory does not exist\")\n    logging.basicConfig(filename='jquery_removal.log', level=logging.INFO)\n    removed_files = []\n    for file in os.listdir(directory):\n        if 'jquery' in file:\n            os.remove(os.path.join(directory, file))\n            removed_files.append(file)\n            logging.info(f\"Removed file: {file}\")\n    return len(removed_files), removed_files", "raw_solution": "import os\nimport logging\n\ndef task_func(directory):\n    if not os.path.exists(directory):\n        raise FileNotFoundError(\"The specified directory does not exist\")\n    logging.basicConfig(filename='jquery_removal.log', level=logging.INFO)\n    removed_files = []\n    for file in os.listdir(directory):\n        if 'jquery' in file:\n            os.remove(os.path.join(directory, file))\n            removed_files.append(file)\n            logging.info(f\"Removed file: {file}\")\n    return len(removed_files), removed_files\n```"}
{"task_id": "BigCodeBench/307", "solution": "import seaborn as sns\nimport matplotlib.pyplot as plt\nimport random\ndef task_func(list_of_lists, seed=0):\n    random.seed(seed)\n    combined_data = []\n    for sublist in list_of_lists:\n        if not sublist:\n            combined_data.extend([random.randint(0, 100) for _ in range(5)])\n        else:\n            combined_data.extend(sublist)\n    sns.histplot(combined_data)\n    plt.show()\n    return plt.axes()", "raw_solution": "import seaborn as sns\nimport matplotlib.pyplot as plt\nimport random\n\ndef task_func(list_of_lists, seed=0):\n    random.seed(seed)\n    combined_data = []\n    for sublist in list_of_lists:\n        if not sublist:\n            combined_data.extend([random.randint(0, 100) for _ in range(5)])\n        else:\n            combined_data.extend(sublist)\n    sns.histplot(combined_data)\n    plt.show()\n    return plt.axes()\n```"}
{"task_id": "BigCodeBench/308", "solution": "import pandas as pd\nfrom statistics import mean\nimport random\nFIELDS = ['Physics', 'Math', 'Chemistry', 'Biology', 'English', 'History']\nSTUDENTS = ['Student_' + str(i) for i in range(1, 101)]\ndef task_func(additional_fields = []):\n    # Generate the report data\n    report_data = []\n    for student in STUDENTS:\n        student_data = {'Student': student}\n        for field in FIELDS:\n            student_data[field] = random.randint(0, 100)\n        report_data.append(student_data)\n    report_data.append({'Average': 'Average', 'Average Grade': mean([student_data[field] for field in FIELDS])})\n    report_data.append({'Average': 'Average Grade', 'Average Grade': mean([student_data[field] for student_data in report_data for field in FIELDS if field != 'Average'])})\n    report_data.append({'Average': 'Average Grade', 'Average Grade': mean([student_data[field] for student_data in report_data for field in FIELDS if field != 'Average' and field != 'Average Grade'])})\n    report_data.append({'Average': 'Average Grade', 'Average Grade': mean([student_data[field] for student_data in report_data for field in FIELDS if field != 'Average' and field != 'Average Grade' and field != 'Average Grade'])})\n    report_data.append({'Average': 'Average Grade', 'Average Grade': mean([student_data[field] for student_data in report_data for field in FIELDS if field != 'Average' and field != 'Average Grade' and field != 'Average Grade' and field != 'Average Grade'])})\n    report_data.append({'Average': 'Average Grade', 'Average Grade': mean([student_data[field] for student_data in report_data for field in FIELDS if field != 'Average' and field != 'Average Grade' and field != 'Average Grade' and field != 'Average Grade' and field != 'Average Grade'])})\n    report_data.append({'Average': 'Average Grade', 'Average Grade': mean([student_data[field] for student_data in report_data for field in FIELDS if field != 'Average' and field != 'Average Grade' and field != 'Average Grade' and field != 'Average Grade' and field != 'Average Grade' and field != 'Average Grade'])})\n    report_data.append({'Average': 'Average Grade', 'Average Grade': mean([student_data[field] for student_data in report_data for field in FIELDS if field != 'Average' and field != 'Average Grade' and field != 'Average Grade' and field != 'Average Grade' and field != 'Average Grade' and field != 'Average Grade' and field != 'Average Grade'])})\n    report_data.append({'Average': 'Average Grade', 'Average Grade': mean([student_data[field] for student_data in report_data for field in FIELDS if field != 'Average' and field != 'Average Grade' and field != 'Average Grade' and field != 'Average Grade' and field != 'Average Grade' and field != 'Average Grade' and field != 'Average Grade' and field != 'Average Grade'])})\n    report_data.append({'Average': 'Average Grade', 'Average Grade': mean([student_data[field] for student_data in report_data for field in FIELDS if field != 'Average' and field != 'Average Grade' and field != 'Average Grade' and field != 'Average Grade' and field != 'Average Grade' and field != 'Average Grade' and field != 'Average Grade' and field != 'Average Grade' and field != 'Average Grade'])})\n    report_data.append({'Average': 'Average Grade', 'Average Grade': mean([student_data[field] for student_data in report_data for field in FIELDS if field != 'Average' and field != 'Average Grade' and field != 'Average Grade' and field != 'Average Grade' and field != 'Average Grade' and field != 'Average Grade' and field != 'Average Grade' and field != 'Average Grade' and field != 'Average Grade' and field != 'Average Grade'])})\n    report_data.append({'Average': 'Average Grade', 'Average Grade': mean([student_data[field] for student_data in report_data for field in FIELDS if field != 'Average' and field != 'Average Grade' and field != 'Average Grade' and field != 'Average Grade' and field != 'Average Grade' and field != 'Average Grade' and field != 'Average Grade' and field != 'Average Grade' and field != 'Average Grade' and field != 'Average Grade' and field != 'Average Grade'])})\n    report_data.append({'Average': 'Average Grade', 'Average Grade': mean([student_data[field] for student_data in report_data for field in FIELDS if field != 'Average' and field != 'Average Grade' and field != 'Average Grade' and field != 'Average Grade' and field != 'Average Grade' and field != 'Average Grade' and field != 'Average Grade' and field != 'Average Grade' and field != 'Average Grade' and field != 'Average Grade' and field != 'Average Grade' and field != 'Average Grade'])})\n    report_data.append({'Average': 'Average Grade', 'Average Grade': mean([student_data[field] for student_data in report_data for field in FIELDS if field != 'Average' and field != 'Average Grade' and field != 'Average Grade' and field != 'Average Grade' and field != 'Average Grade' and field != 'Average Grade' and field != 'Average Grade' and field != 'Average Grade' and field != 'Average Grade' and field != 'Average Grade' and field != 'Average Grade' and field != 'Average Grade' and field != 'Average Grade'])})", "raw_solution": "import pandas as pd\nfrom statistics import mean\nimport random\n# Constants for generating the report data\nFIELDS = ['Physics', 'Math', 'Chemistry', 'Biology', 'English', 'History']\nSTUDENTS = ['Student_' + str(i) for i in range(1, 101)]\ndef task_func(additional_fields = []):\n    # Generate the report data\n    report_data = []\n    for student in STUDENTS:\n        student_data = {'Student': student}\n        for field in FIELDS:\n            student_data[field] = random.randint(0, 100)\n        report_data.append(student_data)\n    report_data.append({'Average': 'Average', 'Average Grade': mean([student_data[field] for field in FIELDS])})\n    report_data.append({'Average': 'Average Grade', 'Average Grade': mean([student_data[field] for student_data in report_data for field in FIELDS if field != 'Average'])})\n    report_data.append({'Average': 'Average Grade', 'Average Grade': mean([student_data[field] for student_data in report_data for field in FIELDS if field != 'Average' and field != 'Average Grade'])})\n    report_data.append({'Average': 'Average Grade', 'Average Grade': mean([student_data[field] for student_data in report_data for field in FIELDS if field != 'Average' and field != 'Average Grade' and field != 'Average Grade'])})\n    report_data.append({'Average': 'Average Grade', 'Average Grade': mean([student_data[field] for student_data in report_data for field in FIELDS if field != 'Average' and field != 'Average Grade' and field != 'Average Grade' and field != 'Average Grade'])})\n    report_data.append({'Average': 'Average Grade', 'Average Grade': mean([student_data[field] for student_data in report_data for field in FIELDS if field != 'Average' and field != 'Average Grade' and field != 'Average Grade' and field != 'Average Grade' and field != 'Average Grade'])})\n    report_data.append({'Average': 'Average Grade', 'Average Grade': mean([student_data[field] for student_data in report_data for field in FIELDS if field != 'Average' and field != 'Average Grade' and field != 'Average Grade' and field != 'Average Grade' and field != 'Average Grade' and field != 'Average Grade'])})\n    report_data.append({'Average': 'Average Grade', 'Average Grade': mean([student_data[field] for student_data in report_data for field in FIELDS if field != 'Average' and field != 'Average Grade' and field != 'Average Grade' and field != 'Average Grade' and field != 'Average Grade' and field != 'Average Grade' and field != 'Average Grade'])})\n    report_data.append({'Average': 'Average Grade', 'Average Grade': mean([student_data[field] for student_data in report_data for field in FIELDS if field != 'Average' and field != 'Average Grade' and field != 'Average Grade' and field != 'Average Grade' and field != 'Average Grade' and field != 'Average Grade' and field != 'Average Grade' and field != 'Average Grade'])})\n    report_data.append({'Average': 'Average Grade', 'Average Grade': mean([student_data[field] for student_data in report_data for field in FIELDS if field != 'Average' and field != 'Average Grade' and field != 'Average Grade' and field != 'Average Grade' and field != 'Average Grade' and field != 'Average Grade' and field != 'Average Grade' and field != 'Average Grade' and field != 'Average Grade'])})\n    report_data.append({'Average': 'Average Grade', 'Average Grade': mean([student_data[field] for student_data in report_data for field in FIELDS if field != 'Average' and field != 'Average Grade' and field != 'Average Grade' and field != 'Average Grade' and field != 'Average Grade' and field != 'Average Grade' and field != 'Average Grade' and field != 'Average Grade' and field != 'Average Grade' and field != 'Average Grade'])})\n    report_data.append({'Average': 'Average Grade', 'Average Grade': mean([student_data[field] for student_data in report_data for field in FIELDS if field != 'Average' and field != 'Average Grade' and field != 'Average Grade' and field != 'Average Grade' and field != 'Average Grade' and field != 'Average Grade' and field != 'Average Grade' and field != 'Average Grade' and field != 'Average Grade' and field != 'Average Grade' and field != 'Average Grade'])})\n    report_data.append({'Average': 'Average Grade', 'Average Grade': mean([student_data[field] for student_data in report_data for field in FIELDS if field != 'Average' and field != 'Average Grade' and field != 'Average Grade' and field != 'Average Grade' and field != 'Average Grade' and field != 'Average Grade' and field != 'Average Grade' and field != 'Average Grade' and field != 'Average Grade' and field != 'Average Grade' and field != 'Average Grade' and field != 'Average Grade'])})\n    report_data.append({'Average': 'Average Grade', 'Average Grade': mean([student_data[field] for student_data in report_data for field in FIELDS if field != 'Average' and field != 'Average Grade' and field != 'Average Grade' and field != 'Average Grade' and field != 'Average Grade' and field != 'Average Grade' and field != 'Average Grade' and field != 'Average Grade' and field != 'Average Grade' and field != 'Average Grade' and field != 'Average Grade' and field != 'Average Grade' and field != 'Average Grade'])})\n    report_data.append({'Average': 'Average Grade', 'Average Grade': mean([student_data[field] for student_data in report_data for field in FIELDS if field != 'Average' and field != 'Average Grade' and field != 'Average Grade' and field != 'Average Grade' and field != 'Average Grade' and"}
{"task_id": "BigCodeBench/309", "solution": "import numpy as np\nimport random\nfrom sklearn.preprocessing import MinMaxScaler\ndef task_func(list_of_lists, seed=42):\n    random.seed(seed)\n    scaler = MinMaxScaler()\n    for i in range(len(list_of_lists)):\n        if len(list_of_lists[i]) == 0:\n            list_of_lists[i] = [random.randint(0, 100) for _ in range(5)]\n        list_of_lists[i] = scaler.fit_transform(np.array(list_of_lists[i]).reshape(-1, 1)).flatten()\n    return list_of_lists", "raw_solution": "import numpy as np\nimport random\nfrom sklearn.preprocessing import MinMaxScaler\n\ndef task_func(list_of_lists, seed=42):\n    random.seed(seed)\n    scaler = MinMaxScaler()\n    for i in range(len(list_of_lists)):\n        if len(list_of_lists[i]) == 0:\n            list_of_lists[i] = [random.randint(0, 100) for _ in range(5)]\n        list_of_lists[i] = scaler.fit_transform(np.array(list_of_lists[i]).reshape(-1, 1)).flatten()\n    return list_of_lists\n```"}
{"task_id": "BigCodeBench/310", "solution": "import os\nimport csv\nimport random\nfrom statistics import mean\nCOLUMNS = ['Name', 'Age', 'Height', 'Weight']\nPEOPLE_COUNT = 100\ndef task_func(filename):\n    # Generate random data\n    names = [f\"Person {i}\" for i in range(1, PEOPLE_COUNT + 1)]\n    ages = [random.randint(18, 65) for _ in range(PEOPLE_COUNT)]\n    heights = [random.uniform(150, 200) for _ in range(PEOPLE_COUNT)]\n    weights = [random.uniform(50, 100) for _ in range(PEOPLE_COUNT)]\n    \n    # Calculate average values\n    avg_age = mean(ages)\n    avg_height = mean(heights)\n    avg_weight = mean(weights)\n    \n    # Write data to CSV file\n    with open(filename, 'w', newline='') as file:\n        writer = csv.DictWriter(file, fieldnames=COLUMNS)\n        writer.writeheader()\n        for i in range(PEOPLE_COUNT):\n            writer.writerow({\n                'Name': names[i],\n                'Age': ages[i],\n                'Height': heights[i],\n                'Weight': weights[i]\n            })\n    \n    # Append average values to CSV file\n    with open(filename, 'a', newline='') as file:\n        writer = csv.writer(file)\n        writer.writerow(['Average Age', avg_age])\n        writer.writerow(['Average Height', avg_height])\n        writer.writerow(['Average Weight', avg_weight])\n    \n    return os.path.abspath(filename)", "raw_solution": "import os\nimport csv\nimport random\nfrom statistics import mean\n# Constants\nCOLUMNS = ['Name', 'Age', 'Height', 'Weight']\nPEOPLE_COUNT = 100\n\ndef task_func(filename):\n    # Generate random data\n    names = [f\"Person {i}\" for i in range(1, PEOPLE_COUNT + 1)]\n    ages = [random.randint(18, 65) for _ in range(PEOPLE_COUNT)]\n    heights = [random.uniform(150, 200) for _ in range(PEOPLE_COUNT)]\n    weights = [random.uniform(50, 100) for _ in range(PEOPLE_COUNT)]\n    \n    # Calculate average values\n    avg_age = mean(ages)\n    avg_height = mean(heights)\n    avg_weight = mean(weights)\n    \n    # Write data to CSV file\n    with open(filename, 'w', newline='') as file:\n        writer = csv.DictWriter(file, fieldnames=COLUMNS)\n        writer.writeheader()\n        for i in range(PEOPLE_COUNT):\n            writer.writerow({\n                'Name': names[i],\n                'Age': ages[i],\n                'Height': heights[i],\n                'Weight': weights[i]\n            })\n    \n    # Append average values to CSV file\n    with open(filename, 'a', newline='') as file:\n        writer = csv.writer(file)\n        writer.writerow(['Average Age', avg_age])\n        writer.writerow(['Average Height', avg_height])\n        writer.writerow(['Average Weight', avg_weight])\n    \n    return os.path.abspath(filename)\n```"}
{"task_id": "BigCodeBench/311", "solution": "import numpy as np\nimport random\nfrom scipy import stats\ndef task_func(list_of_lists, size=5, seed=0):\n    random.seed(seed)\n    np.random.seed(seed)\n    if len(list_of_lists) == 0:\n        list_of_lists = [[random.randint(0, 100) for _ in range(size)] for _ in range(size)]\n    mean = np.mean(list_of_lists)\n    median = np.median(list_of_lists)\n    mode = stats.mode(list_of_lists)\n    return {'mean': mean, 'median': median, 'mode': mode}", "raw_solution": "import numpy as np\nimport random\nfrom scipy import stats\n\ndef task_func(list_of_lists, size=5, seed=0):\n    random.seed(seed)\n    np.random.seed(seed)\n    if len(list_of_lists) == 0:\n        list_of_lists = [[random.randint(0, 100) for _ in range(size)] for _ in range(size)]\n    mean = np.mean(list_of_lists)\n    median = np.median(list_of_lists)\n    mode = stats.mode(list_of_lists)\n    return {'mean': mean, 'median': median, 'mode': mode}\n```"}
{"task_id": "BigCodeBench/312", "solution": "import random\nimport matplotlib.pyplot as plt\nDISTRIBUTION_SIZE = 1000\ndef task_func(bins=30):\n    # Generate a Gaussian distribution\n    distribution = [random.gauss(0, 1) for _ in range(DISTRIBUTION_SIZE)]\n    \n    # Plot the histogram\n    fig, ax = plt.subplots()\n    ax.hist(distribution, bins=bins)\n    \n    return (distribution, ax)", "raw_solution": "import random\nimport matplotlib.pyplot as plt\n# Constants\nDISTRIBUTION_SIZE = 1000\n\ndef task_func(bins=30):\n    # Generate a Gaussian distribution\n    distribution = [random.gauss(0, 1) for _ in range(DISTRIBUTION_SIZE)]\n    \n    # Plot the histogram\n    fig, ax = plt.subplots()\n    ax.hist(distribution, bins=bins)\n    \n    return (distribution, ax)\n```"}
{"task_id": "BigCodeBench/313", "solution": "import re\nimport os\nimport shutil\nfrom datetime import datetime\ndef task_func(directory):\n    # Get all files in the directory\n    files = os.listdir(directory)\n    # Create a dictionary to store the organized files\n    organized_files = {}\n    # Loop through each file\n    for file in files:\n        # Check if the file is a regular file\n        if os.path.isfile(os.path.join(directory, file)):\n            # Get the first text that is not enclosed in square brackets\n            match = re.search(r'\\[(.*?)\\]', file)\n            if match:\n                # Create a subdirectory if it doesn't exist\n                if match.group(1) not in organized_files:\n                    organized_files[match.group(1)] = []\n                # Move the file to the subdirectory\n                shutil.move(os.path.join(directory, file), os.path.join(directory, match.group(1), file))\n    # Return the directory path with organized files and the dictionary of organized files\n    return (directory, organized_files)", "raw_solution": "import re\nimport os\nimport shutil\nfrom datetime import datetime\n\ndef task_func(directory):\n    # Get all files in the directory\n    files = os.listdir(directory)\n    # Create a dictionary to store the organized files\n    organized_files = {}\n    # Loop through each file\n    for file in files:\n        # Check if the file is a regular file\n        if os.path.isfile(os.path.join(directory, file)):\n            # Get the first text that is not enclosed in square brackets\n            match = re.search(r'\\[(.*?)\\]', file)\n            if match:\n                # Create a subdirectory if it doesn't exist\n                if match.group(1) not in organized_files:\n                    organized_files[match.group(1)] = []\n                # Move the file to the subdirectory\n                shutil.move(os.path.join(directory, file), os.path.join(directory, match.group(1), file))\n    # Return the directory path with organized files and the dictionary of organized files\n    return (directory, organized_files)\n```"}
{"task_id": "BigCodeBench/314", "solution": "import socket\nimport ssl\nimport http.client\ndef task_func(SERVER_NAME, SERVER_PORT, path):\n    try:\n        context = ssl.create_default_context()\n        conn = http.client.HTTPSConnection(SERVER_NAME, SERVER_PORT, context=context)\n        conn.request('GET', path)\n        response = conn.getresponse()\n        return response.read().decode('utf-8')\n    except ssl.SSLError as e:\n        raise e", "raw_solution": "import socket\nimport ssl\nimport http.client\ndef task_func(SERVER_NAME, SERVER_PORT, path):\n    try:\n        context = ssl.create_default_context()\n        conn = http.client.HTTPSConnection(SERVER_NAME, SERVER_PORT, context=context)\n        conn.request('GET', path)\n        response = conn.getresponse()\n        return response.read().decode('utf-8')\n    except ssl.SSLError as e:\n        raise e\n```"}
{"task_id": "BigCodeBench/315", "solution": "import os\nfrom sendgrid import SendGridAPIClient\nfrom sendgrid.helpers.mail import Mail\nfrom python_http_client.exceptions import HTTPError\ndef task_func(dir, api_key, recipient_email):\n    if not os.path.exists(dir):\n        raise FileNotFoundError(\"The specified directory does not exist.\")\n    try:\n        client = SendGridAPIClient(api_key)\n        with open(dir, 'r') as f:\n            content = f.read()\n        message = Mail(\n            from_email='your_email@example.com',\n            to_emails=recipient_email,\n            subject='Files in directory',\n            html_content=content\n        )\n        response = client.send(message)\n        if response.status_code in range(200, 299):\n            return True\n        else:\n            raise HTTPError(response.status_code, response.body)\n    except Exception as e:\n        raise Exception(e)", "raw_solution": "import os\nfrom sendgrid import SendGridAPIClient\nfrom sendgrid.helpers.mail import Mail\nfrom python_http_client.exceptions import HTTPError\n\ndef task_func(dir, api_key, recipient_email):\n    if not os.path.exists(dir):\n        raise FileNotFoundError(\"The specified directory does not exist.\")\n    try:\n        client = SendGridAPIClient(api_key)\n        with open(dir, 'r') as f:\n            content = f.read()\n        message = Mail(\n            from_email='your_email@example.com',\n            to_emails=recipient_email,\n            subject='Files in directory',\n            html_content=content\n        )\n        response = client.send(message)\n        if response.status_code in range(200, 299):\n            return True\n        else:\n            raise HTTPError(response.status_code, response.body)\n    except Exception as e:\n        raise Exception(e)\n```"}
{"task_id": "BigCodeBench/316", "solution": "import pandas as pd\nimport random\nCATEGORIES = ['A', 'B', 'C', 'D', 'E']\ndef task_func(value_range=(0, 100)):\n    # Generate random category distribution\n    category_distribution = [random.randint(value_range[0], value_range[1]) for _ in range(len(CATEGORIES))]\n    # Create DataFrame\n    df = pd.DataFrame({'Category': CATEGORIES, 'Count': category_distribution})\n    return df", "raw_solution": "import pandas as pd\nimport random\n# Constants\nCATEGORIES = ['A', 'B', 'C', 'D', 'E']\ndef task_func(value_range=(0, 100)):\n    # Generate random category distribution\n    category_distribution = [random.randint(value_range[0], value_range[1]) for _ in range(len(CATEGORIES))]\n    # Create DataFrame\n    df = pd.DataFrame({'Category': CATEGORIES, 'Count': category_distribution})\n    return df\n```"}
{"task_id": "BigCodeBench/317", "solution": "import numpy as np\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nimport re\ndef task_func(example_str):\n    # Extract all texts not enclosed in square brackets\n    texts = re.findall(r'\\[[^\\]]*\\]', example_str)\n    texts = [text[1:-1] for text in texts]\n    \n    # Create a TfidfVectorizer object\n    vectorizer = TfidfVectorizer()\n    \n    # Fit and transform the texts\n    X = vectorizer.fit_transform(texts)\n    \n    # Get the feature names\n    feature_names = vectorizer.get_feature_names_out()\n    \n    # Create a dictionary with words as keys and TF-IDF scores as values\n    tfidf_dict = {}\n    for i, text in enumerate(texts):\n        for word in text.split():\n            tfidf_dict[word] = X[i, feature_names.index(word)]\n    \n    return tfidf_dict", "raw_solution": "import numpy as np\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nimport re\n\ndef task_func(example_str):\n    # Extract all texts not enclosed in square brackets\n    texts = re.findall(r'\\[[^\\]]*\\]', example_str)\n    texts = [text[1:-1] for text in texts]\n    \n    # Create a TfidfVectorizer object\n    vectorizer = TfidfVectorizer()\n    \n    # Fit and transform the texts\n    X = vectorizer.fit_transform(texts)\n    \n    # Get the feature names\n    feature_names = vectorizer.get_feature_names_out()\n    \n    # Create a dictionary with words as keys and TF-IDF scores as values\n    tfidf_dict = {}\n    for i, text in enumerate(texts):\n        for word in text.split():\n            tfidf_dict[word] = X[i, feature_names.index(word)]\n    \n    return tfidf_dict\n```"}
{"task_id": "BigCodeBench/318", "solution": "import random\nimport math\nimport matplotlib.pyplot as plt\ndef task_func(points_count=1000, radius=1):\n    # Generate random points within a circle of a given radius\n    points = []\n    for _ in range(points_count):\n        while True:\n            x = random.uniform(-radius, radius)\n            y = random.uniform(-radius, radius)\n            if x**2 + y**2 <= radius**2:\n                points.append((x, y))\n                break\n    # Plot the points\n    fig, ax = plt.subplots()\n    ax.scatter([p[0] for p in points], [p[1] for p in points], s=1)\n    ax.set_aspect('equal')\n    return ax", "raw_solution": "import random\nimport math\nimport matplotlib.pyplot as plt\n\ndef task_func(points_count=1000, radius=1):\n    # Generate random points within a circle of a given radius\n    points = []\n    for _ in range(points_count):\n        while True:\n            x = random.uniform(-radius, radius)\n            y = random.uniform(-radius, radius)\n            if x**2 + y**2 <= radius**2:\n                points.append((x, y))\n                break\n    # Plot the points\n    fig, ax = plt.subplots()\n    ax.scatter([p[0] for p in points], [p[1] for p in points], s=1)\n    ax.set_aspect('equal')\n    return ax\n```"}
{"task_id": "BigCodeBench/319", "solution": "import re\nimport matplotlib.pyplot as plt\nfrom nltk.probability import FreqDist\ndef task_func(example_str, top_n=30):\n    # Extract all texts that are not enclosed in square brackets\n    text = re.sub(r'\\[[^\\]]*\\]', '', example_str)\n    \n    # Split the text into words\n    words = text.split()\n    \n    # Create a frequency distribution of the words\n    freq_dist = FreqDist(words)\n    \n    # Plot the frequency distribution\n    fig, ax = plt.subplots()\n    freq_dist.plot(10, cumulative=False)\n    ax.set_title('Frequency Distribution of Words')\n    ax.set_xlabel('Words')\n    ax.set_ylabel('Frequency')\n    \n    # Return the frequency distribution plot and the top_n most common words\n    return ax, dict(freq_dist.most_common(top_n))", "raw_solution": "import re\nimport matplotlib.pyplot as plt\nfrom nltk.probability import FreqDist\n\ndef task_func(example_str, top_n=30):\n    # Extract all texts that are not enclosed in square brackets\n    text = re.sub(r'\\[[^\\]]*\\]', '', example_str)\n    \n    # Split the text into words\n    words = text.split()\n    \n    # Create a frequency distribution of the words\n    freq_dist = FreqDist(words)\n    \n    # Plot the frequency distribution\n    fig, ax = plt.subplots()\n    freq_dist.plot(10, cumulative=False)\n    ax.set_title('Frequency Distribution of Words')\n    ax.set_xlabel('Words')\n    ax.set_ylabel('Frequency')\n    \n    # Return the frequency distribution plot and the top_n most common words\n    return ax, dict(freq_dist.most_common(top_n))\n```"}
{"task_id": "BigCodeBench/320", "solution": "import subprocess\nimport os\nimport random\ndef task_func(directory, file_list):\n    if not file_list:\n        return None\n    file = random.choice(file_list)\n    file_path = os.path.join(directory, file)\n    try:\n        result = subprocess.run([file_path], check=True)\n        return result.returncode\n    except subprocess.CalledProcessError as e:\n        return e.returncode", "raw_solution": "import subprocess\nimport os\nimport random\n\ndef task_func(directory, file_list):\n    if not file_list:\n        return None\n    file = random.choice(file_list)\n    file_path = os.path.join(directory, file)\n    try:\n        result = subprocess.run([file_path], check=True)\n        return result.returncode\n    except subprocess.CalledProcessError as e:\n        return e.returncode\n```"}
{"task_id": "BigCodeBench/321", "solution": "import pandas as pd\nimport re\nfrom scipy import stats\ndef task_func(text):\n    names = re.findall(r'\\b\\w+\\b', text)\n    name_freq = pd.Series(names).value_counts()\n    name_freq = name_freq.dropna()\n    name_freq = name_freq.sort_values(ascending=False)\n    name_freq = name_freq.reset_index(drop=True)\n    name_freq.columns = ['Name', 'Frequency']\n    name_freq = name_freq.set_index('Name')\n    name_freq = name_freq.rename_axis(None)\n    name_freq = name_freq.rename(columns={'Frequency': 'Count'})\n    name_freq = name_freq.reset_index(drop=True)\n    name_freq = name_freq.set_index('Name')\n    name_freq = name_freq.rename_axis(None)\n    name_freq = name_freq.rename(columns={'Frequency': 'Count'})\n    name_freq = name_freq.reset_index(drop=True)\n    name_freq = name_freq.set_index('Name')\n    name_freq = name_freq.rename_axis(None)\n    name_freq = name_freq.rename(columns={'Frequency': 'Count'})\n    name_freq = name_freq.reset_index(drop=True)\n    name_freq = name_freq.set_index('Name')\n    name_freq = name_freq.rename_axis(None)\n    name_freq = name_freq.rename(columns={'Frequency': 'Count'})\n    name_freq = name_freq.reset_index(drop=True)\n    name_freq = name_freq.set_index('Name')\n    name_freq = name_freq.rename_axis(None)\n    name_freq = name_freq.rename(columns={'Frequency': 'Count'})\n    name_freq = name_freq.reset_index(drop=True)\n    name_freq = name_freq.set_index('Name')\n    name_freq = name_freq.rename_axis(None)\n    name_freq = name_freq.rename(columns={'Frequency': 'Count'})\n    name_freq = name_freq.reset_index(drop=True)\n    name_freq = name_freq.set_index('Name')\n    name_freq = name_freq.rename_axis(None)\n    name_freq = name_freq.rename(columns={'Frequency': 'Count'})\n    name_freq = name_freq.reset_index(drop=True)\n    name_freq = name_freq.set_index('Name')\n    name_freq = name_freq.rename_axis(None)\n    name_freq = name_freq.rename(columns={'Frequency': 'Count'})\n    name_freq = name_freq.reset_index(drop=True)\n    name_freq = name_freq.set_index('Name')\n    name_freq = name_freq.rename_axis(None)\n    name_freq = name_freq.rename(columns={'Frequency': 'Count'})\n    name_freq = name_freq.reset_index(drop=True)\n    name_freq = name_freq.set_index('Name')\n    name_freq = name_freq.rename_axis(None)\n    name_freq = name_freq.rename(columns={'Frequency': 'Count'})\n    name_freq = name_freq.reset_index(drop=True)\n    name_freq = name_freq.set_index('Name')\n    name_freq = name_freq.rename_axis(None)\n    name_freq = name_freq.rename(columns={'Frequency': 'Count'})\n    name_freq = name_freq.reset_index(drop=True)\n    name_freq = name_freq.set_index('Name')\n    name_freq = name_freq.rename_axis(None)\n    name_freq = name_freq.rename(columns={'Frequency': 'Count'})\n    name_freq = name_freq.reset_index(drop=True)\n    name_freq = name_freq.set_index('Name')\n    name_freq = name_freq.rename_axis(None)\n    name_freq = name_freq.rename(columns={'Frequency': 'Count'})\n    name_freq = name_freq.reset_index(drop=True)\n    name_freq = name_freq.set_index('Name')\n    name_freq = name_freq.rename_axis(None)\n    name_freq = name_freq.rename(columns={'Frequency': 'Count'})\n    name_freq = name_freq.reset_index(drop=True)\n    name_freq = name_freq.set_index('Name')\n    name_freq = name_freq.rename_axis(None)\n    name_freq = name_freq.rename(columns={'Frequency': 'Count'})\n    name_freq = name_freq.reset_index(drop=True)\n    name_freq = name_freq.set_index('Name')\n    name_freq = name_freq.rename_axis(None)\n    name_freq = name_freq.rename(columns={'Frequency': 'Count'})\n    name_freq = name_freq.reset_index(drop=True)\n    name_freq = name_freq.set_index('Name')\n    name_freq = name_freq.rename_axis(None)\n    name_freq = name_freq.rename(columns={'Frequency': 'Count'})\n    name_freq = name_freq.reset_index(drop=True)\n    name_freq = name_freq.set_index('Name')\n    name_freq = name_freq.rename_axis(None)\n    name_freq = name_freq.rename(columns={'Frequency': 'Count'})\n    name_freq = name_freq.reset_index(drop=True)\n    name_freq = name_freq.set_index('Name')\n    name_freq = name_freq.rename_axis(None)\n    name_freq = name_freq.rename(columns={'Frequency': 'Count'})\n    name_freq = name_freq.reset_index(drop=True)\n    name_freq = name_freq.set_index('Name')\n    name_freq = name_freq.rename_axis(None)\n    name_freq = name_freq.rename(columns={'Frequency': 'Count'})\n    name_freq = name_freq.reset_index(drop=True)\n    name_freq = name_freq.set_index('Name')\n    name_freq = name_freq.rename_axis(None)\n    name_freq = name_freq.rename(columns={'Frequency': 'Count'})\n    name_freq = name_freq.reset_index(drop=True)\n    name_freq = name_freq.set_index('Name')\n    name_freq = name_freq.rename_axis(None)\n    name_freq = name_freq.rename(columns={'Frequency': 'Count'})\n    name_freq = name_freq.reset_index(drop=True)\n    name_freq = name_freq.set_index('Name')\n    name_freq = name_freq.rename_axis(None)\n    name_freq = name_freq.rename(columns={'Frequency': 'Count'})\n    name_freq = name_freq.reset_index(drop=True)\n    name_freq = name_freq.set_index('Name')\n    name_freq = name_freq.rename_axis(None)\n    name_freq = name_freq.rename(columns={'Frequency': 'Count'})\n    name_freq = name_freq.reset_index(drop=True)\n    name_freq = name_freq.set_index('Name')\n    name_freq = name_freq.rename_axis(None)\n    name_freq = name_freq.rename(columns={'Frequency': 'Count'})\n    name_freq = name_freq.reset_index(drop=True)\n    name_freq = name_freq.set_index('Name')\n    name_freq = name_freq.rename_axis(None)\n    name_freq = name_freq.rename(columns={'Frequency': 'Count'})\n    name_freq = name_freq.reset_index", "raw_solution": "import pandas as pd\nimport re\nfrom scipy import stats\n\ndef task_func(text):\n    names = re.findall(r'\\b\\w+\\b', text)\n    name_freq = pd.Series(names).value_counts()\n    name_freq = name_freq.dropna()\n    name_freq = name_freq.sort_values(ascending=False)\n    name_freq = name_freq.reset_index(drop=True)\n    name_freq.columns = ['Name', 'Frequency']\n    name_freq = name_freq.set_index('Name')\n    name_freq = name_freq.rename_axis(None)\n    name_freq = name_freq.rename(columns={'Frequency': 'Count'})\n    name_freq = name_freq.reset_index(drop=True)\n    name_freq = name_freq.set_index('Name')\n    name_freq = name_freq.rename_axis(None)\n    name_freq = name_freq.rename(columns={'Frequency': 'Count'})\n    name_freq = name_freq.reset_index(drop=True)\n    name_freq = name_freq.set_index('Name')\n    name_freq = name_freq.rename_axis(None)\n    name_freq = name_freq.rename(columns={'Frequency': 'Count'})\n    name_freq = name_freq.reset_index(drop=True)\n    name_freq = name_freq.set_index('Name')\n    name_freq = name_freq.rename_axis(None)\n    name_freq = name_freq.rename(columns={'Frequency': 'Count'})\n    name_freq = name_freq.reset_index(drop=True)\n    name_freq = name_freq.set_index('Name')\n    name_freq = name_freq.rename_axis(None)\n    name_freq = name_freq.rename(columns={'Frequency': 'Count'})\n    name_freq = name_freq.reset_index(drop=True)\n    name_freq = name_freq.set_index('Name')\n    name_freq = name_freq.rename_axis(None)\n    name_freq = name_freq.rename(columns={'Frequency': 'Count'})\n    name_freq = name_freq.reset_index(drop=True)\n    name_freq = name_freq.set_index('Name')\n    name_freq = name_freq.rename_axis(None)\n    name_freq = name_freq.rename(columns={'Frequency': 'Count'})\n    name_freq = name_freq.reset_index(drop=True)\n    name_freq = name_freq.set_index('Name')\n    name_freq = name_freq.rename_axis(None)\n    name_freq = name_freq.rename(columns={'Frequency': 'Count'})\n    name_freq = name_freq.reset_index(drop=True)\n    name_freq = name_freq.set_index('Name')\n    name_freq = name_freq.rename_axis(None)\n    name_freq = name_freq.rename(columns={'Frequency': 'Count'})\n    name_freq = name_freq.reset_index(drop=True)\n    name_freq = name_freq.set_index('Name')\n    name_freq = name_freq.rename_axis(None)\n    name_freq = name_freq.rename(columns={'Frequency': 'Count'})\n    name_freq = name_freq.reset_index(drop=True)\n    name_freq = name_freq.set_index('Name')\n    name_freq = name_freq.rename_axis(None)\n    name_freq = name_freq.rename(columns={'Frequency': 'Count'})\n    name_freq = name_freq.reset_index(drop=True)\n    name_freq = name_freq.set_index('Name')\n    name_freq = name_freq.rename_axis(None)\n    name_freq = name_freq.rename(columns={'Frequency': 'Count'})\n    name_freq = name_freq.reset_index(drop=True)\n    name_freq = name_freq.set_index('Name')\n    name_freq = name_freq.rename_axis(None)\n    name_freq = name_freq.rename(columns={'Frequency': 'Count'})\n    name_freq = name_freq.reset_index(drop=True)\n    name_freq = name_freq.set_index('Name')\n    name_freq = name_freq.rename_axis(None)\n    name_freq = name_freq.rename(columns={'Frequency': 'Count'})\n    name_freq = name_freq.reset_index(drop=True)\n    name_freq = name_freq.set_index('Name')\n    name_freq = name_freq.rename_axis(None)\n    name_freq = name_freq.rename(columns={'Frequency': 'Count'})\n    name_freq = name_freq.reset_index(drop=True)\n    name_freq = name_freq.set_index('Name')\n    name_freq = name_freq.rename_axis(None)\n    name_freq = name_freq.rename(columns={'Frequency': 'Count'})\n    name_freq = name_freq.reset_index(drop=True)\n    name_freq = name_freq.set_index('Name')\n    name_freq = name_freq.rename_axis(None)\n    name_freq = name_freq.rename(columns={'Frequency': 'Count'})\n    name_freq = name_freq.reset_index(drop=True)\n    name_freq = name_freq.set_index('Name')\n    name_freq = name_freq.rename_axis(None)\n    name_freq = name_freq.rename(columns={'Frequency': 'Count'})\n    name_freq = name_freq.reset_index(drop=True)\n    name_freq = name_freq.set_index('Name')\n    name_freq = name_freq.rename_axis(None)\n    name_freq = name_freq.rename(columns={'Frequency': 'Count'})\n    name_freq = name_freq.reset_index(drop=True)\n    name_freq = name_freq.set_index('Name')\n    name_freq = name_freq.rename_axis(None)\n    name_freq = name_freq.rename(columns={'Frequency': 'Count'})\n    name_freq = name_freq.reset_index(drop=True)\n    name_freq = name_freq.set_index('Name')\n    name_freq = name_freq.rename_axis(None)\n    name_freq = name_freq.rename(columns={'Frequency': 'Count'})\n    name_freq = name_freq.reset_index(drop=True)\n    name_freq = name_freq.set_index('Name')\n    name_freq = name_freq.rename_axis(None)\n    name_freq = name_freq.rename(columns={'Frequency': 'Count'})\n    name_freq = name_freq.reset_index(drop=True)\n    name_freq = name_freq.set_index('Name')\n    name_freq = name_freq.rename_axis(None)\n    name_freq = name_freq.rename(columns={'Frequency': 'Count'})\n    name_freq = name_freq.reset_index(drop=True)\n    name_freq = name_freq.set_index('Name')\n    name_freq = name_freq.rename_axis(None)\n    name_freq = name_freq.rename(columns={'Frequency': 'Count'})\n    name_freq = name_freq.reset_index(drop=True)\n    name_freq = name_freq.set_index('Name')\n    name_freq = name_freq.rename_axis(None)\n    name_freq = name_freq.rename(columns={'Frequency': 'Count'})\n    name_freq = name_freq.reset_index(drop=True)\n    name_freq = name_freq.set_index('Name')\n    name_freq = name_freq.rename_axis(None)\n    name_freq = name_freq.rename(columns={'Frequency': 'Count'})\n    name_freq = name_freq.reset_index"}
{"task_id": "BigCodeBench/322", "solution": "import subprocess\nimport os\nimport shutil\nimport sys\nDIRECTORY = 'c:\\Program Files\\VMware\\VMware Server'\nBACKUP_DIRECTORY = 'c:\\Program Files\\VMware\\VMware Server\\Backup'\ndef task_func(filename):\n    # Check if the file exists in the directory\n    if not os.path.exists(os.path.join(DIRECTORY, filename)):\n        print(f\"File {filename} does not exist in the directory {DIRECTORY}\")\n        return -1\n    # Create the backup directory if it does not exist\n    if not os.path.exists(BACKUP_DIRECTORY):\n        os.makedirs(BACKUP_DIRECTORY)\n    # Copy the file to the backup directory\n    shutil.copy(os.path.join(DIRECTORY, filename), os.path.join(BACKUP_DIRECTORY, filename))\n    # Execute the backup process as a subprocess\n    try:\n        subprocess.run(['cmd', '/c', f'copy {os.path.join(BACKUP_DIRECTORY, filename)} {os.path.join(DIRECTORY, filename)}'], check=True)\n        print(f\"Backup of {filename} completed successfully\")\n        return 0\n    except subprocess.CalledProcessError as e:\n        print(f\"Backup of {filename} failed with error code {e.returncode}\")\n        return -1", "raw_solution": "import subprocess\nimport os\nimport shutil\nimport sys\n# Constants\nDIRECTORY = 'c:\\Program Files\\VMware\\VMware Server'\nBACKUP_DIRECTORY = 'c:\\Program Files\\VMware\\VMware Server\\Backup'\ndef task_func(filename):\n    # Check if the file exists in the directory\n    if not os.path.exists(os.path.join(DIRECTORY, filename)):\n        print(f\"File {filename} does not exist in the directory {DIRECTORY}\")\n        return -1\n    # Create the backup directory if it does not exist\n    if not os.path.exists(BACKUP_DIRECTORY):\n        os.makedirs(BACKUP_DIRECTORY)\n    # Copy the file to the backup directory\n    shutil.copy(os.path.join(DIRECTORY, filename), os.path.join(BACKUP_DIRECTORY, filename))\n    # Execute the backup process as a subprocess\n    try:\n        subprocess.run(['cmd', '/c', f'copy {os.path.join(BACKUP_DIRECTORY, filename)} {os.path.join(DIRECTORY, filename)}'], check=True)\n        print(f\"Backup of {filename} completed successfully\")\n        return 0\n    except subprocess.CalledProcessError as e:\n        print(f\"Backup of {filename} failed with error code {e.returncode}\")\n        return -1\n```"}
{"task_id": "BigCodeBench/323", "solution": "import re\nimport numpy as np\nfrom collections import Counter\nfrom sklearn.mixture import GaussianMixture\ndef task_func(text, num_gaussians=1, seed=42):\n    if num_gaussians <= 0:\n        raise ValueError(\"num_gaussians must be greater than 0\")\n    if num_gaussians > len(set(re.findall(r'\\w+', text))):\n        raise ValueError(\"num_gaussians must be less than or equal to the number of unique words\")\n    words = re.findall(r'\\w+', text)\n    word_counts = Counter(words)\n    means, covariances = [], []\n    for word, count in word_counts.items():\n        means.append(word)\n        covariances.append(np.eye(1) * count)\n    gmm = GaussianMixture(n_components=num_gaussians, random_state=seed)\n    gmm.fit(np.array(means).reshape(-1, 1), np.array(covariances))\n    means = gmm.means_.flatten()\n    covariances = gmm.covariances_.flatten()\n    return {'means': means, 'covariances': covariances}", "raw_solution": "import re\nimport numpy as np\nfrom collections import Counter\nfrom sklearn.mixture import GaussianMixture\n\ndef task_func(text, num_gaussians=1, seed=42):\n    if num_gaussians <= 0:\n        raise ValueError(\"num_gaussians must be greater than 0\")\n    if num_gaussians > len(set(re.findall(r'\\w+', text))):\n        raise ValueError(\"num_gaussians must be less than or equal to the number of unique words\")\n    words = re.findall(r'\\w+', text)\n    word_counts = Counter(words)\n    means, covariances = [], []\n    for word, count in word_counts.items():\n        means.append(word)\n        covariances.append(np.eye(1) * count)\n    gmm = GaussianMixture(n_components=num_gaussians, random_state=seed)\n    gmm.fit(np.array(means).reshape(-1, 1), np.array(covariances))\n    means = gmm.means_.flatten()\n    covariances = gmm.covariances_.flatten()\n    return {'means': means, 'covariances': covariances}\n```"}
{"task_id": "BigCodeBench/324", "solution": "import subprocess\nimport time\nimport threading\ndef task_func(file_list):\n    exit_codes = []\n    for file in file_list:\n        process = subprocess.Popen(['python', file], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n        exit_code = process.wait()\n        exit_codes.append(exit_code)\n    return exit_codes", "raw_solution": "import subprocess\nimport time\nimport threading\n\ndef task_func(file_list):\n    exit_codes = []\n    for file in file_list:\n        process = subprocess.Popen(['python', file], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n        exit_code = process.wait()\n        exit_codes.append(exit_code)\n    return exit_codes\n```"}
{"task_id": "BigCodeBench/325", "solution": "import re\nimport os\nfrom pathlib import Path\nimport glob\ndef task_func(directory_path: str, regex_pattern: str = r'\\\\(.+?\\\\)|\\\\w') -> dict:\n    matches = {}\n    for file_path in glob.glob(os.path.join(directory_path, '**/*.txt'), recursive=True):\n        with open(file_path, 'r') as file:\n            text = file.read()\n            matches[Path(file_path).name] = re.findall(regex_pattern, text)\n    return matches", "raw_solution": "import re\nimport os\nfrom pathlib import Path\nimport glob\ndef task_func(directory_path: str, regex_pattern: str = r'\\\\(.+?\\\\)|\\\\w') -> dict:\n    matches = {}\n    for file_path in glob.glob(os.path.join(directory_path, '**/*.txt'), recursive=True):\n        with open(file_path, 'r') as file:\n            text = file.read()\n            matches[Path(file_path).name] = re.findall(regex_pattern, text)\n    return matches\n```"}
{"task_id": "BigCodeBench/326", "solution": "import subprocess\nimport os\nimport sys\nimport glob\ndef task_func(directory_path):\n    file_list = glob.glob(os.path.join(directory_path, '*.bat'))\n    result = []\n    for file_path in file_list:\n        try:\n            result.append((file_path, subprocess.run(file_path, check=True).returncode))\n        except subprocess.CalledProcessError:\n            result.append((file_path, None))\n    return result", "raw_solution": "import subprocess\nimport os\nimport sys\nimport glob\n\ndef task_func(directory_path):\n    file_list = glob.glob(os.path.join(directory_path, '*.bat'))\n    result = []\n    for file_path in file_list:\n        try:\n            result.append((file_path, subprocess.run(file_path, check=True).returncode))\n        except subprocess.CalledProcessError:\n            result.append((file_path, None))\n    return result\n```"}
{"task_id": "BigCodeBench/327", "solution": "import csv\nimport re\nfrom collections import Counter\ndef task_func(file_path, regex_pattern=r'\\(.+?\\)|\\w+|[\\W_]+'):\n    with open(file_path, newline='') as file:\n        reader = csv.reader(file)\n        matches = []\n        for row in reader:\n            for match in re.finditer(regex_pattern, ''.join(row)):\n                matches.append(match.group())\n    return dict(Counter(matches))", "raw_solution": "import csv\nimport re\nfrom collections import Counter\n\ndef task_func(file_path, regex_pattern=r'\\(.+?\\)|\\w+|[\\W_]+'):\n    with open(file_path, newline='') as file:\n        reader = csv.reader(file)\n        matches = []\n        for row in reader:\n            for match in re.finditer(regex_pattern, ''.join(row)):\n                matches.append(match.group())\n    return dict(Counter(matches))\n```"}
{"task_id": "BigCodeBench/328", "solution": "import collections\nimport random\nfrom queue import PriorityQueue\ndef task_func(number_teams=5):\n    teams = collections.OrderedDict()\n    for i in range(1, number_teams + 1):\n        teams[f\"Team {i}\"] = random.randint(0, 100)\n    sorted_teams = collections.OrderedDict(sorted(teams.items(), key=lambda x: x[1], reverse=True))\n    return sorted_teams", "raw_solution": "import collections\nimport random\nfrom queue import PriorityQueue\ndef task_func(number_teams=5):\n    teams = collections.OrderedDict()\n    for i in range(1, number_teams + 1):\n        teams[f\"Team {i}\"] = random.randint(0, 100)\n    sorted_teams = collections.OrderedDict(sorted(teams.items(), key=lambda x: x[1], reverse=True))\n    return sorted_teams\n```"}
{"task_id": "BigCodeBench/329", "solution": "import re\nimport json\nimport os\ndef task_func(file_path: str, regex_pattern=r'\\(.+?\\)|\\w') -> dict:\n    with open(file_path, 'r') as f:\n        data = json.load(f)\n    matches = []\n    for key, value in data.items():\n        if isinstance(value, str):\n            matches.extend(re.findall(regex_pattern, value))\n    return {file_path: matches}", "raw_solution": "import re\nimport json\nimport os\ndef task_func(file_path: str, regex_pattern=r'\\(.+?\\)|\\w') -> dict:\n    with open(file_path, 'r') as f:\n        data = json.load(f)\n    matches = []\n    for key, value in data.items():\n        if isinstance(value, str):\n            matches.extend(re.findall(regex_pattern, value))\n    return {file_path: matches}\n```"}
{"task_id": "BigCodeBench/330", "solution": "import heapq\nimport random\ndef task_func(list_length:5, k:int):\n    # Generate a random list of integers\n    random_list = [random.randint(1, 100) for _ in range(list_length)]\n    # Use heapq to find the k largest numbers\n    k_largest = heapq.nlargest(k, random_list)\n    # Return the list of integers and the k largest numbers\n    return random_list, k_largest", "raw_solution": "import heapq\nimport random\n\ndef task_func(list_length:5, k:int):\n    # Generate a random list of integers\n    random_list = [random.randint(1, 100) for _ in range(list_length)]\n    # Use heapq to find the k largest numbers\n    k_largest = heapq.nlargest(k, random_list)\n    # Return the list of integers and the k largest numbers\n    return random_list, k_largest\n```"}
{"task_id": "BigCodeBench/331", "solution": "import bisect\nimport random\ndef task_func(num, list_length = 5, min_value = 0, max_value = 0):\n    # Generate a random list of integers\n    random_list = [random.randint(min_value, max_value) for _ in range(list_length)]\n    # Insert the number into the list\n    bisect.insort(random_list, num)\n    # Return the new sorted list\n    return (random_list, random_list + [num])", "raw_solution": "import bisect\nimport random\n\ndef task_func(num, list_length = 5, min_value = 0, max_value = 0):\n    # Generate a random list of integers\n    random_list = [random.randint(min_value, max_value) for _ in range(list_length)]\n    # Insert the number into the list\n    bisect.insort(random_list, num)\n    # Return the new sorted list\n    return (random_list, random_list + [num])\n```"}
{"task_id": "BigCodeBench/332", "solution": "import re\nfrom collections import Counter\nfrom nltk.corpus import stopwords\ndef task_func(text: str) -> dict:\n    # Remove punctuation and convert to lowercase\n    text = re.sub(r'[^\\w\\s]', '', text).lower()\n    # Split text into words\n    words = text.split()\n    # Remove stop words\n    stop_words = set(stopwords.words('english'))\n    words = [word for word in words if word not in stop_words]\n    # Count the number of non-stop words\n    word_counts = Counter(words)\n    return word_counts", "raw_solution": "import re\nfrom collections import Counter\nfrom nltk.corpus import stopwords\n\ndef task_func(text: str) -> dict:\n    # Remove punctuation and convert to lowercase\n    text = re.sub(r'[^\\w\\s]', '', text).lower()\n    # Split text into words\n    words = text.split()\n    # Remove stop words\n    stop_words = set(stopwords.words('english'))\n    words = [word for word in words if word not in stop_words]\n    # Count the number of non-stop words\n    word_counts = Counter(words)\n    return word_counts\n```"}
{"task_id": "BigCodeBench/333", "solution": "import heapq\nimport random\ndef task_func(k, list_length = 5, min_value = 0, max_value = 100):\n    # Generate a list of random integers\n    random_list = [random.randint(min_value, max_value) for _ in range(list_length)]\n    \n    # Use heapq to find the k smallest numbers\n    k_smallest = heapq.nsmallest(k, random_list)\n    \n    # Return the list of random integers and the k smallest numbers\n    return random_list, k_smallest", "raw_solution": "import heapq\nimport random\n\ndef task_func(k, list_length = 5, min_value = 0, max_value = 100):\n    # Generate a list of random integers\n    random_list = [random.randint(min_value, max_value) for _ in range(list_length)]\n    \n    # Use heapq to find the k smallest numbers\n    k_smallest = heapq.nsmallest(k, random_list)\n    \n    # Return the list of random integers and the k smallest numbers\n    return random_list, k_smallest\n```"}
{"task_id": "BigCodeBench/334", "solution": "from nltk.tokenize import word_tokenize\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nimport pandas as pd\ndef task_func(documents):\n    # Tokenize the documents\n    tokenized_docs = [word_tokenize(doc) for doc in documents]\n    \n    # Create a TfidfVectorizer object\n    vectorizer = TfidfVectorizer()\n    \n    # Fit and transform the documents\n    tfidf_matrix = vectorizer.fit_transform(tokenized_docs)\n    \n    # Get the vocabulary\n    vocab = vectorizer.get_feature_names_out()\n    \n    # Create a DataFrame with words as columns and documents as rows, containing the TF-IDF scores\n    df = pd.DataFrame(tfidf_matrix.toarray(), columns=vocab, index=documents)\n    \n    return df", "raw_solution": "from nltk.tokenize import word_tokenize\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nimport pandas as pd\n\ndef task_func(documents):\n    # Tokenize the documents\n    tokenized_docs = [word_tokenize(doc) for doc in documents]\n    \n    # Create a TfidfVectorizer object\n    vectorizer = TfidfVectorizer()\n    \n    # Fit and transform the documents\n    tfidf_matrix = vectorizer.fit_transform(tokenized_docs)\n    \n    # Get the vocabulary\n    vocab = vectorizer.get_feature_names_out()\n    \n    # Create a DataFrame with words as columns and documents as rows, containing the TF-IDF scores\n    df = pd.DataFrame(tfidf_matrix.toarray(), columns=vocab, index=documents)\n    \n    return df\n```"}
{"task_id": "BigCodeBench/335", "solution": "import collections\nfrom queue import PriorityQueue\nimport random\nLETTERS = ['a', 'b', 'c', 'd', 'e']\ndef task_func(string_length=100):\n    # Generate a random string of the given length\n    random_string = ''.join(random.choice(LETTERS) for _ in range(string_length))\n    # Count the frequency of each letter\n    letter_counts = collections.Counter(random_string)\n    # Return the ordered dictionary sorted by frequency in descending order\n    return collections.OrderedDict(sorted(letter_counts.items(), key=lambda x: x[1], reverse=True))", "raw_solution": "import collections\nfrom queue import PriorityQueue\nimport random\n# Constants\nLETTERS = ['a', 'b', 'c', 'd', 'e']\ndef task_func(string_length=100):\n    # Generate a random string of the given length\n    random_string = ''.join(random.choice(LETTERS) for _ in range(string_length))\n    # Count the frequency of each letter\n    letter_counts = collections.Counter(random_string)\n    # Return the ordered dictionary sorted by frequency in descending order\n    return collections.OrderedDict(sorted(letter_counts.items(), key=lambda x: x[1], reverse=True))\n```"}
{"task_id": "BigCodeBench/336", "solution": "import re\nimport os\nimport glob\nfrom pathlib import Path\ndef task_func(pattern, directory, extensions):\n    # Initialize an empty list to store the file paths\n    file_paths = []\n    # Get the absolute path of the directory\n    directory = Path(directory).resolve()\n    # Loop through all files in the directory\n    for file_path in glob.glob(os.path.join(directory, '**/*'), recursive=True):\n        # Check if the file extension is in the list of extensions\n        if Path(file_path).suffix in extensions:\n            # Open the file and read its contents\n            with open(file_path, 'r', encoding='utf-8') as f:\n                content = f.read()\n            # Check if the pattern is found in the content\n            if re.search(pattern, content, re.IGNORECASE):\n                # Add the file path to the list\n                file_paths.append(file_path)\n    # Return the list of file paths\n    return file_paths", "raw_solution": "import re\nimport os\nimport glob\nfrom pathlib import Path\n\ndef task_func(pattern, directory, extensions):\n    # Initialize an empty list to store the file paths\n    file_paths = []\n    # Get the absolute path of the directory\n    directory = Path(directory).resolve()\n    # Loop through all files in the directory\n    for file_path in glob.glob(os.path.join(directory, '**/*'), recursive=True):\n        # Check if the file extension is in the list of extensions\n        if Path(file_path).suffix in extensions:\n            # Open the file and read its contents\n            with open(file_path, 'r', encoding='utf-8') as f:\n                content = f.read()\n            # Check if the pattern is found in the content\n            if re.search(pattern, content, re.IGNORECASE):\n                # Add the file path to the list\n                file_paths.append(file_path)\n    # Return the list of file paths\n    return file_paths\n```"}
{"task_id": "BigCodeBench/337", "solution": "import numpy as np\nimport matplotlib.pyplot as plt\nCOLORS = ['r', 'g', 'b']\ndef task_func(df, group_col, value_col):\n    # Check if the 'Value' has non-numeric values\n    if not np.issubdtype(df[value_col].dtype, np.number):\n        raise TypeError(\"This function will raise TypeError if the 'Value' has non-numeric values.\")\n    # Create a bar chart of data in multiple groups with error bars\n    ax = df.groupby(group_col)[value_col].plot(kind='bar', yerr=df.groupby(group_col)[value_col].std(), color=COLORS)\n    # Set the plot title\n    ax.set_title(\"Bar chart of {value_col} by {group_col}\".format(value_col=value_col, group_col=group_col))\n    # Set the xlabel and ylabel\n    ax.set_xlabel(group_col)\n    ax.set_ylabel(value_col)\n    # Return the axes object\n    return ax", "raw_solution": "import numpy as np\nimport matplotlib.pyplot as plt\n# Constants\nCOLORS = ['r', 'g', 'b']\ndef task_func(df, group_col, value_col):\n    # Check if the 'Value' has non-numeric values\n    if not np.issubdtype(df[value_col].dtype, np.number):\n        raise TypeError(\"This function will raise TypeError if the 'Value' has non-numeric values.\")\n    # Create a bar chart of data in multiple groups with error bars\n    ax = df.groupby(group_col)[value_col].plot(kind='bar', yerr=df.groupby(group_col)[value_col].std(), color=COLORS)\n    # Set the plot title\n    ax.set_title(\"Bar chart of {value_col} by {group_col}\".format(value_col=value_col, group_col=group_col))\n    # Set the xlabel and ylabel\n    ax.set_xlabel(group_col)\n    ax.set_ylabel(value_col)\n    # Return the axes object\n    return ax\n```"}
{"task_id": "BigCodeBench/338", "solution": "import random\nimport string\nfrom matplotlib import pyplot as plt\ndef task_func(elements, seed=100):\n    random.seed(seed)\n    formatted_elements = []\n    for element in elements:\n        formatted_element = \"% {0}%\" % ''.join(random.choices(string.ascii_letters + string.digits, k=5))\n        formatted_elements.append(formatted_element)\n    plt.hist([char for element in formatted_elements for char in element], bins=26)\n    char_count = {}\n    for element in formatted_elements:\n        for char in element:\n            if char in char_count:\n                char_count[char] += 1\n            else:\n                char_count[char] = 1\n    return formatted_elements, plt.gca(), char_count", "raw_solution": "import random\nimport string\nfrom matplotlib import pyplot as plt\n\ndef task_func(elements, seed=100):\n    random.seed(seed)\n    formatted_elements = []\n    for element in elements:\n        formatted_element = \"% {0}%\" % ''.join(random.choices(string.ascii_letters + string.digits, k=5))\n        formatted_elements.append(formatted_element)\n    plt.hist([char for element in formatted_elements for char in element], bins=26)\n    char_count = {}\n    for element in formatted_elements:\n        for char in element:\n            if char in char_count:\n                char_count[char] += 1\n            else:\n                char_count[char] = 1\n    return formatted_elements, plt.gca(), char_count\n```"}
{"task_id": "BigCodeBench/339", "solution": "import json\nimport urllib.parse\nimport hmac\nimport hashlib\ndef task_func(req_data, secret_key):\n    if not isinstance(req_data, dict):\n        raise TypeError('If req_data is not a dictionary.')\n    req_data_str = json.dumps(req_data, sort_keys=True)\n    signature = hmac.new(secret_key.encode('utf-8'), req_data_str.encode('utf-8'), hashlib.sha256).hexdigest()\n    return urllib.parse.quote(signature.replace(' ', '+'))", "raw_solution": "import json\nimport urllib.parse\nimport hmac\nimport hashlib\n\ndef task_func(req_data, secret_key):\n    if not isinstance(req_data, dict):\n        raise TypeError('If req_data is not a dictionary.')\n    req_data_str = json.dumps(req_data, sort_keys=True)\n    signature = hmac.new(secret_key.encode('utf-8'), req_data_str.encode('utf-8'), hashlib.sha256).hexdigest()\n    return urllib.parse.quote(signature.replace(' ', '+'))\n```"}
{"task_id": "BigCodeBench/340", "solution": "import json\nimport hashlib\nimport blake3\ndef task_func(req_data):\n    # Convert request data to JSON string\n    req_data_json = json.dumps(req_data)\n    \n    # Hash the request data with BLAKE3\n    blake3_hash = blake3.blake3(req_data_json.encode()).digest()\n    \n    # Convert the BLAKE3 hash to hexadecimal representation\n    blake3_hex = blake3_hash.hex()\n    \n    # Generate an MD5 hash of the BLAKE3 hash for demonstration purposes\n    md5_hash = hashlib.md5(blake3_hex.encode()).hexdigest()\n    \n    return (blake3_hex, md5_hash)", "raw_solution": "import json\nimport hashlib\nimport blake3\n\ndef task_func(req_data):\n    # Convert request data to JSON string\n    req_data_json = json.dumps(req_data)\n    \n    # Hash the request data with BLAKE3\n    blake3_hash = blake3.blake3(req_data_json.encode()).digest()\n    \n    # Convert the BLAKE3 hash to hexadecimal representation\n    blake3_hex = blake3_hash.hex()\n    \n    # Generate an MD5 hash of the BLAKE3 hash for demonstration purposes\n    md5_hash = hashlib.md5(blake3_hex.encode()).hexdigest()\n    \n    return (blake3_hex, md5_hash)\n```"}
{"task_id": "BigCodeBench/341", "solution": "import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\ndef task_func(df, col):\n    if not isinstance(df, pd.DataFrame):\n        raise ValueError(\"The input df must be DataFrame\")\n    if df.empty:\n        raise ValueError(\"The input df must not be empty\")\n    if col not in df.columns:\n        raise ValueError(\"The input df must contain the specified column\")\n    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n    sns.histplot(df[col], kde=True, ax=ax1)\n    sns.boxplot(df[col], ax=ax2)\n    return fig", "raw_solution": "import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\ndef task_func(df, col):\n    if not isinstance(df, pd.DataFrame):\n        raise ValueError(\"The input df must be DataFrame\")\n    if df.empty:\n        raise ValueError(\"The input df must not be empty\")\n    if col not in df.columns:\n        raise ValueError(\"The input df must contain the specified column\")\n    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n    sns.histplot(df[col], kde=True, ax=ax1)\n    sns.boxplot(df[col], ax=ax2)\n    return fig\n```"}
{"task_id": "BigCodeBench/342", "solution": "import string\nimport random\nimport re\ndef task_func(elements, pattern, seed=100):\n    random.seed(seed)\n    formatted_elements = []\n    for element in elements:\n        formatted_element = \"\"\n        for char in element:\n            formatted_element += random.choice(string.ascii_letters)\n        formatted_elements.append(f\"%{formatted_element}%\")\n    return formatted_elements, re.search(pattern, \"\".join(formatted_elements)) is not None", "raw_solution": "import string\nimport random\nimport re\ndef task_func(elements, pattern, seed=100):\n    random.seed(seed)\n    formatted_elements = []\n    for element in elements:\n        formatted_element = \"\"\n        for char in element:\n            formatted_element += random.choice(string.ascii_letters)\n        formatted_elements.append(f\"%{formatted_element}%\")\n    return formatted_elements, re.search(pattern, \"\".join(formatted_elements)) is not None\n```"}
{"task_id": "BigCodeBench/343", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nCOLORS = ['r', 'g', 'b', 'y', 'm']\ndef task_func(df, col, title=None):\n    if not isinstance(df, pd.DataFrame):\n        raise ValueError(\"The input df must be DataFrame\")\n    if df.empty:\n        raise ValueError(\"The input df must not be empty\")\n    if col not in df.columns:\n        raise ValueError(\"The input df must contain the specified column\")\n    # Count the number of unique values in the column\n    unique_values = df[col].nunique()\n    # Create a pie chart\n    fig, ax = plt.subplots()\n    ax.pie(unique_values, labels=unique_values.index, colors=COLORS, autopct='%1.1f%%')\n    if title:\n        ax.set_title(title)\n    return ax", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\n# Constants for pie chart colors\nCOLORS = ['r', 'g', 'b', 'y', 'm']\ndef task_func(df, col, title=None):\n    if not isinstance(df, pd.DataFrame):\n        raise ValueError(\"The input df must be DataFrame\")\n    if df.empty:\n        raise ValueError(\"The input df must not be empty\")\n    if col not in df.columns:\n        raise ValueError(\"The input df must contain the specified column\")\n    # Count the number of unique values in the column\n    unique_values = df[col].nunique()\n    # Create a pie chart\n    fig, ax = plt.subplots()\n    ax.pie(unique_values, labels=unique_values.index, colors=COLORS, autopct='%1.1f%%')\n    if title:\n        ax.set_title(title)\n    return ax\n```"}
{"task_id": "BigCodeBench/344", "solution": "import os\nimport shutil\ndef task_func(src_folder, backup_dir):\n    if not os.path.exists(src_folder):\n        raise ValueError(\"Source folder does not exist.\")\n    try:\n        shutil.copytree(src_folder, backup_dir)\n        os.rmdir(src_folder)\n        return True\n    except Exception as e:\n        raise Exception(\"An error occurred while deleting the source folder.\")", "raw_solution": "import os\nimport shutil\ndef task_func(src_folder, backup_dir):\n    if not os.path.exists(src_folder):\n        raise ValueError(\"Source folder does not exist.\")\n    try:\n        shutil.copytree(src_folder, backup_dir)\n        os.rmdir(src_folder)\n        return True\n    except Exception as e:\n        raise Exception(\"An error occurred while deleting the source folder.\")\n```"}
{"task_id": "BigCodeBench/345", "solution": "import pandas as pd\nimport seaborn as sns\ndef task_func(df, col1, col2):\n    if not isinstance(df, pd.DataFrame):\n        raise ValueError(\"Input df is not a DataFrame\")\n    if df.empty:\n        raise ValueError(\"Input df is empty\")\n    if col1 not in df.columns or col2 not in df.columns:\n        raise ValueError(\"Input df does not contain the specified columns\")\n    if not df[col1].dtype in [int, float] or not df[col2].dtype in [int, float]:\n        raise TypeError(\"df use non-numeric data\")\n    sns.scatterplot(x=col1, y=col2, data=df)\n    sns.regplot(x=col1, y=col2, data=df)\n    return sns.axes.Axes", "raw_solution": "import pandas as pd\nimport seaborn as sns\ndef task_func(df, col1, col2):\n    if not isinstance(df, pd.DataFrame):\n        raise ValueError(\"Input df is not a DataFrame\")\n    if df.empty:\n        raise ValueError(\"Input df is empty\")\n    if col1 not in df.columns or col2 not in df.columns:\n        raise ValueError(\"Input df does not contain the specified columns\")\n    if not df[col1].dtype in [int, float] or not df[col2].dtype in [int, float]:\n        raise TypeError(\"df use non-numeric data\")\n    sns.scatterplot(x=col1, y=col2, data=df)\n    sns.regplot(x=col1, y=col2, data=df)\n    return sns.axes.Axes\n```"}
{"task_id": "BigCodeBench/346", "solution": "import subprocess\nimport os\nimport sys\nimport time\ndef task_func(script_path, wait=True, *args):\n    if not os.path.exists(script_path):\n        raise ValueError(\"The script does not exist.\")\n    try:\n        if wait:\n            return subprocess.run([script_path] + list(args), check=True).returncode\n        else:\n            return None\n    except subprocess.CalledProcessError as e:\n        raise e", "raw_solution": "import subprocess\nimport os\nimport sys\nimport time\n\ndef task_func(script_path, wait=True, *args):\n    if not os.path.exists(script_path):\n        raise ValueError(\"The script does not exist.\")\n    try:\n        if wait:\n            return subprocess.run([script_path] + list(args), check=True).returncode\n        else:\n            return None\n    except subprocess.CalledProcessError as e:\n        raise e\n```"}
{"task_id": "BigCodeBench/347", "solution": "import pandas as pd\nimport re\nimport numpy as np\nPATTERN = r\"([a-fA-F\\d]{32})\"\ndef task_func(df, column):\n    if column not in df.columns:\n        raise KeyError(\"The function will raise KeyError if the 'column' does not exist in input 'df'\")\n    matches = df[column].str.extract(PATTERN)\n    return matches.value_counts()", "raw_solution": "import pandas as pd\nimport re\nimport numpy as np\n# Constants\nPATTERN = r\"([a-fA-F\\d]{32})\"\ndef task_func(df, column):\n    if column not in df.columns:\n        raise KeyError(\"The function will raise KeyError if the 'column' does not exist in input 'df'\")\n    matches = df[column].str.extract(PATTERN)\n    return matches.value_counts()\n```"}
{"task_id": "BigCodeBench/348", "solution": "import subprocess\nimport os\nimport signal\nimport time\ndef task_func(process_name: str) -> int:\n    try:\n        # Get all running processes\n        processes = subprocess.check_output(['ps', '-ef']).decode('utf-8').split('\\n')\n        # Filter processes by name\n        filtered_processes = [p for p in processes if process_name in p]\n        # Terminate processes\n        for p in filtered_processes:\n            pid = p.split()[1]\n            os.kill(int(pid), signal.SIGTERM)\n            time.sleep(1)\n        # Return the number of processes stopped\n        return len(filtered_processes)\n    except Exception as e:\n        print(f\"Error: {e}\")\n        return 0", "raw_solution": "import subprocess\nimport os\nimport signal\nimport time\n\ndef task_func(process_name: str) -> int:\n    try:\n        # Get all running processes\n        processes = subprocess.check_output(['ps', '-ef']).decode('utf-8').split('\\n')\n        # Filter processes by name\n        filtered_processes = [p for p in processes if process_name in p]\n        # Terminate processes\n        for p in filtered_processes:\n            pid = p.split()[1]\n            os.kill(int(pid), signal.SIGTERM)\n            time.sleep(1)\n        # Return the number of processes stopped\n        return len(filtered_processes)\n    except Exception as e:\n        print(f\"Error: {e}\")\n        return 0\n```"}
{"task_id": "BigCodeBench/349", "solution": "import pandas as pd\nimport random\ndef task_func(product_list, categories):\n    sales_data = []\n    for product in product_list:\n        category = random.choice(categories)\n        quantity_sold = random.randint(1, 100)\n        revenue = quantity_sold * random.randint(10, 100)\n        sales_data.append({'Product': product, 'Category': category, 'Quantity Sold': quantity_sold, 'Revenue': revenue})\n    return pd.DataFrame(sales_data)", "raw_solution": "import pandas as pd\nimport random\n\ndef task_func(product_list, categories):\n    sales_data = []\n    for product in product_list:\n        category = random.choice(categories)\n        quantity_sold = random.randint(1, 100)\n        revenue = quantity_sold * random.randint(10, 100)\n        sales_data.append({'Product': product, 'Category': category, 'Quantity Sold': quantity_sold, 'Revenue': revenue})\n    return pd.DataFrame(sales_data)\n```"}
{"task_id": "BigCodeBench/350", "solution": "import subprocess\nimport os\nimport shutil\nfrom glob import glob\ndef task_func(src_folder, dst_folder):\n    try:\n        # Create destination folder if it does not exist\n        if not os.path.exists(dst_folder):\n            os.makedirs(dst_folder)\n        \n        # Get all files in source folder\n        files = glob(os.path.join(src_folder, '*'))\n        \n        # Compress and move files\n        failed_files = []\n        for file in files:\n            # Compress file\n            compressed_file = file + '.gz'\n            subprocess.run(['gzip', file], check=True)\n            \n            # Move compressed file to destination folder\n            shutil.move(compressed_file, os.path.join(dst_folder, os.path.basename(compressed_file)))\n            \n            # Check if file was successfully compressed and moved\n            if not os.path.exists(compressed_file):\n                failed_files.append(file)\n        \n        # Return success message\n        return {\n            'success': True,\n            'message': 'All files were compressed and moved successfully.',\n            'failed_files': failed_files\n        }\n    except Exception as e:\n        # Return error message\n        return {\n            'success': False,\n            'message': str(e),\n            'failed_files': []\n        }", "raw_solution": "import subprocess\nimport os\nimport shutil\nfrom glob import glob\n\ndef task_func(src_folder, dst_folder):\n    try:\n        # Create destination folder if it does not exist\n        if not os.path.exists(dst_folder):\n            os.makedirs(dst_folder)\n        \n        # Get all files in source folder\n        files = glob(os.path.join(src_folder, '*'))\n        \n        # Compress and move files\n        failed_files = []\n        for file in files:\n            # Compress file\n            compressed_file = file + '.gz'\n            subprocess.run(['gzip', file], check=True)\n            \n            # Move compressed file to destination folder\n            shutil.move(compressed_file, os.path.join(dst_folder, os.path.basename(compressed_file)))\n            \n            # Check if file was successfully compressed and moved\n            if not os.path.exists(compressed_file):\n                failed_files.append(file)\n        \n        # Return success message\n        return {\n            'success': True,\n            'message': 'All files were compressed and moved successfully.',\n            'failed_files': failed_files\n        }\n    except Exception as e:\n        # Return error message\n        return {\n            'success': False,\n            'message': str(e),\n            'failed_files': []\n        }\n```"}
{"task_id": "BigCodeBench/351", "solution": "import pandas as pd\nimport random\ndef task_func(product_list, categories, min_value = 10, max_value = 100):\n    sales_data = []\n    for product in product_list:\n        quantity_sold = random.randint(min_value, max_value)\n        revenue = quantity_sold * random.randint(min_value, max_value)\n        sales_data.append({'Product': product, 'Category': random.choice(categories), 'Quantity Sold': quantity_sold, 'Revenue': revenue})\n    return pd.DataFrame(sales_data)", "raw_solution": "import pandas as pd\nimport random\n\ndef task_func(product_list, categories, min_value = 10, max_value = 100):\n    sales_data = []\n    for product in product_list:\n        quantity_sold = random.randint(min_value, max_value)\n        revenue = quantity_sold * random.randint(min_value, max_value)\n        sales_data.append({'Product': product, 'Category': random.choice(categories), 'Quantity Sold': quantity_sold, 'Revenue': revenue})\n    return pd.DataFrame(sales_data)\n```"}
{"task_id": "BigCodeBench/352", "solution": "import pandas as pd\nfrom collections import Counter\ndef task_func(text_dict, word_keys, top_k=2):\n    if top_k < 0:\n        raise ValueError(\"top_k must be a non-negative integer\")\n    word_freq = Counter(text_dict)\n    top_k_words = word_freq.most_common(top_k)\n    top_k_dict = {word: freq for word, freq in top_k_words}\n    fig, ax = plt.subplots()\n    ax.bar(top_k_dict.keys(), top_k_dict.values())\n    return ax, top_k_dict", "raw_solution": "import pandas as pd\nfrom collections import Counter\ndef task_func(text_dict, word_keys, top_k=2):\n    if top_k < 0:\n        raise ValueError(\"top_k must be a non-negative integer\")\n    word_freq = Counter(text_dict)\n    top_k_words = word_freq.most_common(top_k)\n    top_k_dict = {word: freq for word, freq in top_k_words}\n    fig, ax = plt.subplots()\n    ax.bar(top_k_dict.keys(), top_k_dict.values())\n    return ax, top_k_dict\n```"}
{"task_id": "BigCodeBench/353", "solution": "import pandas as pd\nimport random\ndef task_func(product_list, categories, min_value = 10, max_value = 100):\n    # Create a DataFrame with the product list\n    df = pd.DataFrame({'Product': product_list, 'Category': categories})\n    \n    # Generate random sales data for each product\n    df['Quantity Sold'] = [random.randint(min_value, max_value) for _ in range(len(product_list))]\n    df['Revenue'] = [random.randint(min_value, max_value) for _ in range(len(product_list))]\n    \n    # Calculate total revenue for each product\n    df['Total Revenue'] = df['Quantity Sold'] * df['Revenue']\n    \n    return df", "raw_solution": "import pandas as pd\nimport random\n\ndef task_func(product_list, categories, min_value = 10, max_value = 100):\n    # Create a DataFrame with the product list\n    df = pd.DataFrame({'Product': product_list, 'Category': categories})\n    \n    # Generate random sales data for each product\n    df['Quantity Sold'] = [random.randint(min_value, max_value) for _ in range(len(product_list))]\n    df['Revenue'] = [random.randint(min_value, max_value) for _ in range(len(product_list))]\n    \n    # Calculate total revenue for each product\n    df['Total Revenue'] = df['Quantity Sold'] * df['Revenue']\n    \n    return df\n```"}
{"task_id": "BigCodeBench/354", "solution": "import collections\nimport matplotlib.pyplot as plt\nimport pandas as pd\ndef task_func(sentences_dict, word_keys):\n    # Count the occurrence of each word\n    word_counts = collections.Counter()\n    for sentence in sentences_dict.values():\n        for word in sentence.split():\n            if word in word_keys:\n                word_counts[word] += 1\n    # Create a bar chart\n    df = pd.DataFrame(word_counts.items(), columns=['Word', 'Frequency'])\n    ax = df.plot(kind='bar', x='Word', y='Frequency', color='skyblue')\n    ax.set_title('Word Frequencies')\n    ax.set_xlabel('Word')\n    ax.set_ylabel('Frequency')\n    plt.show()\n    return ax", "raw_solution": "import collections\nimport matplotlib.pyplot as plt\nimport pandas as pd\n# Constants\nWORDS = ['the', 'be', 'to', 'of', 'and', 'a', 'in', 'that', 'have', 'I']\ndef task_func(sentences_dict, word_keys):\n    # Count the occurrence of each word\n    word_counts = collections.Counter()\n    for sentence in sentences_dict.values():\n        for word in sentence.split():\n            if word in word_keys:\n                word_counts[word] += 1\n    # Create a bar chart\n    df = pd.DataFrame(word_counts.items(), columns=['Word', 'Frequency'])\n    ax = df.plot(kind='bar', x='Word', y='Frequency', color='skyblue')\n    ax.set_title('Word Frequencies')\n    ax.set_xlabel('Word')\n    ax.set_ylabel('Frequency')\n    plt.show()\n    return ax\n```"}
{"task_id": "BigCodeBench/355", "solution": "import numpy as np\nimport math\nimport matplotlib.pyplot as plt\nfrom scipy.signal import get_window\ndef task_func(amplitude, frequency, time):\n    # Generate the time points\n    t = np.linspace(0, time, 1000)\n    \n    # Generate the complex wave\n    real_part = amplitude * np.cos(2 * math.pi * frequency * t)\n    imag_part = amplitude * np.sin(2 * math.pi * frequency * t)\n    wave = real_part + 1j * imag_part\n    \n    # Apply Hann window\n    window = get_window('hann', len(t))\n    wave = wave * window\n    \n    # Plot the wave\n    fig, ax = plt.subplots()\n    ax.plot(t, np.real(wave), label='Real part')\n    ax.plot(t, np.imag(wave), label='Imaginary part')\n    ax.set_title('Complex Wave with Hann Window')\n    ax.set_xlabel('Time')\n    ax.set_ylabel('Amplitude')\n    ax.legend()\n    \n    return wave, fig, ax", "raw_solution": "import numpy as np\nimport math\nimport matplotlib.pyplot as plt\nfrom scipy.signal import get_window\n\ndef task_func(amplitude, frequency, time):\n    # Generate the time points\n    t = np.linspace(0, time, 1000)\n    \n    # Generate the complex wave\n    real_part = amplitude * np.cos(2 * math.pi * frequency * t)\n    imag_part = amplitude * np.sin(2 * math.pi * frequency * t)\n    wave = real_part + 1j * imag_part\n    \n    # Apply Hann window\n    window = get_window('hann', len(t))\n    wave = wave * window\n    \n    # Plot the wave\n    fig, ax = plt.subplots()\n    ax.plot(t, np.real(wave), label='Real part')\n    ax.plot(t, np.imag(wave), label='Imaginary part')\n    ax.set_title('Complex Wave with Hann Window')\n    ax.set_xlabel('Time')\n    ax.set_ylabel('Amplitude')\n    ax.legend()\n    \n    return wave, fig, ax\n```"}
{"task_id": "BigCodeBench/356", "solution": "import numpy as np\nimport matplotlib.pyplot as plt\nimport cmath\ndef task_func(x, y):\n    if not isinstance(x, np.ndarray) or not isinstance(y, np.ndarray):\n        raise TypeError('If either x or y is not a numpy.ndarray.')\n    if len(x) != len(y):\n        raise ValueError('If x and y do not have the same length.')\n    phase = np.zeros((len(x), len(y)))\n    for i in range(len(x)):\n        for j in range(len(y)):\n            phase[i, j] = cmath.phase(x[i] + 1j * y[j])\n    return plt.axes(), phase", "raw_solution": "import numpy as np\nimport matplotlib.pyplot as plt\nimport cmath\n\ndef task_func(x, y):\n    if not isinstance(x, np.ndarray) or not isinstance(y, np.ndarray):\n        raise TypeError('If either x or y is not a numpy.ndarray.')\n    if len(x) != len(y):\n        raise ValueError('If x and y do not have the same length.')\n    phase = np.zeros((len(x), len(y)))\n    for i in range(len(x)):\n        for j in range(len(y)):\n            phase[i, j] = cmath.phase(x[i] + 1j * y[j])\n    return plt.axes(), phase\n```"}
{"task_id": "BigCodeBench/357", "solution": "import numpy as np\nfrom scipy.stats import norm\nimport matplotlib.pyplot as plt\ndef task_func(x):\n    if not isinstance(x, np.ndarray):\n        raise TypeError(\"If x is not a numpy.ndarray.\")\n    real_part = norm(loc=0, scale=1).pdf(x)\n    imag_part = norm(loc=2, scale=2).pdf(x)\n    complex_distribution = real_part + 1j * imag_part\n    return complex_distribution", "raw_solution": "import numpy as np\nfrom scipy.stats import norm\nimport matplotlib.pyplot as plt\n\ndef task_func(x):\n    if not isinstance(x, np.ndarray):\n        raise TypeError(\"If x is not a numpy.ndarray.\")\n    real_part = norm(loc=0, scale=1).pdf(x)\n    imag_part = norm(loc=2, scale=2).pdf(x)\n    complex_distribution = real_part + 1j * imag_part\n    return complex_distribution\n```"}
{"task_id": "BigCodeBench/358", "solution": "import itertools\nimport json\ndef task_func(json_list, r):\n    try:\n        data = json.loads(json_list)\n        if not isinstance(data, dict) or 'number_list' not in data:\n            raise Exception('Invalid JSON or missing key')\n        number_list = data['number_list']\n        if not isinstance(number_list, list):\n            raise Exception('Invalid number_list')\n        if len(number_list) == 0:\n            raise Exception('Empty number_list')\n        return list(itertools.combinations(number_list, r))\n    except Exception as e:\n        raise e", "raw_solution": "import itertools\nimport json\n\ndef task_func(json_list, r):\n    try:\n        data = json.loads(json_list)\n        if not isinstance(data, dict) or 'number_list' not in data:\n            raise Exception('Invalid JSON or missing key')\n        number_list = data['number_list']\n        if not isinstance(number_list, list):\n            raise Exception('Invalid number_list')\n        if len(number_list) == 0:\n            raise Exception('Empty number_list')\n        return list(itertools.combinations(number_list, r))\n    except Exception as e:\n        raise e\n```"}
{"task_id": "BigCodeBench/359", "solution": "from scipy import stats\nimport matplotlib.pyplot as plt\ndef task_func(data_dict, data_keys):\n    data1 = data_dict[data_keys[0]]\n    data2 = data_dict[data_keys[1]]\n    corr, p = stats.pearsonr(data1, data2)\n    fig, ax = plt.subplots()\n    ax.scatter(data1, data2)\n    ax.set_xlabel(data_keys[0])\n    ax.set_ylabel(data_keys[1])\n    ax.set_title(f'Correlation: {corr}')\n    return (corr, ax)", "raw_solution": "from scipy import stats\nimport matplotlib.pyplot as plt\n\ndef task_func(data_dict, data_keys):\n    data1 = data_dict[data_keys[0]]\n    data2 = data_dict[data_keys[1]]\n    corr, p = stats.pearsonr(data1, data2)\n    fig, ax = plt.subplots()\n    ax.scatter(data1, data2)\n    ax.set_xlabel(data_keys[0])\n    ax.set_ylabel(data_keys[1])\n    ax.set_title(f'Correlation: {corr}')\n    return (corr, ax)\n```"}
{"task_id": "BigCodeBench/360", "solution": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport os\ndef task_func(file_location, sheet_name):\n    try:\n        # Load data from Excel spreadsheet\n        df = pd.read_excel(file_location, sheet_name=sheet_name)\n        # Calculate mean and standard deviation of each column\n        mean = df.mean()\n        std = df.std()\n        # Draw a bar chart\n        fig, ax = plt.subplots()\n        ax.bar(df.columns, mean, yerr=std, capsize=5)\n        ax.set_title('Mean and Standard Deviation')\n        ax.set_xlabel('Columns')\n        ax.set_ylabel('Values')\n        return {'mean': mean, 'std': std}, fig\n    except FileNotFoundError:\n        raise FileNotFoundError('File not found at the specified path.')\n    except ValueError:\n        raise ValueError('Specified sheet does not exist in the workbook.')", "raw_solution": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport os\ndef task_func(file_location, sheet_name):\n    try:\n        # Load data from Excel spreadsheet\n        df = pd.read_excel(file_location, sheet_name=sheet_name)\n        # Calculate mean and standard deviation of each column\n        mean = df.mean()\n        std = df.std()\n        # Draw a bar chart\n        fig, ax = plt.subplots()\n        ax.bar(df.columns, mean, yerr=std, capsize=5)\n        ax.set_title('Mean and Standard Deviation')\n        ax.set_xlabel('Columns')\n        ax.set_ylabel('Values')\n        return {'mean': mean, 'std': std}, fig\n    except FileNotFoundError:\n        raise FileNotFoundError('File not found at the specified path.')\n    except ValueError:\n        raise ValueError('Specified sheet does not exist in the workbook.')\n```"}
{"task_id": "BigCodeBench/361", "solution": "import pandas as pd\nimport logging\ndef task_func(sheet_name, excel_file_location=\"test.xlsx\", csv_file_location=\"test.csv\"):\n    try:\n        # Read data from Excel file\n        df = pd.read_excel(excel_file_location, sheet_name=sheet_name)\n        # Convert data to CSV file\n        df.to_csv(csv_file_location, index=False)\n        # Calculate sum of each column\n        sum_dict = df.sum(axis=0).to_dict()\n        return sum_dict\n    except FileNotFoundError:\n        logging.error(f\"File not found at {excel_file_location}\")\n        raise\n    except ValueError:\n        logging.error(f\"Sheet name {sheet_name} not found in the Excel file\")\n        raise", "raw_solution": "import pandas as pd\nimport logging\n# Set up basic configuration for logging\nlogging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\ndef task_func(sheet_name, excel_file_location=\"test.xlsx\", csv_file_location=\"test.csv\"):\n    try:\n        # Read data from Excel file\n        df = pd.read_excel(excel_file_location, sheet_name=sheet_name)\n        # Convert data to CSV file\n        df.to_csv(csv_file_location, index=False)\n        # Calculate sum of each column\n        sum_dict = df.sum(axis=0).to_dict()\n        return sum_dict\n    except FileNotFoundError:\n        logging.error(f\"File not found at {excel_file_location}\")\n        raise\n    except ValueError:\n        logging.error(f\"Sheet name {sheet_name} not found in the Excel file\")\n        raise\n```"}
{"task_id": "BigCodeBench/362", "solution": "import pandas as pd\nimport os\ndef task_func(original_file_location=\"test.xlsx\", new_file_location=\"new_test.xlsx\", sheet_name=\"Sheet1\"):\n    try:\n        # Check if the original Excel file exists\n        if not os.path.exists(original_file_location):\n            raise FileNotFoundError(\"File not found\")\n        \n        # Read the original Excel file\n        df = pd.read_excel(original_file_location, sheet_name=sheet_name)\n        \n        # Write the data to a new Excel file\n        df.to_excel(new_file_location, index=False)\n        \n        # Read the new Excel file\n        new_df = pd.read_excel(new_file_location)\n        \n        return new_df\n    except FileNotFoundError as e:\n        raise e\n    except ValueError as e:\n        raise e", "raw_solution": "import pandas as pd\nimport os\n\ndef task_func(original_file_location=\"test.xlsx\", new_file_location=\"new_test.xlsx\", sheet_name=\"Sheet1\"):\n    try:\n        # Check if the original Excel file exists\n        if not os.path.exists(original_file_location):\n            raise FileNotFoundError(\"File not found\")\n        \n        # Read the original Excel file\n        df = pd.read_excel(original_file_location, sheet_name=sheet_name)\n        \n        # Write the data to a new Excel file\n        df.to_excel(new_file_location, index=False)\n        \n        # Read the new Excel file\n        new_df = pd.read_excel(new_file_location)\n        \n        return new_df\n    except FileNotFoundError as e:\n        raise e\n    except ValueError as e:\n        raise e\n```"}
{"task_id": "BigCodeBench/363", "solution": "from multiprocessing import Pool\nimport math\ndef calculate_factorial(number: int) -> tuple:\n    if not isinstance(number, int) or number < 0:\n        raise ValueError(\"If any element in the input list is not an integer or is negative.\")\n    return number, math.factorial(number)\ndef task_func(numbers: list) -> dict:\n    with Pool(processes=4) as pool:\n        results = pool.map(calculate_factorial, numbers)\n    return dict(results)", "raw_solution": "from multiprocessing import Pool\nimport math\ndef calculate_factorial(number: int) -> tuple:\n    if not isinstance(number, int) or number < 0:\n        raise ValueError(\"If any element in the input list is not an integer or is negative.\")\n    return number, math.factorial(number)\n    \ndef task_func(numbers: list) -> dict:\n    with Pool(processes=4) as pool:\n        results = pool.map(calculate_factorial, numbers)\n    return dict(results)\n```"}
{"task_id": "BigCodeBench/364", "solution": "import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nFEATURES = ['feature '+str(i) for i in range(1, 11)]\nTARGET = 'target'\ndef task_func(df):\n    if not isinstance(df, pd.DataFrame):\n        raise ValueError('The function will raise a ValueError is input df is not a DataFrame.')\n    X = df[FEATURES]\n    y = df[TARGET]\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n    model = LinearRegression()\n    model.fit(X_train, y_train)\n    return model", "raw_solution": "import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\n# Constants\nFEATURES = ['feature '+str(i) for i in range(1, 11)]\nTARGET = 'target'\ndef task_func(df):\n    if not isinstance(df, pd.DataFrame):\n        raise ValueError('The function will raise a ValueError is input df is not a DataFrame.')\n    X = df[FEATURES]\n    y = df[TARGET]\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n    model = LinearRegression()\n    model.fit(X_train, y_train)\n    return model\n```"}
{"task_id": "BigCodeBench/365", "solution": "from collections import Counter\nimport json\nimport random\nWORDS = ['apple', 'banana', 'cherry', 'date', 'elderberry', 'fig', 'grape', 'honeydew']\ndef task_func(n, file_name, seed=77):\n    random.seed(seed)\n    selected_words = random.sample(WORDS, n)\n    with open(file_name, 'w') as f:\n        json.dump(selected_words, f)\n    return file_name", "raw_solution": "from collections import Counter\nimport json\nimport random\n# Constants\nWORDS = ['apple', 'banana', 'cherry', 'date', 'elderberry', 'fig', 'grape', 'honeydew']\ndef task_func(n, file_name, seed=77):\n    random.seed(seed)\n    selected_words = random.sample(WORDS, n)\n    with open(file_name, 'w') as f:\n        json.dump(selected_words, f)\n    return file_name\n```"}
{"task_id": "BigCodeBench/366", "solution": "import matplotlib.pyplot as plt\nimport random\nCOLORS = ['#00bfbf', '#000000', '#0000ff']\ndef task_func(number_list, bins):\n    # Generate a random color from the predefined set of colors\n    color = random.choice(COLORS)\n    # Create a histogram subplot\n    fig, ax = plt.subplots()\n    ax.hist(number_list, bins=bins, color=color)\n    # Set the plot title and axis labels\n    ax.set_title('Histogram')\n    ax.set_xlabel('Number')\n    ax.set_ylabel('Frequency')\n    # Return the axes object representing the histogram plot\n    return ax", "raw_solution": "import matplotlib.pyplot as plt\nimport random\n# Constants\nCOLORS = ['#00bfbf', '#000000', '#0000ff']\ndef task_func(number_list, bins):\n    # Generate a random color from the predefined set of colors\n    color = random.choice(COLORS)\n    # Create a histogram subplot\n    fig, ax = plt.subplots()\n    ax.hist(number_list, bins=bins, color=color)\n    # Set the plot title and axis labels\n    ax.set_title('Histogram')\n    ax.set_xlabel('Number')\n    ax.set_ylabel('Frequency')\n    # Return the axes object representing the histogram plot\n    return ax\n```"}
{"task_id": "BigCodeBench/367", "solution": "from datetime import datetime\nfrom collections import defaultdict\nimport matplotlib.pyplot as plt\ndef task_func(activities):\n    if not all(isinstance(activity, datetime) for activity in activities):\n        raise TypeError(\"If the activities are not datetime objects.\")\n    activities_per_day = defaultdict(int)\n    for activity in activities:\n        activities_per_day[activity.strftime('%A')] += 1\n    fig, ax = plt.subplots()\n    ax.bar(activities_per_day.keys(), activities_per_day.values())\n    ax.set_xlabel('Day of the Week')\n    ax.set_ylabel('Number of Activities')\n    ax.set_title('Weekly Activity')\n    return ax", "raw_solution": "from datetime import datetime\nfrom collections import defaultdict\nimport matplotlib.pyplot as plt\n\ndef task_func(activities):\n    if not all(isinstance(activity, datetime) for activity in activities):\n        raise TypeError(\"If the activities are not datetime objects.\")\n    activities_per_day = defaultdict(int)\n    for activity in activities:\n        activities_per_day[activity.strftime('%A')] += 1\n    fig, ax = plt.subplots()\n    ax.bar(activities_per_day.keys(), activities_per_day.values())\n    ax.set_xlabel('Day of the Week')\n    ax.set_ylabel('Number of Activities')\n    ax.set_title('Weekly Activity')\n    return ax\n```"}
{"task_id": "BigCodeBench/368", "solution": "import os\nimport shutil\nimport random\ndef task_func(src_dir: str, dest_dir: str, seed:int = 100) -> str:\n    random.seed(seed)\n    files = os.listdir(src_dir)\n    if not files:\n        return 'No files found in source directory'\n    file = random.choice(files)\n    src_file = os.path.join(src_dir, file)\n    dest_file = os.path.join(dest_dir, file)\n    shutil.move(src_file, dest_file)\n    return file", "raw_solution": "import os\nimport shutil\nimport random\n\ndef task_func(src_dir: str, dest_dir: str, seed:int = 100) -> str:\n    random.seed(seed)\n    files = os.listdir(src_dir)\n    if not files:\n        return 'No files found in source directory'\n    file = random.choice(files)\n    src_file = os.path.join(src_dir, file)\n    dest_file = os.path.join(dest_dir, file)\n    shutil.move(src_file, dest_file)\n    return file\n```"}
{"task_id": "BigCodeBench/369", "solution": "import numpy as np\nfrom scipy import stats\nimport matplotlib.pyplot as plt\ndef task_func(l):\n    # Calculate the mean and standard deviation of the array\n    mean = np.mean(l)\n    std = np.std(l)\n    \n    # Create a histogram of the array\n    ax = plt.hist(l, bins=30, density=True)\n    \n    # Fit a Gaussian to the histogram\n    popt, pcov = stats.gaussian_fit(l)\n    x = np.linspace(min(l), max(l), 1000)\n    y = stats.gaussian(x, *popt)\n    ax.plot(x, y, 'r-', label='Gaussian fit')\n    \n    # Set the title of the plot\n    ax.set_title(f'Fit results: mu = {mean:.2f},  std = {std:.2f}')\n    \n    # Show the plot\n    plt.show()\n    \n    # Return the axes object\n    return ax", "raw_solution": "import numpy as np\nfrom scipy import stats\nimport matplotlib.pyplot as plt\n\ndef task_func(l):\n    # Calculate the mean and standard deviation of the array\n    mean = np.mean(l)\n    std = np.std(l)\n    \n    # Create a histogram of the array\n    ax = plt.hist(l, bins=30, density=True)\n    \n    # Fit a Gaussian to the histogram\n    popt, pcov = stats.gaussian_fit(l)\n    x = np.linspace(min(l), max(l), 1000)\n    y = stats.gaussian(x, *popt)\n    ax.plot(x, y, 'r-', label='Gaussian fit')\n    \n    # Set the title of the plot\n    ax.set_title(f'Fit results: mu = {mean:.2f},  std = {std:.2f}')\n    \n    # Show the plot\n    plt.show()\n    \n    # Return the axes object\n    return ax\n```"}
{"task_id": "BigCodeBench/370", "solution": "import os\nimport re\nimport json\nimport glob\ndef task_func(directory_path: str) -> list:\n    if not os.path.exists(directory_path):\n        raise FileNotFoundError(\"The specified directory does not exist.\")\n    processed_files = []\n    for file_path in glob.glob(os.path.join(directory_path, \"*.json\")):\n        with open(file_path, \"r\") as file:\n            content = file.read()\n        content = re.sub(r'\"', r'\\\\\"', content)\n        with open(file_path, \"w\") as file:\n            file.write(content)\n        processed_files.append(file_path)\n    return processed_files", "raw_solution": "import os\nimport re\nimport json\nimport glob\n\ndef task_func(directory_path: str) -> list:\n    if not os.path.exists(directory_path):\n        raise FileNotFoundError(\"The specified directory does not exist.\")\n    processed_files = []\n    for file_path in glob.glob(os.path.join(directory_path, \"*.json\")):\n        with open(file_path, \"r\") as file:\n            content = file.read()\n        content = re.sub(r'\"', r'\\\\\"', content)\n        with open(file_path, \"w\") as file:\n            file.write(content)\n        processed_files.append(file_path)\n    return processed_files\n```"}
{"task_id": "BigCodeBench/371", "solution": "from sklearn.preprocessing import MinMaxScaler\nimport pandas as pd\ndef task_func(l):\n    scaler = MinMaxScaler()\n    scaled_array = scaler.fit_transform(l)\n    df = pd.DataFrame(scaled_array, columns=['Scaled Values'])\n    return df", "raw_solution": "from sklearn.preprocessing import MinMaxScaler\nimport pandas as pd\n\ndef task_func(l):\n    scaler = MinMaxScaler()\n    scaled_array = scaler.fit_transform(l)\n    df = pd.DataFrame(scaled_array, columns=['Scaled Values'])\n    return df\n```"}
{"task_id": "BigCodeBench/372", "solution": "import re\nimport glob\nfrom docx import Document\ndef task_func(directory_path: str) -> int:\n    count = 0\n    for file_path in glob.glob(directory_path + '/*.docx'):\n        count += 1\n        doc = Document(file_path)\n        for paragraph in doc.paragraphs:\n            text = paragraph.text\n            text = re.sub(r'\"', r'\\\"', text)\n            paragraph.text = text\n    return count", "raw_solution": "import re\nimport glob\nfrom docx import Document\n\ndef task_func(directory_path: str) -> int:\n    count = 0\n    for file_path in glob.glob(directory_path + '/*.docx'):\n        count += 1\n        doc = Document(file_path)\n        for paragraph in doc.paragraphs:\n            text = paragraph.text\n            text = re.sub(r'\"', r'\\\"', text)\n            paragraph.text = text\n    return count\n```"}
{"task_id": "BigCodeBench/373", "solution": "from scipy.optimize import curve_fit\nimport matplotlib.pyplot as plt\ndef task_func(l, x_data, plot=False):\n    def func(x, a, b, c):\n        return a * x**2 + b * x + c\n    params, _ = curve_fit(func, x_data, l)\n    fitted_values = func(x_data, *params)\n    if plot:\n        plt.plot(x_data, l, 'o', label='Original data')\n        plt.plot(x_data, fitted_values, label='Fitted curve')\n        plt.legend()\n        plt.show()\n    return params, fitted_values", "raw_solution": "from scipy.optimize import curve_fit\nimport matplotlib.pyplot as plt\n\ndef task_func(l, x_data, plot=False):\n    def func(x, a, b, c):\n        return a * x**2 + b * x + c\n    params, _ = curve_fit(func, x_data, l)\n    fitted_values = func(x_data, *params)\n    if plot:\n        plt.plot(x_data, l, 'o', label='Original data')\n        plt.plot(x_data, fitted_values, label='Fitted curve')\n        plt.legend()\n        plt.show()\n    return params, fitted_values\n```"}
{"task_id": "BigCodeBench/374", "solution": "import regex as re\nimport glob\nimport os\nfrom openpyxl import load_workbook\ndef task_func(directory_path='./xlsx_files/'):\n    count = 0\n    for file in glob.glob(os.path.join(directory_path, '*.xlsx')):\n        wb = load_workbook(file)\n        for sheet in wb.worksheets:\n            for row in sheet.iter_rows(values_only=True):\n                for cell in row:\n                    if isinstance(cell, str):\n                        cell = re.sub(r'\"', r'\\\\\\\"', cell)\n                        sheet[cell[0]][cell[1]] = cell\n        wb.save(file)\n        count += 1\n    return count", "raw_solution": "import regex as re\nimport glob\nimport os\nfrom openpyxl import load_workbook\n\ndef task_func(directory_path='./xlsx_files/'):\n    count = 0\n    for file in glob.glob(os.path.join(directory_path, '*.xlsx')):\n        wb = load_workbook(file)\n        for sheet in wb.worksheets:\n            for row in sheet.iter_rows(values_only=True):\n                for cell in row:\n                    if isinstance(cell, str):\n                        cell = re.sub(r'\"', r'\\\\\\\"', cell)\n                        sheet[cell[0]][cell[1]] = cell\n        wb.save(file)\n        count += 1\n    return count\n```"}
{"task_id": "BigCodeBench/375", "solution": "from sklearn.decomposition import PCA\nimport matplotlib.pyplot as plt\ndef task_func(l):\n    pca = PCA(n_components=2)\n    pca.fit(l)\n    ax = plt.figure().add_subplot(111)\n    ax.plot(pca.components_[0, 0], pca.components_[0, 1], 'r')\n    ax.plot(pca.components_[1, 0], pca.components_[1, 1], 'b')\n    ax.set_title('PCA Result')\n    ax.set_xlabel('First Principal Component')\n    ax.set_ylabel('Second Principal Component')\n    return ax", "raw_solution": "from sklearn.decomposition import PCA\nimport matplotlib.pyplot as plt\n\ndef task_func(l):\n    pca = PCA(n_components=2)\n    pca.fit(l)\n    ax = plt.figure().add_subplot(111)\n    ax.plot(pca.components_[0, 0], pca.components_[0, 1], 'r')\n    ax.plot(pca.components_[1, 0], pca.components_[1, 1], 'b')\n    ax.set_title('PCA Result')\n    ax.set_xlabel('First Principal Component')\n    ax.set_ylabel('Second Principal Component')\n    return ax\n```"}
{"task_id": "BigCodeBench/376", "solution": "import nltk\nimport re\nfrom collections import Counter\nSTOPWORDS = nltk.corpus.stopwords.words('english')\ndef task_func(text):\n    # Remove punctuation marks and convert to lowercase\n    text = re.sub(r'[^\\w\\s]', '', text).lower()\n    # Split text into words\n    words = text.split()\n    # Remove stopwords\n    words = [word for word in words if word not in STOPWORDS]\n    # Calculate frequency of each word\n    word_freq = Counter(words)\n    return word_freq", "raw_solution": "import nltk\nimport re\nfrom collections import Counter\n# Constants\nSTOPWORDS = nltk.corpus.stopwords.words('english')\n\ndef task_func(text):\n    # Remove punctuation marks and convert to lowercase\n    text = re.sub(r'[^\\w\\s]', '', text).lower()\n    # Split text into words\n    words = text.split()\n    # Remove stopwords\n    words = [word for word in words if word not in STOPWORDS]\n    # Calculate frequency of each word\n    word_freq = Counter(words)\n    return word_freq\n```"}
{"task_id": "BigCodeBench/377", "solution": "from texttable import Texttable\nimport os\nimport psutil\ndef task_func():\n    table = Texttable()\n    table.set_cols_align(['l', 'r'])\n    table.set_cols_valign(['t', 'm'])\n    table.add_row(['Item', 'Value'])\n    table.add_row(['CPU Usage', f'{psutil.cpu_percent(interval=1)}%'])\n    table.add_row(['Memory Usage', f'{psutil.virtual_memory().percent}%'])\n    table.add_row(['Disk Usage', f'{psutil.disk_usage(\"/\").percent}%'])\n    return table.draw()", "raw_solution": "from texttable import Texttable\nimport os\nimport psutil\n\ndef task_func():\n    table = Texttable()\n    table.set_cols_align(['l', 'r'])\n    table.set_cols_valign(['t', 'm'])\n    table.add_row(['Item', 'Value'])\n    table.add_row(['CPU Usage', f'{psutil.cpu_percent(interval=1)}%'])\n    table.add_row(['Memory Usage', f'{psutil.virtual_memory().percent}%'])\n    table.add_row(['Disk Usage', f'{psutil.disk_usage(\"/\").percent}%'])\n    return table.draw()\n```"}
{"task_id": "BigCodeBench/378", "solution": "import pandas as pd\nfrom texttable import Texttable\nimport os\nimport glob\ndef task_func(data_dir='./data/'):\n    if not os.path.exists(data_dir):\n        raise FileNotFoundError(\"The specified directory does not exist.\")\n    csv_files = glob.glob(os.path.join(data_dir, \"*.csv\"))\n    if not csv_files:\n        raise ValueError(\"There are no CSV files in the specified directory.\")\n    table = Texttable()\n    table.set_cols_align([\"l\", \"r\", \"r\"])\n    table.set_cols_valign([\"l\", \"l\", \"l\"])\n    table.add_row([\"File Name\", \"Number of Rows\", \"Number of Columns\"])\n    for file in csv_files:\n        try:\n            df = pd.read_csv(file)\n            table.add_row([os.path.basename(file), len(df), len(df.columns)])\n        except pd.errors.EmptyDataError:\n            continue\n    return str(table)", "raw_solution": "import pandas as pd\nfrom texttable import Texttable\nimport os\nimport glob\n\ndef task_func(data_dir='./data/'):\n    if not os.path.exists(data_dir):\n        raise FileNotFoundError(\"The specified directory does not exist.\")\n    csv_files = glob.glob(os.path.join(data_dir, \"*.csv\"))\n    if not csv_files:\n        raise ValueError(\"There are no CSV files in the specified directory.\")\n    table = Texttable()\n    table.set_cols_align([\"l\", \"r\", \"r\"])\n    table.set_cols_valign([\"l\", \"l\", \"l\"])\n    table.add_row([\"File Name\", \"Number of Rows\", \"Number of Columns\"])\n    for file in csv_files:\n        try:\n            df = pd.read_csv(file)\n            table.add_row([os.path.basename(file), len(df), len(df.columns)])\n        except pd.errors.EmptyDataError:\n            continue\n    return str(table)\n```"}
{"task_id": "BigCodeBench/379", "solution": "import pandas as pd\nimport numpy as np\nCOLUMNS = ['Column1', 'Column2', 'Column3', 'Column4', 'Column5']\ndef task_func(length):\n    # Generate random data\n    data = np.random.rand(length, len(COLUMNS))\n    # Create DataFrame\n    df = pd.DataFrame(data, columns=COLUMNS)\n    return df", "raw_solution": "import pandas as pd\nimport numpy as np\n# Constants\nCOLUMNS = ['Column1', 'Column2', 'Column3', 'Column4', 'Column5']\ndef task_func(length):\n    # Generate random data\n    data = np.random.rand(length, len(COLUMNS))\n    # Create DataFrame\n    df = pd.DataFrame(data, columns=COLUMNS)\n    return df\n```"}
{"task_id": "BigCodeBench/380", "solution": "import re\nimport os\nimport shutil\ndef task_func(directory):\n    # Create a new directory for each extension\n    for root, dirs, files in os.walk(directory):\n        for file in files:\n            # Get the extension of the file\n            ext = os.path.splitext(file)[1]\n            # Create a new directory for the extension\n            if not os.path.exists(os.path.join(root, ext)):\n                os.makedirs(os.path.join(root, ext))\n            # Move the file to the corresponding directory\n            shutil.move(os.path.join(root, file), os.path.join(root, ext, file))", "raw_solution": "import re\nimport os\nimport shutil\n\ndef task_func(directory):\n    # Create a new directory for each extension\n    for root, dirs, files in os.walk(directory):\n        for file in files:\n            # Get the extension of the file\n            ext = os.path.splitext(file)[1]\n            # Create a new directory for the extension\n            if not os.path.exists(os.path.join(root, ext)):\n                os.makedirs(os.path.join(root, ext))\n            # Move the file to the corresponding directory\n            shutil.move(os.path.join(root, file), os.path.join(root, ext, file))\n```"}
{"task_id": "BigCodeBench/381", "solution": "import pandas as pd\nfrom sklearn.ensemble import RandomForestClassifier\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\ndef task_func(file_path='arena.csv', target_column='Index', seed=42):\n    # Check if the file exists\n    if not os.path.exists(file_path):\n        raise FileNotFoundError(\"File not found\")\n    \n    # Load the data\n    df = pd.read_csv(file_path)\n    \n    # Check if the target column exists\n    if target_column not in df.columns:\n        raise ValueError(\"Target column not found\")\n    \n    # Drop rows with NaN values\n    df = df.dropna()\n    \n    # Split the data into features and target\n    X = df.drop(columns=[target_column])\n    y = df[target_column]\n    \n    # Initialize the random forest classifier\n    rf = RandomForestClassifier(n_estimators=100, random_state=seed)\n    \n    # Train the model\n    rf.fit(X, y)\n    \n    # Get the feature importances\n    importances = rf.feature_importances_\n    \n    # Create a bar plot of the feature importances\n    fig, ax = plt.subplots()\n    sns.barplot(x=importances, y=X.columns, ax=ax)\n    ax.set_title('Feature Importances')\n    ax.set_xlabel('Importance')\n    ax.set_ylabel('Feature')\n    \n    return ax, importances", "raw_solution": "import pandas as pd\nfrom sklearn.ensemble import RandomForestClassifier\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\n\ndef task_func(file_path='arena.csv', target_column='Index', seed=42):\n    # Check if the file exists\n    if not os.path.exists(file_path):\n        raise FileNotFoundError(\"File not found\")\n    \n    # Load the data\n    df = pd.read_csv(file_path)\n    \n    # Check if the target column exists\n    if target_column not in df.columns:\n        raise ValueError(\"Target column not found\")\n    \n    # Drop rows with NaN values\n    df = df.dropna()\n    \n    # Split the data into features and target\n    X = df.drop(columns=[target_column])\n    y = df[target_column]\n    \n    # Initialize the random forest classifier\n    rf = RandomForestClassifier(n_estimators=100, random_state=seed)\n    \n    # Train the model\n    rf.fit(X, y)\n    \n    # Get the feature importances\n    importances = rf.feature_importances_\n    \n    # Create a bar plot of the feature importances\n    fig, ax = plt.subplots()\n    sns.barplot(x=importances, y=X.columns, ax=ax)\n    ax.set_title('Feature Importances')\n    ax.set_xlabel('Importance')\n    ax.set_ylabel('Feature')\n    \n    return ax, importances\n```"}
{"task_id": "BigCodeBench/382", "solution": "import numpy as np\nfrom scipy.stats import norm\nimport matplotlib.pyplot as plt\ndef task_func(length):\n    mu = 0\n    sigma = 1\n    x = np.linspace(mu - 3 * sigma, mu + 3 * sigma, length)\n    y = norm.pdf(x, mu, sigma)\n    plt.plot(x, y)\n    plt.show()\n    return (x, plt.gca())", "raw_solution": "import numpy as np\nfrom scipy.stats import norm\nimport matplotlib.pyplot as plt\n\ndef task_func(length):\n    mu = 0\n    sigma = 1\n    x = np.linspace(mu - 3 * sigma, mu + 3 * sigma, length)\n    y = norm.pdf(x, mu, sigma)\n    plt.plot(x, y)\n    plt.show()\n    return (x, plt.gca())\n```"}
{"task_id": "BigCodeBench/383", "solution": "import pandas as pd\nimport seaborn as sns\nfrom collections import Counter\nfrom textblob import TextBlob\nfrom matplotlib import pyplot as plt\ndef task_func(text, n, top_k):\n    # Create a textblob object\n    blob = TextBlob(text)\n    \n    # Get the n-grams\n    ngrams = blob.ngrams(n)\n    \n    # Count the frequency of each n-gram\n    ngram_counts = Counter(ngrams)\n    \n    # Get the top k n-grams\n    top_ngrams = ngram_counts.most_common(top_k)\n    \n    # Create a dataframe to store the n-grams and their frequencies\n    df = pd.DataFrame(top_ngrams, columns=['n-gram', 'frequency'])\n    \n    # Plot the n-grams and their frequencies\n    sns.barplot(x='n-gram', y='frequency', data=df)\n    plt.title('Top {} n-grams in the text'.format(top_k))\n    plt.xlabel('n-gram')\n    plt.ylabel('frequency')\n    plt.show()", "raw_solution": "import pandas as pd\nimport seaborn as sns\nfrom collections import Counter\nfrom textblob import TextBlob\nfrom matplotlib import pyplot as plt\n\ndef task_func(text, n, top_k):\n    # Create a textblob object\n    blob = TextBlob(text)\n    \n    # Get the n-grams\n    ngrams = blob.ngrams(n)\n    \n    # Count the frequency of each n-gram\n    ngram_counts = Counter(ngrams)\n    \n    # Get the top k n-grams\n    top_ngrams = ngram_counts.most_common(top_k)\n    \n    # Create a dataframe to store the n-grams and their frequencies\n    df = pd.DataFrame(top_ngrams, columns=['n-gram', 'frequency'])\n    \n    # Plot the n-grams and their frequencies\n    sns.barplot(x='n-gram', y='frequency', data=df)\n    plt.title('Top {} n-grams in the text'.format(top_k))\n    plt.xlabel('n-gram')\n    plt.ylabel('frequency')\n    plt.show()\n```"}
{"task_id": "BigCodeBench/384", "solution": "import collections\nimport random\nimport itertools\ndef task_func(animal_dict, max_count=10, seed=0):\n    random.seed(seed)\n    reversed_dict = {v: [k] for k, v in animal_dict.items()}\n    counter = collections.Counter(itertools.chain.from_iterable(reversed_dict.values()))\n    return reversed_dict, counter", "raw_solution": "import collections\nimport random\nimport itertools\nANIMALS = ['Cat', 'Dog', 'Elephant', 'Lion', 'Tiger', 'Bear', 'Giraffe', 'Horse', 'Rabbit', 'Snake', 'Zebra']\n\ndef task_func(animal_dict, max_count=10, seed=0):\n    random.seed(seed)\n    reversed_dict = {v: [k] for k, v in animal_dict.items()}\n    counter = collections.Counter(itertools.chain.from_iterable(reversed_dict.values()))\n    return reversed_dict, counter\n```"}
{"task_id": "BigCodeBench/385", "solution": "import matplotlib.pyplot as plt\nfrom collections import Counter\ndef task_func(fruit_dict):\n    fruit_counts = Counter(fruit_dict.values())\n    fig, ax = plt.subplots()\n    ax.bar(fruit_counts.keys(), fruit_counts.values())\n    return dict(fruit_counts), ax", "raw_solution": "import matplotlib.pyplot as plt\nfrom collections import Counter\nFRUITS = ['Apple', 'Banana', 'Cherry', 'Date', 'Elderberry', 'Fig', 'Grape', 'Honeydew', 'Indian Prune', 'Jackfruit']\n\ndef task_func(fruit_dict):\n    fruit_counts = Counter(fruit_dict.values())\n    fig, ax = plt.subplots()\n    ax.bar(fruit_counts.keys(), fruit_counts.values())\n    return dict(fruit_counts), ax\n```"}
{"task_id": "BigCodeBench/386", "solution": "import numpy as np\nimport pandas as pd\nCOLUMNS = ['Column1', 'Column2', 'Column3', 'Column4', 'Column5']\ndef task_func(length, min_value = 0, max_value = 100):\n    # Generate a random DataFrame\n    df = pd.DataFrame(np.random.randint(min_value, max_value, (length, len(COLUMNS))), columns=COLUMNS)\n    # Calculate the cumulative distribution function (CDF)\n    df['CDF'] = df.apply(lambda x: np.sum(x <= x), axis=1)\n    return df", "raw_solution": "import numpy as np\nimport pandas as pd\n# Constants\nCOLUMNS = ['Column1', 'Column2', 'Column3', 'Column4', 'Column5']\ndef task_func(length, min_value = 0, max_value = 100):\n    # Generate a random DataFrame\n    df = pd.DataFrame(np.random.randint(min_value, max_value, (length, len(COLUMNS))), columns=COLUMNS)\n    # Calculate the cumulative distribution function (CDF)\n    df['CDF'] = df.apply(lambda x: np.sum(x <= x), axis=1)\n    return df\n```"}
{"task_id": "BigCodeBench/387", "solution": "import numpy as np\nimport matplotlib.pyplot as plt\nCITIES = ['New York', 'London', 'Beijing', 'Tokyo', 'Sydney', 'Paris', 'Berlin', 'Moscow', 'Madrid', 'Rome']\ndef task_func(city_dict, max_range=1000000, seed=0):\n    np.random.seed(seed)\n    city_populations = {}\n    for city in CITIES:\n        if city in city_dict:\n            city_populations[city] = np.random.randint(1, max_range)\n        else:\n            city_populations[city] = -1\n    plt.bar(city_populations.keys(), city_populations.values())\n    plt.show()\n    return city_populations, plt.gca()", "raw_solution": "import numpy as np\nimport matplotlib.pyplot as plt\n# Constants\nCITIES = ['New York', 'London', 'Beijing', 'Tokyo', 'Sydney', 'Paris', 'Berlin', 'Moscow', 'Madrid', 'Rome']\ndef task_func(city_dict, max_range=1000000, seed=0):\n    np.random.seed(seed)\n    city_populations = {}\n    for city in CITIES:\n        if city in city_dict:\n            city_populations[city] = np.random.randint(1, max_range)\n        else:\n            city_populations[city] = -1\n    plt.bar(city_populations.keys(), city_populations.values())\n    plt.show()\n    return city_populations, plt.gca()\n```"}
{"task_id": "BigCodeBench/388", "solution": "import collections\nimport pandas as pd\ndef task_func(my_tuple, path_csv_files):\n    # Unpack the tuple\n    columns = my_tuple[0]\n    # Initialize a dictionary to store the counts\n    counts = collections.defaultdict(dict)\n    # Loop through each CSV file\n    for path in path_csv_files:\n        # Read the CSV file\n        df = pd.read_csv(path)\n        # Loop through each column\n        for col in columns:\n            # Count the occurrences of each unique value in the column\n            counts[col] = df[col].value_counts().to_dict()\n    # Return the counts dictionary\n    return counts", "raw_solution": "import collections\nimport pandas as pd\ndef task_func(my_tuple, path_csv_files):\n    # Unpack the tuple\n    columns = my_tuple[0]\n    # Initialize a dictionary to store the counts\n    counts = collections.defaultdict(dict)\n    # Loop through each CSV file\n    for path in path_csv_files:\n        # Read the CSV file\n        df = pd.read_csv(path)\n        # Loop through each column\n        for col in columns:\n            # Count the occurrences of each unique value in the column\n            counts[col] = df[col].value_counts().to_dict()\n    # Return the counts dictionary\n    return counts\n```"}
{"task_id": "BigCodeBench/389", "solution": "import re\nimport os\nimport shutil\ndef task_func(directory):\n    # Find files with filenames containing \"like\" or \"what\"\n    files = [f for f in os.listdir(directory) if re.search(r'like|what', f)]\n    \n    # Create a new subdirectory called \"Interesting Files\"\n    new_dir = os.path.join(directory, 'Interesting Files')\n    os.makedirs(new_dir, exist_ok=True)\n    \n    # Move the files to the new subdirectory\n    for f in files:\n        src = os.path.join(directory, f)\n        dst = os.path.join(new_dir, f)\n        shutil.move(src, dst)\n    \n    # Output the list of files moved\n    print(f'List of files moved: {files}')", "raw_solution": "import re\nimport os\nimport shutil\n\ndef task_func(directory):\n    # Find files with filenames containing \"like\" or \"what\"\n    files = [f for f in os.listdir(directory) if re.search(r'like|what', f)]\n    \n    # Create a new subdirectory called \"Interesting Files\"\n    new_dir = os.path.join(directory, 'Interesting Files')\n    os.makedirs(new_dir, exist_ok=True)\n    \n    # Move the files to the new subdirectory\n    for f in files:\n        src = os.path.join(directory, f)\n        dst = os.path.join(new_dir, f)\n        shutil.move(src, dst)\n    \n    # Output the list of files moved\n    print(f'List of files moved: {files}')\n```"}
{"task_id": "BigCodeBench/390", "solution": "import pandas as pd\nimport requests\nfrom io import StringIO\ndef task_func(csv_url_dict, sort_by_column=\"title\"):\n    if not csv_url_dict or \"URL\" not in csv_url_dict:\n        raise ValueError(\"This function will raise a ValueError if the dictionary is empty or the key 'URL' does not exist in the dictionary.\")\n    response = requests.get(csv_url_dict[\"URL\"])\n    csv_data = StringIO(response.text)\n    df = pd.read_csv(csv_data)\n    return df.sort_values(by=sort_by_column)", "raw_solution": "import pandas as pd\nimport requests\nfrom io import StringIO\n\ndef task_func(csv_url_dict, sort_by_column=\"title\"):\n    if not csv_url_dict or \"URL\" not in csv_url_dict:\n        raise ValueError(\"This function will raise a ValueError if the dictionary is empty or the key 'URL' does not exist in the dictionary.\")\n    response = requests.get(csv_url_dict[\"URL\"])\n    csv_data = StringIO(response.text)\n    df = pd.read_csv(csv_data)\n    return df.sort_values(by=sort_by_column)\n```"}
{"task_id": "BigCodeBench/391", "solution": "import os\nimport glob\nimport shutil\ndef task_func(directory, archive_dir='archive'):\n    try:\n        os.makedirs(archive_dir, exist_ok=True)\n        files = glob.glob(os.path.join(directory, '*.json'))\n        for file in files:\n            shutil.move(file, os.path.join(archive_dir, os.path.basename(file)))\n        return (True, [])\n    except Exception as e:\n        return (False, [str(e)])", "raw_solution": "import os\nimport glob\nimport shutil\ndef task_func(directory, archive_dir='archive'):\n    try:\n        os.makedirs(archive_dir, exist_ok=True)\n        files = glob.glob(os.path.join(directory, '*.json'))\n        for file in files:\n            shutil.move(file, os.path.join(archive_dir, os.path.basename(file)))\n        return (True, [])\n    except Exception as e:\n        return (False, [str(e)])\n```"}
{"task_id": "BigCodeBench/392", "solution": "import numpy as np\nimport matplotlib.pyplot as plt\nCOLORS = ['r', 'g', 'b']\ndef task_func(df, group_col, value_col, group_name):\n    if group_name not in df.columns:\n        raise ValueError('group_name does not exist in df')\n    ax = df.groupby(group_col)[value_col].sum().plot(kind='bar', color=COLORS)\n    ax.set_title('Bar chart of {} for {}'.format(value_col, group_name))\n    ax.set_xlabel(group_col)\n    ax.set_ylabel(value_col)\n    return ax", "raw_solution": "import numpy as np\nimport matplotlib.pyplot as plt\n# Constants\nCOLORS = ['r', 'g', 'b']\ndef task_func(df, group_col, value_col, group_name):\n    if group_name not in df.columns:\n        raise ValueError('group_name does not exist in df')\n    ax = df.groupby(group_col)[value_col].sum().plot(kind='bar', color=COLORS)\n    ax.set_title('Bar chart of {} for {}'.format(value_col, group_name))\n    ax.set_xlabel(group_col)\n    ax.set_ylabel(value_col)\n    return ax\n```"}
{"task_id": "BigCodeBench/393", "solution": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy import stats\ndef task_func(mu, sigma, num_samples=1000, seed=77):\n    np.random.seed(seed)\n    data = np.random.normal(mu, sigma, num_samples)\n    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n    ax1.hist(data, bins=30, density=True)\n    ax1.set_title('Histogram')\n    ax2.plot(stats.norm.cdf(data), label='CDF')\n    ax2.plot(stats.norm.ppf(data), label='PPF')\n    ax2.set_title('Q-Q Plot')\n    ax2.legend()\n    return fig", "raw_solution": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy import stats\n\ndef task_func(mu, sigma, num_samples=1000, seed=77):\n    np.random.seed(seed)\n    data = np.random.normal(mu, sigma, num_samples)\n    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n    ax1.hist(data, bins=30, density=True)\n    ax1.set_title('Histogram')\n    ax2.plot(stats.norm.cdf(data), label='CDF')\n    ax2.plot(stats.norm.ppf(data), label='PPF')\n    ax2.set_title('Q-Q Plot')\n    ax2.legend()\n    return fig\n```"}
{"task_id": "BigCodeBench/394", "solution": "import collections\nimport string\nimport random\ndef task_func(length, seed=0):\n    random.seed(seed)\n    string = ''.join(random.choice(string.ascii_letters) for _ in range(length))\n    return collections.Counter(string)", "raw_solution": "import collections\nimport string\nimport random\n\ndef task_func(length, seed=0):\n    random.seed(seed)\n    string = ''.join(random.choice(string.ascii_letters) for _ in range(length))\n    return collections.Counter(string)\n```"}
{"task_id": "BigCodeBench/395", "solution": "import re\nimport os\nimport glob\nimport natsort\nimport pandas as pd\ndef task_func(directory='./', file_pattern='*.txt', regex=r'([0-9]+)'):\n    if not os.path.exists(directory):\n        raise FileNotFoundError('The specified directory does not exist.')\n    files = glob.glob(os.path.join(directory, file_pattern))\n    if not files:\n        raise ValueError('No files matching the pattern are found.')\n    numeric_data = []\n    for file in natsort.natsorted(files):\n        with open(file, 'r') as f:\n            data = f.read()\n            numeric_data.append(re.findall(regex, data))\n    df = pd.DataFrame({'Filename': files, 'Numeric Data': numeric_data})\n    return df", "raw_solution": "import re\nimport os\nimport glob\nimport natsort\nimport pandas as pd\n\ndef task_func(directory='./', file_pattern='*.txt', regex=r'([0-9]+)'):\n    if not os.path.exists(directory):\n        raise FileNotFoundError('The specified directory does not exist.')\n    files = glob.glob(os.path.join(directory, file_pattern))\n    if not files:\n        raise ValueError('No files matching the pattern are found.')\n    numeric_data = []\n    for file in natsort.natsorted(files):\n        with open(file, 'r') as f:\n            data = f.read()\n            numeric_data.append(re.findall(regex, data))\n    df = pd.DataFrame({'Filename': files, 'Numeric Data': numeric_data})\n    return df\n```"}
{"task_id": "BigCodeBench/396", "solution": "import matplotlib\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy import stats\ndef task_func(mu, sigma, sample_size, seed=0):\n    np.random.seed(seed)\n    sample = np.random.normal(mu, sigma, sample_size)\n    density = stats.gaussian_kde(sample)\n    axes = density.plot()\n    return axes", "raw_solution": "import matplotlib\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy import stats\ndef task_func(mu, sigma, sample_size, seed=0):\n    np.random.seed(seed)\n    sample = np.random.normal(mu, sigma, sample_size)\n    density = stats.gaussian_kde(sample)\n    axes = density.plot()\n    return axes\n```"}
{"task_id": "BigCodeBench/397", "solution": "import re\nimport urllib.request\nimport json\nIP_REGEX = r'[0-9]+(?:\\.[0-9]+){3}'\ndef task_func(API_URL):\n    try:\n        response = urllib.request.urlopen(API_URL)\n        data = response.read()\n        ip = re.search(IP_REGEX, data.decode('utf-8'))\n        if ip:\n            return ip.group()\n        else:\n            raise Exception('No IP address found in response')\n    except Exception as e:\n        return str(e)", "raw_solution": "import re\nimport urllib.request\nimport json\n# Constants\nIP_REGEX = r'[0-9]+(?:\\.[0-9]+){3}'\ndef task_func(API_URL):\n    try:\n        response = urllib.request.urlopen(API_URL)\n        data = response.read()\n        ip = re.search(IP_REGEX, data.decode('utf-8'))\n        if ip:\n            return ip.group()\n        else:\n            raise Exception('No IP address found in response')\n    except Exception as e:\n        return str(e)\n```"}
{"task_id": "BigCodeBench/398", "solution": "import json\nimport os\ndef task_func(file_path):\n    with open(file_path, 'r') as f:\n        data = json.load(f)\n    if isinstance(data, list) and all(isinstance(item, dict) for item in data):\n        return True\n    else:\n        return False", "raw_solution": "import json\nimport os\ndef task_func(file_path):\n    with open(file_path, 'r') as f:\n        data = json.load(f)\n    if isinstance(data, list) and all(isinstance(item, dict) for item in data):\n        return True\n    else:\n        return False\n```"}
{"task_id": "BigCodeBench/399", "solution": "import numpy as np\nimport matplotlib.pyplot as plt\nimport math\ndef task_func(frequency, sample_size=10000):\n    if frequency < 0:\n        raise ValueError(\"If the frequency is negative.\")\n    if sample_size <= 0:\n        raise ValueError(\"If the sample size is non-positive.\")\n    x = np.linspace(0, 2 * math.pi, sample_size)\n    y1 = np.sin(frequency * x)\n    y2 = np.cos(frequency * x)\n    fig, ax = plt.subplots()\n    ax.plot(x, y1, label=\"sin\")\n    ax.plot(x, y2, label=\"cos\")\n    ax.legend()\n    return fig, ax", "raw_solution": "import numpy as np\nimport matplotlib.pyplot as plt\nimport math\ndef task_func(frequency, sample_size=10000):\n    if frequency < 0:\n        raise ValueError(\"If the frequency is negative.\")\n    if sample_size <= 0:\n        raise ValueError(\"If the sample size is non-positive.\")\n    x = np.linspace(0, 2 * math.pi, sample_size)\n    y1 = np.sin(frequency * x)\n    y2 = np.cos(frequency * x)\n    fig, ax = plt.subplots()\n    ax.plot(x, y1, label=\"sin\")\n    ax.plot(x, y2, label=\"cos\")\n    ax.legend()\n    return fig, ax\n```"}
{"task_id": "BigCodeBench/400", "solution": "import json\nfrom glob import glob\ndef task_func(directory, string):\n    file_paths = []\n    for file_path in glob(f\"{directory}/**/*.json\", recursive=True):\n        with open(file_path, 'r') as file:\n            data = json.load(file)\n            if string in str(data):\n                file_paths.append(file_path)\n    return file_paths", "raw_solution": "import json\nfrom glob import glob\n\ndef task_func(directory, string):\n    file_paths = []\n    for file_path in glob(f\"{directory}/**/*.json\", recursive=True):\n        with open(file_path, 'r') as file:\n            data = json.load(file)\n            if string in str(data):\n                file_paths.append(file_path)\n    return file_paths\n```"}
{"task_id": "BigCodeBench/401", "solution": "from flask import Flask\nimport os\nfrom flask_mail import Mail\ndef task_func(app_name):\n    app = Flask(app_name)\n    app.config['MAIL_SERVER'] = os.getenv('MAIL_SERVER', 'localhost')\n    app.config['MAIL_PORT'] = os.getenv('MAIL_PORT', 25)\n    app.config['MAIL_USE_TLS'] = os.getenv('MAIL_USE_TLS', False)\n    app.config['MAIL_USERNAME'] = os.getenv('MAIL_USERNAME', None)\n    app.config['MAIL_PASSWORD'] = os.getenv('MAIL_PASSWORD', None)\n    mail = Mail(app)\n    return (mail, app.config)", "raw_solution": "from flask import Flask\nimport os\nfrom flask_mail import Mail\n\ndef task_func(app_name):\n    app = Flask(app_name)\n    app.config['MAIL_SERVER'] = os.getenv('MAIL_SERVER', 'localhost')\n    app.config['MAIL_PORT'] = os.getenv('MAIL_PORT', 25)\n    app.config['MAIL_USE_TLS'] = os.getenv('MAIL_USE_TLS', False)\n    app.config['MAIL_USERNAME'] = os.getenv('MAIL_USERNAME', None)\n    app.config['MAIL_PASSWORD'] = os.getenv('MAIL_PASSWORD', None)\n    mail = Mail(app)\n    return (mail, app.config)\n```"}
{"task_id": "BigCodeBench/402", "solution": "import re\nimport requests\nimport json\nimport csv\nimport os\nAPI_URL = 'https://api.example.com/data'\ndef task_func(pattern):\n    # Make a GET request to the API\n    response = requests.get(API_URL)\n    # Extract data that matches the RegEx pattern\n    data = re.findall(pattern, response.text)\n    # Write the data to a CSV file\n    with open('matched_data.csv', 'w', newline='') as file:\n        writer = csv.writer(file)\n        writer.writerow(['data'])\n        for item in data:\n            writer.writerow([item])\n    # Return the absolute path to the CSV file\n    return os.path.abspath('matched_data.csv')", "raw_solution": "import re\nimport requests\nimport json\nimport csv\nimport os  \n# Constants\nAPI_URL = 'https://api.example.com/data'\ndef task_func(pattern):\n    # Make a GET request to the API\n    response = requests.get(API_URL)\n    # Extract data that matches the RegEx pattern\n    data = re.findall(pattern, response.text)\n    # Write the data to a CSV file\n    with open('matched_data.csv', 'w', newline='') as file:\n        writer = csv.writer(file)\n        writer.writerow(['data'])\n        for item in data:\n            writer.writerow([item])\n    # Return the absolute path to the CSV file\n    return os.path.abspath('matched_data.csv')\n```"}
{"task_id": "BigCodeBench/403", "solution": "from PIL import Image, ImageFilter\nimport cv2\nimport numpy as np\nimport os\ndef task_func(img_path, blur_radius=5):\n    if not os.path.exists(img_path):\n        raise FileNotFoundError(\"File not found at specified path\")\n    original_image = Image.open(img_path)\n    blurred_image = original_image.filter(ImageFilter.GaussianBlur(blur_radius))\n    original_array = np.array(original_image)\n    blurred_array = np.array(blurred_image)\n    return (original_array, blurred_array)", "raw_solution": "from PIL import Image, ImageFilter\nimport cv2\nimport numpy as np\nimport os\n\ndef task_func(img_path, blur_radius=5):\n    if not os.path.exists(img_path):\n        raise FileNotFoundError(\"File not found at specified path\")\n    original_image = Image.open(img_path)\n    blurred_image = original_image.filter(ImageFilter.GaussianBlur(blur_radius))\n    original_array = np.array(original_image)\n    blurred_array = np.array(blurred_image)\n    return (original_array, blurred_array)\n```"}
{"task_id": "BigCodeBench/404", "solution": "import cv2\nimport numpy as np\nimport os\ndef task_func(img_path):\n    if not os.path.exists(img_path):\n        raise FileNotFoundError(\"File not found at specified path\")\n    img = cv2.imread(img_path)\n    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n    contours, _ = cv2.findContours(gray, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n    return img, contours", "raw_solution": "import cv2\nimport numpy as np\nimport os\n\ndef task_func(img_path):\n    if not os.path.exists(img_path):\n        raise FileNotFoundError(\"File not found at specified path\")\n    img = cv2.imread(img_path)\n    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n    contours, _ = cv2.findContours(gray, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n    return img, contours\n```"}
{"task_id": "BigCodeBench/405", "solution": "import random\nimport matplotlib.pyplot as plt\ndef task_func(points: int):\n    # Generate random numbers\n    random_numbers = [random.random() for _ in range(points)]\n    \n    # Create a plot\n    fig, ax = plt.subplots()\n    ax.plot(range(points), random_numbers)\n    \n    return random_numbers, ax", "raw_solution": "import random\nimport matplotlib.pyplot as plt\n\ndef task_func(points: int):\n    # Generate random numbers\n    random_numbers = [random.random() for _ in range(points)]\n    \n    # Create a plot\n    fig, ax = plt.subplots()\n    ax.plot(range(points), random_numbers)\n    \n    return random_numbers, ax\n```"}
{"task_id": "BigCodeBench/406", "solution": "from PIL import Image\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport os\ndef task_func(img_path, angle):\n    if not os.path.exists(img_path):\n        raise FileNotFoundError(\"File not found at specified path\")\n    img = Image.open(img_path)\n    img = img.rotate(angle)\n    img = np.array(img)\n    plt.figure(figsize=(10, 5))\n    plt.subplot(1, 2, 1)\n    plt.imshow(img)\n    plt.title(\"Original Image\")\n    plt.subplot(1, 2, 2)\n    plt.imshow(img)\n    plt.title(\"Rotated Image\")\n    plt.show()\n    return (img, img)", "raw_solution": "from PIL import Image\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\ndef task_func(img_path, angle):\n    if not os.path.exists(img_path):\n        raise FileNotFoundError(\"File not found at specified path\")\n    img = Image.open(img_path)\n    img = img.rotate(angle)\n    img = np.array(img)\n    plt.figure(figsize=(10, 5))\n    plt.subplot(1, 2, 1)\n    plt.imshow(img)\n    plt.title(\"Original Image\")\n    plt.subplot(1, 2, 2)\n    plt.imshow(img)\n    plt.title(\"Rotated Image\")\n    plt.show()\n    return (img, img)\n```"}
{"task_id": "BigCodeBench/407", "solution": "import os\nimport csv\nfrom openpyxl import load_workbook\ndef task_func(file_name, excel_file_path, csv_file_path) -> str:\n    wb = load_workbook(excel_file_path)\n    sheet = wb.active\n    with open(csv_file_path, 'w', newline='') as f:\n        writer = csv.writer(f)\n        for row in sheet.iter_rows(values_only=True):\n            writer.writerow(row)\n    return os.path.basename(csv_file_path)", "raw_solution": "import os\nimport csv\nfrom openpyxl import load_workbook\n\ndef task_func(file_name, excel_file_path, csv_file_path) -> str:\n    wb = load_workbook(excel_file_path)\n    sheet = wb.active\n    with open(csv_file_path, 'w', newline='') as f:\n        writer = csv.writer(f)\n        for row in sheet.iter_rows(values_only=True):\n            writer.writerow(row)\n    return os.path.basename(csv_file_path)\n```"}
{"task_id": "BigCodeBench/408", "solution": "import sqlite3\nimport pandas as pd\ndef task_func(db_file: str, query: str) -> pd.DataFrame:\n    conn = sqlite3.connect(db_file)\n    df = pd.read_sql(query, conn)\n    return df", "raw_solution": "import sqlite3\nimport pandas as pd\n\ndef task_func(db_file: str, query: str) -> pd.DataFrame:\n    conn = sqlite3.connect(db_file)\n    df = pd.read_sql(query, conn)\n    return df\n```"}
{"task_id": "BigCodeBench/409", "solution": "import os\nimport pandas as pd\nimport numpy as np\ndef task_func(excel_file_path, file_name, column_name):\n    if not os.path.exists(excel_file_path):\n        raise FileNotFoundError(\"File not found at the specified path.\")\n    df = pd.read_excel(excel_file_path, sheet_name=file_name)\n    if column_name not in df.columns:\n        raise ValueError(\"The specified column is not found in the Excel file.\")\n    mean = df[column_name].mean()\n    median = df[column_name].median()\n    std_dev = df[column_name].std()\n    return {'mean': mean, 'median': median, 'std_dev': std_dev}", "raw_solution": "import os\nimport pandas as pd\nimport numpy as np\ndef task_func(excel_file_path, file_name, column_name):\n    if not os.path.exists(excel_file_path):\n        raise FileNotFoundError(\"File not found at the specified path.\")\n    df = pd.read_excel(excel_file_path, sheet_name=file_name)\n    if column_name not in df.columns:\n        raise ValueError(\"The specified column is not found in the Excel file.\")\n    mean = df[column_name].mean()\n    median = df[column_name].median()\n    std_dev = df[column_name].std()\n    return {'mean': mean, 'median': median, 'std_dev': std_dev}\n```"}
{"task_id": "BigCodeBench/410", "solution": "import os\nimport pandas as pd\nfrom datetime import datetime\ndef task_func(excel_directory: str, file_name: str, column_name: str, start_date: str, end_date: str) -> pd.DataFrame:\n    if not os.path.exists(excel_directory):\n        raise FileNotFoundError(\"File not found\")\n    try:\n        df = pd.read_excel(os.path.join(excel_directory, file_name))\n    except Exception as e:\n        raise ValueError(\"Error reading file: \" + str(e))\n    if column_name not in df.columns:\n        raise ValueError(\"Column not found\")\n    try:\n        start_date = datetime.strptime(start_date, \"%Y-%m-%d\")\n        end_date = datetime.strptime(end_date, \"%Y-%m-%d\")\n    except Exception as e:\n        raise ValueError(\"Error parsing date: \" + str(e))\n    filtered_df = df[(df[column_name] >= start_date) & (df[column_name] <= end_date)]\n    return filtered_df", "raw_solution": "import os\nimport pandas as pd\nfrom datetime import datetime\n\ndef task_func(excel_directory: str, file_name: str, column_name: str, start_date: str, end_date: str) -> pd.DataFrame:\n    if not os.path.exists(excel_directory):\n        raise FileNotFoundError(\"File not found\")\n    try:\n        df = pd.read_excel(os.path.join(excel_directory, file_name))\n    except Exception as e:\n        raise ValueError(\"Error reading file: \" + str(e))\n    if column_name not in df.columns:\n        raise ValueError(\"Column not found\")\n    try:\n        start_date = datetime.strptime(start_date, \"%Y-%m-%d\")\n        end_date = datetime.strptime(end_date, \"%Y-%m-%d\")\n    except Exception as e:\n        raise ValueError(\"Error parsing date: \" + str(e))\n    filtered_df = df[(df[column_name] >= start_date) & (df[column_name] <= end_date)]\n    return filtered_df\n```"}
{"task_id": "BigCodeBench/411", "solution": "import pandas as pd\nimport json\ndef task_func(data: dict, output_path: str = \"./default_data_output.json\") -> str:\n    df = pd.DataFrame(data)\n    if 'c' in df.columns:\n        df.drop(columns=['c'], inplace=True)\n    df.to_json(output_path, orient='records')\n    return output_path", "raw_solution": "import pandas as pd\nimport json\ndef task_func(data: dict, output_path: str = \"./default_data_output.json\") -> str:\n    df = pd.DataFrame(data)\n    if 'c' in df.columns:\n        df.drop(columns=['c'], inplace=True)\n    df.to_json(output_path, orient='records')\n    return output_path\n```"}
{"task_id": "BigCodeBench/412", "solution": "import json\nimport base64\nimport unicodedata\ndef task_func(json_file: str) -> dict:\n    with open(json_file, 'r') as f:\n        data = json.load(f)\n    decoded_data = {key: base64.b64decode(value).decode('utf-8') for key, value in data.items()}\n    normalized_data = {key: unicodedata.normalize('NFC', value) for key, value in decoded_data.items()}\n    return normalized_data", "raw_solution": "import json\nimport base64\nimport unicodedata\n\ndef task_func(json_file: str) -> dict:\n    with open(json_file, 'r') as f:\n        data = json.load(f)\n    decoded_data = {key: base64.b64decode(value).decode('utf-8') for key, value in data.items()}\n    normalized_data = {key: unicodedata.normalize('NFC', value) for key, value in decoded_data.items()}\n    return normalized_data\n```"}
{"task_id": "BigCodeBench/413", "solution": "import os\nfrom flask_mail import Mail\ndef task_func(app):\n    mail = Mail(app)\n    mail_config = {\n        'MAIL_SERVER': os.getenv('MAIL_SERVER', 'smtp.gmail.com'),\n        'MAIL_PORT': os.getenv('MAIL_PORT', 587),\n        'MAIL_USE_TLS': os.getenv('MAIL_USE_TLS', True),\n        'MAIL_USERNAME': os.getenv('MAIL_USERNAME', 'your_email@gmail.com'),\n        'MAIL_PASSWORD': os.getenv('MAIL_PASSWORD', 'your_password')\n    }\n    return (mail, mail_config)", "raw_solution": "import os\nfrom flask_mail import Mail\n\ndef task_func(app):\n    mail = Mail(app)\n    mail_config = {\n        'MAIL_SERVER': os.getenv('MAIL_SERVER', 'smtp.gmail.com'),\n        'MAIL_PORT': os.getenv('MAIL_PORT', 587),\n        'MAIL_USE_TLS': os.getenv('MAIL_USE_TLS', True),\n        'MAIL_USERNAME': os.getenv('MAIL_USERNAME', 'your_email@gmail.com'),\n        'MAIL_PASSWORD': os.getenv('MAIL_PASSWORD', 'your_password')\n    }\n    return (mail, mail_config)\n```"}
{"task_id": "BigCodeBench/414", "solution": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\ndef task_func(data, column=\"c\"):\n    df = data.copy()\n    if column in df.columns:\n        df.drop(columns=[column], inplace=True)\n    if df.select_dtypes(include=[np.number]).shape[1] > 0:\n        ax = df.plot()\n        return df, ax\n    else:\n        return df, None", "raw_solution": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef task_func(data, column=\"c\"):\n    df = data.copy()\n    if column in df.columns:\n        df.drop(columns=[column], inplace=True)\n    if df.select_dtypes(include=[np.number]).shape[1] > 0:\n        ax = df.plot()\n        return df, ax\n    else:\n        return df, None\n```"}
{"task_id": "BigCodeBench/415", "solution": "import pandas as pd\nimport codecs\ndef task_func(dataframe: pd.DataFrame) -> pd.DataFrame:\n    if not isinstance(dataframe, pd.DataFrame):\n        raise TypeError(\"Input is not a Pandas DataFrame\")\n    if \"UnicodeString\" not in dataframe.columns:\n        raise KeyError(\"Column 'UnicodeString' does not exist in the DataFrame\")\n    dataframe[\"UnicodeString\"] = dataframe[\"UnicodeString\"].apply(lambda x: codecs.decode(x, \"unicode_escape\"))\n    return dataframe", "raw_solution": "import pandas as pd\nimport codecs\n\ndef task_func(dataframe: pd.DataFrame) -> pd.DataFrame:\n    if not isinstance(dataframe, pd.DataFrame):\n        raise TypeError(\"Input is not a Pandas DataFrame\")\n    if \"UnicodeString\" not in dataframe.columns:\n        raise KeyError(\"Column 'UnicodeString' does not exist in the DataFrame\")\n    dataframe[\"UnicodeString\"] = dataframe[\"UnicodeString\"].apply(lambda x: codecs.decode(x, \"unicode_escape\"))\n    return dataframe\n```"}
{"task_id": "BigCodeBench/416", "solution": "import pandas as pd\nimport seaborn as sns\ndef task_func(data, column=\"c\"):\n    if not data or not data[column].dtype in [int, float]:\n        return None\n    data = data.drop(column, axis=1)\n    corr_matrix = data.corr()\n    sns.heatmap(corr_matrix)\n    return sns.plt.gca()", "raw_solution": "import pandas as pd\nimport seaborn as sns\ndef task_func(data, column=\"c\"):\n    if not data or not data[column].dtype in [int, float]:\n        return None\n    data = data.drop(column, axis=1)\n    corr_matrix = data.corr()\n    sns.heatmap(corr_matrix)\n    return sns.plt.gca()\n```"}
{"task_id": "BigCodeBench/417", "solution": "from sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.optimizers import SGD\ndef task_func(X, Y):\n    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.25, random_state=42)\n    model = Sequential()\n    model.add(Dense(1, input_dim=2, activation='sigmoid'))\n    model.compile(loss='binary_crossentropy', optimizer=SGD(lr=0.01), metrics=['accuracy'])\n    model.fit(X_train, Y_train, epochs=100, verbose=0, validation_data=(X_test, Y_test))\n    plt.plot(range(1, 101), model.history.history['loss'], label='Train')\n    plt.plot(range(1, 101), model.history.history['val_loss'], label='Test')\n    plt.title('Model loss')\n    plt.xlabel('Epoch')\n    plt.ylabel('Loss')\n    plt.legend()\n    return model, plt.gca()", "raw_solution": "from sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.optimizers import SGD\ndef task_func(X, Y):\n    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.25, random_state=42)\n    model = Sequential()\n    model.add(Dense(1, input_dim=2, activation='sigmoid'))\n    model.compile(loss='binary_crossentropy', optimizer=SGD(lr=0.01), metrics=['accuracy'])\n    model.fit(X_train, Y_train, epochs=100, verbose=0, validation_data=(X_test, Y_test))\n    plt.plot(range(1, 101), model.history.history['loss'], label='Train')\n    plt.plot(range(1, 101), model.history.history['val_loss'], label='Test')\n    plt.title('Model loss')\n    plt.xlabel('Epoch')\n    plt.ylabel('Loss')\n    plt.legend()\n    return model, plt.gca()\n```"}
{"task_id": "BigCodeBench/418", "solution": "from tensorflow import keras\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_curve, auc\nimport matplotlib.pyplot as plt\ndef task_func(X, Y):\n    # Split the data into training and test sets\n    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=42)\n    \n    # Create a Keras Sequential model with one hidden layer using a sigmoid activation function\n    model = keras.Sequential([\n        keras.layers.Dense(10, activation='sigmoid', input_shape=(X_train.shape[1],)),\n        keras.layers.Dense(1, activation='sigmoid')\n    ])\n    \n    # Compile the model with binary cross-entropy loss and an SGD optimizer specifying a learning rate\n    model.compile(loss='binary_crossentropy', optimizer='sgd', metrics=['accuracy'])\n    \n    # Fit the model to the training data in a non-verbose mode\n    model.fit(X_train, Y_train, epochs=10, batch_size=32, verbose=0)\n    \n    # Plot the ROC curve for the model on the test set, including the AUC score in the plot legend\n    y_pred = model.predict(X_test)\n    fpr, tpr, _ = roc_curve(Y_test, y_pred)\n    roc_auc = auc(fpr, tpr)\n    plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n    plt.xlim([0.0, 1.0])\n    plt.ylim([0.0, 1.05])\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('Receiver operating characteristic')\n    plt.legend(loc=\"lower right\")\n    plt.show()\n    \n    return model, plt.gca()", "raw_solution": "from tensorflow import keras\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_curve, auc\nimport matplotlib.pyplot as plt\ndef task_func(X, Y):\n    # Split the data into training and test sets\n    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=42)\n    \n    # Create a Keras Sequential model with one hidden layer using a sigmoid activation function\n    model = keras.Sequential([\n        keras.layers.Dense(10, activation='sigmoid', input_shape=(X_train.shape[1],)),\n        keras.layers.Dense(1, activation='sigmoid')\n    ])\n    \n    # Compile the model with binary cross-entropy loss and an SGD optimizer specifying a learning rate\n    model.compile(loss='binary_crossentropy', optimizer='sgd', metrics=['accuracy'])\n    \n    # Fit the model to the training data in a non-verbose mode\n    model.fit(X_train, Y_train, epochs=10, batch_size=32, verbose=0)\n    \n    # Plot the ROC curve for the model on the test set, including the AUC score in the plot legend\n    y_pred = model.predict(X_test)\n    fpr, tpr, _ = roc_curve(Y_test, y_pred)\n    roc_auc = auc(fpr, tpr)\n    plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n    plt.xlim([0.0, 1.0])\n    plt.ylim([0.0, 1.05])\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('Receiver operating characteristic')\n    plt.legend(loc=\"lower right\")\n    plt.show()\n    \n    return model, plt.gca()\n```"}
{"task_id": "BigCodeBench/419", "solution": "from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import precision_recall_curve\nfrom tensorflow import keras\nimport matplotlib.pyplot as plt\ndef task_func(X, Y):\n    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=42)\n    model = keras.Sequential()\n    model.add(keras.layers.Dense(X_train.shape[1], activation='sigmoid'))\n    model.compile(loss='binary_crossentropy', optimizer='sgd')\n    model.fit(X_train, Y_train, verbose=0)\n    precision, recall, _ = precision_recall_curve(Y_test, model.predict(X_test))\n    plt.plot(recall, precision)\n    plt.xlabel('Recall')\n    plt.ylabel('Precision')\n    plt.title('Precision-Recall Curve')\n    plt.show()\n    return model, plt.gca()", "raw_solution": "from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import precision_recall_curve\nfrom tensorflow import keras\nimport matplotlib.pyplot as plt\n\ndef task_func(X, Y):\n    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=42)\n    model = keras.Sequential()\n    model.add(keras.layers.Dense(X_train.shape[1], activation='sigmoid'))\n    model.compile(loss='binary_crossentropy', optimizer='sgd')\n    model.fit(X_train, Y_train, verbose=0)\n    precision, recall, _ = precision_recall_curve(Y_test, model.predict(X_test))\n    plt.plot(recall, precision)\n    plt.xlabel('Recall')\n    plt.ylabel('Precision')\n    plt.title('Precision-Recall Curve')\n    plt.show()\n    return model, plt.gca()\n```"}
{"task_id": "BigCodeBench/420", "solution": "import pandas as pd\nfrom sklearn.preprocessing import StandardScaler\ndef task_func(data):\n    scaler = StandardScaler()\n    scaled_data = scaler.fit_transform(data)\n    scaled_df = pd.DataFrame(scaled_data, columns=data.columns)\n    return scaled_df", "raw_solution": "import pandas as pd\nfrom sklearn.preprocessing import StandardScaler\n\ndef task_func(data):\n    scaler = StandardScaler()\n    scaled_data = scaler.fit_transform(data)\n    scaled_df = pd.DataFrame(scaled_data, columns=data.columns)\n    return scaled_df\n```"}
{"task_id": "BigCodeBench/421", "solution": "import requests\nimport os\nimport json\nimport time\nHEADERS = {\n    'accept': 'text/json',\n    'Content-Type': 'application/json'\n}\ndef task_func(url, directory, metadata):\n    if not os.path.exists(directory):\n        raise FileNotFoundError(\"The directory does not exist.\")\n    if not url.startswith(\"http://\") and not url.startswith(\"https://\"):\n        raise TypeError(\"The url is invalid.\")\n    status_codes = []\n    for filename in os.listdir(directory):\n        file_path = os.path.join(directory, filename)\n        if os.path.isfile(file_path):\n            with open(file_path, 'rb') as f:\n                file_data = f.read()\n            response = requests.post(url, headers=HEADERS, data=json.dumps({'file': file_data, 'metadata': metadata}), timeout=10)\n            status_codes.append(response.status_code)\n            time.sleep(1)\n    return status_codes", "raw_solution": "import requests\nimport os\nimport json\nimport time\n# Redefining the function in the current context\nHEADERS = {\n    'accept': 'text/json',\n    'Content-Type': 'application/json'\n}\ndef task_func(url, directory, metadata):\n    if not os.path.exists(directory):\n        raise FileNotFoundError(\"The directory does not exist.\")\n    if not url.startswith(\"http://\") and not url.startswith(\"https://\"):\n        raise TypeError(\"The url is invalid.\")\n    status_codes = []\n    for filename in os.listdir(directory):\n        file_path = os.path.join(directory, filename)\n        if os.path.isfile(file_path):\n            with open(file_path, 'rb') as f:\n                file_data = f.read()\n            response = requests.post(url, headers=HEADERS, data=json.dumps({'file': file_data, 'metadata': metadata}), timeout=10)\n            status_codes.append(response.status_code)\n            time.sleep(1)\n    return status_codes\n```"}
{"task_id": "BigCodeBench/422", "solution": "import pandas as pd\nfrom sklearn.model_selection import train_test_split\ndef task_func(df, target_column, column_to_remove=\"c\", test_size=0.2):\n    if column_to_remove in df.columns:\n        df.drop(columns=[column_to_remove], inplace=True)\n    X_train, X_test, y_train, y_test = train_test_split(df.drop(columns=[target_column]), df[target_column], test_size=test_size, random_state=42)\n    return X_train, X_test, y_train, y_test", "raw_solution": "import pandas as pd\nfrom sklearn.model_selection import train_test_split\n\ndef task_func(df, target_column, column_to_remove=\"c\", test_size=0.2):\n    if column_to_remove in df.columns:\n        df.drop(columns=[column_to_remove], inplace=True)\n    X_train, X_test, y_train, y_test = train_test_split(df.drop(columns=[target_column]), df[target_column], test_size=test_size, random_state=42)\n    return X_train, X_test, y_train, y_test\n```"}
{"task_id": "BigCodeBench/423", "solution": "import numpy as np\nimport cv2\nimport os\ndef task_func(image_path='image.jpg', threshold=128):\n    if not os.path.exists(image_path):\n        raise FileNotFoundError('File not found')\n    if not isinstance(threshold, int) or not 0 <= threshold <= 255:\n        raise ValueError('Invalid threshold value')\n    image = cv2.imread(image_path)\n    if image is None:\n        raise ValueError('Invalid image format')\n    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n    binarized_image = np.where(gray_image > threshold, 255, 0)\n    return (gray_image, binarized_image)", "raw_solution": "import numpy as np\nimport cv2\nimport os\n\ndef task_func(image_path='image.jpg', threshold=128):\n    if not os.path.exists(image_path):\n        raise FileNotFoundError('File not found')\n    if not isinstance(threshold, int) or not 0 <= threshold <= 255:\n        raise ValueError('Invalid threshold value')\n    image = cv2.imread(image_path)\n    if image is None:\n        raise ValueError('Invalid image format')\n    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n    binarized_image = np.where(gray_image > threshold, 255, 0)\n    return (gray_image, binarized_image)\n```"}
{"task_id": "BigCodeBench/424", "solution": "import cv2\nimport numpy as np\nimport os\nfrom sklearn.cluster import KMeans\ndef task_func(image_path='image.jpg', n_clusters=3, random_seed=42):\n    if not os.path.exists(image_path):\n        raise FileNotFoundError('File not found at specified path.')\n    if not isinstance(n_clusters, int) or n_clusters <= 0:\n        raise ValueError('n_clusters must be a positive integer.')\n    image = cv2.imread(image_path)\n    if image is None:\n        raise ValueError('Failed to read image.')\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    kmeans = KMeans(n_clusters=n_clusters, random_state=random_seed)\n    kmeans.fit(image.reshape(-1, 3))\n    segmented_image = kmeans.cluster_centers_[kmeans.labels_].reshape(image.shape)\n    return image, segmented_image", "raw_solution": "import cv2\nimport numpy as np\nimport os\nfrom sklearn.cluster import KMeans\n\ndef task_func(image_path='image.jpg', n_clusters=3, random_seed=42):\n    if not os.path.exists(image_path):\n        raise FileNotFoundError('File not found at specified path.')\n    if not isinstance(n_clusters, int) or n_clusters <= 0:\n        raise ValueError('n_clusters must be a positive integer.')\n    image = cv2.imread(image_path)\n    if image is None:\n        raise ValueError('Failed to read image.')\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    kmeans = KMeans(n_clusters=n_clusters, random_state=random_seed)\n    kmeans.fit(image.reshape(-1, 3))\n    segmented_image = kmeans.cluster_centers_[kmeans.labels_].reshape(image.shape)\n    return image, segmented_image\n```"}
{"task_id": "BigCodeBench/425", "solution": "import cv2\nimport os\nfrom matplotlib import pyplot as plt\ndef task_func(image_path='image.jpg', histogram_path='histogram.png'):\n    # Check if the image file exists\n    if not os.path.exists(image_path):\n        raise FileNotFoundError(\"File not found at specified path\")\n    \n    # Read the image\n    image = cv2.imread(image_path)\n    \n    # Create a histogram of the image pixel intensities\n    histogram = cv2.calcHist([image], [0], None, [256], [0, 256])\n    \n    # Save the histogram as a PNG file\n    plt.imsave(histogram_path, histogram)\n    \n    # Display the original image and its histogram\n    plt.figure(figsize=(10, 5))\n    plt.subplot(1, 2, 1)\n    plt.imshow(image)\n    plt.title('Original Image')\n    plt.axis('off')\n    plt.subplot(1, 2, 2)\n    plt.plot(histogram)\n    plt.title('Histogram')\n    plt.xlabel('Pixel Intensity')\n    plt.ylabel('Frequency')\n    plt.axis('off')\n    plt.show()\n    \n    # Return the histogram plot object\n    return plt.gca()", "raw_solution": "import cv2\nimport os\nfrom matplotlib import pyplot as plt\n\ndef task_func(image_path='image.jpg', histogram_path='histogram.png'):\n    # Check if the image file exists\n    if not os.path.exists(image_path):\n        raise FileNotFoundError(\"File not found at specified path\")\n    \n    # Read the image\n    image = cv2.imread(image_path)\n    \n    # Create a histogram of the image pixel intensities\n    histogram = cv2.calcHist([image], [0], None, [256], [0, 256])\n    \n    # Save the histogram as a PNG file\n    plt.imsave(histogram_path, histogram)\n    \n    # Display the original image and its histogram\n    plt.figure(figsize=(10, 5))\n    plt.subplot(1, 2, 1)\n    plt.imshow(image)\n    plt.title('Original Image')\n    plt.axis('off')\n    plt.subplot(1, 2, 2)\n    plt.plot(histogram)\n    plt.title('Histogram')\n    plt.xlabel('Pixel Intensity')\n    plt.ylabel('Frequency')\n    plt.axis('off')\n    plt.show()\n    \n    # Return the histogram plot object\n    return plt.gca()\n```"}
{"task_id": "BigCodeBench/426", "solution": "import numpy as np\nimport cv2\nimport os\ndef task_func(image_path='image.jpg', threshold=128):\n    if not os.path.exists(image_path):\n        raise FileNotFoundError('File not found')\n    if not isinstance(threshold, int) or not 0 <= threshold <= 255:\n        raise ValueError('Invalid threshold')\n    image = cv2.imread(image_path)\n    if image is None:\n        raise ValueError('Invalid image format')\n    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n    binary_image = np.where(gray_image > threshold, 255, 0)\n    return (gray_image, binary_image)", "raw_solution": "import numpy as np\nimport cv2\nimport os\n\ndef task_func(image_path='image.jpg', threshold=128):\n    if not os.path.exists(image_path):\n        raise FileNotFoundError('File not found')\n    if not isinstance(threshold, int) or not 0 <= threshold <= 255:\n        raise ValueError('Invalid threshold')\n    image = cv2.imread(image_path)\n    if image is None:\n        raise ValueError('Invalid image format')\n    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n    binary_image = np.where(gray_image > threshold, 255, 0)\n    return (gray_image, binary_image)\n```"}
{"task_id": "BigCodeBench/427", "solution": "import pandas as pd\nfrom sklearn.linear_model import LinearRegression\nimport matplotlib.pyplot as plt\ndef task_func(df1, df2, features=[\"feature1\", \"feature2\", \"feature3\"], target=\"target\"):\n    # Merge two dataframes based on the 'id' column\n    df = pd.merge(df1, df2, on='id')\n    \n    # Perform linear regression using columns specified in features to predict the target\n    model = LinearRegression()\n    model.fit(df[features], df[target])\n    \n    # Get regression coefficients and intercept\n    coefficients = model.coef_\n    intercept = model.intercept_\n    \n    # Plot the residuals\n    residuals = df[target] - model.predict(df[features])\n    plt.scatter(df[features], residuals)\n    plt.title('Residuals Plot')\n    plt.xlabel('Predicted Values')\n    plt.ylabel('Residuals')\n    plt.show()\n    \n    # Return the results\n    return {'coefficients': coefficients, 'intercept': intercept, 'residuals_plot': plt.gca()}", "raw_solution": "import pandas as pd\nfrom sklearn.linear_model import LinearRegression\nimport matplotlib.pyplot as plt\n\ndef task_func(df1, df2, features=[\"feature1\", \"feature2\", \"feature3\"], target=\"target\"):\n    # Merge two dataframes based on the 'id' column\n    df = pd.merge(df1, df2, on='id')\n    \n    # Perform linear regression using columns specified in features to predict the target\n    model = LinearRegression()\n    model.fit(df[features], df[target])\n    \n    # Get regression coefficients and intercept\n    coefficients = model.coef_\n    intercept = model.intercept_\n    \n    # Plot the residuals\n    residuals = df[target] - model.predict(df[features])\n    plt.scatter(df[features], residuals)\n    plt.title('Residuals Plot')\n    plt.xlabel('Predicted Values')\n    plt.ylabel('Residuals')\n    plt.show()\n    \n    # Return the results\n    return {'coefficients': coefficients, 'intercept': intercept, 'residuals_plot': plt.gca()}\n```"}
{"task_id": "BigCodeBench/428", "solution": "import pandas as pd\nimport seaborn as sns\nfrom sklearn.preprocessing import StandardScaler\ndef task_func(df1, df2):\n    merged_df = pd.merge(df1, df2, on='id', how='outer')\n    scaler = StandardScaler()\n    merged_df_scaled = scaler.fit_transform(merged_df)\n    pair_plot = sns.pairplot(merged_df_scaled)\n    return merged_df_scaled, pair_plot", "raw_solution": "import pandas as pd\nimport seaborn as sns\nfrom sklearn.preprocessing import StandardScaler\n\ndef task_func(df1, df2):\n    merged_df = pd.merge(df1, df2, on='id', how='outer')\n    scaler = StandardScaler()\n    merged_df_scaled = scaler.fit_transform(merged_df)\n    pair_plot = sns.pairplot(merged_df_scaled)\n    return merged_df_scaled, pair_plot\n```"}
{"task_id": "BigCodeBench/429", "solution": "import pandas as pd\nfrom sklearn.feature_selection import SelectKBest, f_classif\nimport seaborn as sns\ndef task_func(df1, df2):\n    # Select the top 2 features\n    selector = SelectKBest(f_classif, k=2)\n    X = df1.drop('target', axis=1)\n    y = df1['target']\n    X_new = selector.fit_transform(X, y)\n    X_new = pd.DataFrame(X_new, columns=selector.get_support(indices=True))\n    \n    # Create a heatmap of the feature correlations\n    corr = X_new.corr()\n    sns.heatmap(corr, annot=True, cmap='coolwarm')\n    \n    # Return the selected features and the heatmap\n    return list(X_new.columns), sns.heatmap(corr, annot=True, cmap='coolwarm')", "raw_solution": "import pandas as pd\nfrom sklearn.feature_selection import SelectKBest, f_classif\nimport seaborn as sns\ndef task_func(df1, df2):\n    # Select the top 2 features\n    selector = SelectKBest(f_classif, k=2)\n    X = df1.drop('target', axis=1)\n    y = df1['target']\n    X_new = selector.fit_transform(X, y)\n    X_new = pd.DataFrame(X_new, columns=selector.get_support(indices=True))\n    \n    # Create a heatmap of the feature correlations\n    corr = X_new.corr()\n    sns.heatmap(corr, annot=True, cmap='coolwarm')\n    \n    # Return the selected features and the heatmap\n    return list(X_new.columns), sns.heatmap(corr, annot=True, cmap='coolwarm')\n```"}
{"task_id": "BigCodeBench/430", "solution": "from sklearn.cluster import KMeans\nimport matplotlib.pyplot as plt\ndef task_func(df1, df2, column1=\"feature1\", column2=\"feature2\"):\n    kmeans = KMeans(n_clusters=2, n_init=10)\n    labels = kmeans.fit_predict(df1[[column1, column2]])\n    ax = df1.plot.scatter(column1, column2, c=labels)\n    return labels, ax", "raw_solution": "from sklearn.cluster import KMeans\nimport matplotlib.pyplot as plt\n\ndef task_func(df1, df2, column1=\"feature1\", column2=\"feature2\"):\n    kmeans = KMeans(n_clusters=2, n_init=10)\n    labels = kmeans.fit_predict(df1[[column1, column2]])\n    ax = df1.plot.scatter(column1, column2, c=labels)\n    return labels, ax\n```"}
{"task_id": "BigCodeBench/431", "solution": "import cv2\nimport os\nimport numpy as np\ndef task_func(image_file: str) -> np.ndarray:\n    if not os.path.exists(image_file):\n        raise FileNotFoundError(\"File not found\")\n    if not image_file.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif')):\n        raise ValueError(\"Invalid image file\")\n    image = cv2.imread(image_file)\n    if image is None:\n        raise ValueError(\"Invalid image file\")\n    histogram = np.zeros(256, dtype=int)\n    for row in image:\n        for pixel in row:\n            histogram[pixel] += 1\n    return histogram", "raw_solution": "import cv2\nimport os\nimport numpy as np\n\ndef task_func(image_file: str) -> np.ndarray:\n    if not os.path.exists(image_file):\n        raise FileNotFoundError(\"File not found\")\n    if not image_file.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif')):\n        raise ValueError(\"Invalid image file\")\n    image = cv2.imread(image_file)\n    if image is None:\n        raise ValueError(\"Invalid image file\")\n    histogram = np.zeros(256, dtype=int)\n    for row in image:\n        for pixel in row:\n            histogram[pixel] += 1\n    return histogram\n```"}
{"task_id": "BigCodeBench/432", "solution": "import pandas as pd\nimport numpy as np\nimport seaborn as sns\nfrom scipy.stats import chi2_contingency\nimport matplotlib.pyplot as plt\ndef task_func(df1, df2, column1=\"feature1\", column2=\"feature2\"):\n    # Merge two dataframes based on the 'id' column\n    df = pd.merge(df1, df2, on='id')\n    \n    # Perform a chi-square independence test on the merged dataframe\n    contingency_table = pd.crosstab(df[column1], df[column2])\n    chi2, p, dof, expected = chi2_contingency(contingency_table)\n    \n    # Draw a heatmap of the contingency table created from the features in column1, column2\n    sns.heatmap(contingency_table, annot=True, fmt='d')\n    plt.show()\n    \n    return p, plt.gca()", "raw_solution": "import pandas as pd\nimport numpy as np\nimport seaborn as sns\nfrom scipy.stats import chi2_contingency\nimport matplotlib.pyplot as plt\n\ndef task_func(df1, df2, column1=\"feature1\", column2=\"feature2\"):\n    # Merge two dataframes based on the 'id' column\n    df = pd.merge(df1, df2, on='id')\n    \n    # Perform a chi-square independence test on the merged dataframe\n    contingency_table = pd.crosstab(df[column1], df[column2])\n    chi2, p, dof, expected = chi2_contingency(contingency_table)\n    \n    # Draw a heatmap of the contingency table created from the features in column1, column2\n    sns.heatmap(contingency_table, annot=True, fmt='d')\n    plt.show()\n    \n    return p, plt.gca()\n```"}
{"task_id": "BigCodeBench/433", "solution": "import base64\nimport hashlib\nimport hmac\nimport binascii\ndef task_func(s, signature, secret_key):\n    # decode base64-encoded message\n    message = base64.b64decode(s)\n    # compute HMAC SHA-1 hash of the message\n    computed_signature = hmac.new(secret_key.encode(), message, hashlib.sha1).hexdigest()\n    # compare the computed signature with the provided signature\n    return computed_signature == signature", "raw_solution": "import base64\nimport hashlib\nimport hmac\nimport binascii\ndef task_func(s, signature, secret_key):\n    # decode base64-encoded message\n    message = base64.b64decode(s)\n    # compute HMAC SHA-1 hash of the message\n    computed_signature = hmac.new(secret_key.encode(), message, hashlib.sha1).hexdigest()\n    # compare the computed signature with the provided signature\n    return computed_signature == signature\n```"}
{"task_id": "BigCodeBench/434", "solution": "import pandas as pd\nimport re\nimport random\ndef task_func(s: str, seed: int = 0) -> pd.DataFrame:\n    random.seed(seed)\n    data = s.split('\\n')\n    data_df = pd.DataFrame(columns=['ID', 'Quantity', 'Code', 'Price', 'Product', 'Description'])\n    for i in range(len(data)):\n        data_df.loc[i] = [int(data[i].split()[0]), int(data[i].split()[1]), data[i].split()[2], int(data[i].split()[3]), random.choice(['Apple', 'Banana', 'Orange', 'Pear', 'Grape']), ' '.join(data[i].split()[4:])]\n    return data_df", "raw_solution": "import pandas as pd\nimport re\nimport random\n\ndef task_func(s: str, seed: int = 0) -> pd.DataFrame:\n    random.seed(seed)\n    data = s.split('\\n')\n    data_df = pd.DataFrame(columns=['ID', 'Quantity', 'Code', 'Price', 'Product', 'Description'])\n    for i in range(len(data)):\n        data_df.loc[i] = [int(data[i].split()[0]), int(data[i].split()[1]), data[i].split()[2], int(data[i].split()[3]), random.choice(['Apple', 'Banana', 'Orange', 'Pear', 'Grape']), ' '.join(data[i].split()[4:])]\n    return data_df\n```"}
{"task_id": "BigCodeBench/435", "solution": "import pandas as pd\nfrom random import randint\ndef task_func(name: str, age: int, code: str, salary: float, bio: str) -> pd.DataFrame:\n    job_titles = ['Engineer', 'Manager', 'Analyst', 'Developer', 'Tester']\n    job_title = job_titles[randint(0, 4)]\n    data_df = pd.DataFrame({\n        'Name': [name],\n        'Age': [age],\n        'Code': [code],\n        'Salary': [salary],\n        'Bio': [bio],\n        'Job Title': [job_title]\n    })\n    return data_df", "raw_solution": "import pandas as pd\nfrom random import randint\n\ndef task_func(name: str, age: int, code: str, salary: float, bio: str) -> pd.DataFrame:\n    job_titles = ['Engineer', 'Manager', 'Analyst', 'Developer', 'Tester']\n    job_title = job_titles[randint(0, 4)]\n    data_df = pd.DataFrame({\n        'Name': [name],\n        'Age': [age],\n        'Code': [code],\n        'Salary': [salary],\n        'Bio': [bio],\n        'Job Title': [job_title]\n    })\n    return data_df\n```"}
{"task_id": "BigCodeBench/436", "solution": "import string\nimport matplotlib.pyplot as plt\ndef task_func(s):\n    if not isinstance(s, str):\n        raise ValueError(\"Input must be a string\")\n    s = s.lower()\n    freq = {}\n    for char in s:\n        if char in string.ascii_lowercase:\n            if char in freq:\n                freq[char] += 1\n            else:\n                freq[char] = 1\n    fig, ax = plt.subplots()\n    ax.bar(freq.keys(), freq.values())\n    ax.set_xlabel('Letters')\n    ax.set_ylabel('Frequency')\n    return (freq, ax)", "raw_solution": "import string\nimport matplotlib.pyplot as plt\n\ndef task_func(s):\n    if not isinstance(s, str):\n        raise ValueError(\"Input must be a string\")\n    s = s.lower()\n    freq = {}\n    for char in s:\n        if char in string.ascii_lowercase:\n            if char in freq:\n                freq[char] += 1\n            else:\n                freq[char] = 1\n    fig, ax = plt.subplots()\n    ax.bar(freq.keys(), freq.values())\n    ax.set_xlabel('Letters')\n    ax.set_ylabel('Frequency')\n    return (freq, ax)\n```"}
{"task_id": "BigCodeBench/437", "solution": "import pickle\nimport os\ndef task_func(df, file_name=\"save.pkl\"):\n    # Save the DataFrame to a pickle file\n    with open(file_name, 'wb') as f:\n        pickle.dump(df, f)\n    # Read the DataFrame back from the pickle file\n    loaded_df = pickle.load(open(file_name, 'rb'))\n    # Delete the intermediate file\n    os.remove(file_name)\n    return loaded_df", "raw_solution": "import pickle\nimport os\ndef task_func(df, file_name=\"save.pkl\"):\n    # Save the DataFrame to a pickle file\n    with open(file_name, 'wb') as f:\n        pickle.dump(df, f)\n    # Read the DataFrame back from the pickle file\n    loaded_df = pickle.load(open(file_name, 'rb'))\n    # Delete the intermediate file\n    os.remove(file_name)\n    return loaded_df\n```"}
{"task_id": "BigCodeBench/438", "solution": "import pickle\nimport os\nimport matplotlib.pyplot as plt\ndef task_func(numbers, file_path=\"save.pkl\"):\n    if not isinstance(numbers, list):\n        raise TypeError(\"If the input is not a list of numbers.\")\n    fig = plt.figure()\n    plt.plot(numbers)\n    plt.savefig(file_path)\n    loaded_fig = pickle.load(open(file_path, \"rb\"))\n    os.remove(file_path)\n    return loaded_fig", "raw_solution": "import pickle\nimport os\nimport matplotlib.pyplot as plt\n\ndef task_func(numbers, file_path=\"save.pkl\"):\n    if not isinstance(numbers, list):\n        raise TypeError(\"If the input is not a list of numbers.\")\n    fig = plt.figure()\n    plt.plot(numbers)\n    plt.savefig(file_path)\n    loaded_fig = pickle.load(open(file_path, \"rb\"))\n    os.remove(file_path)\n    return loaded_fig\n```"}
{"task_id": "BigCodeBench/439", "solution": "import numpy as np\nimport seaborn as sns\ndef task_func(P, T):\n    # Check if the input is a numpy matrix\n    if not isinstance(P, np.ndarray) or not isinstance(T, np.ndarray):\n        raise ValueError(\"Input should be numpy matrices\")\n    # Check if the input matrices have the same number of columns\n    if P.shape[1] != T.shape[0]:\n        raise ValueError(\"The number of columns in the first matrix should be equal to the number of rows in the second matrix\")\n    # Perform matrix-tensor multiplication\n    result = np.dot(P, T)\n    # Create a heatmap of the 2D result\n    fig, ax = plt.subplots()\n    sns.heatmap(result, ax=ax)\n    return result, ax", "raw_solution": "import numpy as np\nimport seaborn as sns\ndef task_func(P, T):\n    # Check if the input is a numpy matrix\n    if not isinstance(P, np.ndarray) or not isinstance(T, np.ndarray):\n        raise ValueError(\"Input should be numpy matrices\")\n    # Check if the input matrices have the same number of columns\n    if P.shape[1] != T.shape[0]:\n        raise ValueError(\"The number of columns in the first matrix should be equal to the number of rows in the second matrix\")\n    # Perform matrix-tensor multiplication\n    result = np.dot(P, T)\n    # Create a heatmap of the 2D result\n    fig, ax = plt.subplots()\n    sns.heatmap(result, ax=ax)\n    return result, ax\n```"}
{"task_id": "BigCodeBench/440", "solution": "import numpy as np\nimport pandas as pd\nfrom sklearn.preprocessing import StandardScaler\ndef task_func(P, T):\n    if P.shape[1] != T.shape[0]:\n        raise ValueError(\"The number of columns in P must be equal to the number of rows in T.\")\n    result = np.dot(P, T)\n    scaler = StandardScaler()\n    result = scaler.fit_transform(result.reshape(-1, 1)).reshape(result.shape)\n    return pd.DataFrame(result, columns=[f'feature_{i}' for i in range(result.shape[1])])", "raw_solution": "import numpy as np\nimport pandas as pd\nfrom sklearn.preprocessing import StandardScaler\n\ndef task_func(P, T):\n    if P.shape[1] != T.shape[0]:\n        raise ValueError(\"The number of columns in P must be equal to the number of rows in T.\")\n    result = np.dot(P, T)\n    scaler = StandardScaler()\n    result = scaler.fit_transform(result.reshape(-1, 1)).reshape(result.shape)\n    return pd.DataFrame(result, columns=[f'feature_{i}' for i in range(result.shape[1])])\n```"}
{"task_id": "BigCodeBench/441", "solution": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\ndef task_func(P, T):\n    result = np.einsum('ij,klm->iklm', P, T)\n    ax = plt.axes(projection='3d')\n    ax.voxels(result, edgecolor='k')\n    plt.show()\n    return result, ax", "raw_solution": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\n\ndef task_func(P, T):\n    result = np.einsum('ij,klm->iklm', P, T)\n    ax = plt.axes(projection='3d')\n    ax.voxels(result, edgecolor='k')\n    plt.show()\n    return result, ax\n```"}
{"task_id": "BigCodeBench/442", "solution": "import numpy as np\nfrom sklearn.decomposition import PCA\nimport matplotlib.pyplot as plt\ndef task_func(P, T, tensor_shape=(3, 3, 3)):\n    # Calculate the product of matrix P and 3D tensor T\n    P_T = np.dot(P, T.reshape(tensor_shape[0], -1).T).reshape(tensor_shape)\n    \n    # Apply PCA to reduce the dimensionality of the result\n    pca = PCA(n_components=2)\n    pca_result = pca.fit_transform(P_T)\n    \n    # Plot the PCA result\n    ax = plt.axes()\n    ax.scatter(pca_result[:, 0], pca_result[:, 1])\n    ax.set_xlabel('Principal Component 1')\n    ax.set_ylabel('Principal Component 2')\n    return pca_result, ax", "raw_solution": "import numpy as np\nfrom sklearn.decomposition import PCA\nimport matplotlib.pyplot as plt\n\ndef task_func(P, T, tensor_shape=(3, 3, 3)):\n    # Calculate the product of matrix P and 3D tensor T\n    P_T = np.dot(P, T.reshape(tensor_shape[0], -1).T).reshape(tensor_shape)\n    \n    # Apply PCA to reduce the dimensionality of the result\n    pca = PCA(n_components=2)\n    pca_result = pca.fit_transform(P_T)\n    \n    # Plot the PCA result\n    ax = plt.axes()\n    ax.scatter(pca_result[:, 0], pca_result[:, 1])\n    ax.set_xlabel('Principal Component 1')\n    ax.set_ylabel('Principal Component 2')\n    return pca_result, ax\n```"}
{"task_id": "BigCodeBench/443", "solution": "import numpy as np\nfrom sklearn.cluster import KMeans\nimport matplotlib.pyplot as plt\ndef task_func(\n    P: np.ndarray,\n    T: np.ndarray,\n    n_clusters: int = 3,\n    random_state: int = 0,\n    n_init: int = 10,\n) -> (np.ndarray, plt.Axes):\n    P_T = np.dot(P, T)\n    P_T_flat = P_T.flatten()\n    kmeans = KMeans(n_clusters=n_clusters, random_state=random_state, n_init=n_init)\n    cluster_result = kmeans.fit_predict(P_T_flat)\n    ax = plt.axes()\n    ax.scatter(P_T_flat, cluster_result)\n    ax.set_title('KMeans Clustering Visualization')\n    return cluster_result, ax", "raw_solution": "import numpy as np\nfrom sklearn.cluster import KMeans\nimport matplotlib.pyplot as plt\n\ndef task_func(\n    P: np.ndarray,\n    T: np.ndarray,\n    n_clusters: int = 3,\n    random_state: int = 0,\n    n_init: int = 10,\n) -> (np.ndarray, plt.Axes):\n    P_T = np.dot(P, T)\n    P_T_flat = P_T.flatten()\n    kmeans = KMeans(n_clusters=n_clusters, random_state=random_state, n_init=n_init)\n    cluster_result = kmeans.fit_predict(P_T_flat)\n    ax = plt.axes()\n    ax.scatter(P_T_flat, cluster_result)\n    ax.set_title('KMeans Clustering Visualization')\n    return cluster_result, ax\n```"}
{"task_id": "BigCodeBench/444", "solution": "import numpy as np\nimport matplotlib.pyplot as plt\ndef task_func(n_points=100, random_seed=None):\n    if random_seed is not None:\n        np.random.seed(random_seed)\n    points = np.random.rand(n_points, 3)\n    fig = plt.figure()\n    ax = fig.add_subplot(111, projection='3d')\n    ax.scatter(points[:, 0], points[:, 1], points[:, 2])\n    return points, ax", "raw_solution": "import numpy as np\nimport matplotlib.pyplot as plt\ndef task_func(n_points=100, random_seed=None):\n    if random_seed is not None:\n        np.random.seed(random_seed)\n    points = np.random.rand(n_points, 3)\n    fig = plt.figure()\n    ax = fig.add_subplot(111, projection='3d')\n    ax.scatter(points[:, 0], points[:, 1], points[:, 2])\n    return points, ax\n```"}
{"task_id": "BigCodeBench/445", "solution": "import numpy as np\nfrom scipy.spatial import Voronoi, voronoi_plot_2d\nimport matplotlib.pyplot as plt\ndef task_func(points, seed=0):\n    np.random.seed(seed)\n    vor = Voronoi(points)\n    voronoi_plot_2d(vor)\n    plt.show()\n    return (vor, plt.gca())", "raw_solution": "import numpy as np\nfrom scipy.spatial import Voronoi, voronoi_plot_2d\nimport matplotlib.pyplot as plt\n\ndef task_func(points, seed=0):\n    np.random.seed(seed)\n    vor = Voronoi(points)\n    voronoi_plot_2d(vor)\n    plt.show()\n    return (vor, plt.gca())\n```"}
{"task_id": "BigCodeBench/446", "solution": "import matplotlib.pyplot as plt\nfrom sklearn.datasets import make_blobs\nimport numpy as np\ndef task_func(n_samples=100, centers=3, n_features=2, random_seed=42):\n    X, y = make_blobs(n_samples=n_samples, centers=centers, n_features=n_features, random_state=random_seed)\n    ax = plt.scatter(X[:, 0], X[:, 1], c=y)\n    return (X, y, ax)", "raw_solution": "import matplotlib.pyplot as plt\nfrom sklearn.datasets import make_blobs\nimport numpy as np\n\ndef task_func(n_samples=100, centers=3, n_features=2, random_seed=42):\n    X, y = make_blobs(n_samples=n_samples, centers=centers, n_features=n_features, random_state=random_seed)\n    ax = plt.scatter(X[:, 0], X[:, 1], c=y)\n    return (X, y, ax)\n```"}
{"task_id": "BigCodeBench/447", "solution": "import numpy as np\nfrom sklearn.decomposition import PCA\nimport matplotlib.pyplot as plt\ndef task_func(data, n_components=2, random_state=None):\n    pca = PCA(n_components=n_components, random_state=random_state)\n    transformed_data = pca.fit_transform(data)\n    ax = plt.scatter(transformed_data[:, 0], transformed_data[:, 1])\n    return {\"transformed_data\": transformed_data, \"ax\": ax}", "raw_solution": "import numpy as np\nfrom sklearn.decomposition import PCA\nimport matplotlib.pyplot as plt\n\ndef task_func(data, n_components=2, random_state=None):\n    pca = PCA(n_components=n_components, random_state=random_state)\n    transformed_data = pca.fit_transform(data)\n    ax = plt.scatter(transformed_data[:, 0], transformed_data[:, 1])\n    return {\"transformed_data\": transformed_data, \"ax\": ax}\n```"}
{"task_id": "BigCodeBench/448", "solution": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import norm\ndef task_func(mu=0, sigma=1):\n    x = np.linspace(mu - 3*sigma, mu + 3*sigma, 100)\n    y = norm.pdf(x, mu, sigma)\n    fig, ax = plt.subplots()\n    ax.plot(x, y)\n    return ax", "raw_solution": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import norm\n\ndef task_func(mu=0, sigma=1):\n    x = np.linspace(mu - 3*sigma, mu + 3*sigma, 100)\n    y = norm.pdf(x, mu, sigma)\n    fig, ax = plt.subplots()\n    ax.plot(x, y)\n    return ax\n```"}
{"task_id": "BigCodeBench/449", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import StandardScaler\ndef task_func(data: pd.DataFrame) -> (pd.DataFrame, list):\n    standardized_data = StandardScaler().fit_transform(data)\n    axes_list = []\n    for i in range(data.shape[1]):\n        axes_list.append(plt.hist(standardized_data[:, i], bins=20))\n    return standardized_data, axes_list", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import StandardScaler\n\ndef task_func(data: pd.DataFrame) -> (pd.DataFrame, list):\n    standardized_data = StandardScaler().fit_transform(data)\n    axes_list = []\n    for i in range(data.shape[1]):\n        axes_list.append(plt.hist(standardized_data[:, i], bins=20))\n    return standardized_data, axes_list\n```"}
{"task_id": "BigCodeBench/450", "solution": "from scipy.spatial.distance import cdist\nfrom sklearn.datasets import make_blobs\nimport matplotlib.pyplot as plt\ndef task_func(n_samples=200, centers=4, plot_path=None, random_seed=None):\n    X, y = make_blobs(n_samples=n_samples, centers=centers, random_state=random_seed)\n    plt.scatter(X[:, 0], X[:, 1], c=y)\n    if plot_path is not None:\n        plt.savefig(plot_path)\n    return cdist(X, X)", "raw_solution": "from scipy.spatial.distance import cdist\nfrom sklearn.datasets import make_blobs\nimport matplotlib.pyplot as plt\n\ndef task_func(n_samples=200, centers=4, plot_path=None, random_seed=None):\n    X, y = make_blobs(n_samples=n_samples, centers=centers, random_state=random_seed)\n    plt.scatter(X[:, 0], X[:, 1], c=y)\n    if plot_path is not None:\n        plt.savefig(plot_path)\n    return cdist(X, X)\n```"}
{"task_id": "BigCodeBench/451", "solution": "import numpy as np\nfrom sklearn.decomposition import PCA\nimport matplotlib.pyplot as plt\nimport seaborn as sns\ndef task_func(n_components=2, N_SAMPLES=500, N_FEATURES=50, random_seed=None):\n    np.random.seed(random_seed)\n    X = np.random.rand(N_SAMPLES, N_FEATURES)\n    pca = PCA(n_components=n_components)\n    transformed_data = pca.fit_transform(X)\n    if n_components == 1:\n        heatmap_axes = None\n    else:\n        heatmap_axes = sns.heatmap(pca.components_.T, annot=True, cmap='coolwarm')\n    return transformed_data, heatmap_axes", "raw_solution": "import numpy as np\nfrom sklearn.decomposition import PCA\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\ndef task_func(n_components=2, N_SAMPLES=500, N_FEATURES=50, random_seed=None):\n    np.random.seed(random_seed)\n    X = np.random.rand(N_SAMPLES, N_FEATURES)\n    pca = PCA(n_components=n_components)\n    transformed_data = pca.fit_transform(X)\n    if n_components == 1:\n        heatmap_axes = None\n    else:\n        heatmap_axes = sns.heatmap(pca.components_.T, annot=True, cmap='coolwarm')\n    return transformed_data, heatmap_axes\n```"}
{"task_id": "BigCodeBench/452", "solution": "import numpy as np\nfrom sklearn import datasets\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\ndef task_func(n_samples=100, n_features=10, random_seed=None):\n    # Generate synthetic data\n    X, y = datasets.make_regression(n_samples=n_samples, n_features=n_features, random_state=random_seed)\n    \n    # Split data into training and test sets\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=random_seed)\n    \n    # Fit linear regression model\n    model = LinearRegression()\n    model.fit(X_train, y_train)\n    \n    # Predict values\n    predictions = model.predict(X_test)\n    \n    # Return results\n    return predictions, model.coef_, model.intercept_, model.score(X_test, y_test)", "raw_solution": "import numpy as np\nfrom sklearn import datasets\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\n\ndef task_func(n_samples=100, n_features=10, random_seed=None):\n    # Generate synthetic data\n    X, y = datasets.make_regression(n_samples=n_samples, n_features=n_features, random_state=random_seed)\n    \n    # Split data into training and test sets\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=random_seed)\n    \n    # Fit linear regression model\n    model = LinearRegression()\n    model.fit(X_train, y_train)\n    \n    # Predict values\n    predictions = model.predict(X_test)\n    \n    # Return results\n    return predictions, model.coef_, model.intercept_, model.score(X_test, y_test)\n```"}
{"task_id": "BigCodeBench/453", "solution": "import re\nimport string\nfrom random import choice\ndef task_func(n, pattern):\n    while True:\n        s = ''.join(choice(string.ascii_letters) for _ in range(n))\n        if re.match(pattern, s):\n            return s", "raw_solution": "import re\nimport string\nfrom random import choice\n\ndef task_func(n, pattern):\n    while True:\n        s = ''.join(choice(string.ascii_letters) for _ in range(n))\n        if re.match(pattern, s):\n            return s\n```"}
{"task_id": "BigCodeBench/454", "solution": "import os\nimport shutil\nimport glob\ndef task_func(src_dir, dest_dir, ext):\n    if not os.path.exists(src_dir):\n        raise FileNotFoundError(\"Source directory does not exist\")\n    if not os.path.exists(dest_dir):\n        raise FileNotFoundError(\"Destination directory does not exist\")\n    files = glob.glob(os.path.join(src_dir, f'*{ext}'))\n    moved_files = []\n    for file in files:\n        file_name = os.path.basename(file)\n        dest_file = os.path.join(dest_dir, file_name)\n        if os.path.exists(dest_file):\n            continue\n        shutil.move(file, dest_file)\n        moved_files.append(file)\n    return moved_files", "raw_solution": "import os\nimport shutil\nimport glob\n\ndef task_func(src_dir, dest_dir, ext):\n    if not os.path.exists(src_dir):\n        raise FileNotFoundError(\"Source directory does not exist\")\n    if not os.path.exists(dest_dir):\n        raise FileNotFoundError(\"Destination directory does not exist\")\n    files = glob.glob(os.path.join(src_dir, f'*{ext}'))\n    moved_files = []\n    for file in files:\n        file_name = os.path.basename(file)\n        dest_file = os.path.join(dest_dir, file_name)\n        if os.path.exists(dest_file):\n            continue\n        shutil.move(file, dest_file)\n        moved_files.append(file)\n    return moved_files\n```"}
{"task_id": "BigCodeBench/455", "solution": "import numpy as np\nfrom scipy import stats\nimport matplotlib.pyplot as plt\ndef task_func(mean, std_dev, n):\n    samples = np.random.normal(mean, std_dev, n)\n    plt.hist(samples, bins=50, density=True)\n    plt.plot(stats.norm.pdf(np.linspace(-10, 10, 1000), mean, std_dev))\n    plt.show()\n    return samples", "raw_solution": "import numpy as np\nfrom scipy import stats\nimport matplotlib.pyplot as plt\n\ndef task_func(mean, std_dev, n):\n    samples = np.random.normal(mean, std_dev, n)\n    plt.hist(samples, bins=50, density=True)\n    plt.plot(stats.norm.pdf(np.linspace(-10, 10, 1000), mean, std_dev))\n    plt.show()\n    return samples\n```"}
{"task_id": "BigCodeBench/456", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.preprocessing import MinMaxScaler\ndef task_func(data: pd.DataFrame) -> (pd.DataFrame, plt.Axes):\n    scaler = MinMaxScaler()\n    normalized_data = scaler.fit_transform(data)\n    sns.heatmap(normalized_data, cmap=\"YlGnBu\", annot=True, fmt=\".2f\", cbar_kws={\"label\": \"Normalized Value\"})\n    plt.show()\n    return normalized_data, plt.gca()", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.preprocessing import MinMaxScaler\n\ndef task_func(data: pd.DataFrame) -> (pd.DataFrame, plt.Axes):\n    scaler = MinMaxScaler()\n    normalized_data = scaler.fit_transform(data)\n    sns.heatmap(normalized_data, cmap=\"YlGnBu\", annot=True, fmt=\".2f\", cbar_kws={\"label\": \"Normalized Value\"})\n    plt.show()\n    return normalized_data, plt.gca()\n```"}
{"task_id": "BigCodeBench/457", "solution": "import pandas as pd\nimport numpy as np\ndef task_func(L):\n    if not isinstance(L, list) or not all(isinstance(sublist, list) for sublist in L) or not all(isinstance(item, int) for sublist in L for item in sublist):\n        raise TypeError(\"Input is not a list of list of integers\")\n    df = pd.DataFrame(L)\n    ax = df.hist(bins=len(df.unique()), rwidth=0.8)\n    return ax", "raw_solution": "import pandas as pd\nimport numpy as np\n\ndef task_func(L):\n    if not isinstance(L, list) or not all(isinstance(sublist, list) for sublist in L) or not all(isinstance(item, int) for sublist in L for item in sublist):\n        raise TypeError(\"Input is not a list of list of integers\")\n    df = pd.DataFrame(L)\n    ax = df.hist(bins=len(df.unique()), rwidth=0.8)\n    return ax\n```"}
{"task_id": "BigCodeBench/458", "solution": "import json\nimport re\nimport pandas as pd\ndef task_func(json_str):\n    # Convert JSON string to dictionary\n    data = json.loads(json_str)\n    \n    # Normalize dictionary by doubling numerical values\n    for key, value in data.items():\n        if isinstance(value, (int, float)):\n            data[key] = value * 2\n        elif isinstance(value, list):\n            data[key] = [item * 2 for item in value]\n        elif isinstance(value, str):\n            data[key] = re.findall(r'-?\\d+', value)\n    \n    # Create a Pandas DataFrame from the dictionary\n    df = pd.DataFrame(data)\n    \n    return df", "raw_solution": "import json\nimport re\nimport pandas as pd\n\ndef task_func(json_str):\n    # Convert JSON string to dictionary\n    data = json.loads(json_str)\n    \n    # Normalize dictionary by doubling numerical values\n    for key, value in data.items():\n        if isinstance(value, (int, float)):\n            data[key] = value * 2\n        elif isinstance(value, list):\n            data[key] = [item * 2 for item in value]\n        elif isinstance(value, str):\n            data[key] = re.findall(r'-?\\d+', value)\n    \n    # Create a Pandas DataFrame from the dictionary\n    df = pd.DataFrame(data)\n    \n    return df\n```"}
{"task_id": "BigCodeBench/459", "solution": "import subprocess\nimport os\nimport time\nfrom datetime import datetime\ndef task_func(script_dir, scripts, delay):\n    if delay < 0 or not scripts:\n        raise ValueError(\"Delay must be non-negative and scripts must be provided\")\n    timestamps = []\n    for script in scripts:\n        start_time = datetime.now()\n        subprocess.run([os.path.join(script_dir, script)], check=True)\n        end_time = datetime.now()\n        timestamps.append((start_time, end_time))\n        time.sleep(delay)\n    return timestamps", "raw_solution": "import subprocess\nimport os\nimport time\nfrom datetime import datetime\n\ndef task_func(script_dir, scripts, delay):\n    if delay < 0 or not scripts:\n        raise ValueError(\"Delay must be non-negative and scripts must be provided\")\n    timestamps = []\n    for script in scripts:\n        start_time = datetime.now()\n        subprocess.run([os.path.join(script_dir, script)], check=True)\n        end_time = datetime.now()\n        timestamps.append((start_time, end_time))\n        time.sleep(delay)\n    return timestamps\n```"}
{"task_id": "BigCodeBench/460", "solution": "import subprocess\nimport pandas as pd\nimport matplotlib.pyplot as plt\ndef task_func(script_path, output_file_path):\n    try:\n        # Execute the script\n        subprocess.run(['python', script_path], check=True)\n    except subprocess.CalledProcessError as e:\n        raise ValueError(\"The script failed to execute.\")\n    \n    # Read the CSV\n    try:\n        df = pd.read_csv(output_file_path)\n    except pd.errors.EmptyDataError:\n        raise ValueError(\"The produced CSV is empty.\")\n    except pd.errors.ParserError:\n        raise ValueError(\"The produced CSV is not valid.\")\n    \n    # Check if the CSV has exactly 2 columns\n    if df.shape[1] != 2:\n        raise ValueError(\"The CSV does not contain exactly 2 columns.\")\n    \n    # Plot the bar graph\n    ax = df.plot(kind='bar', x=df.columns[0], y=df.columns[1])\n    return df, ax", "raw_solution": "import subprocess\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndef task_func(script_path, output_file_path):\n    try:\n        # Execute the script\n        subprocess.run(['python', script_path], check=True)\n    except subprocess.CalledProcessError as e:\n        raise ValueError(\"The script failed to execute.\")\n    \n    # Read the CSV\n    try:\n        df = pd.read_csv(output_file_path)\n    except pd.errors.EmptyDataError:\n        raise ValueError(\"The produced CSV is empty.\")\n    except pd.errors.ParserError:\n        raise ValueError(\"The produced CSV is not valid.\")\n    \n    # Check if the CSV has exactly 2 columns\n    if df.shape[1] != 2:\n        raise ValueError(\"The CSV does not contain exactly 2 columns.\")\n    \n    # Plot the bar graph\n    ax = df.plot(kind='bar', x=df.columns[0], y=df.columns[1])\n    return df, ax\n```"}
{"task_id": "BigCodeBench/461", "solution": "import subprocess\nimport psutil\nimport time\nimport os\ndef task_func(script_path: str, timeout=10) -> dict:\n    if not os.path.exists(script_path):\n        return {'CPU Usage': 0, 'Memory Usage': 0}\n    try:\n        start_time = time.time()\n        process = subprocess.Popen(['bash', script_path], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n        while True:\n            if process.poll() is not None:\n                break\n            if time.time() - start_time > timeout:\n                break\n            time.sleep(0.1)\n        cpu_usage = process.cpu_percent(interval=1)\n        memory_usage = process.memory_info().rss\n        return {'CPU Usage': cpu_usage, 'Memory Usage': memory_usage}\n    except Exception as e:\n        return {'CPU Usage': 0, 'Memory Usage': 0}", "raw_solution": "import subprocess\nimport psutil\nimport time\nimport os\n\ndef task_func(script_path: str, timeout=10) -> dict:\n    if not os.path.exists(script_path):\n        return {'CPU Usage': 0, 'Memory Usage': 0}\n    try:\n        start_time = time.time()\n        process = subprocess.Popen(['bash', script_path], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n        while True:\n            if process.poll() is not None:\n                break\n            if time.time() - start_time > timeout:\n                break\n            time.sleep(0.1)\n        cpu_usage = process.cpu_percent(interval=1)\n        memory_usage = process.memory_info().rss\n        return {'CPU Usage': cpu_usage, 'Memory Usage': memory_usage}\n    except Exception as e:\n        return {'CPU Usage': 0, 'Memory Usage': 0}\n```"}
{"task_id": "BigCodeBench/462", "solution": "import pandas as pd\nimport random\ndef task_func(num_rows=100, categories=[\"a\", \"b\", \"c\", \"d\", \"e\"], random_seed=42):\n    random.seed(random_seed)\n    df = pd.DataFrame({\n        \"category\": [random.choice(categories) for _ in range(num_rows)],\n        \"value\": [random.randint(1, 100) for _ in range(num_rows)]\n    })\n    ax = df[\"category\"].value_counts().plot(kind=\"bar\")\n    ax.set_title(\"Category Counts\")\n    return df, ax", "raw_solution": "import pandas as pd\nimport random\ndef task_func(num_rows=100, categories=[\"a\", \"b\", \"c\", \"d\", \"e\"], random_seed=42):\n    random.seed(random_seed)\n    df = pd.DataFrame({\n        \"category\": [random.choice(categories) for _ in range(num_rows)],\n        \"value\": [random.randint(1, 100) for _ in range(num_rows)]\n    })\n    ax = df[\"category\"].value_counts().plot(kind=\"bar\")\n    ax.set_title(\"Category Counts\")\n    return df, ax\n```"}
{"task_id": "BigCodeBench/463", "solution": "import numpy as np\nimport pandas as pd\ndef task_func(data_str, separator=\",\", bins=20):\n    if not data_str:\n        raise ValueError(\"Data is empty\")\n    try:\n        data = np.array(data_str.split(separator), dtype=int)\n    except ValueError:\n        raise ValueError(\"Failed to convert data\")\n    series = pd.Series(data)\n    axes = series.hist(grid=True, rwidth=0.9, color='#607c8e')\n    return series, axes", "raw_solution": "import numpy as np\nimport pandas as pd\ndef task_func(data_str, separator=\",\", bins=20):\n    if not data_str:\n        raise ValueError(\"Data is empty\")\n    try:\n        data = np.array(data_str.split(separator), dtype=int)\n    except ValueError:\n        raise ValueError(\"Failed to convert data\")\n    series = pd.Series(data)\n    axes = series.hist(grid=True, rwidth=0.9, color='#607c8e')\n    return series, axes\n```"}
{"task_id": "BigCodeBench/464", "solution": "import json\nfrom datetime import datetime\nfrom decimal import Decimal\ndef task_func(my_obj):\n    return json.dumps(my_obj, default=lambda o: o.__dict__ if hasattr(o, '__dict__') else o)", "raw_solution": "import json\nfrom datetime import datetime\nfrom decimal import Decimal\n\ndef task_func(my_obj):\n    return json.dumps(my_obj, default=lambda o: o.__dict__ if hasattr(o, '__dict__') else o)\n```"}
{"task_id": "BigCodeBench/465", "solution": "import json\nfrom datetime import datetime\nimport numpy as np\nfrom decimal import Decimal\ndef task_func(my_obj):\n    class CustomJSONEncoder(json.JSONEncoder):\n        def default(self, obj):\n            if isinstance(obj, datetime):\n                return obj.isoformat()\n            elif isinstance(obj, np.ndarray):\n                return obj.tolist()\n            elif isinstance(obj, Decimal):\n                return str(obj)\n            return json.JSONEncoder.default(self, obj)\n    return json.dumps(my_obj, cls=CustomJSONEncoder)", "raw_solution": "import json\nfrom datetime import datetime\nimport numpy as np\nfrom decimal import Decimal\n\ndef task_func(my_obj):\n    class CustomJSONEncoder(json.JSONEncoder):\n        def default(self, obj):\n            if isinstance(obj, datetime):\n                return obj.isoformat()\n            elif isinstance(obj, np.ndarray):\n                return obj.tolist()\n            elif isinstance(obj, Decimal):\n                return str(obj)\n            return json.JSONEncoder.default(self, obj)\n    return json.dumps(my_obj, cls=CustomJSONEncoder)\n```"}
{"task_id": "BigCodeBench/466", "solution": "import json\nfrom enum import Enum\ndef task_func(my_obj):\n    return json.dumps(my_obj, cls=CustomJSONEncoder)", "raw_solution": "import json\nfrom enum import Enum\n\nclass Color(Enum):\n    RED = 1\n    GREEN = 2\n    BLUE = 3\n\ndef task_func(my_obj):\n    return json.dumps(my_obj, cls=CustomJSONEncoder)\n```"}
{"task_id": "BigCodeBench/467", "solution": "import matplotlib.pyplot as plt\nimport numpy as np\ndef task_func(n, seed=0):\n    np.random.seed(seed)\n    x = np.random.rand(n)\n    y = np.random.rand(n)\n    plt.figure(figsize=(8, 6))\n    plt.scatter(x, y, color='blue')\n    plt.title('Scatter plot of random points')\n    plt.xlabel('X')\n    plt.ylabel('Y')\n    plt.show()\n    return plt.gcf(), list(zip(x, y))", "raw_solution": "import matplotlib.pyplot as plt\nimport numpy as np\ndef task_func(n, seed=0):\n    np.random.seed(seed)\n    x = np.random.rand(n)\n    y = np.random.rand(n)\n    plt.figure(figsize=(8, 6))\n    plt.scatter(x, y, color='blue')\n    plt.title('Scatter plot of random points')\n    plt.xlabel('X')\n    plt.ylabel('Y')\n    plt.show()\n    return plt.gcf(), list(zip(x, y))\n```"}
{"task_id": "BigCodeBench/468", "solution": "import pandas as pd\nimport numpy as np\ndef task_func(file_path=\"data.csv\", columns=[\"A\", \"B\", \"C\"]):\n    df = pd.read_csv(file_path)\n    df[columns] = df[columns].astype(float)\n    ax = df.plot(kind='line')\n    cube_root = df[columns].apply(np.cbrt)\n    return df, ax, cube_root", "raw_solution": "import pandas as pd\nimport numpy as np\ndef task_func(file_path=\"data.csv\", columns=[\"A\", \"B\", \"C\"]):\n    df = pd.read_csv(file_path)\n    df[columns] = df[columns].astype(float)\n    ax = df.plot(kind='line')\n    cube_root = df[columns].apply(np.cbrt)\n    return df, ax, cube_root\n```"}
{"task_id": "BigCodeBench/469", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nfrom collections import Counter\ndef task_func(student_grades, possible_grades=[\"A\", \"B\", \"C\", \"D\", \"F\"]):\n    # Convert student grades to lower case\n    student_grades = student_grades.lower()\n    # Filter out grades not in possible grades\n    student_grades = [grade for grade in student_grades if grade in possible_grades]\n    # Count the number of each grade\n    grade_counts = Counter(student_grades)\n    # Create a DataFrame with 'Grade' as the named index and their 'Count' as values\n    grade_df = pd.DataFrame(grade_counts, index=['Count'])\n    # Create a bar chart plot\n    grade_df.plot(kind='bar', ax=plt.gca())\n    # Set the title and labels\n    plt.title('Grade Distribution')\n    plt.xlabel('Grade')\n    plt.ylabel('Number of Students')\n    # Show the plot\n    plt.show()\n    # Return the DataFrame and the bar chart plot\n    return grade_df, plt.gca()", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nfrom collections import Counter\n\ndef task_func(student_grades, possible_grades=[\"A\", \"B\", \"C\", \"D\", \"F\"]):\n    # Convert student grades to lower case\n    student_grades = student_grades.lower()\n    # Filter out grades not in possible grades\n    student_grades = [grade for grade in student_grades if grade in possible_grades]\n    # Count the number of each grade\n    grade_counts = Counter(student_grades)\n    # Create a DataFrame with 'Grade' as the named index and their 'Count' as values\n    grade_df = pd.DataFrame(grade_counts, index=['Count'])\n    # Create a bar chart plot\n    grade_df.plot(kind='bar', ax=plt.gca())\n    # Set the title and labels\n    plt.title('Grade Distribution')\n    plt.xlabel('Grade')\n    plt.ylabel('Number of Students')\n    # Show the plot\n    plt.show()\n    # Return the DataFrame and the bar chart plot\n    return grade_df, plt.gca()\n```"}
{"task_id": "BigCodeBench/470", "solution": "import matplotlib.pyplot as plt\nimport numpy as np\ndef task_func(myList):\n    # Create a histogram of the values in the list\n    ax = plt.hist(myList, bins=np.arange(min(myList), max(myList) + 1), edgecolor='black')\n    \n    # Set the labels and title\n    ax.set_xlabel('Value')\n    ax.set_ylabel('Frequency')\n    ax.set_title('Histogram of Values')\n    \n    return ax", "raw_solution": "import matplotlib.pyplot as plt\nimport numpy as np\n\ndef task_func(myList):\n    # Create a histogram of the values in the list\n    ax = plt.hist(myList, bins=np.arange(min(myList), max(myList) + 1), edgecolor='black')\n    \n    # Set the labels and title\n    ax.set_xlabel('Value')\n    ax.set_ylabel('Frequency')\n    ax.set_title('Histogram of Values')\n    \n    return ax\n```"}
{"task_id": "BigCodeBench/471", "solution": "from collections import Counter\nimport pandas as pd\ndef task_func(myList):\n    word_counts = Counter(myList)\n    return pd.DataFrame(word_counts.items(), columns=['Word', 'Count'])", "raw_solution": "from collections import Counter\nimport pandas as pd\n\ndef task_func(myList):\n    word_counts = Counter(myList)\n    return pd.DataFrame(word_counts.items(), columns=['Word', 'Count'])\n```"}
{"task_id": "BigCodeBench/472", "solution": "import matplotlib.pyplot as plt\nfrom sklearn.cluster import KMeans\ndef task_func(myList, n_clusters):\n    if not isinstance(myList, list) or not all(isinstance(item, list) for item in myList):\n        raise ValueError(\"myList must be a list of lists\")\n    if not isinstance(n_clusters, int) or n_clusters <= 0:\n        raise ValueError(\"n_clusters must be a positive integer\")\n    kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)\n    kmeans.fit(myList)\n    plt.scatter(*zip(*myList), c=kmeans.labels_)\n    plt.scatter(*zip(*kmeans.cluster_centers_), c='red', marker='x')\n    plt.show()\n    return plt.axes()", "raw_solution": "import matplotlib.pyplot as plt\nfrom sklearn.cluster import KMeans\n\ndef task_func(myList, n_clusters):\n    if not isinstance(myList, list) or not all(isinstance(item, list) for item in myList):\n        raise ValueError(\"myList must be a list of lists\")\n    if not isinstance(n_clusters, int) or n_clusters <= 0:\n        raise ValueError(\"n_clusters must be a positive integer\")\n    kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)\n    kmeans.fit(myList)\n    plt.scatter(*zip(*myList), c=kmeans.labels_)\n    plt.scatter(*zip(*kmeans.cluster_centers_), c='red', marker='x')\n    plt.show()\n    return plt.axes()\n```"}
{"task_id": "BigCodeBench/473", "solution": "import numpy as np\nimport matplotlib.pyplot as plt\nimport itertools\ndef task_func(n_walks, n_steps, seed=None):\n    if n_walks < 1 or n_steps < 1:\n        raise ValueError(\"n_walks and n_steps must be positive integers\")\n    if seed is not None:\n        np.random.seed(seed)\n    colors = itertools.cycle(['b', 'g', 'r', 'c', 'm', 'y', 'k'])\n    ax = plt.axes()\n    for i in range(n_walks):\n        walk = np.cumsum(np.random.normal(0, 1, n_steps))\n        ax.plot(walk, color=next(colors))\n    ax.set_xlabel('Step')\n    ax.set_ylabel('Position')\n    ax.set_title('Random Walks')\n    return ax", "raw_solution": "import numpy as np\nimport matplotlib.pyplot as plt\nimport itertools\n\ndef task_func(n_walks, n_steps, seed=None):\n    if n_walks < 1 or n_steps < 1:\n        raise ValueError(\"n_walks and n_steps must be positive integers\")\n    if seed is not None:\n        np.random.seed(seed)\n    colors = itertools.cycle(['b', 'g', 'r', 'c', 'm', 'y', 'k'])\n    ax = plt.axes()\n    for i in range(n_walks):\n        walk = np.cumsum(np.random.normal(0, 1, n_steps))\n        ax.plot(walk, color=next(colors))\n    ax.set_xlabel('Step')\n    ax.set_ylabel('Position')\n    ax.set_title('Random Walks')\n    return ax\n```"}
{"task_id": "BigCodeBench/474", "solution": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import norm\ndef task_func(n_samples=1000, mu=0, sigma=1, random_seed=0):\n    np.random.seed(random_seed)\n    samples = np.random.normal(mu, sigma, n_samples)\n    ax = plt.hist(samples, bins=50, density=True, alpha=0.6, color='g')\n    x = np.linspace(mu - 3*sigma, mu + 3*sigma, 100)\n    y = norm.pdf(x, mu, sigma)\n    ax.plot(x, y, 'r', linewidth=2)\n    return ax, samples", "raw_solution": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import norm\n\ndef task_func(n_samples=1000, mu=0, sigma=1, random_seed=0):\n    np.random.seed(random_seed)\n    samples = np.random.normal(mu, sigma, n_samples)\n    ax = plt.hist(samples, bins=50, density=True, alpha=0.6, color='g')\n    x = np.linspace(mu - 3*sigma, mu + 3*sigma, 100)\n    y = norm.pdf(x, mu, sigma)\n    ax.plot(x, y, 'r', linewidth=2)\n    return ax, samples\n```"}
{"task_id": "BigCodeBench/475", "solution": "import pandas as pd\nfrom datetime import datetime\ndef task_func(data, date_format, country, country_codes=None):\n    if not isinstance(data, pd.DataFrame):\n        raise ValueError('If \\'data\\' is not a DataFrame')\n    if not isinstance(date_format, str):\n        raise ValueError('If \\'date_format\\' is not a string')\n    if country not in country_codes:\n        raise ValueError('If \\'country\\' is not in \\'country_codes\\'')\n    if not isinstance(country_codes, dict):\n        raise ValueError('If \\'country_codes\\' is not a dictionary')\n    data['date'] = pd.to_datetime(data['date'], format=date_format)\n    data = data[data['country'] == country]\n    data = data.groupby('date')['date'].count().reset_index(name='frequency')\n    fig, ax = plt.subplots()\n    ax.hist(data['date'], bins=30, edgecolor='black')\n    ax.set_title('Date Distribution')\n    ax.set_xlabel('Date')\n    ax.set_ylabel('Frequency')\n    return ax", "raw_solution": "import pandas as pd\nfrom datetime import datetime\ndef task_func(data, date_format, country, country_codes=None):\n    if not isinstance(data, pd.DataFrame):\n        raise ValueError('If \\'data\\' is not a DataFrame')\n    if not isinstance(date_format, str):\n        raise ValueError('If \\'date_format\\' is not a string')\n    if country not in country_codes:\n        raise ValueError('If \\'country\\' is not in \\'country_codes\\'')\n    if not isinstance(country_codes, dict):\n        raise ValueError('If \\'country_codes\\' is not a dictionary')\n    data['date'] = pd.to_datetime(data['date'], format=date_format)\n    data = data[data['country'] == country]\n    data = data.groupby('date')['date'].count().reset_index(name='frequency')\n    fig, ax = plt.subplots()\n    ax.hist(data['date'], bins=30, edgecolor='black')\n    ax.set_title('Date Distribution')\n    ax.set_xlabel('Date')\n    ax.set_ylabel('Frequency')\n    return ax\n```"}
{"task_id": "BigCodeBench/476", "solution": "import matplotlib.pyplot as plt\nfrom scipy.optimize import curve_fit\ndef task_func(X, Y):\n    # Define the quadratic function\n    def quadratic_func(X, a, b, c):\n        return a * X**2 + b * X + c\n    # Fit the quadratic function to the data\n    popt, pcov = curve_fit(quadratic_func, X, Y)\n    # Return the optimized parameters and the plot\n    return popt, plt.scatter(X, Y, color='red') + plt.plot(X, quadratic_func(X, *popt), color='blue')", "raw_solution": "import matplotlib.pyplot as plt\nfrom scipy.optimize import curve_fit\n\ndef task_func(X, Y):\n    # Define the quadratic function\n    def quadratic_func(X, a, b, c):\n        return a * X**2 + b * X + c\n    # Fit the quadratic function to the data\n    popt, pcov = curve_fit(quadratic_func, X, Y)\n    # Return the optimized parameters and the plot\n    return popt, plt.scatter(X, Y, color='red') + plt.plot(X, quadratic_func(X, *popt), color='blue')\n```"}
{"task_id": "BigCodeBench/477", "solution": "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\ndef task_func(N=100, CATEGORIES=[\"A\", \"B\", \"C\", \"D\", \"E\"], seed=42):\n    np.random.seed(seed)\n    df = pd.DataFrame({\n        \"x\": np.random.rand(N),\n        \"y\": np.random.rand(N),\n        \"category\": np.random.choice(CATEGORIES, size=N, replace=False)\n    })\n    ax = df.plot.scatter(x=\"x\", y=\"y\", c=\"category\")\n    return df, ax", "raw_solution": "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndef task_func(N=100, CATEGORIES=[\"A\", \"B\", \"C\", \"D\", \"E\"], seed=42):\n    np.random.seed(seed)\n    df = pd.DataFrame({\n        \"x\": np.random.rand(N),\n        \"y\": np.random.rand(N),\n        \"category\": np.random.choice(CATEGORIES, size=N, replace=False)\n    })\n    ax = df.plot.scatter(x=\"x\", y=\"y\", c=\"category\")\n    return df, ax\n```"}
{"task_id": "BigCodeBench/478", "solution": "import pandas as pd\nimport re\nimport random\ndef task_func(data_list, seed=None):\n    if seed is not None:\n        random.seed(seed)\n    df = pd.DataFrame({'Original String': data_list})\n    df['Modified String'] = df['Original String'].apply(lambda x: re.sub(r',\\s*(\\w+)', '', x))\n    return df", "raw_solution": "import pandas as pd\nimport re\nimport random\n\ndef task_func(data_list, seed=None):\n    if seed is not None:\n        random.seed(seed)\n    df = pd.DataFrame({'Original String': data_list})\n    df['Modified String'] = df['Original String'].apply(lambda x: re.sub(r',\\s*(\\w+)', '', x))\n    return df\n```"}
{"task_id": "BigCodeBench/479", "solution": "import random\nimport string\nimport pandas as pd\ndef task_func(data_list, seed=0):\n    random.seed(seed)\n    df = pd.DataFrame({'Original String': data_list})\n    for i in range(len(data_list)):\n        s = data_list[i]\n        if ',' in s:\n            start = s.find(',')\n            end = s.rfind(',')\n            if start == -1:\n                start = 0\n            if end == -1:\n                end = len(s)\n            s = s[:start] + ''.join(random.choices(string.ascii_lowercase, k=end-start)) + s[end:]\n        else:\n            s = ''.join(random.choices(string.ascii_lowercase, k=len(s)))\n        df.at[i, 'Modified String'] = s\n    return df", "raw_solution": "import random\nimport string\nimport pandas as pd\n\ndef task_func(data_list, seed=0):\n    random.seed(seed)\n    df = pd.DataFrame({'Original String': data_list})\n    for i in range(len(data_list)):\n        s = data_list[i]\n        if ',' in s:\n            start = s.find(',')\n            end = s.rfind(',')\n            if start == -1:\n                start = 0\n            if end == -1:\n                end = len(s)\n            s = s[:start] + ''.join(random.choices(string.ascii_lowercase, k=end-start)) + s[end:]\n        else:\n            s = ''.join(random.choices(string.ascii_lowercase, k=len(s)))\n        df.at[i, 'Modified String'] = s\n    return df\n```"}
{"task_id": "BigCodeBench/480", "solution": "import re\nimport random\nimport pandas as pd\ndef task_func(data_list, seed=None):\n    if seed is not None:\n        random.seed(seed)\n    df = pd.DataFrame(columns=['Original String', 'Shuffled String'])\n    for data in data_list:\n        substrings = re.split(r',\\s*', data)\n        substrings = [s.strip() for s in substrings]\n        random.shuffle(substrings)\n        df = df.append({'Original String': data, 'Shuffled String': ','.join(substrings)}, ignore_index=True)\n    return df", "raw_solution": "import re\nimport random\nimport pandas as pd\n\ndef task_func(data_list, seed=None):\n    if seed is not None:\n        random.seed(seed)\n    df = pd.DataFrame(columns=['Original String', 'Shuffled String'])\n    for data in data_list:\n        substrings = re.split(r',\\s*', data)\n        substrings = [s.strip() for s in substrings]\n        random.shuffle(substrings)\n        df = df.append({'Original String': data, 'Shuffled String': ','.join(substrings)}, ignore_index=True)\n    return df\n```"}
{"task_id": "BigCodeBench/481", "solution": "import pandas as pd\nimport random\nimport re\ndef task_func(data_list, seed=42):\n    random.seed(seed)\n    randomized_list = []\n    for string in data_list:\n        randomized_string = re.sub(r'\\s*,\\s*', ', ', string)\n        randomized_list.append(randomized_string)\n    df = pd.DataFrame({'Original String': data_list, 'Randomized String': randomized_list})\n    return df", "raw_solution": "import pandas as pd\nimport random\nimport re\n\ndef task_func(data_list, seed=42):\n    random.seed(seed)\n    randomized_list = []\n    for string in data_list:\n        randomized_string = re.sub(r'\\s*,\\s*', ', ', string)\n        randomized_list.append(randomized_string)\n    df = pd.DataFrame({'Original String': data_list, 'Randomized String': randomized_list})\n    return df\n```"}
{"task_id": "BigCodeBench/482", "solution": "import pandas as pd\nimport random\nimport re\ndef task_func(data_list, seed=None):\n    if seed is not None:\n        random.seed(seed)\n    df = pd.DataFrame({'Original String': data_list})\n    for i in range(len(data_list)):\n        string = data_list[i]\n        if len(string) == 1:\n            continue\n        substrings = re.split(r',\\s*', string)\n        operation = random.choice(['remove', 'replace', 'shuffle', 'randomize'])\n        if operation == 'remove':\n            index = random.randint(0, len(substrings) - 1)\n            substrings.pop(index)\n        elif operation == 'replace':\n            index = random.randint(0, len(substrings) - 1)\n            substrings[index] = 'random_string'\n        elif operation == 'shuffle':\n            random.shuffle(substrings)\n        elif operation == 'randomize':\n            random.shuffle(substrings)\n        modified_string = ','.join(substrings)\n        df.at[i, 'Modified String'] = modified_string\n    return df", "raw_solution": "import pandas as pd\nimport random\nimport re\n\ndef task_func(data_list, seed=None):\n    if seed is not None:\n        random.seed(seed)\n    df = pd.DataFrame({'Original String': data_list})\n    for i in range(len(data_list)):\n        string = data_list[i]\n        if len(string) == 1:\n            continue\n        substrings = re.split(r',\\s*', string)\n        operation = random.choice(['remove', 'replace', 'shuffle', 'randomize'])\n        if operation == 'remove':\n            index = random.randint(0, len(substrings) - 1)\n            substrings.pop(index)\n        elif operation == 'replace':\n            index = random.randint(0, len(substrings) - 1)\n            substrings[index] = 'random_string'\n        elif operation == 'shuffle':\n            random.shuffle(substrings)\n        elif operation == 'randomize':\n            random.shuffle(substrings)\n        modified_string = ','.join(substrings)\n        df.at[i, 'Modified String'] = modified_string\n    return df\n```"}
{"task_id": "BigCodeBench/483", "solution": "import re\nimport pandas as pd\ndef task_func(df: pd.DataFrame, column_name: str, pattern: str) -> pd.DataFrame:\n    def reverse_words(match):\n        words = match.group(0).split()\n        if pattern:\n            words = [word for word in words if re.match(pattern, word)]\n        return ' '.join(words[::-1])\n    return df[column_name].apply(reverse_words).str.replace(r'\\s+', ' ', regex=True)", "raw_solution": "import re\nimport pandas as pd\n\ndef task_func(df: pd.DataFrame, column_name: str, pattern: str) -> pd.DataFrame:\n    def reverse_words(match):\n        words = match.group(0).split()\n        if pattern:\n            words = [word for word in words if re.match(pattern, word)]\n        return ' '.join(words[::-1])\n    return df[column_name].apply(reverse_words).str.replace(r'\\s+', ' ', regex=True)\n```"}
{"task_id": "BigCodeBench/484", "solution": "import math\nimport numpy as np\nfrom datetime import datetime\nimport pandas as pd\ndef task_func(\n    start_time,\n    end_time,\n    step,\n    columns=[\"Timestamp\", \"Sensor1\", \"Sensor2\", \"Sensor3\", \"SensorStatus\"],\n    sensor_statuses=[\"OK\", \"MAINTENANCE_REQUIRED\", \"ERROR\"],\n    random_seed=42,\n):\n    np.random.seed(random_seed)\n    timestamps = pd.date_range(start=start_time, end=end_time, freq=step)\n    sensor1 = np.sin(np.array(timestamps) * 2 * np.pi / 86400) + np.random.normal(0, 0.1)\n    sensor2 = np.cos(np.array(timestamps) * 2 * np.pi / 86400) + np.random.normal(0, 0.1)\n    sensor3 = np.tan(np.array(timestamps) * 2 * np.pi / 86400) + np.random.normal(0, 0.1)\n    sensor_status = np.random.choice(sensor_statuses, len(timestamps))\n    df = pd.DataFrame(\n        {\n            columns[0]: timestamps,\n            columns[1]: sensor1,\n            columns[2]: sensor2,\n            columns[3]: sensor3,\n            columns[4]: sensor_status,\n        }\n    )\n    return df", "raw_solution": "import math\nimport numpy as np\nfrom datetime import datetime\nimport pandas as pd\ndef task_func(\n    start_time,\n    end_time,\n    step,\n    columns=[\"Timestamp\", \"Sensor1\", \"Sensor2\", \"Sensor3\", \"SensorStatus\"],\n    sensor_statuses=[\"OK\", \"MAINTENANCE_REQUIRED\", \"ERROR\"],\n    random_seed=42,\n):\n    np.random.seed(random_seed)\n    timestamps = pd.date_range(start=start_time, end=end_time, freq=step)\n    sensor1 = np.sin(np.array(timestamps) * 2 * np.pi / 86400) + np.random.normal(0, 0.1)\n    sensor2 = np.cos(np.array(timestamps) * 2 * np.pi / 86400) + np.random.normal(0, 0.1)\n    sensor3 = np.tan(np.array(timestamps) * 2 * np.pi / 86400) + np.random.normal(0, 0.1)\n    sensor_status = np.random.choice(sensor_statuses, len(timestamps))\n    df = pd.DataFrame(\n        {\n            columns[0]: timestamps,\n            columns[1]: sensor1,\n            columns[2]: sensor2,\n            columns[3]: sensor3,\n            columns[4]: sensor_status,\n        }\n    )\n    return df\n```"}
{"task_id": "BigCodeBench/485", "solution": "from datetime import datetime, timedelta\nimport pytz\nimport numpy as np\nimport matplotlib.pyplot as plt\ndef task_func(start_time, end_time):\n    # Define the time zones\n    time_zones = [\"UTC\", \"America/Los_Angeles\", \"Europe/Paris\", \"Asia/Kolkata\", \"Australia/Sydney\"]\n    # Define the color palette\n    colors = [\"b\", \"g\", \"r\", \"c\", \"m\", \"y\", \"k\"]\n    # Convert the start and end times to datetime objects\n    start_time = datetime.strptime(start_time, \"%Y-%m-%d %H:%M:%S\")\n    end_time = datetime.strptime(end_time, \"%Y-%m-%d %H:%M:%S\")\n    # Create a list to store the time differences\n    time_differences = []\n    # Loop through each time zone\n    for i, time_zone in enumerate(time_zones):\n        # Create a timezone object\n        tz = pytz.timezone(time_zone)\n        # Convert the start and end times to the specified time zone\n        start_time_tz = start_time.astimezone(tz)\n        end_time_tz = end_time.astimezone(tz)\n        # Calculate the time difference in hours\n        time_difference = (end_time_tz - start_time_tz).total_seconds() / 3600\n        # Append the time difference to the list\n        time_differences.append(time_difference)\n    # Create a figure and axes object\n    fig, ax = plt.subplots()\n    # Plot the time differences\n    ax.plot(time_differences, color=colors)\n    # Set the x-axis label\n    ax.set_xlabel(\"Date\")\n    # Set the y-axis label\n    ax.set_ylabel(\"Time Difference (hours)\")\n    # Set the title\n    ax.set_title(\"Hourly Difference Between UTC and Time Zones\")\n    # Show the plot\n    plt.show()\n    # Return the Axes object\n    return ax", "raw_solution": "from datetime import datetime, timedelta\nimport pytz\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef task_func(start_time, end_time):\n    # Define the time zones\n    time_zones = [\"UTC\", \"America/Los_Angeles\", \"Europe/Paris\", \"Asia/Kolkata\", \"Australia/Sydney\"]\n    # Define the color palette\n    colors = [\"b\", \"g\", \"r\", \"c\", \"m\", \"y\", \"k\"]\n    # Convert the start and end times to datetime objects\n    start_time = datetime.strptime(start_time, \"%Y-%m-%d %H:%M:%S\")\n    end_time = datetime.strptime(end_time, \"%Y-%m-%d %H:%M:%S\")\n    # Create a list to store the time differences\n    time_differences = []\n    # Loop through each time zone\n    for i, time_zone in enumerate(time_zones):\n        # Create a timezone object\n        tz = pytz.timezone(time_zone)\n        # Convert the start and end times to the specified time zone\n        start_time_tz = start_time.astimezone(tz)\n        end_time_tz = end_time.astimezone(tz)\n        # Calculate the time difference in hours\n        time_difference = (end_time_tz - start_time_tz).total_seconds() / 3600\n        # Append the time difference to the list\n        time_differences.append(time_difference)\n    # Create a figure and axes object\n    fig, ax = plt.subplots()\n    # Plot the time differences\n    ax.plot(time_differences, color=colors)\n    # Set the x-axis label\n    ax.set_xlabel(\"Date\")\n    # Set the y-axis label\n    ax.set_ylabel(\"Time Difference (hours)\")\n    # Set the title\n    ax.set_title(\"Hourly Difference Between UTC and Time Zones\")\n    # Show the plot\n    plt.show()\n    # Return the Axes object\n    return ax\n```"}
{"task_id": "BigCodeBench/486", "solution": "from datetime import datetime\nimport pandas as pd\nimport numpy as np\ndef task_func(start_time, end_time, step, trend, seed=42):\n    np.random.seed(seed)\n    start_time = datetime.strptime(start_time, '%Y-%m-%d %H:%M:%S')\n    end_time = datetime.strptime(end_time, '%Y-%m-%d %H:%M:%S')\n    time_series = pd.date_range(start=start_time, end=end_time, freq=f'{step}S')\n    values = np.random.normal(loc=0, scale=1, size=len(time_series))\n    values = np.cumsum(values) * trend\n    ax = time_series.plot(x='Time', y='Value')\n    ax.set_xlabel('Time')\n    ax.set_ylabel('Value')\n    return ax", "raw_solution": "from datetime import datetime\nimport pandas as pd\nimport numpy as np\ndef task_func(start_time, end_time, step, trend, seed=42):\n    np.random.seed(seed)\n    start_time = datetime.strptime(start_time, '%Y-%m-%d %H:%M:%S')\n    end_time = datetime.strptime(end_time, '%Y-%m-%d %H:%M:%S')\n    time_series = pd.date_range(start=start_time, end=end_time, freq=f'{step}S')\n    values = np.random.normal(loc=0, scale=1, size=len(time_series))\n    values = np.cumsum(values) * trend\n    ax = time_series.plot(x='Time', y='Value')\n    ax.set_xlabel('Time')\n    ax.set_ylabel('Value')\n    return ax\n```"}
{"task_id": "BigCodeBench/487", "solution": "import os\nimport pandas as pd\nimport re\ndef task_func(file_path: str) -> pd.DataFrame:\n    if not os.path.exists(file_path):\n        raise FileNotFoundError(\"File not found\")\n    log_entries = []\n    with open(file_path, 'r') as f:\n        for line in f:\n            match = re.match(r'(\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2}\\.\\d{6}) - (\\w+) - (.*)', line)\n            if match:\n                log_entries.append({\n                    'Timestamp': match.group(1),\n                    'Level': match.group(2),\n                    'Message': match.group(3)\n                })\n    if not log_entries:\n        return pd.DataFrame(columns=['Timestamp', 'Level', 'Message'])\n    return pd.DataFrame(log_entries)", "raw_solution": "import os\nimport pandas as pd\nimport re\ndef task_func(file_path: str) -> pd.DataFrame:\n    if not os.path.exists(file_path):\n        raise FileNotFoundError(\"File not found\")\n    log_entries = []\n    with open(file_path, 'r') as f:\n        for line in f:\n            match = re.match(r'(\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2}\\.\\d{6}) - (\\w+) - (.*)', line)\n            if match:\n                log_entries.append({\n                    'Timestamp': match.group(1),\n                    'Level': match.group(2),\n                    'Message': match.group(3)\n                })\n    if not log_entries:\n        return pd.DataFrame(columns=['Timestamp', 'Level', 'Message'])\n    return pd.DataFrame(log_entries)\n```"}
{"task_id": "BigCodeBench/488", "solution": "from datetime import datetime\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\ndef task_func(start_time, end_time, step, amplitude, period, seed=0):\n    np.random.seed(seed)\n    time = pd.date_range(start=start_time, end=end_time, freq=step)\n    seasonality = np.sin(2 * np.pi * time / period)\n    time_series = amplitude * seasonality\n    plt.plot(time, time_series)\n    plt.xlabel('Timestamp')\n    plt.ylabel('Value')\n    plt.show()\n    return plt.gca()", "raw_solution": "from datetime import datetime\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef task_func(start_time, end_time, step, amplitude, period, seed=0):\n    np.random.seed(seed)\n    time = pd.date_range(start=start_time, end=end_time, freq=step)\n    seasonality = np.sin(2 * np.pi * time / period)\n    time_series = amplitude * seasonality\n    plt.plot(time, time_series)\n    plt.xlabel('Timestamp')\n    plt.ylabel('Value')\n    plt.show()\n    return plt.gca()\n```"}
{"task_id": "BigCodeBench/489", "solution": "import pandas as pd\nfrom datetime import datetime, timedelta\nimport random\ndef task_func(epoch_milliseconds, seed=0):\n    random.seed(seed)\n    start_time = datetime.fromtimestamp(epoch_milliseconds / 1000)\n    current_time = datetime.now()\n    if start_time > current_time:\n        raise ValueError(\"Start time is after the current system time.\")\n    users = ['user1', 'user2', 'user3', 'user4', 'user5']\n    activities = ['login', 'logout', 'browse', 'search', 'purchase']\n    logs = []\n    while start_time <= current_time:\n        user = random.choice(users)\n        activity = random.choice(activities)\n        time = start_time + timedelta(seconds=random.randint(1, 10))\n        logs.append({'User': user, 'Activity': activity, 'Time': time})\n        start_time = time\n    return pd.DataFrame(logs)", "raw_solution": "import pandas as pd\nfrom datetime import datetime, timedelta\nimport random\n\ndef task_func(epoch_milliseconds, seed=0):\n    random.seed(seed)\n    start_time = datetime.fromtimestamp(epoch_milliseconds / 1000)\n    current_time = datetime.now()\n    if start_time > current_time:\n        raise ValueError(\"Start time is after the current system time.\")\n    users = ['user1', 'user2', 'user3', 'user4', 'user5']\n    activities = ['login', 'logout', 'browse', 'search', 'purchase']\n    logs = []\n    while start_time <= current_time:\n        user = random.choice(users)\n        activity = random.choice(activities)\n        time = start_time + timedelta(seconds=random.randint(1, 10))\n        logs.append({'User': user, 'Activity': activity, 'Time': time})\n        start_time = time\n    return pd.DataFrame(logs)\n```"}
{"task_id": "BigCodeBench/490", "solution": "import xmltodict\nimport json\ndef task_func(s, file_path):\n    xml_dict = xmltodict.parse(s)\n    with open(file_path, 'w') as f:\n        json.dump(xml_dict, f)", "raw_solution": "import xmltodict\nimport json\ndef task_func(s, file_path):\n    xml_dict = xmltodict.parse(s)\n    with open(file_path, 'w') as f:\n        json.dump(xml_dict, f)\n```"}
{"task_id": "BigCodeBench/491", "solution": "import random\nfrom datetime import datetime\nimport matplotlib.pyplot as plt\ndef task_func(epoch_milliseconds, seed=None):\n    if epoch_milliseconds < 0 or epoch_milliseconds > datetime.utcnow().timestamp():\n        raise ValueError(\"If the start time is negative or after the current time.\")\n    random.seed(seed)\n    sales_data = {}\n    for category in ['Electronics', 'Clothing', 'Home', 'Books', 'Sports']:\n        sales_data[category] = [random.randint(10, 50) for _ in range(365)]\n    ax = plt.figure(figsize=(10, 6)).add_subplot(111)\n    for category, sales in sales_data.items():\n        ax.plot(range(365), sales, label=category)\n    ax.set_xlabel('Days since (the start date)')\n    ax.set_ylabel('Sales')\n    ax.set_title('Sales trend for different categories')\n    ax.legend()\n    return sales_data, ax", "raw_solution": "import random\nfrom datetime import datetime\nimport matplotlib.pyplot as plt\n\ndef task_func(epoch_milliseconds, seed=None):\n    if epoch_milliseconds < 0 or epoch_milliseconds > datetime.utcnow().timestamp():\n        raise ValueError(\"If the start time is negative or after the current time.\")\n    random.seed(seed)\n    sales_data = {}\n    for category in ['Electronics', 'Clothing', 'Home', 'Books', 'Sports']:\n        sales_data[category] = [random.randint(10, 50) for _ in range(365)]\n    ax = plt.figure(figsize=(10, 6)).add_subplot(111)\n    for category, sales in sales_data.items():\n        ax.plot(range(365), sales, label=category)\n    ax.set_xlabel('Days since (the start date)')\n    ax.set_ylabel('Sales')\n    ax.set_title('Sales trend for different categories')\n    ax.legend()\n    return sales_data, ax\n```"}
{"task_id": "BigCodeBench/492", "solution": "import pandas as pd\nfrom datetime import datetime\nimport random\ndef task_func(\n    epoch_milliseconds,\n    random_seed=0,\n    products=[\"Product1\", \"Product2\", \"Product3\", \"Product4\", \"Product5\"],\n):\n    random.seed(random_seed)\n    start_date = datetime.fromtimestamp(epoch_milliseconds / 1000)\n    end_date = datetime.now()\n    delta = end_date - start_date\n    days = delta.days + 1\n    sales_data = []\n    for day in range(days):\n        for product in products:\n            sales_data.append({\n                'Product': product,\n                'Date': start_date + datetime.timedelta(days=day),\n                'Sales': random.randint(10, 50)\n            })\n    return pd.DataFrame(sales_data)", "raw_solution": "import pandas as pd\nfrom datetime import datetime\nimport random\n\ndef task_func(\n    epoch_milliseconds,\n    random_seed=0,\n    products=[\"Product1\", \"Product2\", \"Product3\", \"Product4\", \"Product5\"],\n):\n    random.seed(random_seed)\n    start_date = datetime.fromtimestamp(epoch_milliseconds / 1000)\n    end_date = datetime.now()\n    delta = end_date - start_date\n    days = delta.days + 1\n    sales_data = []\n    for day in range(days):\n        for product in products:\n            sales_data.append({\n                'Product': product,\n                'Date': start_date + datetime.timedelta(days=day),\n                'Sales': random.randint(10, 50)\n            })\n    return pd.DataFrame(sales_data)\n```"}
{"task_id": "BigCodeBench/493", "solution": "from datetime import datetime\nimport random\nimport matplotlib.pyplot as plt\ndef task_func(\n    epoch_milliseconds,\n    teams=[\"Team1\", \"Team2\", \"Team3\", \"Team4\", \"Team5\"],\n    random_seed=0,\n):\n    random.seed(random_seed)\n    start_date = datetime.fromtimestamp(epoch_milliseconds / 1000)\n    end_date = datetime.now()\n    days = (end_date - start_date).days\n    performance_data = {}\n    for team in teams:\n        performance_data[team] = [random.uniform(0.1, 1) for _ in range(days)]\n    fig, ax = plt.subplots()\n    for team, performance in performance_data.items():\n        ax.plot(range(days), performance, label=team)\n    ax.set_xlabel(\"Days since start date\")\n    ax.set_ylabel(\"Performance\")\n    ax.set_title(\"Performance trend for different teams\")\n    ax.legend()\n    return performance_data, fig", "raw_solution": "from datetime import datetime\nimport random\nimport matplotlib.pyplot as plt\n\ndef task_func(\n    epoch_milliseconds,\n    teams=[\"Team1\", \"Team2\", \"Team3\", \"Team4\", \"Team5\"],\n    random_seed=0,\n):\n    random.seed(random_seed)\n    start_date = datetime.fromtimestamp(epoch_milliseconds / 1000)\n    end_date = datetime.now()\n    days = (end_date - start_date).days\n    performance_data = {}\n    for team in teams:\n        performance_data[team] = [random.uniform(0.1, 1) for _ in range(days)]\n    fig, ax = plt.subplots()\n    for team, performance in performance_data.items():\n        ax.plot(range(days), performance, label=team)\n    ax.set_xlabel(\"Days since start date\")\n    ax.set_ylabel(\"Performance\")\n    ax.set_title(\"Performance trend for different teams\")\n    ax.legend()\n    return performance_data, fig\n```"}
{"task_id": "BigCodeBench/494", "solution": "from datetime import datetime\nimport pytz\nimport re\nfrom faker import Faker\ndef task_func(epoch_milliseconds, seed=0, timezones=[\"UTC\"]):\n    Faker.seed(seed)\n    fake = Faker()\n    event_name = fake.event_name()\n    event_time = datetime.fromtimestamp(epoch_milliseconds / 1000)\n    valid_timezones = [tz for tz in pytz.all_timezones if tz in timezones or re.match(r'^UTC\\+([+-]\\d{2}:\\d{2})$', tz)]\n    if not valid_timezones:\n        timezone = \"UTC\"\n    else:\n        timezone = Faker().random_element(valid_timezones)\n    event_details = {\n        \"date\": event_time.strftime(\"%Y-%m-%d\"),\n        \"time\": event_time.strftime(\"%H:%M:%S\"),\n        \"timezone\": timezone\n    }\n    return {event_name: [event_details]}", "raw_solution": "from datetime import datetime\nimport pytz\nimport re\nfrom faker import Faker\n\ndef task_func(epoch_milliseconds, seed=0, timezones=[\"UTC\"]):\n    Faker.seed(seed)\n    fake = Faker()\n    event_name = fake.event_name()\n    event_time = datetime.fromtimestamp(epoch_milliseconds / 1000)\n    valid_timezones = [tz for tz in pytz.all_timezones if tz in timezones or re.match(r'^UTC\\+([+-]\\d{2}:\\d{2})$', tz)]\n    if not valid_timezones:\n        timezone = \"UTC\"\n    else:\n        timezone = Faker().random_element(valid_timezones)\n    event_details = {\n        \"date\": event_time.strftime(\"%Y-%m-%d\"),\n        \"time\": event_time.strftime(\"%H:%M:%S\"),\n        \"timezone\": timezone\n    }\n    return {event_name: [event_details]}\n```"}
{"task_id": "BigCodeBench/495", "solution": "import pandas as pd\nimport numpy as np\ndef task_func(days, random_seed=0):\n    np.random.seed(random_seed)\n    df = pd.DataFrame(index=pd.date_range(start='2023-01-01', periods=days, freq='D'))\n    df['Groceries'] = np.random.randint(0, 101, size=days)\n    df['Entertainment'] = np.random.randint(0, 101, size=days)\n    df['Rent'] = np.random.randint(0, 101, size=days)\n    df['Utilities'] = np.random.randint(0, 101, size=days)\n    df['Miscellaneous'] = np.random.randint(0, 101, size=days)\n    return df", "raw_solution": "import pandas as pd\nimport numpy as np\n\ndef task_func(days, random_seed=0):\n    np.random.seed(random_seed)\n    df = pd.DataFrame(index=pd.date_range(start='2023-01-01', periods=days, freq='D'))\n    df['Groceries'] = np.random.randint(0, 101, size=days)\n    df['Entertainment'] = np.random.randint(0, 101, size=days)\n    df['Rent'] = np.random.randint(0, 101, size=days)\n    df['Utilities'] = np.random.randint(0, 101, size=days)\n    df['Miscellaneous'] = np.random.randint(0, 101, size=days)\n    return df\n```"}
{"task_id": "BigCodeBench/496", "solution": "from datetime import datetime, timedelta\nimport numpy as np\nimport matplotlib.pyplot as plt\ndef task_func(days_in_past=7, random_seed=0):\n    if days_in_past < 1:\n        raise ValueError(\"If days_in_past is less than 1.\")\n    np.random.seed(random_seed)\n    dates = [datetime.now() - timedelta(days=i) for i in range(days_in_past)]\n    temperatures = np.random.randint(15, 36, days_in_past)\n    ax = plt.plot(dates, temperatures)\n    plt.xlabel('Date')\n    plt.ylabel('Temperature (\u00b0C)')\n    return ax", "raw_solution": "from datetime import datetime, timedelta\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef task_func(days_in_past=7, random_seed=0):\n    if days_in_past < 1:\n        raise ValueError(\"If days_in_past is less than 1.\")\n    np.random.seed(random_seed)\n    dates = [datetime.now() - timedelta(days=i) for i in range(days_in_past)]\n    temperatures = np.random.randint(15, 36, days_in_past)\n    ax = plt.plot(dates, temperatures)\n    plt.xlabel('Date')\n    plt.ylabel('Temperature (\u00b0C)')\n    return ax\n```"}
{"task_id": "BigCodeBench/497", "solution": "from datetime import datetime, timedelta\nimport pytz\nimport calendar\ndef task_func(days_in_past=7):\n    if days_in_past < 0:\n        raise ValueError(\"days_in_past must be non-negative\")\n    target_date = datetime.now(pytz.utc) - timedelta(days=days_in_past)\n    weekday = calendar.day_name[target_date.weekday()]\n    return weekday", "raw_solution": "from datetime import datetime, timedelta\nimport pytz\nimport calendar\ndef task_func(days_in_past=7):\n    if days_in_past < 0:\n        raise ValueError(\"days_in_past must be non-negative\")\n    target_date = datetime.now(pytz.utc) - timedelta(days=days_in_past)\n    weekday = calendar.day_name[target_date.weekday()]\n    return weekday\n```"}
{"task_id": "BigCodeBench/498", "solution": "import xmltodict\nimport json\ndef task_func(s, save_json, json_file_path):\n    if not s.strip():\n        raise ValueError(\"Input XML string is empty or contains only whitespace.\")\n    result = xmltodict.parse(s)\n    if save_json:\n        with open(json_file_path, 'w') as f:\n            json.dump(result, f)\n    return result", "raw_solution": "import xmltodict\nimport json\n\ndef task_func(s, save_json, json_file_path):\n    if not s.strip():\n        raise ValueError(\"Input XML string is empty or contains only whitespace.\")\n    result = xmltodict.parse(s)\n    if save_json:\n        with open(json_file_path, 'w') as f:\n            json.dump(result, f)\n    return result\n```"}
{"task_id": "BigCodeBench/499", "solution": "import xlwt\nimport os\nimport io\nimport csv\ndef task_func(csv_content, filename):\n    # Create a new Excel workbook\n    workbook = xlwt.Workbook()\n    # Create a new sheet\n    sheet = workbook.add_sheet('Sheet 1')\n    # Write the CSV content into the sheet\n    sheet.write(0, 0, csv_content)\n    # Save the workbook as an Excel file\n    workbook.save(filename)\n    # Return the absolute path of the created Excel file\n    return os.path.abspath(filename)", "raw_solution": "import xlwt\nimport os\nimport io\nimport csv\n\ndef task_func(csv_content, filename):\n    # Create a new Excel workbook\n    workbook = xlwt.Workbook()\n    # Create a new sheet\n    sheet = workbook.add_sheet('Sheet 1')\n    # Write the CSV content into the sheet\n    sheet.write(0, 0, csv_content)\n    # Save the workbook as an Excel file\n    workbook.save(filename)\n    # Return the absolute path of the created Excel file\n    return os.path.abspath(filename)\n```"}
{"task_id": "BigCodeBench/500", "solution": "import xlwt\nimport os\nFIELDS = ['ID', 'Name', 'Age']\ndef task_func(values, filename):\n    # Create a new workbook\n    workbook = xlwt.Workbook()\n    # Create a new sheet\n    sheet = workbook.add_sheet('Sheet 1')\n    # Write the column headers\n    for i, field in enumerate(FIELDS):\n        sheet.write(0, i, field)\n    # Write the data\n    for i, row in enumerate(values):\n        for j, field in enumerate(FIELDS):\n            sheet.write(i + 1, j, row[field])\n    # Save the workbook\n    workbook.save(filename)\n    # Return the absolute path of the created Excel file\n    return os.path.abspath(filename)", "raw_solution": "import xlwt\nimport os\n# Constants\nFIELDS = ['ID', 'Name', 'Age']\ndef task_func(values, filename):\n    # Create a new workbook\n    workbook = xlwt.Workbook()\n    # Create a new sheet\n    sheet = workbook.add_sheet('Sheet 1')\n    # Write the column headers\n    for i, field in enumerate(FIELDS):\n        sheet.write(0, i, field)\n    # Write the data\n    for i, row in enumerate(values):\n        for j, field in enumerate(FIELDS):\n            sheet.write(i + 1, j, row[field])\n    # Save the workbook\n    workbook.save(filename)\n    # Return the absolute path of the created Excel file\n    return os.path.abspath(filename)\n```"}
{"task_id": "BigCodeBench/501", "solution": "import xlwt\nimport os\nimport pandas as pd\ndef task_func(json_str, filename, sheet_name=\"sheet1\"):\n    try:\n        # Check if json_str is a valid JSON string\n        json_str = json_str.strip()\n        if json_str[0] != '{' or json_str[-1] != '}':\n            raise ValueError(\"Invalid JSON string\")\n        # Convert JSON string to a pandas DataFrame\n        df = pd.read_json(json_str)\n        # Check if the DataFrame is empty\n        if df.empty:\n            # Create an Excel file with no data rows\n            workbook = xlwt.Workbook()\n            sheet = workbook.add_sheet(sheet_name)\n            workbook.save(filename)\n            return os.path.abspath(filename)\n        else:\n            # Create an Excel file with data rows\n            workbook = xlwt.Workbook()\n            sheet = workbook.add_sheet(sheet_name)\n            for i, row in df.iterrows():\n                for j, value in enumerate(row):\n                    sheet.write(i, j, value)\n            workbook.save(filename)\n            return os.path.abspath(filename)\n    except ValueError as e:\n        raise ValueError(str(e))\n    except TypeError as e:\n        raise TypeError(str(e))\n    except Exception as e:\n        raise Exception(str(e))", "raw_solution": "import xlwt\nimport os\nimport pandas as pd\n\ndef task_func(json_str, filename, sheet_name=\"sheet1\"):\n    try:\n        # Check if json_str is a valid JSON string\n        json_str = json_str.strip()\n        if json_str[0] != '{' or json_str[-1] != '}':\n            raise ValueError(\"Invalid JSON string\")\n        # Convert JSON string to a pandas DataFrame\n        df = pd.read_json(json_str)\n        # Check if the DataFrame is empty\n        if df.empty:\n            # Create an Excel file with no data rows\n            workbook = xlwt.Workbook()\n            sheet = workbook.add_sheet(sheet_name)\n            workbook.save(filename)\n            return os.path.abspath(filename)\n        else:\n            # Create an Excel file with data rows\n            workbook = xlwt.Workbook()\n            sheet = workbook.add_sheet(sheet_name)\n            for i, row in df.iterrows():\n                for j, value in enumerate(row):\n                    sheet.write(i, j, value)\n            workbook.save(filename)\n            return os.path.abspath(filename)\n    except ValueError as e:\n        raise ValueError(str(e))\n    except TypeError as e:\n        raise TypeError(str(e))\n    except Exception as e:\n        raise Exception(str(e))\n```"}
{"task_id": "BigCodeBench/502", "solution": "from datetime import datetime, timedelta\nimport pandas as pd\nimport random\nimport seaborn as sns\ndef task_func(days_in_past=7, random_seed=0):\n    random.seed(random_seed)\n    df = pd.DataFrame(columns=['Date', 'Activity', 'Duration'])\n    for i in range(days_in_past):\n        date = datetime.now() - timedelta(days=i)\n        activities = ['Running', 'Swimming', 'Cycling', 'Yoga', 'Weight Training']\n        activity = random.choice(activities)\n        duration = random.randint(0, 120)\n        df = df.append({'Date': date, 'Activity': activity, 'Duration': duration}, ignore_index=True)\n    ax = sns.lineplot(x='Date', y='Duration', hue='Activity', data=df)\n    return (ax, df)", "raw_solution": "from datetime import datetime, timedelta\nimport pandas as pd\nimport random\nimport seaborn as sns\n\ndef task_func(days_in_past=7, random_seed=0):\n    random.seed(random_seed)\n    df = pd.DataFrame(columns=['Date', 'Activity', 'Duration'])\n    for i in range(days_in_past):\n        date = datetime.now() - timedelta(days=i)\n        activities = ['Running', 'Swimming', 'Cycling', 'Yoga', 'Weight Training']\n        activity = random.choice(activities)\n        duration = random.randint(0, 120)\n        df = df.append({'Date': date, 'Activity': activity, 'Duration': duration}, ignore_index=True)\n    ax = sns.lineplot(x='Date', y='Duration', hue='Activity', data=df)\n    return (ax, df)\n```"}
{"task_id": "BigCodeBench/503", "solution": "import numpy as np\nimport pandas as pd\nfrom datetime import datetime\ndef task_func(\n    days_in_past=7, stock_names=[\"AAPL\", \"GOOGL\", \"MSFT\", \"AMZN\", \"FB\"], random_seed=0\n):\n    np.random.seed(random_seed)\n    prices = np.random.rand(days_in_past, len(stock_names))\n    dates = [datetime.now() - datetime(days=i) for i in range(days_in_past)]\n    df = pd.DataFrame(prices, index=dates, columns=stock_names)\n    return df", "raw_solution": "import numpy as np\nimport pandas as pd\nfrom datetime import datetime\n\ndef task_func(\n    days_in_past=7, stock_names=[\"AAPL\", \"GOOGL\", \"MSFT\", \"AMZN\", \"FB\"], random_seed=0\n):\n    np.random.seed(random_seed)\n    prices = np.random.rand(days_in_past, len(stock_names))\n    dates = [datetime.now() - datetime(days=i) for i in range(days_in_past)]\n    df = pd.DataFrame(prices, index=dates, columns=stock_names)\n    return df\n```"}
{"task_id": "BigCodeBench/504", "solution": "import hashlib\nimport rsa\nimport base64\ndef task_func(file_path):\n    with open(file_path, 'rb') as f:\n        file_contents = f.read()\n    sha256_hash = hashlib.sha256(file_contents).digest()\n    private_key = rsa.PrivateKey.load_pkcs1(open('private.pem', 'rb').read())\n    signature = rsa.sign(sha256_hash, private_key, 'SHA-256')\n    return base64.b64encode(signature).decode('utf-8')", "raw_solution": "import hashlib\nimport rsa\nimport base64\ndef task_func(file_path):\n    with open(file_path, 'rb') as f:\n        file_contents = f.read()\n    sha256_hash = hashlib.sha256(file_contents).digest()\n    private_key = rsa.PrivateKey.load_pkcs1(open('private.pem', 'rb').read())\n    signature = rsa.sign(sha256_hash, private_key, 'SHA-256')\n    return base64.b64encode(signature).decode('utf-8')\n```"}
{"task_id": "BigCodeBench/505", "solution": "import hashlib\nimport hmac\ndef task_func(secret, message):\n    return hmac.new(secret.encode(), message.encode(), hashlib.sha256()).hexdigest()", "raw_solution": "import hashlib\nimport hmac\n\ndef task_func(secret, message):\n    return hmac.new(secret.encode(), message.encode(), hashlib.sha256()).hexdigest()\n```"}
{"task_id": "BigCodeBench/506", "solution": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\ndef task_func(column, data):\n    if len(data) == 0:\n        result = {'sum': np.nan, 'mean': np.nan, 'min': np.inf, 'max': -np.inf, 'plot': None}\n    else:\n        df = pd.DataFrame(data, columns=[column])\n        result = {'sum': df[column].sum(), 'mean': df[column].mean(), 'min': df[column].min(), 'max': df[column].max(), 'plot': df[column].hist()}\n    return result", "raw_solution": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef task_func(column, data):\n    if len(data) == 0:\n        result = {'sum': np.nan, 'mean': np.nan, 'min': np.inf, 'max': -np.inf, 'plot': None}\n    else:\n        df = pd.DataFrame(data, columns=[column])\n        result = {'sum': df[column].sum(), 'mean': df[column].mean(), 'min': df[column].min(), 'max': df[column].max(), 'plot': df[column].hist()}\n    return result\n```"}
{"task_id": "BigCodeBench/507", "solution": "import pandas as pd\nimport numpy as np\ndef task_func(column, data):\n    if column not in data.columns:\n        raise ValueError(\"Invalid column name\")\n    return {\n        'sum': data[column].sum(),\n        'mean': data[column].mean(),\n        'min': data[column].min(),\n        'max': data[column].max()\n    }", "raw_solution": "import pandas as pd\nimport numpy as np\ndef task_func(column, data):\n    if column not in data.columns:\n        raise ValueError(\"Invalid column name\")\n    return {\n        'sum': data[column].sum(),\n        'mean': data[column].mean(),\n        'min': data[column].min(),\n        'max': data[column].max()\n    }\n```"}
{"task_id": "BigCodeBench/508", "solution": "import hashlib\nimport io\nimport os\ndef task_func(file_path1, file_path2):\n    if not os.path.exists(file_path1) or not os.path.exists(file_path2):\n        raise FileNotFoundError(\"One or both files do not exist\")\n    with io.open(file_path1, 'rb') as f1, io.open(file_path2, 'rb') as f2:\n        md5_1 = hashlib.md5(f1.read()).hexdigest()\n        md5_2 = hashlib.md5(f2.read()).hexdigest()\n    return md5_1 == md5_2", "raw_solution": "import hashlib\nimport io\nimport os\n\ndef task_func(file_path1, file_path2):\n    if not os.path.exists(file_path1) or not os.path.exists(file_path2):\n        raise FileNotFoundError(\"One or both files do not exist\")\n    with io.open(file_path1, 'rb') as f1, io.open(file_path2, 'rb') as f2:\n        md5_1 = hashlib.md5(f1.read()).hexdigest()\n        md5_2 = hashlib.md5(f2.read()).hexdigest()\n    return md5_1 == md5_2\n```"}
{"task_id": "BigCodeBench/509", "solution": "import pandas as pd\nimport csv\nfrom difflib import ndiff\ndef task_func(file_path1, file_path2, delimiter=',', quotechar='\"'):\n    try:\n        with open(file_path1, newline='') as f1, open(file_path2, newline='') as f2:\n            reader1 = csv.reader(f1, delimiter=delimiter, quotechar=quotechar)\n            reader2 = csv.reader(f2, delimiter=delimiter, quotechar=quotechar)\n            lines1 = list(reader1)\n            lines2 = list(reader2)\n    except FileNotFoundError:\n        raise FileNotFoundError(\"One of the files cannot be found.\")\n    except ValueError:\n        raise ValueError(\"One of the files is empty.\")\n    except Exception as e:\n        raise Exception(str(e))\n    if len(lines1) != len(lines2):\n        raise Exception(\"The files have different number of lines.\")\n    diff = []\n    for i in range(len(lines1)):\n        line1 = lines1[i]\n        line2 = lines2[i]\n        if line1 == line2:\n            diff.append({'Line Number': i+1, 'Status': ' ', 'Content': line1})\n        elif line1 in line2:\n            diff.append({'Line Number': i+1, 'Status': '-', 'Content': line1})\n        elif line2 in line1:\n            diff.append({'Line Number': i+1, 'Status': '+', 'Content': line2})\n        else:\n            diff.append({'Line Number': i+1, 'Status': ' ', 'Content': line1})\n    df = pd.DataFrame(diff)\n    return df", "raw_solution": "import pandas as pd\nimport csv\nfrom difflib import ndiff\n\ndef task_func(file_path1, file_path2, delimiter=',', quotechar='\"'):\n    try:\n        with open(file_path1, newline='') as f1, open(file_path2, newline='') as f2:\n            reader1 = csv.reader(f1, delimiter=delimiter, quotechar=quotechar)\n            reader2 = csv.reader(f2, delimiter=delimiter, quotechar=quotechar)\n            lines1 = list(reader1)\n            lines2 = list(reader2)\n    except FileNotFoundError:\n        raise FileNotFoundError(\"One of the files cannot be found.\")\n    except ValueError:\n        raise ValueError(\"One of the files is empty.\")\n    except Exception as e:\n        raise Exception(str(e))\n    if len(lines1) != len(lines2):\n        raise Exception(\"The files have different number of lines.\")\n    diff = []\n    for i in range(len(lines1)):\n        line1 = lines1[i]\n        line2 = lines2[i]\n        if line1 == line2:\n            diff.append({'Line Number': i+1, 'Status': ' ', 'Content': line1})\n        elif line1 in line2:\n            diff.append({'Line Number': i+1, 'Status': '-', 'Content': line1})\n        elif line2 in line1:\n            diff.append({'Line Number': i+1, 'Status': '+', 'Content': line2})\n        else:\n            diff.append({'Line Number': i+1, 'Status': ' ', 'Content': line1})\n    df = pd.DataFrame(diff)\n    return df\n```"}
{"task_id": "BigCodeBench/510", "solution": "import difflib\nimport gzip\ndef task_func(file_path1, file_path2):\n    with gzip.open(file_path1, 'rb') as f1, gzip.open(file_path2, 'rb') as f2:\n        file1 = f1.read()\n        file2 = f2.read()\n    diff = difflib.unified_diff(file1.decode('utf-8').splitlines(), file2.decode('utf-8').splitlines())\n    return ''.join(diff)", "raw_solution": "import difflib\nimport gzip\n\ndef task_func(file_path1, file_path2):\n    with gzip.open(file_path1, 'rb') as f1, gzip.open(file_path2, 'rb') as f2:\n        file1 = f1.read()\n        file2 = f2.read()\n    diff = difflib.unified_diff(file1.decode('utf-8').splitlines(), file2.decode('utf-8').splitlines())\n    return ''.join(diff)\n```"}
{"task_id": "BigCodeBench/511", "solution": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\ndef task_func(column, data):\n    if len(data) == 0:\n        return ({\"sum\": 0, \"mean\": np.nan, \"min\": np.nan, \"max\": np.nan}, None)\n    else:\n        return ({\"sum\": np.sum(data[column]), \"mean\": np.mean(data[column]), \"min\": np.min(data[column]), \"max\": np.max(data[column])}, plt.pie(data[column], labels=data[column]))", "raw_solution": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef task_func(column, data):\n    if len(data) == 0:\n        return ({\"sum\": 0, \"mean\": np.nan, \"min\": np.nan, \"max\": np.nan}, None)\n    else:\n        return ({\"sum\": np.sum(data[column]), \"mean\": np.mean(data[column]), \"min\": np.min(data[column]), \"max\": np.max(data[column])}, plt.pie(data[column], labels=data[column]))\n```"}
{"task_id": "BigCodeBench/512", "solution": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\ndef task_func(column, data):\n    if data[column].min() < 0 or data[column].max() < 0:\n        raise ValueError(\"Quantity sold or total sales cannot be negative.\")\n    sum_val = data[column].sum()\n    mean_val = data[column].mean()\n    min_val = data[column].min()\n    max_val = data[column].max()\n    fig, ax = plt.subplots()\n    ax.bar(data[column].index, data[column])\n    ax.set_title(f\"Bar Chart of {column}\")\n    ax.set_xlabel(\"Product\")\n    ax.set_ylabel(\"Quantity Sold\")\n    return (sum_val, mean_val, min_val, max_val), ax", "raw_solution": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef task_func(column, data):\n    if data[column].min() < 0 or data[column].max() < 0:\n        raise ValueError(\"Quantity sold or total sales cannot be negative.\")\n    sum_val = data[column].sum()\n    mean_val = data[column].mean()\n    min_val = data[column].min()\n    max_val = data[column].max()\n    fig, ax = plt.subplots()\n    ax.bar(data[column].index, data[column])\n    ax.set_title(f\"Bar Chart of {column}\")\n    ax.set_xlabel(\"Product\")\n    ax.set_ylabel(\"Quantity Sold\")\n    return (sum_val, mean_val, min_val, max_val), ax\n```"}
{"task_id": "BigCodeBench/513", "solution": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\ndef task_func(column, data):\n    if not data:\n        raise ValueError(\"Data list is empty\")\n    if column not in data.columns:\n        raise KeyError(\"Invalid column\")\n    if not all(isinstance(x, (int, float)) for x in data[column]):\n        raise ValueError(\"Numeric values for steps, calories burned, and distance walked are negative\")\n    data[column] = data[column].clip(lower=0)\n    sum_val = data[column].sum()\n    mean_val = data[column].mean()\n    min_val = data[column].min()\n    max_val = data[column].max()\n    fig, ax = plt.subplots()\n    ax.plot(data.index, data[column])\n    ax.set_title(f\"Line Chart of {column}\")\n    ax.set_xlabel(\"Date\")\n    ax.set_ylabel(column)\n    plt.show()\n    return (sum_val, mean_val, min_val, max_val), ax", "raw_solution": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef task_func(column, data):\n    if not data:\n        raise ValueError(\"Data list is empty\")\n    if column not in data.columns:\n        raise KeyError(\"Invalid column\")\n    if not all(isinstance(x, (int, float)) for x in data[column]):\n        raise ValueError(\"Numeric values for steps, calories burned, and distance walked are negative\")\n    data[column] = data[column].clip(lower=0)\n    sum_val = data[column].sum()\n    mean_val = data[column].mean()\n    min_val = data[column].min()\n    max_val = data[column].max()\n    fig, ax = plt.subplots()\n    ax.plot(data.index, data[column])\n    ax.set_title(f\"Line Chart of {column}\")\n    ax.set_xlabel(\"Date\")\n    ax.set_ylabel(column)\n    plt.show()\n    return (sum_val, mean_val, min_val, max_val), ax\n```"}
{"task_id": "BigCodeBench/514", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\ndef task_func(array):\n    df = pd.DataFrame(array, columns=['A', 'B', 'C', 'D', 'E'])\n    sum_df = df.sum()\n    plt.bar(sum_df.index, sum_df.values)\n    plt.show()\n    return df, plt.gca()", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\n\ndef task_func(array):\n    df = pd.DataFrame(array, columns=['A', 'B', 'C', 'D', 'E'])\n    sum_df = df.sum()\n    plt.bar(sum_df.index, sum_df.values)\n    plt.show()\n    return df, plt.gca()\n```"}
{"task_id": "BigCodeBench/515", "solution": "import pandas as pd\nimport seaborn as sns\ndef task_func(array):\n    if not array or not all(len(sublist) == 5 for sublist in array):\n        raise ValueError(\"Input array is empty or contains sublists of varying lengths.\")\n    df = pd.DataFrame(array, columns=['A', 'B', 'C', 'D', 'E'])\n    heatmap = sns.heatmap(df.corr())\n    return df, heatmap", "raw_solution": "import pandas as pd\nimport seaborn as sns\n\ndef task_func(array):\n    if not array or not all(len(sublist) == 5 for sublist in array):\n        raise ValueError(\"Input array is empty or contains sublists of varying lengths.\")\n    df = pd.DataFrame(array, columns=['A', 'B', 'C', 'D', 'E'])\n    heatmap = sns.heatmap(df.corr())\n    return df, heatmap\n```"}
{"task_id": "BigCodeBench/516", "solution": "import pandas as pd\nimport numpy as np\nimport statsmodels.api as sm\ndef task_func(\n    array: list, random_seed: int = 0\n) -> (pd.DataFrame, sm.regression.linear_model.RegressionResultsWrapper):\n    # Validate input list\n    if not isinstance(array, list) or not all(isinstance(x, list) for x in array):\n        raise ValueError(\"Input list must be a 2D list\")\n    if not all(len(x) == len(array[0]) for x in array):\n        raise ValueError(\"All sublists must have the same length\")\n    \n    # Create DataFrame\n    df = pd.DataFrame(array, columns=['A', 'B', 'C', 'D'])\n    \n    # Separate independent and dependent variables\n    X = df[['A', 'B', 'C']]\n    y = df['D']\n    \n    # Add a constant to the model\n    X = sm.add_constant(X)\n    \n    # Fit a linear regression using statsmodels\n    results = sm.OLS(y, X).fit()\n    \n    return df, results", "raw_solution": "import pandas as pd\nimport numpy as np\nimport statsmodels.api as sm\n\ndef task_func(\n    array: list, random_seed: int = 0\n) -> (pd.DataFrame, sm.regression.linear_model.RegressionResultsWrapper):\n    # Validate input list\n    if not isinstance(array, list) or not all(isinstance(x, list) for x in array):\n        raise ValueError(\"Input list must be a 2D list\")\n    if not all(len(x) == len(array[0]) for x in array):\n        raise ValueError(\"All sublists must have the same length\")\n    \n    # Create DataFrame\n    df = pd.DataFrame(array, columns=['A', 'B', 'C', 'D'])\n    \n    # Separate independent and dependent variables\n    X = df[['A', 'B', 'C']]\n    y = df['D']\n    \n    # Add a constant to the model\n    X = sm.add_constant(X)\n    \n    # Fit a linear regression using statsmodels\n    results = sm.OLS(y, X).fit()\n    \n    return df, results\n```"}
{"task_id": "BigCodeBench/517", "solution": "import pandas as pd\nimport numpy as np\nfrom sklearn.decomposition import PCA\ndef task_func(array: list, random_seed: int = 42) -> (pd.DataFrame, np.ndarray):\n    np.random.seed(random_seed)\n    df = pd.DataFrame(array)\n    pca = PCA(n_components=2)\n    return df, pca.fit_transform(df)", "raw_solution": "import pandas as pd\nimport numpy as np\nfrom sklearn.decomposition import PCA\n\ndef task_func(array: list, random_seed: int = 42) -> (pd.DataFrame, np.ndarray):\n    np.random.seed(random_seed)\n    df = pd.DataFrame(array)\n    pca = PCA(n_components=2)\n    return df, pca.fit_transform(df)\n```"}
{"task_id": "BigCodeBench/518", "solution": "import pandas as pd\nfrom scipy.spatial.distance import pdist, squareform\ndef task_func(array):\n    df = pd.DataFrame(array, columns=[chr(i) for i in range(65, 65+len(array[0]))])\n    distance_matrix = squareform(pdist(df))\n    return df, distance_matrix", "raw_solution": "import pandas as pd\nfrom scipy.spatial.distance import pdist, squareform\n\ndef task_func(array):\n    df = pd.DataFrame(array, columns=[chr(i) for i in range(65, 65+len(array[0]))])\n    distance_matrix = squareform(pdist(df))\n    return df, distance_matrix\n```"}
{"task_id": "BigCodeBench/519", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\ndef task_func(data):\n    df = pd.DataFrame(data)\n    df.fillna(0, inplace=True)\n    plt.plot(df['Time'], df['Sales Quantity'])\n    plt.title('Fruit Sales over Time')\n    plt.xlabel('Time')\n    plt.ylabel('Sales Quantity')\n    return plt.gca()", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\n\ndef task_func(data):\n    df = pd.DataFrame(data)\n    df.fillna(0, inplace=True)\n    plt.plot(df['Time'], df['Sales Quantity'])\n    plt.title('Fruit Sales over Time')\n    plt.xlabel('Time')\n    plt.ylabel('Sales Quantity')\n    return plt.gca()\n```"}
{"task_id": "BigCodeBench/520", "solution": "import collections\nimport matplotlib.pyplot as plt\ndef task_func(data):\n    total_sales = collections.defaultdict(int)\n    for fruit in data:\n        if fruit['sales'] < 0:\n            raise ValueError('Sales quantity must not be negative')\n        total_sales[fruit['name']] += fruit['sales']\n    ax = None\n    if total_sales:\n        ax = plt.bar(total_sales.keys(), total_sales.values(), color=['red', 'yellow', 'green', 'blue', 'purple'])\n    return total_sales, ax", "raw_solution": "import collections\nimport matplotlib.pyplot as plt\n\ndef task_func(data):\n    total_sales = collections.defaultdict(int)\n    for fruit in data:\n        if fruit['sales'] < 0:\n            raise ValueError('Sales quantity must not be negative')\n        total_sales[fruit['name']] += fruit['sales']\n    ax = None\n    if total_sales:\n        ax = plt.bar(total_sales.keys(), total_sales.values(), color=['red', 'yellow', 'green', 'blue', 'purple'])\n    return total_sales, ax\n```"}
{"task_id": "BigCodeBench/521", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\ndef task_func(data_list):\n    df = pd.DataFrame(data_list)\n    ax = df.plot(x='test', y='score', kind='line')\n    return ax", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\n\ndef task_func(data_list):\n    df = pd.DataFrame(data_list)\n    ax = df.plot(x='test', y='score', kind='line')\n    return ax\n```"}
{"task_id": "BigCodeBench/522", "solution": "import collections\nimport matplotlib.pyplot as plt\ndef task_func(data):\n    if not data:\n        return None\n    student_scores = collections.defaultdict(list)\n    for student in data:\n        for score in student.values():\n            if score is None:\n                continue\n            if score < 0:\n                raise ValueError(\"Negative score\")\n            student_scores[student['Student']].append(score)\n    average_scores = {student: sum(scores) / len(scores) for student, scores in student_scores.items()}\n    ax = plt.bar(average_scores.keys(), average_scores.values(), color=['red', 'yellow', 'green', 'blue', 'purple'])\n    plt.xlabel('Student')\n    plt.ylabel('Average Score')\n    plt.show()\n    return ax", "raw_solution": "import collections\nimport matplotlib.pyplot as plt\n\ndef task_func(data):\n    if not data:\n        return None\n    student_scores = collections.defaultdict(list)\n    for student in data:\n        for score in student.values():\n            if score is None:\n                continue\n            if score < 0:\n                raise ValueError(\"Negative score\")\n            student_scores[student['Student']].append(score)\n    average_scores = {student: sum(scores) / len(scores) for student, scores in student_scores.items()}\n    ax = plt.bar(average_scores.keys(), average_scores.values(), color=['red', 'yellow', 'green', 'blue', 'purple'])\n    plt.xlabel('Student')\n    plt.ylabel('Average Score')\n    plt.show()\n    return ax\n```"}
{"task_id": "BigCodeBench/523", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\ndef task_func(data):\n    if not data:\n        return None\n    df = pd.DataFrame(data)\n    df.set_index('Time', inplace=True)\n    ax = df.plot(kind='line', xticks=df.index)\n    ax.set_xlabel('Time')\n    ax.set_ylabel('Data Points')\n    return ax, df", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\n\ndef task_func(data):\n    if not data:\n        return None\n    df = pd.DataFrame(data)\n    df.set_index('Time', inplace=True)\n    ax = df.plot(kind='line', xticks=df.index)\n    ax.set_xlabel('Time')\n    ax.set_ylabel('Data Points')\n    return ax, df\n```"}
{"task_id": "BigCodeBench/524", "solution": "from collections import defaultdict\nimport numpy as np\nimport matplotlib.pyplot as plt\ndef task_func(data):\n    if not data:\n        raise ValueError(\"If the input data is empty.\")\n    if not all(isinstance(d, dict) for d in data):\n        raise TypeError(\"If the input is not a list of dictionaries or if any value in the dictionaries is not numeric.\")\n    means = defaultdict(float)\n    stds = defaultdict(float)\n    for d in data:\n        for k, v in d.items():\n            means[k] += v\n            stds[k] += v**2\n    for k in means:\n        means[k] /= len(data)\n        stds[k] = np.sqrt(stds[k] / len(data) - means[k]**2)\n    return means, stds", "raw_solution": "from collections import defaultdict\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef task_func(data):\n    if not data:\n        raise ValueError(\"If the input data is empty.\")\n    if not all(isinstance(d, dict) for d in data):\n        raise TypeError(\"If the input is not a list of dictionaries or if any value in the dictionaries is not numeric.\")\n    means = defaultdict(float)\n    stds = defaultdict(float)\n    for d in data:\n        for k, v in d.items():\n            means[k] += v\n            stds[k] += v**2\n    for k in means:\n        means[k] /= len(data)\n        stds[k] = np.sqrt(stds[k] / len(data) - means[k]**2)\n    return means, stds\n```"}
{"task_id": "BigCodeBench/525", "solution": "import json\nimport numpy as np\nfrom collections import defaultdict\nimport matplotlib.pyplot as plt\ndef task_func(input_file):\n    with open(input_file, 'r') as f:\n        data = json.load(f)\n    result = defaultdict(dict)\n    plots = []\n    for key, values in data.items():\n        mean = np.mean(values)\n        median = np.median(values)\n        result[key]['mean'] = mean\n        result[key]['median'] = median\n        x = np.arange(len(values))\n        y = values\n        ax = plt.bar(x, y)\n        ax.set_title(f'Mean: {mean}, Median: {median}')\n        plots.append(ax)\n    return result, plots", "raw_solution": "import json\nimport numpy as np\nfrom collections import defaultdict\nimport matplotlib.pyplot as plt\n\ndef task_func(input_file):\n    with open(input_file, 'r') as f:\n        data = json.load(f)\n    result = defaultdict(dict)\n    plots = []\n    for key, values in data.items():\n        mean = np.mean(values)\n        median = np.median(values)\n        result[key]['mean'] = mean\n        result[key]['median'] = median\n        x = np.arange(len(values))\n        y = values\n        ax = plt.bar(x, y)\n        ax.set_title(f'Mean: {mean}, Median: {median}')\n        plots.append(ax)\n    return result, plots\n```"}
{"task_id": "BigCodeBench/526", "solution": "import json\nimport pandas as pd\nimport numpy as np\nfrom collections import defaultdict\ndef task_func(input_file=\"data.json\"):\n    with open(input_file, 'r') as f:\n        data = json.load(f)\n    df = pd.DataFrame(data)\n    for key in data[0].keys():\n        df[key] = df[key].apply(lambda x: np.nan if pd.isna(x) or not isinstance(x, (int, float)) else x)\n    df['mean'] = df.apply(lambda x: np.mean(x.dropna()), axis=1)\n    df['median'] = df.apply(lambda x: np.median(x.dropna()), axis=1)\n    return df", "raw_solution": "import json\nimport pandas as pd\nimport numpy as np\nfrom collections import defaultdict\n\ndef task_func(input_file=\"data.json\"):\n    with open(input_file, 'r') as f:\n        data = json.load(f)\n    df = pd.DataFrame(data)\n    for key in data[0].keys():\n        df[key] = df[key].apply(lambda x: np.nan if pd.isna(x) or not isinstance(x, (int, float)) else x)\n    df['mean'] = df.apply(lambda x: np.mean(x.dropna()), axis=1)\n    df['median'] = df.apply(lambda x: np.median(x.dropna()), axis=1)\n    return df\n```"}
{"task_id": "BigCodeBench/527", "solution": "import json\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np\nfrom collections import defaultdict\ndef task_func(input_file: str) -> plt.Axes:\n    with open(input_file, 'r') as f:\n        data = json.load(f)\n    results = defaultdict(dict)\n    for key, values in data.items():\n        results[key]['mean'] = np.mean(values)\n        results[key]['median'] = np.median(values)\n    df = pd.DataFrame(results)\n    ax = sns.boxplot(x='X', y='Y', data=df)\n    return ax", "raw_solution": "import json\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np\nfrom collections import defaultdict\n\ndef task_func(input_file: str) -> plt.Axes:\n    with open(input_file, 'r') as f:\n        data = json.load(f)\n    results = defaultdict(dict)\n    for key, values in data.items():\n        results[key]['mean'] = np.mean(values)\n        results[key]['median'] = np.median(values)\n    df = pd.DataFrame(results)\n    ax = sns.boxplot(x='X', y='Y', data=df)\n    return ax\n```"}
{"task_id": "BigCodeBench/528", "solution": "import csv\nfrom collections import Counter\nimport pandas as pd\nimport matplotlib.pyplot as plt\ndef task_func(file_path):\n    # Check if the file is in proper format\n    if not file_path.endswith('.csv'):\n        raise ValueError('The file is not in proper format')\n    \n    # Read the CSV file\n    with open(file_path, 'r') as file:\n        reader = csv.reader(file)\n        data = list(reader)\n    \n    # Count the number of duplicates\n    duplicates = Counter(data)\n    \n    # Convert the duplicates to a pandas DataFrame\n    df = pd.DataFrame(duplicates.items(), columns=['Row', 'Count'])\n    \n    # Plot the duplicates\n    fig, ax = plt.subplots()\n    ax.bar(df['Row'], df['Count'])\n    ax.set_xlabel('Row')\n    ax.set_ylabel('Count')\n    ax.set_title('Duplicate Rows')\n    \n    return dict(duplicates), ax", "raw_solution": "import csv\nfrom collections import Counter\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndef task_func(file_path):\n    # Check if the file is in proper format\n    if not file_path.endswith('.csv'):\n        raise ValueError('The file is not in proper format')\n    \n    # Read the CSV file\n    with open(file_path, 'r') as file:\n        reader = csv.reader(file)\n        data = list(reader)\n    \n    # Count the number of duplicates\n    duplicates = Counter(data)\n    \n    # Convert the duplicates to a pandas DataFrame\n    df = pd.DataFrame(duplicates.items(), columns=['Row', 'Count'])\n    \n    # Plot the duplicates\n    fig, ax = plt.subplots()\n    ax.bar(df['Row'], df['Count'])\n    ax.set_xlabel('Row')\n    ax.set_ylabel('Count')\n    ax.set_title('Duplicate Rows')\n    \n    return dict(duplicates), ax\n```"}
{"task_id": "BigCodeBench/529", "solution": "from collections import Counter\nimport random\nimport matplotlib.pyplot as plt\ndef task_func(num_rolls, num_dice, plot_path=None, random_seed=0):\n    random.seed(random_seed)\n    sums = [sum(random.randint(1, 6) for _ in range(num_dice)) for _ in range(num_rolls)]\n    counter = Counter(sums)\n    fig, ax = plt.subplots()\n    ax.bar(counter.keys(), counter.values())\n    if plot_path:\n        plt.savefig(plot_path)\n    return counter, ax", "raw_solution": "from collections import Counter\nimport random\nimport matplotlib.pyplot as plt\n\ndef task_func(num_rolls, num_dice, plot_path=None, random_seed=0):\n    random.seed(random_seed)\n    sums = [sum(random.randint(1, 6) for _ in range(num_dice)) for _ in range(num_rolls)]\n    counter = Counter(sums)\n    fig, ax = plt.subplots()\n    ax.bar(counter.keys(), counter.values())\n    if plot_path:\n        plt.savefig(plot_path)\n    return counter, ax\n```"}
{"task_id": "BigCodeBench/530", "solution": "import pandas as pd\nimport numpy as np\nfrom collections import Counter\nimport seaborn as sns\nimport matplotlib.pyplot as plt\ndef task_func(df: pd.DataFrame) -> (Counter, plt.Axes):\n    if df.empty or df['age'].min() < 0:\n        raise ValueError('DataFrame is empty or age is negative')\n    df['age'] = df['age'].astype(int)\n    duplicates = df[df.duplicated(subset='name', keep=False)]\n    age_distribution = Counter(duplicates['age'])\n    if len(age_distribution) == 0:\n        return age_distribution, None\n    min_age = min(age_distribution.keys())\n    max_age = max(age_distribution.keys())\n    bins = np.arange(min_age, max_age + 1.5)\n    plt.hist(age_distribution.keys(), bins=bins, edgecolor='black')\n    plt.xlabel('Age')\n    plt.ylabel('Count')\n    plt.title('Age Distribution for Duplicate Names')\n    return age_distribution, plt.gca()", "raw_solution": "import pandas as pd\nimport numpy as np\nfrom collections import Counter\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\ndef task_func(df: pd.DataFrame) -> (Counter, plt.Axes):\n    if df.empty or df['age'].min() < 0:\n        raise ValueError('DataFrame is empty or age is negative')\n    df['age'] = df['age'].astype(int)\n    duplicates = df[df.duplicated(subset='name', keep=False)]\n    age_distribution = Counter(duplicates['age'])\n    if len(age_distribution) == 0:\n        return age_distribution, None\n    min_age = min(age_distribution.keys())\n    max_age = max(age_distribution.keys())\n    bins = np.arange(min_age, max_age + 1.5)\n    plt.hist(age_distribution.keys(), bins=bins, edgecolor='black')\n    plt.xlabel('Age')\n    plt.ylabel('Count')\n    plt.title('Age Distribution for Duplicate Names')\n    return age_distribution, plt.gca()\n```"}
{"task_id": "BigCodeBench/531", "solution": "from collections import Counter\nfrom sklearn.cluster import KMeans\nimport matplotlib.pyplot as plt\ndef task_func(df, n_clusters=3, random_state=None, n_init=10):\n    # Identify duplicate points\n    duplicate_points = df[df.duplicated(subset=df.columns, keep=False)]\n    unique_points = df[~df.duplicated(subset=df.columns, keep=False)]\n    \n    # Perform KMeans clustering on unique points\n    kmeans = KMeans(n_clusters=n_clusters, random_state=random_state, n_init=n_init)\n    unique_points['cluster'] = kmeans.fit_predict(unique_points)\n    \n    # Plot the clustered data\n    fig, ax = plt.subplots()\n    ax.scatter(unique_points['x'], unique_points['y'], c=unique_points['cluster'], cmap='viridis')\n    ax.scatter(duplicate_points['x'], duplicate_points['y'], c='red', marker='x')\n    plt.show()\n    \n    # Return the results\n    return Counter(duplicate_points['x']), unique_points, ax", "raw_solution": "from collections import Counter\nfrom sklearn.cluster import KMeans\nimport matplotlib.pyplot as plt\n\ndef task_func(df, n_clusters=3, random_state=None, n_init=10):\n    # Identify duplicate points\n    duplicate_points = df[df.duplicated(subset=df.columns, keep=False)]\n    unique_points = df[~df.duplicated(subset=df.columns, keep=False)]\n    \n    # Perform KMeans clustering on unique points\n    kmeans = KMeans(n_clusters=n_clusters, random_state=random_state, n_init=n_init)\n    unique_points['cluster'] = kmeans.fit_predict(unique_points)\n    \n    # Plot the clustered data\n    fig, ax = plt.subplots()\n    ax.scatter(unique_points['x'], unique_points['y'], c=unique_points['cluster'], cmap='viridis')\n    ax.scatter(duplicate_points['x'], duplicate_points['y'], c='red', marker='x')\n    plt.show()\n    \n    # Return the results\n    return Counter(duplicate_points['x']), unique_points, ax\n```"}
{"task_id": "BigCodeBench/532", "solution": "import numpy as np\nfrom collections import Counter\nfrom scipy.stats import norm\nimport matplotlib.pyplot as plt\ndef task_func(df, bins=4):\n    counter = Counter(df['value'])\n    fig, ax = plt.subplots()\n    ax.hist(df['value'], bins=bins, color='green', alpha=0.6)\n    x = np.linspace(df['value'].min(), df['value'].max(), 100)\n    y = norm.pdf(x, df['value'].mean(), df['value'].std())\n    ax.plot(x, y, 'k-', linewidth=2)\n    ax.set_title('Distribution')\n    ax.set_xlabel('Value')\n    ax.set_ylabel('Frequency')\n    return counter, ax", "raw_solution": "import numpy as np\nfrom collections import Counter\nfrom scipy.stats import norm\nimport matplotlib.pyplot as plt\n\ndef task_func(df, bins=4):\n    counter = Counter(df['value'])\n    fig, ax = plt.subplots()\n    ax.hist(df['value'], bins=bins, color='green', alpha=0.6)\n    x = np.linspace(df['value'].min(), df['value'].max(), 100)\n    y = norm.pdf(x, df['value'].mean(), df['value'].std())\n    ax.plot(x, y, 'k-', linewidth=2)\n    ax.set_title('Distribution')\n    ax.set_xlabel('Value')\n    ax.set_ylabel('Frequency')\n    return counter, ax\n```"}
{"task_id": "BigCodeBench/533", "solution": "import numpy as np\nimport secrets\nimport hashlib\nimport base64\ndef task_func(num, from_base, to_base, alphabet):\n    if from_base < 2 or to_base < 2:\n        raise ValueError('Invalid base for conversion')\n    if not all(c in alphabet for c in num):\n        raise ValueError('Invalid number format for conversion')\n    num = int(num, from_base)\n    salt = secrets.token_hex(16)\n    hash = hashlib.sha256((str(num) + salt).encode()).hexdigest()\n    return (base64.b64encode(hash.encode()).decode(), salt)", "raw_solution": "import numpy as np\nimport secrets\nimport hashlib\nimport base64\ndef task_func(num, from_base, to_base, alphabet):\n    if from_base < 2 or to_base < 2:\n        raise ValueError('Invalid base for conversion')\n    if not all(c in alphabet for c in num):\n        raise ValueError('Invalid number format for conversion')\n    num = int(num, from_base)\n    salt = secrets.token_hex(16)\n    hash = hashlib.sha256((str(num) + salt).encode()).hexdigest()\n    return (base64.b64encode(hash.encode()).decode(), salt)\n```"}
{"task_id": "BigCodeBench/534", "solution": "import numpy as np\nimport base64\nfrom cryptography.hazmat.primitives import hashes\nfrom cryptography.hazmat.primitives.asymmetric import padding\ndef task_func(num, from_base, to_base, private_key, alphabet):\n    # Convert the number from the specified source base to the target base\n    num = int(num, from_base)\n    num = np.base_repr(num, to_base)\n    \n    # Sign the converted number with a private RSA key\n    private_key = private_key.encode('utf-8')\n    signature = private_key.sign(\n        num.encode('utf-8'),\n        padding.PSS(\n            mgf=padding.MGF1(hashes.SHA256()),\n            salt_length=padding.PSS.MAX_LENGTH\n        ),\n        hashes.SHA256()\n    )\n    \n    # Encode the signed number in base64 using a custom alphabet\n    base64_encoded = base64.b64encode(signature).decode('utf-8')\n    base64_encoded = base64_encoded.translate(str.maketrans(alphabet, alphabet))\n    \n    return base64_encoded", "raw_solution": "import numpy as np\nimport base64\nfrom cryptography.hazmat.primitives import hashes\nfrom cryptography.hazmat.primitives.asymmetric import padding\ndef task_func(num, from_base, to_base, private_key, alphabet):\n    # Convert the number from the specified source base to the target base\n    num = int(num, from_base)\n    num = np.base_repr(num, to_base)\n    \n    # Sign the converted number with a private RSA key\n    private_key = private_key.encode('utf-8')\n    signature = private_key.sign(\n        num.encode('utf-8'),\n        padding.PSS(\n            mgf=padding.MGF1(hashes.SHA256()),\n            salt_length=padding.PSS.MAX_LENGTH\n        ),\n        hashes.SHA256()\n    )\n    \n    # Encode the signed number in base64 using a custom alphabet\n    base64_encoded = base64.b64encode(signature).decode('utf-8')\n    base64_encoded = base64_encoded.translate(str.maketrans(alphabet, alphabet))\n    \n    return base64_encoded\n```"}
{"task_id": "BigCodeBench/535", "solution": "import sqlite3\nimport numpy as np\nfrom random import choice, seed\ndef task_func(db_path, table_name, num_entries, random_seed=None):\n    if num_entries < 0:\n        raise ValueError(\"num_entries must be non-negative\")\n    seed(random_seed)\n    names = ['John', 'Jane', 'Steve', 'Emma', 'Liam', 'Olivia']\n    ages = np.random.randint(18, 65, num_entries)\n    heights = np.random.randint(150, 199, num_entries)\n    conn = sqlite3.connect(db_path)\n    cursor = conn.cursor()\n    cursor.execute(f\"CREATE TABLE IF NOT EXISTS {table_name} (name TEXT, age INTEGER, height INTEGER)\")\n    cursor.executemany(f\"INSERT INTO {table_name} (name, age, height) VALUES (?, ?, ?)\", zip(names, ages, heights))\n    conn.commit()\n    conn.close()\n    return num_entries", "raw_solution": "import sqlite3\nimport numpy as np\nfrom random import choice, seed\n\ndef task_func(db_path, table_name, num_entries, random_seed=None):\n    if num_entries < 0:\n        raise ValueError(\"num_entries must be non-negative\")\n    seed(random_seed)\n    names = ['John', 'Jane', 'Steve', 'Emma', 'Liam', 'Olivia']\n    ages = np.random.randint(18, 65, num_entries)\n    heights = np.random.randint(150, 199, num_entries)\n    conn = sqlite3.connect(db_path)\n    cursor = conn.cursor()\n    cursor.execute(f\"CREATE TABLE IF NOT EXISTS {table_name} (name TEXT, age INTEGER, height INTEGER)\")\n    cursor.executemany(f\"INSERT INTO {table_name} (name, age, height) VALUES (?, ?, ?)\", zip(names, ages, heights))\n    conn.commit()\n    conn.close()\n    return num_entries\n```"}
{"task_id": "BigCodeBench/536", "solution": "import sqlite3\nimport pandas as pd\nimport os\ndef task_func(db_name, table_name, csv_path=\"data.csv\"):\n    # Connect to the SQLite database\n    conn = sqlite3.connect(db_name)\n    # Read the table into a pandas DataFrame\n    df = pd.read_sql_query(f\"SELECT * FROM {table_name}\", conn)\n    # Export the DataFrame to a CSV file\n    df.to_csv(csv_path, index=False)\n    # Close the connection\n    conn.close()\n    # Return the absolute path of the exported CSV file\n    return os.path.abspath(csv_path)", "raw_solution": "import sqlite3\nimport pandas as pd\nimport os\ndef task_func(db_name, table_name, csv_path=\"data.csv\"):\n    # Connect to the SQLite database\n    conn = sqlite3.connect(db_name)\n    # Read the table into a pandas DataFrame\n    df = pd.read_sql_query(f\"SELECT * FROM {table_name}\", conn)\n    # Export the DataFrame to a CSV file\n    df.to_csv(csv_path, index=False)\n    # Close the connection\n    conn.close()\n    # Return the absolute path of the exported CSV file\n    return os.path.abspath(csv_path)\n```"}
{"task_id": "BigCodeBench/537", "solution": "import sqlite3\nimport pandas as pd\nimport seaborn as sns\ndef task_func(db_name=\"test.db\", table_name=\"People\"):\n    # Connect to the SQLite database\n    conn = sqlite3.connect(db_name)\n    # Load the data into a pandas DataFrame\n    df = pd.read_sql_query(f\"SELECT age FROM {table_name}\", conn)\n    # Check if there are any negative age values\n    if df['age'].min() < 0:\n        raise ValueError(\"If the data contains negative age values.\")\n    # Create a KDE plot of the age distribution\n    ax = sns.kdeplot(df['age'], bins=30)\n    # Return the Axes object of the plot\n    return ax", "raw_solution": "import sqlite3\nimport pandas as pd\nimport seaborn as sns\ndef task_func(db_name=\"test.db\", table_name=\"People\"):\n    # Connect to the SQLite database\n    conn = sqlite3.connect(db_name)\n    # Load the data into a pandas DataFrame\n    df = pd.read_sql_query(f\"SELECT age FROM {table_name}\", conn)\n    # Check if there are any negative age values\n    if df['age'].min() < 0:\n        raise ValueError(\"If the data contains negative age values.\")\n    # Create a KDE plot of the age distribution\n    ax = sns.kdeplot(df['age'], bins=30)\n    # Return the Axes object of the plot\n    return ax\n```"}
{"task_id": "BigCodeBench/538", "solution": "import sqlite3\nimport pandas as pd\ndef task_func(db_name, table_name):\n    # Connect to the database\n    conn = sqlite3.connect(db_name)\n    # Load the table into a pandas DataFrame\n    df = pd.read_sql_query(f\"SELECT * FROM {table_name}\", conn)\n    # Check if the table has less than two numerical columns\n    if len(df.select_dtypes(include=['number']).columns) < 2:\n        raise ValueError(\"If the table has less than two numerical columns.\")\n    # Plot the relationship between the first and second numerical columns\n    ax = df.plot.scatter(x=df.columns[0], y=df.columns[1])\n    # Return the axes object\n    return ax", "raw_solution": "import sqlite3\nimport pandas as pd\ndef task_func(db_name, table_name):\n    # Connect to the database\n    conn = sqlite3.connect(db_name)\n    # Load the table into a pandas DataFrame\n    df = pd.read_sql_query(f\"SELECT * FROM {table_name}\", conn)\n    # Check if the table has less than two numerical columns\n    if len(df.select_dtypes(include=['number']).columns) < 2:\n        raise ValueError(\"If the table has less than two numerical columns.\")\n    # Plot the relationship between the first and second numerical columns\n    ax = df.plot.scatter(x=df.columns[0], y=df.columns[1])\n    # Return the axes object\n    return ax\n```"}
{"task_id": "BigCodeBench/539", "solution": "import sqlite3\nfrom random import choice, seed\nimport os\ndef task_func(db_name, table_name, num_entries, random_seed=None):\n    if num_entries < 0:\n        raise ValueError(\"num_entries must be non-negative\")\n    seed(random_seed)\n    names = ['John', 'Jane', 'Steve', 'Emma', 'Liam', 'Olivia']\n    ages = range(18, 66)\n    heights = range(150, 201)\n    conn = sqlite3.connect(db_name)\n    cursor = conn.cursor()\n    cursor.execute(f\"CREATE TABLE {table_name} (name TEXT, age INTEGER, height INTEGER)\")\n    for i in range(num_entries):\n        cursor.execute(f\"INSERT INTO {table_name} (name, age, height) VALUES (?, ?, ?)\", (choice(names), choice(ages), choice(heights)))\n    conn.commit()\n    conn.close()\n    return os.path.abspath(db_name)", "raw_solution": "import sqlite3\nfrom random import choice, seed\nimport os\n\ndef task_func(db_name, table_name, num_entries, random_seed=None):\n    if num_entries < 0:\n        raise ValueError(\"num_entries must be non-negative\")\n    seed(random_seed)\n    names = ['John', 'Jane', 'Steve', 'Emma', 'Liam', 'Olivia']\n    ages = range(18, 66)\n    heights = range(150, 201)\n    conn = sqlite3.connect(db_name)\n    cursor = conn.cursor()\n    cursor.execute(f\"CREATE TABLE {table_name} (name TEXT, age INTEGER, height INTEGER)\")\n    for i in range(num_entries):\n        cursor.execute(f\"INSERT INTO {table_name} (name, age, height) VALUES (?, ?, ?)\", (choice(names), choice(ages), choice(heights)))\n    conn.commit()\n    conn.close()\n    return os.path.abspath(db_name)\n```"}
{"task_id": "BigCodeBench/540", "solution": "from collections import Counter\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport itertools\ndef task_func(list_of_menuitems, title=\"Menu Distribution\", color=\"blue\", width=1.0):\n    # Flatten the list using itertools.chain\n    flat_list = list(itertools.chain(*list_of_menuitems))\n    \n    # Count the occurrences of each item\n    item_counts = Counter(flat_list)\n    \n    # Sort the x-axis alphabetically\n    sorted_items = sorted(item_counts.keys())\n    \n    # Create the histogram plot\n    ax = plt.bar(sorted_items, item_counts.values(), color=color, width=width)\n    ax.set_title(title)\n    ax.set_xlabel(\"Menu Items\")\n    ax.set_ylabel(\"Frequency\")\n    \n    return ax", "raw_solution": "from collections import Counter\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport itertools\n\ndef task_func(list_of_menuitems, title=\"Menu Distribution\", color=\"blue\", width=1.0):\n    # Flatten the list using itertools.chain\n    flat_list = list(itertools.chain(*list_of_menuitems))\n    \n    # Count the occurrences of each item\n    item_counts = Counter(flat_list)\n    \n    # Sort the x-axis alphabetically\n    sorted_items = sorted(item_counts.keys())\n    \n    # Create the histogram plot\n    ax = plt.bar(sorted_items, item_counts.values(), color=color, width=width)\n    ax.set_title(title)\n    ax.set_xlabel(\"Menu Items\")\n    ax.set_ylabel(\"Frequency\")\n    \n    return ax\n```"}
{"task_id": "BigCodeBench/541", "solution": "import os\nimport sys\nimport importlib\nfrom pkgutil import iter_modules\ndef task_func(package_name):\n    try:\n        # Import the package\n        importlib.import_module(package_name)\n        # Get the list of modules in the package\n        modules = [name for _, name, _ in iter_modules([package_name])]\n        # Add the modules to the system path\n        sys.path.extend([os.path.join(package_name, module) for module in modules])\n        return modules\n    except ImportError:\n        # Raise an exception if the package is not installed or cannot be found\n        raise ImportError(f\"pip install {package_name}\")", "raw_solution": "import os\nimport sys\nimport importlib\nfrom pkgutil import iter_modules\n\ndef task_func(package_name):\n    try:\n        # Import the package\n        importlib.import_module(package_name)\n        # Get the list of modules in the package\n        modules = [name for _, name, _ in iter_modules([package_name])]\n        # Add the modules to the system path\n        sys.path.extend([os.path.join(package_name, module) for module in modules])\n        return modules\n    except ImportError:\n        # Raise an exception if the package is not installed or cannot be found\n        raise ImportError(f\"pip install {package_name}\")\n```"}
{"task_id": "BigCodeBench/542", "solution": "import hashlib\nimport random\nimport struct\nKEYS = ['470FC614', '4A0FC614', '4B9FC614', '4C8FC614', '4D7FC614']\ndef task_func(hex_keys=KEYS, seed=42):\n    random.seed(seed)\n    key = random.choice(hex_keys)\n    float_num = struct.unpack('!f', bytes.fromhex(key))[0]\n    md5_hash = hashlib.md5(str(float_num).encode()).hexdigest()\n    return md5_hash", "raw_solution": "import hashlib\nimport random\nimport struct\nKEYS = ['470FC614', '4A0FC614', '4B9FC614', '4C8FC614', '4D7FC614']\ndef task_func(hex_keys=KEYS, seed=42):\n    random.seed(seed)\n    key = random.choice(hex_keys)\n    float_num = struct.unpack('!f', bytes.fromhex(key))[0]\n    md5_hash = hashlib.md5(str(float_num).encode()).hexdigest()\n    return md5_hash\n```"}
{"task_id": "BigCodeBench/543", "solution": "import base64\nimport os\ndef task_func():\n    random_float = os.urandom(4)\n    hex_str = random_float.hex()\n    base64_str = base64.b64encode(hex_str.encode()).decode()\n    return base64_str", "raw_solution": "import base64\nimport os\n\ndef task_func():\n    random_float = os.urandom(4)\n    hex_str = random_float.hex()\n    base64_str = base64.b64encode(hex_str.encode()).decode()\n    return base64_str\n```"}
{"task_id": "BigCodeBench/544", "solution": "import struct\nimport zlib\nKEY = '470FC614'\ndef task_func(hex_string=KEY):\n    # Convert hex string to float number\n    float_num = struct.unpack('!f', bytes.fromhex(hex_string))[0]\n    # Compress the binary32 float number\n    compressed = zlib.compress(struct.pack('!f', float_num))\n    # Return the compressed float number\n    return compressed", "raw_solution": "import struct\nimport zlib\n# Constants\nKEY = '470FC614'\ndef task_func(hex_string=KEY):\n    # Convert hex string to float number\n    float_num = struct.unpack('!f', bytes.fromhex(hex_string))[0]\n    # Compress the binary32 float number\n    compressed = zlib.compress(struct.pack('!f', float_num))\n    # Return the compressed float number\n    return compressed\n```"}
{"task_id": "BigCodeBench/545", "solution": "import codecs\nimport random\nimport struct\nKEYS = ['470FC614', '4A0FC614', '4B9FC614', '4C8FC614', '4D7FC614']\ndef task_func(hex_keys=KEYS):\n    # Generate a random float number from the list of hex strings\n    hex_str = random.choice(hex_keys)\n    float_num = struct.unpack('f', codecs.decode(hex_str, 'hex'))[0]\n    \n    # Encode the float number in utf-8\n    bytes = codecs.encode(str(float_num), 'utf-8')\n    \n    return bytes", "raw_solution": "import codecs\nimport random\nimport struct\nKEYS = ['470FC614', '4A0FC614', '4B9FC614', '4C8FC614', '4D7FC614']\ndef task_func(hex_keys=KEYS):\n    # Generate a random float number from the list of hex strings\n    hex_str = random.choice(hex_keys)\n    float_num = struct.unpack('f', codecs.decode(hex_str, 'hex'))[0]\n    \n    # Encode the float number in utf-8\n    bytes = codecs.encode(str(float_num), 'utf-8')\n    \n    return bytes\n```"}
{"task_id": "BigCodeBench/546", "solution": "from collections import OrderedDict\nfrom prettytable import PrettyTable\ndef task_func(my_dict):\n    sorted_dict = OrderedDict(sorted(my_dict.items()))\n    table = PrettyTable(['Key', 'Value'])\n    for key, value in sorted_dict.items():\n        table.add_row([key, value])\n    return table", "raw_solution": "from collections import OrderedDict\nfrom prettytable import PrettyTable\n\ndef task_func(my_dict):\n    sorted_dict = OrderedDict(sorted(my_dict.items()))\n    table = PrettyTable(['Key', 'Value'])\n    for key, value in sorted_dict.items():\n        table.add_row([key, value])\n    return table\n```"}
{"task_id": "BigCodeBench/547", "solution": "import hashlib\nimport os\nimport base64\ndef task_func(password: str, salt_length: int = 8) -> str:\n    salt = os.urandom(salt_length)\n    salted_password = password.encode() + salt\n    hashed_password = hashlib.sha256(salted_password).hexdigest()\n    return base64.b64encode(hashed_password.encode()).decode()", "raw_solution": "import hashlib\nimport os\nimport base64\ndef task_func(password: str, salt_length: int = 8) -> str:\n    salt = os.urandom(salt_length)\n    salted_password = password.encode() + salt\n    hashed_password = hashlib.sha256(salted_password).hexdigest()\n    return base64.b64encode(hashed_password.encode()).decode()\n```"}
{"task_id": "BigCodeBench/548", "solution": "import random\nimport string\nimport base64\nimport zlib\ndef task_func(string_length=100):\n    random_string = ''.join(random.choice(string.ascii_uppercase + string.digits) for _ in range(string_length))\n    compressed_string = zlib.compress(random_string.encode('utf-8'))\n    base64_string = base64.b64encode(compressed_string).decode('utf-8')\n    return str(base64_string)", "raw_solution": "import random\nimport string\nimport base64\nimport zlib\ndef task_func(string_length=100):\n    random_string = ''.join(random.choice(string.ascii_uppercase + string.digits) for _ in range(string_length))\n    compressed_string = zlib.compress(random_string.encode('utf-8'))\n    base64_string = base64.b64encode(compressed_string).decode('utf-8')\n    return str(base64_string)\n```"}
{"task_id": "BigCodeBench/549", "solution": "import base64\nimport pandas as pd\ndef task_func(df):\n    # Convert the DataFrame to CSV format\n    csv_data = df.to_csv(index=False)\n    \n    # Encode the CSV data to bytes\n    csv_bytes = csv_data.encode('utf-8')\n    \n    # Encode the bytes to Base64 string\n    base64_string = base64.b64encode(csv_bytes).decode('utf-8')\n    \n    return base64_string", "raw_solution": "import base64\nimport pandas as pd\n\ndef task_func(df):\n    # Convert the DataFrame to CSV format\n    csv_data = df.to_csv(index=False)\n    \n    # Encode the CSV data to bytes\n    csv_bytes = csv_data.encode('utf-8')\n    \n    # Encode the bytes to Base64 string\n    base64_string = base64.b64encode(csv_bytes).decode('utf-8')\n    \n    return base64_string\n```"}
{"task_id": "BigCodeBench/550", "solution": "from collections import Counter\nimport pandas as pd\ndef task_func(list_of_menuitems):\n    menu_items = []\n    for item in list_of_menuitems:\n        if isinstance(item, list):\n            menu_items.extend(item)\n        else:\n            menu_items.append(item)\n    menu_item_counts = Counter(menu_items)\n    return pd.DataFrame(menu_item_counts, index=['MenuItem'], columns=['Count'])", "raw_solution": "from collections import Counter\nimport pandas as pd\n\ndef task_func(list_of_menuitems):\n    menu_items = []\n    for item in list_of_menuitems:\n        if isinstance(item, list):\n            menu_items.extend(item)\n        else:\n            menu_items.append(item)\n    menu_item_counts = Counter(menu_items)\n    return pd.DataFrame(menu_item_counts, index=['MenuItem'], columns=['Count'])\n```"}
{"task_id": "BigCodeBench/551", "solution": "from collections import Counter\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport seaborn as sns\ndef task_func(list_of_menuitems):\n    # Flatten the list of menu items\n    flat_list = []\n    for item in list_of_menuitems:\n        if isinstance(item, list):\n            flat_list.extend(item)\n        else:\n            flat_list.append(item)\n    \n    # Count the frequency of each menu item\n    item_counts = Counter(flat_list)\n    \n    # Create a DataFrame from the item counts\n    df = pd.DataFrame(item_counts.items(), columns=['Item', 'Count'])\n    \n    # Create a barplot of the item counts\n    sns.barplot(x='Item', y='Count', data=df)\n    \n    # Return the Axes object representing the visualization\n    return plt.gca()", "raw_solution": "from collections import Counter\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport seaborn as sns\n\ndef task_func(list_of_menuitems):\n    # Flatten the list of menu items\n    flat_list = []\n    for item in list_of_menuitems:\n        if isinstance(item, list):\n            flat_list.extend(item)\n        else:\n            flat_list.append(item)\n    \n    # Count the frequency of each menu item\n    item_counts = Counter(flat_list)\n    \n    # Create a DataFrame from the item counts\n    df = pd.DataFrame(item_counts.items(), columns=['Item', 'Count'])\n    \n    # Create a barplot of the item counts\n    sns.barplot(x='Item', y='Count', data=df)\n    \n    # Return the Axes object representing the visualization\n    return plt.gca()\n```"}
{"task_id": "BigCodeBench/552", "solution": "import collections\nimport itertools\nimport matplotlib.pyplot as plt\nITEMS = ['apple', 'banana']\ndef task_func(a, b, items=ITEMS):\n    # Combine two lists\n    combined_list = list(itertools.chain(a, b))\n    # Count the frequency of predefined items\n    item_counts = collections.Counter(combined_list)\n    # Create a bar chart\n    plt.figure(figsize=(10, 5))\n    plt.bar(item_counts.keys(), item_counts.values())\n    plt.xlabel('Items')\n    plt.ylabel('Frequency')\n    plt.title('Frequency of predefined items in combined list')\n    plt.show()", "raw_solution": "import collections\nimport itertools\nimport matplotlib.pyplot as plt\n# Constants\nITEMS = ['apple', 'banana']\n\ndef task_func(a, b, items=ITEMS):\n    # Combine two lists\n    combined_list = list(itertools.chain(a, b))\n    # Count the frequency of predefined items\n    item_counts = collections.Counter(combined_list)\n    # Create a bar chart\n    plt.figure(figsize=(10, 5))\n    plt.bar(item_counts.keys(), item_counts.values())\n    plt.xlabel('Items')\n    plt.ylabel('Frequency')\n    plt.title('Frequency of predefined items in combined list')\n    plt.show()\n```"}
{"task_id": "BigCodeBench/553", "solution": "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nCOLUMNS = ['A', 'B', 'C', 'D', 'E']\ndef task_func(a, b):\n    # Generate random values\n    data = np.random.rand(len(a), len(b))\n    # Create DataFrame\n    df = pd.DataFrame(data, index=a, columns=COLUMNS)\n    # Plot bar chart\n    ax = df.plot(kind='bar')\n    return ax", "raw_solution": "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n# Constants\nCOLUMNS = ['A', 'B', 'C', 'D', 'E']\n\ndef task_func(a, b):\n    # Generate random values\n    data = np.random.rand(len(a), len(b))\n    # Create DataFrame\n    df = pd.DataFrame(data, index=a, columns=COLUMNS)\n    # Plot bar chart\n    ax = df.plot(kind='bar')\n    return ax\n```"}
{"task_id": "BigCodeBench/554", "solution": "import numpy as np\nimport random\ndef task_func(MIN_WORDS, MAX_WORDS, WORDS_POOL):\n    if MIN_WORDS > MAX_WORDS:\n        raise ValueError(\"MIN_WORDS must be less than or equal to MAX_WORDS\")\n    sentence_length = np.random.randint(MIN_WORDS, MAX_WORDS + 1)\n    sentence = ' '.join(random.sample(WORDS_POOL, sentence_length))\n    return sentence", "raw_solution": "import numpy as np\nimport random\n\ndef task_func(MIN_WORDS, MAX_WORDS, WORDS_POOL):\n    if MIN_WORDS > MAX_WORDS:\n        raise ValueError(\"MIN_WORDS must be less than or equal to MAX_WORDS\")\n    sentence_length = np.random.randint(MIN_WORDS, MAX_WORDS + 1)\n    sentence = ' '.join(random.sample(WORDS_POOL, sentence_length))\n    return sentence\n```"}
{"task_id": "BigCodeBench/555", "solution": "import matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom scipy import stats\ndef task_func(a, b):\n    # Calculate the Pearson correlation coefficient\n    corr = stats.pearsonr(a, b)[0]\n    \n    # Generate a Pandas DataFrame from these lists\n    df = pd.DataFrame({'a': a, 'b': b})\n    \n    # Draw a scatter plot with a regression line\n    plt.figure(figsize=(10, 6))\n    plt.scatter(df['a'], df['b'])\n    plt.plot(df['a'], stats.linregress(df['a'], df['b'])[0] * df['a'] + stats.linregress(df['a'], df['b'])[1], color='red')\n    plt.xlabel('a')\n    plt.ylabel('b')\n    plt.title('Scatter plot with regression line')\n    plt.show()\n    \n    return corr, plt.gca()", "raw_solution": "import matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom scipy import stats\n\ndef task_func(a, b):\n    # Calculate the Pearson correlation coefficient\n    corr = stats.pearsonr(a, b)[0]\n    \n    # Generate a Pandas DataFrame from these lists\n    df = pd.DataFrame({'a': a, 'b': b})\n    \n    # Draw a scatter plot with a regression line\n    plt.figure(figsize=(10, 6))\n    plt.scatter(df['a'], df['b'])\n    plt.plot(df['a'], stats.linregress(df['a'], df['b'])[0] * df['a'] + stats.linregress(df['a'], df['b'])[1], color='red')\n    plt.xlabel('a')\n    plt.ylabel('b')\n    plt.title('Scatter plot with regression line')\n    plt.show()\n    \n    return corr, plt.gca()\n```"}
{"task_id": "BigCodeBench/556", "solution": "import numpy as np\nimport random\nfrom difflib import SequenceMatcher\ndef task_func(s, min_length, max_length, letters):\n    # Generate a random string of length between min_length and max_length\n    length = random.randint(min_length, max_length)\n    string = ''.join(random.choice(letters) for _ in range(length))\n    \n    # Calculate the similarity score between the generated string and the provided string\n    similarity = SequenceMatcher(None, string, s).ratio()\n    \n    # Return a tuple containing the generated string and a boolean indicating whether it's considered similar to s based on the similarity threshold\n    return (string, similarity >= 0.5)", "raw_solution": "import numpy as np\nimport random\nfrom difflib import SequenceMatcher\n\ndef task_func(s, min_length, max_length, letters):\n    # Generate a random string of length between min_length and max_length\n    length = random.randint(min_length, max_length)\n    string = ''.join(random.choice(letters) for _ in range(length))\n    \n    # Calculate the similarity score between the generated string and the provided string\n    similarity = SequenceMatcher(None, string, s).ratio()\n    \n    # Return a tuple containing the generated string and a boolean indicating whether it's considered similar to s based on the similarity threshold\n    return (string, similarity >= 0.5)\n```"}
{"task_id": "BigCodeBench/557", "solution": "import numpy as np\nfrom difflib import SequenceMatcher\nimport matplotlib.pyplot as plt\ndef task_func(s_list, plot_path=None):\n    if not isinstance(s_list, list) or not all(isinstance(s, str) for s in s_list):\n        raise ValueError(\"If s_list is not a list of strings.\")\n    if len(s_list) == 1:\n        return np.nan\n    scores = []\n    for i in range(len(s_list)):\n        score = 0\n        for j in range(len(s_list)):\n            if i != j:\n                score += SequenceMatcher(None, s_list[i], s_list[j]).ratio()\n        scores.append(score / (len(s_list) - 1))\n    if plot_path:\n        plt.plot(scores)\n        plt.savefig(plot_path)\n    return scores", "raw_solution": "import numpy as np\nfrom difflib import SequenceMatcher\nimport matplotlib.pyplot as plt\n\ndef task_func(s_list, plot_path=None):\n    if not isinstance(s_list, list) or not all(isinstance(s, str) for s in s_list):\n        raise ValueError(\"If s_list is not a list of strings.\")\n    if len(s_list) == 1:\n        return np.nan\n    scores = []\n    for i in range(len(s_list)):\n        score = 0\n        for j in range(len(s_list)):\n            if i != j:\n                score += SequenceMatcher(None, s_list[i], s_list[j]).ratio()\n        scores.append(score / (len(s_list) - 1))\n    if plot_path:\n        plt.plot(scores)\n        plt.savefig(plot_path)\n    return scores\n```"}
{"task_id": "BigCodeBench/558", "solution": "import matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom sklearn.preprocessing import StandardScaler\ndef task_func(a, b, columns=['A', 'B']):\n    scaler = StandardScaler()\n    a_scaled = scaler.fit_transform(a.reshape(-1, 1))\n    b_scaled = scaler.fit_transform(b.reshape(-1, 1))\n    df = pd.DataFrame({'A': a_scaled.flatten(), 'B': b_scaled.flatten()})\n    ax = df.plot(kind='bar')\n    plt.show()\n    return df, ax", "raw_solution": "import matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom sklearn.preprocessing import StandardScaler\n\ndef task_func(a, b, columns=['A', 'B']):\n    scaler = StandardScaler()\n    a_scaled = scaler.fit_transform(a.reshape(-1, 1))\n    b_scaled = scaler.fit_transform(b.reshape(-1, 1))\n    df = pd.DataFrame({'A': a_scaled.flatten(), 'B': b_scaled.flatten()})\n    ax = df.plot(kind='bar')\n    plt.show()\n    return df, ax\n```"}
{"task_id": "BigCodeBench/559", "solution": "import pandas as pd\nfrom scipy.spatial import distance\nimport matplotlib.pyplot as plt\ndef task_func(a, b):\n    # Calculate the Euclidean distance between the two lists\n    distance = distance.euclidean(a, b)\n    \n    # Create a Pandas DataFrame from these lists with indices 'A' and 'B'\n    df = pd.DataFrame({'A': a, 'B': b})\n    \n    # Draw the values with a line displaying the Euclidean distance\n    fig, ax = plt.subplots()\n    ax.plot(df.index, df.values, marker='o')\n    ax.axhline(distance, color='r', linestyle='--', linewidth=2)\n    ax.set_xlabel('Index')\n    ax.set_ylabel('Value')\n    ax.set_title('Euclidean Distance Plot')\n    \n    return distance, df, ax", "raw_solution": "import pandas as pd\nfrom scipy.spatial import distance\nimport matplotlib.pyplot as plt\n\ndef task_func(a, b):\n    # Calculate the Euclidean distance between the two lists\n    distance = distance.euclidean(a, b)\n    \n    # Create a Pandas DataFrame from these lists with indices 'A' and 'B'\n    df = pd.DataFrame({'A': a, 'B': b})\n    \n    # Draw the values with a line displaying the Euclidean distance\n    fig, ax = plt.subplots()\n    ax.plot(df.index, df.values, marker='o')\n    ax.axhline(distance, color='r', linestyle='--', linewidth=2)\n    ax.set_xlabel('Index')\n    ax.set_ylabel('Value')\n    ax.set_title('Euclidean Distance Plot')\n    \n    return distance, df, ax\n```"}
{"task_id": "BigCodeBench/560", "solution": "from datetime import datetime\nimport matplotlib.pyplot as plt\nimport pandas as pd\ndef task_func(data):\n    df = pd.DataFrame(data)\n    df['month'] = pd.to_datetime(df['month']).dt.month\n    df['value'] = pd.to_numeric(df['value'])\n    fig, ax = plt.subplots()\n    ax.bar(df['month'], df['value'])\n    ax.set_title(f'Monthly Data for {datetime.now().year}')\n    ax.set_xlabel('Month')\n    ax.set_ylabel('Value')\n    return ax", "raw_solution": "from datetime import datetime\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\ndef task_func(data):\n    df = pd.DataFrame(data)\n    df['month'] = pd.to_datetime(df['month']).dt.month\n    df['value'] = pd.to_numeric(df['value'])\n    fig, ax = plt.subplots()\n    ax.bar(df['month'], df['value'])\n    ax.set_title(f'Monthly Data for {datetime.now().year}')\n    ax.set_xlabel('Month')\n    ax.set_ylabel('Value')\n    return ax\n```"}
{"task_id": "BigCodeBench/561", "solution": "import pytz\nfrom dateutil import parser\ndef task_func(date_str, from_tz, to_tz):\n    from_tz = pytz.timezone(from_tz)\n    to_tz = pytz.timezone(to_tz)\n    dt = parser.parse(date_str)\n    dt = dt.astimezone(to_tz)\n    return dt.strftime(\"%Y-%m-%d %H:%M:%S\")", "raw_solution": "import pytz\nfrom dateutil import parser\n\ndef task_func(date_str, from_tz, to_tz):\n    from_tz = pytz.timezone(from_tz)\n    to_tz = pytz.timezone(to_tz)\n    dt = parser.parse(date_str)\n    dt = dt.astimezone(to_tz)\n    return dt.strftime(\"%Y-%m-%d %H:%M:%S\")\n```"}
{"task_id": "BigCodeBench/562", "solution": "import os\nimport ctypes\nimport sys\nimport subprocess\ndef task_func(filepath):\n    if not os.path.isfile(filepath):\n        raise OSError(\"Invalid or empty filepath\")\n    if not isinstance(filepath, str):\n        raise TypeError(\"Input filepath is not a string\")\n    try:\n        dll = ctypes.CDLL(filepath)\n        system_name = ctypes.c_char_p()\n        ctypes.windll.kernel32.GetSystemInfo(ctypes.byref(system_name))\n        system_name = system_name.value.decode('utf-8')\n        node_name = ctypes.c_char_p()\n        ctypes.windll.kernel32.GetComputerName(ctypes.byref(node_name))\n        node_name = node_name.value.decode('utf-8')\n        release = ctypes.c_char_p()\n        ctypes.windll.kernel32.GetVersionExW(ctypes.byref(release))\n        release = release.value.decode('utf-8')\n        version = ctypes.c_char_p()\n        ctypes.windll.kernel32.GetVersionExW(ctypes.byref(version))\n        version = version.value.decode('utf-8')\n        machine = ctypes.c_char_p()\n        ctypes.windll.kernel32.GetSystemInfo(ctypes.byref(machine))\n        machine = machine.value.decode('utf-8')\n        python_version = sys.version\n        pip_version = subprocess.check_output(['pip', '--version']).decode('utf-8')\n        print(f\"System: {system_name} Node Name: {node_name} Release: {release} Version: {version} Machine: {machine} Python Version: {python_version} PIP Version: {pip_version}\")\n    except Exception as e:\n        print(f\"Error: {e}\")", "raw_solution": "import os\nimport ctypes\nimport sys\nimport subprocess\n\ndef task_func(filepath):\n    if not os.path.isfile(filepath):\n        raise OSError(\"Invalid or empty filepath\")\n    if not isinstance(filepath, str):\n        raise TypeError(\"Input filepath is not a string\")\n    try:\n        dll = ctypes.CDLL(filepath)\n        system_name = ctypes.c_char_p()\n        ctypes.windll.kernel32.GetSystemInfo(ctypes.byref(system_name))\n        system_name = system_name.value.decode('utf-8')\n        node_name = ctypes.c_char_p()\n        ctypes.windll.kernel32.GetComputerName(ctypes.byref(node_name))\n        node_name = node_name.value.decode('utf-8')\n        release = ctypes.c_char_p()\n        ctypes.windll.kernel32.GetVersionExW(ctypes.byref(release))\n        release = release.value.decode('utf-8')\n        version = ctypes.c_char_p()\n        ctypes.windll.kernel32.GetVersionExW(ctypes.byref(version))\n        version = version.value.decode('utf-8')\n        machine = ctypes.c_char_p()\n        ctypes.windll.kernel32.GetSystemInfo(ctypes.byref(machine))\n        machine = machine.value.decode('utf-8')\n        python_version = sys.version\n        pip_version = subprocess.check_output(['pip', '--version']).decode('utf-8')\n        print(f\"System: {system_name} Node Name: {node_name} Release: {release} Version: {version} Machine: {machine} Python Version: {python_version} PIP Version: {pip_version}\")\n    except Exception as e:\n        print(f\"Error: {e}\")\n```"}
{"task_id": "BigCodeBench/563", "solution": "import ctypes\nimport os\nimport shutil\nimport glob\ndef task_func(filepath, destination_dir):\n    # Load the DLL file\n    dll = ctypes.CDLL(filepath)\n    print(\"Loaded DLL file: \" + dll.name)\n    \n    # Get the current directory\n    current_dir = os.getcwd()\n    \n    # Get all DLL files in the current directory\n    dll_files = glob.glob(os.path.join(current_dir, \"*.dll\"))\n    \n    # Move all DLL files to the destination directory\n    for dll_file in dll_files:\n        shutil.move(dll_file, destination_dir)", "raw_solution": "import ctypes\nimport os\nimport shutil\nimport glob\n\ndef task_func(filepath, destination_dir):\n    # Load the DLL file\n    dll = ctypes.CDLL(filepath)\n    print(\"Loaded DLL file: \" + dll.name)\n    \n    # Get the current directory\n    current_dir = os.getcwd()\n    \n    # Get all DLL files in the current directory\n    dll_files = glob.glob(os.path.join(current_dir, \"*.dll\"))\n    \n    # Move all DLL files to the destination directory\n    for dll_file in dll_files:\n        shutil.move(dll_file, destination_dir)\n```"}
{"task_id": "BigCodeBench/564", "solution": "import os\nimport ctypes\nfrom datetime import datetime\nimport pytz\ndef task_func(filepath):\n    # Load the DLL file\n    dll = ctypes.CDLL(filepath)\n    \n    # Get the creation time of the DLL file\n    creation_time = os.path.getctime(filepath)\n    creation_time = datetime.utcfromtimestamp(creation_time)\n    creation_time = creation_time.astimezone(pytz.utc)\n    \n    # Get the modification time of the DLL file\n    modification_time = os.path.getmtime(filepath)\n    modification_time = datetime.utcfromtimestamp(modification_time)\n    modification_time = modification_time.astimezone(pytz.utc)\n    \n    # Get the size of the DLL file\n    size = os.path.getsize(filepath)\n    \n    # Return the metadata of the DLL file\n    return {\n        'Creation Time': creation_time.strftime('%Y-%m-%d %H:%M:%S'),\n        'Modification Time': modification_time.strftime('%Y-%m-%d %H:%M:%S'),\n        'Size': size\n    }", "raw_solution": "import os\nimport ctypes\nfrom datetime import datetime\nimport pytz\n\ndef task_func(filepath):\n    # Load the DLL file\n    dll = ctypes.CDLL(filepath)\n    \n    # Get the creation time of the DLL file\n    creation_time = os.path.getctime(filepath)\n    creation_time = datetime.utcfromtimestamp(creation_time)\n    creation_time = creation_time.astimezone(pytz.utc)\n    \n    # Get the modification time of the DLL file\n    modification_time = os.path.getmtime(filepath)\n    modification_time = datetime.utcfromtimestamp(modification_time)\n    modification_time = modification_time.astimezone(pytz.utc)\n    \n    # Get the size of the DLL file\n    size = os.path.getsize(filepath)\n    \n    # Return the metadata of the DLL file\n    return {\n        'Creation Time': creation_time.strftime('%Y-%m-%d %H:%M:%S'),\n        'Modification Time': modification_time.strftime('%Y-%m-%d %H:%M:%S'),\n        'Size': size\n    }\n```"}
{"task_id": "BigCodeBench/565", "solution": "import ctypes\nimport hashlib\nimport binascii\ndef task_func(filepath):\n    # Load the DLL file\n    dll = ctypes.CDLL(filepath)\n    \n    # Calculate MD5 hash\n    md5 = hashlib.md5()\n    md5.update(dll)\n    md5_hex = binascii.hexlify(md5.digest()).decode('utf-8')\n    \n    # Calculate SHA256 hash\n    sha256 = hashlib.sha256()\n    sha256.update(dll)\n    sha256_hex = binascii.hexlify(sha256.digest()).decode('utf-8')\n    \n    # Print the hashes\n    print(f\"Loaded DLL file: {filepath}\")\n    print(f\"MD5 hash: {md5_hex}\")\n    print(f\"SHA256 hash: {sha256_hex}\")", "raw_solution": "import ctypes\nimport hashlib\nimport binascii\n\ndef task_func(filepath):\n    # Load the DLL file\n    dll = ctypes.CDLL(filepath)\n    \n    # Calculate MD5 hash\n    md5 = hashlib.md5()\n    md5.update(dll)\n    md5_hex = binascii.hexlify(md5.digest()).decode('utf-8')\n    \n    # Calculate SHA256 hash\n    sha256 = hashlib.sha256()\n    sha256.update(dll)\n    sha256_hex = binascii.hexlify(sha256.digest()).decode('utf-8')\n    \n    # Print the hashes\n    print(f\"Loaded DLL file: {filepath}\")\n    print(f\"MD5 hash: {md5_hex}\")\n    print(f\"SHA256 hash: {sha256_hex}\")\n```"}
{"task_id": "BigCodeBench/566", "solution": "import inspect\nimport types\ndef task_func(f):\n    return {\n        'name': f.__name__,\n        'is_lambda': isinstance(f, types.LambdaType),\n        'arguments': inspect.signature(f).parameters,\n        'defaults': {k: v.default for k, v in inspect.signature(f).parameters.items() if v.default is not inspect.Parameter.empty},\n        'annotations': {k: v.annotation for k, v in inspect.signature(f).parameters.items()}\n    }", "raw_solution": "import inspect\nimport types\n\ndef task_func(f):\n    return {\n        'name': f.__name__,\n        'is_lambda': isinstance(f, types.LambdaType),\n        'arguments': inspect.signature(f).parameters,\n        'defaults': {k: v.default for k, v in inspect.signature(f).parameters.items() if v.default is not inspect.Parameter.empty},\n        'annotations': {k: v.annotation for k, v in inspect.signature(f).parameters.items()}\n    }\n```"}
{"task_id": "BigCodeBench/567", "solution": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\ndef task_func(data):\n    data = pd.Series(data)\n    ax = data.value_counts().plot(kind='bar', title='Histogram of Values')\n    ax.set_xlabel('Value')\n    ax.set_ylabel('Frequency')\n    return ax", "raw_solution": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef task_func(data):\n    data = pd.Series(data)\n    ax = data.value_counts().plot(kind='bar', title='Histogram of Values')\n    ax.set_xlabel('Value')\n    ax.set_ylabel('Frequency')\n    return ax\n```"}
{"task_id": "BigCodeBench/568", "solution": "import inspect\nimport matplotlib.pyplot as plt\nimport pandas as pd", "raw_solution": "import inspect\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\ndef task_func(f_list):\n    if any(isinstance(f, lambda) for f in f_list):\n        raise ValueError(\"if the input contains lambda function\")\n    df = pd.DataFrame(columns=['Function', 'Arguments'])\n    for f in f_list:\n        df = df.append({'Function': f.__name__, 'Arguments': len(inspect.signature(f).parameters)}, ignore_index=True)\n    df = df.sort_values(by='Arguments', ascending=False)\n    plt.figure(figsize=(10, 5))\n    plt.bar(df['Function'], df['Arguments'])\n    plt.xlabel('Function')\n    plt.ylabel('Number of Arguments')\n    plt.title('Number of Arguments for Each Function')\n    plt.xticks(rotation=45)\n    plt.show()\n    return df\n```"}
{"task_id": "BigCodeBench/569", "solution": "import inspect\nimport types\nimport math\ndef task_func(f):\n    # Get the function's name\n    func_name = f.__name__\n    # Get the number of arguments\n    num_args = len(inspect.signature(f).parameters)\n    # Get the count of lambda functions in default values\n    lambda_count = sum(isinstance(arg.default, types.LambdaType) for arg in inspect.signature(f).parameters.values())\n    # Return the dictionary\n    return {'name': func_name, 'sqrt_num_args': math.sqrt(num_args), 'lambda_count': lambda_count}", "raw_solution": "import inspect\nimport types\nimport math\n\ndef task_func(f):\n    # Get the function's name\n    func_name = f.__name__\n    # Get the number of arguments\n    num_args = len(inspect.signature(f).parameters)\n    # Get the count of lambda functions in default values\n    lambda_count = sum(isinstance(arg.default, types.LambdaType) for arg in inspect.signature(f).parameters.values())\n    # Return the dictionary\n    return {'name': func_name, 'sqrt_num_args': math.sqrt(num_args), 'lambda_count': lambda_count}\n```"}
{"task_id": "BigCodeBench/570", "solution": "import inspect\nimport types\nimport json\ndef task_func(f):\n    spec = inspect.getfullargspec(f)\n    return json.dumps({\n        'name': f.__name__,\n        'args': spec.args,\n        'defaults': spec.defaults,\n        'annotations': str(spec.annotations),\n        'is_lambda': isinstance(f, types.LambdaType)\n    })", "raw_solution": "import inspect\nimport types\nimport json\n\ndef task_func(f):\n    spec = inspect.getfullargspec(f)\n    return json.dumps({\n        'name': f.__name__,\n        'args': spec.args,\n        'defaults': spec.defaults,\n        'annotations': str(spec.annotations),\n        'is_lambda': isinstance(f, types.LambdaType)\n    })\n```"}
{"task_id": "BigCodeBench/571", "solution": "import inspect\nimport pandas as pd\ndef task_func(f_list, file_path):\n    if not isinstance(f_list, list) or not f_list:\n        raise ValueError('f_list is not a list of functions or is empty')\n    if not isinstance(file_path, str):\n        raise ValueError('file_path is not a valid path')\n    if not inspect.isfunction(f_list[0]):\n        raise ValueError('f_list is not a list of functions')\n    if not inspect.isfile(file_path):\n        raise IOError('There is an error in writing to the specified file path')\n    df = pd.DataFrame(columns=['Function Name', 'Number of Arguments', 'Defaults', 'Annotations', 'Is Lambda'])\n    for f in f_list:\n        func_name = f.__name__\n        num_args = len(inspect.signature(f).parameters)\n        defaults = ', '.join([f'{k}: {v}' for k, v in inspect.signature(f).parameters.items() if v.default is not inspect.Parameter.empty])\n        annotations = ', '.join([f'{k}: {v}' for k, v in inspect.signature(f).annotations.items()])\n        is_lambda = 'True' if inspect.isfunction(f) and f.__name__ == '<lambda>' else 'False'\n        df = df.append({'Function Name': func_name, 'Number of Arguments': num_args, 'Defaults': defaults, 'Annotations': annotations, 'Is Lambda': is_lambda}, ignore_index=True)\n    df.to_csv(file_path, index=False)\n    return None", "raw_solution": "import inspect\nimport pandas as pd\n\ndef task_func(f_list, file_path):\n    if not isinstance(f_list, list) or not f_list:\n        raise ValueError('f_list is not a list of functions or is empty')\n    if not isinstance(file_path, str):\n        raise ValueError('file_path is not a valid path')\n    if not inspect.isfunction(f_list[0]):\n        raise ValueError('f_list is not a list of functions')\n    if not inspect.isfile(file_path):\n        raise IOError('There is an error in writing to the specified file path')\n    df = pd.DataFrame(columns=['Function Name', 'Number of Arguments', 'Defaults', 'Annotations', 'Is Lambda'])\n    for f in f_list:\n        func_name = f.__name__\n        num_args = len(inspect.signature(f).parameters)\n        defaults = ', '.join([f'{k}: {v}' for k, v in inspect.signature(f).parameters.items() if v.default is not inspect.Parameter.empty])\n        annotations = ', '.join([f'{k}: {v}' for k, v in inspect.signature(f).annotations.items()])\n        is_lambda = 'True' if inspect.isfunction(f) and f.__name__ == '<lambda>' else 'False'\n        df = df.append({'Function Name': func_name, 'Number of Arguments': num_args, 'Defaults': defaults, 'Annotations': annotations, 'Is Lambda': is_lambda}, ignore_index=True)\n    df.to_csv(file_path, index=False)\n    return None\n```"}
{"task_id": "BigCodeBench/572", "solution": "from random import randint\nimport matplotlib.pyplot as plt\nimport numpy as np\ndef task_func(array_length=100):\n    array1 = [randint(0, 100) for _ in range(array_length)]\n    array2 = [randint(0, 100) for _ in range(array_length)]\n    max_values = [max(array1[i], array2[i]) for i in range(array_length)]\n    plt.plot(max_values)\n    plt.ylabel('Maximum Values')\n    plt.show()\n    return plt.gca()", "raw_solution": "from random import randint\nimport matplotlib.pyplot as plt\nimport numpy as np\n\ndef task_func(array_length=100):\n    array1 = [randint(0, 100) for _ in range(array_length)]\n    array2 = [randint(0, 100) for _ in range(array_length)]\n    max_values = [max(array1[i], array2[i]) for i in range(array_length)]\n    plt.plot(max_values)\n    plt.ylabel('Maximum Values')\n    plt.show()\n    return plt.gca()\n```"}
{"task_id": "BigCodeBench/573", "solution": "import numpy as np\nimport pandas as pd\ndef task_func(array_length=100):\n    array1 = np.random.rand(array_length)\n    array2 = np.random.rand(array_length)\n    mean1 = np.mean(array1)\n    mean2 = np.mean(array2)\n    median1 = np.median(array1)\n    median2 = np.median(array2)\n    std1 = np.std(array1)\n    std2 = np.std(array2)\n    statistics = pd.DataFrame({\n        'Array1': [mean1, median1, std1],\n        'Array2': [mean2, median2, std2]\n    })\n    return statistics", "raw_solution": "import numpy as np\nimport pandas as pd\ndef task_func(array_length=100):\n    array1 = np.random.rand(array_length)\n    array2 = np.random.rand(array_length)\n    mean1 = np.mean(array1)\n    mean2 = np.mean(array2)\n    median1 = np.median(array1)\n    median2 = np.median(array2)\n    std1 = np.std(array1)\n    std2 = np.std(array2)\n    statistics = pd.DataFrame({\n        'Array1': [mean1, median1, std1],\n        'Array2': [mean2, median2, std2]\n    })\n    return statistics\n```"}
{"task_id": "BigCodeBench/574", "solution": "from scipy.optimize import curve_fit\nimport matplotlib.pyplot as plt\nimport numpy as np\ndef task_func(array_length=100, noise_level=0.2):\n    # Generate a noisy sine wave\n    x = np.linspace(0, 2 * np.pi, array_length)\n    y = np.sin(x) + np.random.normal(0, noise_level, array_length)\n    \n    # Define the curve to fit\n    def curve(x, a, b):\n        return a * np.sin(b * x)\n    \n    # Fit the curve to the data\n    popt, pcov = curve_fit(curve, x, y)\n    \n    # Plot the noisy sine wave and the adjusted curve\n    plt.plot(x, y, label='Noisy sine wave')\n    plt.plot(x, curve(x, *popt), label='Adjusted curve')\n    plt.legend()\n    plt.show()", "raw_solution": "from scipy.optimize import curve_fit\nimport matplotlib.pyplot as plt\nimport numpy as np\n\ndef task_func(array_length=100, noise_level=0.2):\n    # Generate a noisy sine wave\n    x = np.linspace(0, 2 * np.pi, array_length)\n    y = np.sin(x) + np.random.normal(0, noise_level, array_length)\n    \n    # Define the curve to fit\n    def curve(x, a, b):\n        return a * np.sin(b * x)\n    \n    # Fit the curve to the data\n    popt, pcov = curve_fit(curve, x, y)\n    \n    # Plot the noisy sine wave and the adjusted curve\n    plt.plot(x, y, label='Noisy sine wave')\n    plt.plot(x, curve(x, *popt), label='Adjusted curve')\n    plt.legend()\n    plt.show()\n```"}
{"task_id": "BigCodeBench/575", "solution": "from random import shuffle\nimport pandas as pd\nimport numpy as np\ndef task_func(l, n_groups = 5):\n    shuffle(l)\n    df = pd.DataFrame(l)\n    for i in range(len(df)):\n        df.iloc[i, :] = np.roll(df.iloc[i, :], n_groups)\n    return df", "raw_solution": "from random import shuffle\nimport pandas as pd\nimport numpy as np\n# Constants\ndef task_func(l, n_groups = 5):\n    shuffle(l)\n    df = pd.DataFrame(l)\n    for i in range(len(df)):\n        df.iloc[i, :] = np.roll(df.iloc[i, :], n_groups)\n    return df\n```"}
{"task_id": "BigCodeBench/576", "solution": "from random import shuffle, randint\nimport pandas as pd\ndef task_func(l, n_groups = 5):\n    shuffle(l)\n    series = pd.Series(l)\n    for i in range(len(series)):\n        start = randint(0, len(series[i]) - n_groups)\n        end = start + n_groups\n        series[i] = series[i][end:] + series[i][:end]\n    return series", "raw_solution": "from random import shuffle, randint\nimport pandas as pd\n\ndef task_func(l, n_groups = 5):\n    shuffle(l)\n    series = pd.Series(l)\n    for i in range(len(series)):\n        start = randint(0, len(series[i]) - n_groups)\n        end = start + n_groups\n        series[i] = series[i][end:] + series[i][:end]\n    return series\n```"}
{"task_id": "BigCodeBench/577", "solution": "import os\nimport pathlib\nfrom hashlib import md5\nimport unicodedata\ndef task_func(directory):\n    result = {}\n    for root, dirs, files in os.walk(directory):\n        for file in files:\n            file_path = os.path.join(root, file)\n            normalized_file = unicodedata.normalize('NFKD', file).encode('ascii', 'ignore').decode('ascii')\n            with open(file_path, 'rb') as f:\n                file_size = os.path.getsize(file_path)\n                file_md5 = md5(f.read()).hexdigest()\n            result[normalized_file] = {'Size': file_size, 'MD5 Hash': file_md5}\n    return result", "raw_solution": "import os\nimport pathlib\nfrom hashlib import md5\nimport unicodedata\n\ndef task_func(directory):\n    result = {}\n    for root, dirs, files in os.walk(directory):\n        for file in files:\n            file_path = os.path.join(root, file)\n            normalized_file = unicodedata.normalize('NFKD', file).encode('ascii', 'ignore').decode('ascii')\n            with open(file_path, 'rb') as f:\n                file_size = os.path.getsize(file_path)\n                file_md5 = md5(f.read()).hexdigest()\n            result[normalized_file] = {'Size': file_size, 'MD5 Hash': file_md5}\n    return result\n```"}
{"task_id": "BigCodeBench/578", "solution": "import unicodedata\nimport requests\nURL = 'https://api.github.com/users/'\ndef task_func(username):\n    try:\n        response = requests.get(URL + username)\n        response.raise_for_status()\n        user_data = response.json()\n        normalized_data = {k: unicodedata.normalize('NFKD', v).encode('ascii', 'ignore').decode('ascii') for k, v in user_data.items()}\n        return normalized_data\n    except requests.exceptions.HTTPError as e:\n        raise e", "raw_solution": "import unicodedata\nimport requests\nURL = 'https://api.github.com/users/'\ndef task_func(username):\n    try:\n        response = requests.get(URL + username)\n        response.raise_for_status()\n        user_data = response.json()\n        normalized_data = {k: unicodedata.normalize('NFKD', v).encode('ascii', 'ignore').decode('ascii') for k, v in user_data.items()}\n        return normalized_data\n    except requests.exceptions.HTTPError as e:\n        raise e\n```"}
{"task_id": "BigCodeBench/579", "solution": "import unicodedata\nimport csv\nfrom collections import Counter\nimport matplotlib.pyplot as plt\ndef task_func(csv_file):\n    try:\n        with open(csv_file, 'r', encoding='utf-8') as f:\n            reader = csv.reader(f)\n            text = ''.join([row[0] for row in reader])\n    except FileNotFoundError:\n        raise FileNotFoundError('File not found')\n    except IOError:\n        raise IOError('Error in reading file')\n    text = unicodedata.normalize('NFKD', text)\n    text = text.encode('ascii', 'ignore').decode('ascii')\n    words = text.split()\n    word_counts = Counter(words)\n    top_10_words = word_counts.most_common(10)\n    fig, ax = plt.subplots()\n    ax.bar([word[0] for word in top_10_words], [word[1] for word in top_10_words])\n    ax.set_title('Top 10 Words')\n    ax.set_xlabel('Words')\n    ax.set_ylabel('Frequency')\n    return ax, top_10_words", "raw_solution": "import unicodedata\nimport csv\nfrom collections import Counter\nimport matplotlib.pyplot as plt\n\ndef task_func(csv_file):\n    try:\n        with open(csv_file, 'r', encoding='utf-8') as f:\n            reader = csv.reader(f)\n            text = ''.join([row[0] for row in reader])\n    except FileNotFoundError:\n        raise FileNotFoundError('File not found')\n    except IOError:\n        raise IOError('Error in reading file')\n    text = unicodedata.normalize('NFKD', text)\n    text = text.encode('ascii', 'ignore').decode('ascii')\n    words = text.split()\n    word_counts = Counter(words)\n    top_10_words = word_counts.most_common(10)\n    fig, ax = plt.subplots()\n    ax.bar([word[0] for word in top_10_words], [word[1] for word in top_10_words])\n    ax.set_title('Top 10 Words')\n    ax.set_xlabel('Words')\n    ax.set_ylabel('Frequency')\n    return ax, top_10_words\n```"}
{"task_id": "BigCodeBench/580", "solution": "import pandas as pd\nimport random\nimport statistics\nimport matplotlib.pyplot as plt\nimport numpy as np\nRANGE = 10000\nSIZE = 1000\nBIN_WIDTH = 100\ndef task_func():\n    # Generate random numbers\n    random_numbers = [random.randint(0, RANGE) for _ in range(SIZE)]\n    \n    # Calculate moving average\n    moving_average = [statistics.mean(random_numbers[i:i+5]) for i in range(SIZE-4)]\n    \n    # Create DataFrame\n    df = pd.DataFrame({\n        \"Random Numbers\": random_numbers,\n        \"Moving Average\": moving_average\n    })\n    \n    # Plot histogram\n    plt.hist(df[\"Random Numbers\"], bins=BIN_WIDTH)\n    plt.title(\"Histogram of Random Numbers\")\n    plt.xlabel(\"Random Numbers\")\n    plt.ylabel(\"Frequency\")\n    plt.show()\n    \n    return df", "raw_solution": "import pandas as pd\nimport random\nimport statistics\nimport matplotlib.pyplot as plt\nimport numpy as np\n# Constants\nRANGE = 10000  # The range within which random numbers are generated\nSIZE = 1000  # The number of random numbers to generate\nBIN_WIDTH = 100  # The width of bins for the histogram\n\ndef task_func():\n    # Generate random numbers\n    random_numbers = [random.randint(0, RANGE) for _ in range(SIZE)]\n    \n    # Calculate moving average\n    moving_average = [statistics.mean(random_numbers[i:i+5]) for i in range(SIZE-4)]\n    \n    # Create DataFrame\n    df = pd.DataFrame({\n        \"Random Numbers\": random_numbers,\n        \"Moving Average\": moving_average\n    })\n    \n    # Plot histogram\n    plt.hist(df[\"Random Numbers\"], bins=BIN_WIDTH)\n    plt.title(\"Histogram of Random Numbers\")\n    plt.xlabel(\"Random Numbers\")\n    plt.ylabel(\"Frequency\")\n    plt.show()\n    \n    return df\n```"}
{"task_id": "BigCodeBench/581", "solution": "import math\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport random\nSIZE = 1000\nPI = np.pi\ndef task_func(size=SIZE, frequency=1):\n    # Generate random sinusoidal values\n    x = np.linspace(0, 2 * PI, size)\n    y = np.sin(frequency * x)\n    # Plot the sinusoidal wave\n    plt.plot(x, y)\n    plt.show()", "raw_solution": "import math\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport random\n# Constants\nRANGE = 10000\nSIZE = 1000\nPI = np.pi\ndef task_func(size=SIZE, frequency=1):\n    # Generate random sinusoidal values\n    x = np.linspace(0, 2 * PI, size)\n    y = np.sin(frequency * x)\n    # Plot the sinusoidal wave\n    plt.plot(x, y)\n    plt.show()\n```"}
{"task_id": "BigCodeBench/582", "solution": "import numpy as np\nfrom scipy import stats\nimport matplotlib.pyplot as plt\ndef task_func(size=1000):\n    # Generate normally distributed random numbers\n    data = stats.norm.rvs(size=size)\n    \n    # Create histogram\n    fig, ax = plt.subplots()\n    ax.hist(data, bins=30, density=True, alpha=0.6, color='g')\n    \n    # Create PDF\n    x = np.linspace(data.min(), data.max(), 1000)\n    y = stats.norm.pdf(x, data.mean(), data.std())\n    ax.plot(x, y, 'r', linewidth=2)\n    \n    return fig", "raw_solution": "import numpy as np\nfrom scipy import stats\nimport matplotlib.pyplot as plt\n\ndef task_func(size=1000):\n    # Generate normally distributed random numbers\n    data = stats.norm.rvs(size=size)\n    \n    # Create histogram\n    fig, ax = plt.subplots()\n    ax.hist(data, bins=30, density=True, alpha=0.6, color='g')\n    \n    # Create PDF\n    x = np.linspace(data.min(), data.max(), 1000)\n    y = stats.norm.pdf(x, data.mean(), data.std())\n    ax.plot(x, y, 'r', linewidth=2)\n    \n    return fig\n```"}
{"task_id": "BigCodeBench/583", "solution": "import rsa\nimport os\nfrom Crypto.Random import get_random_bytes\nfrom Crypto.Cipher import AES\nfrom base64 import b64encode, b64decode\ndef task_func():\n    # Generate RSA public and private key pair\n    (public_key, private_key) = rsa.newkeys(2048)\n    \n    # Generate a random password and nonce\n    password = get_random_bytes(16)\n    nonce = get_random_bytes(16)\n    \n    # Encrypt the private key with AES\n    cipher = AES.new(password, AES.MODE_GCM, nonce)\n    encrypted_private_key = cipher.encrypt(private_key.export_key())\n    \n    # Save the encrypted private key to a file\n    filename = f\"private_key_{os.urandom(8).hex()}.txt\"\n    with open(filename, \"wb\") as f:\n        f.write(encrypted_private_key)\n    \n    # Return the public key, filename, password, and nonce\n    return public_key, filename, password, nonce", "raw_solution": "import rsa\nimport os\nfrom Crypto.Random import get_random_bytes\nfrom Crypto.Cipher import AES\nfrom base64 import b64encode, b64decode\n\ndef task_func():\n    # Generate RSA public and private key pair\n    (public_key, private_key) = rsa.newkeys(2048)\n    \n    # Generate a random password and nonce\n    password = get_random_bytes(16)\n    nonce = get_random_bytes(16)\n    \n    # Encrypt the private key with AES\n    cipher = AES.new(password, AES.MODE_GCM, nonce)\n    encrypted_private_key = cipher.encrypt(private_key.export_key())\n    \n    # Save the encrypted private key to a file\n    filename = f\"private_key_{os.urandom(8).hex()}.txt\"\n    with open(filename, \"wb\") as f:\n        f.write(encrypted_private_key)\n    \n    # Return the public key, filename, password, and nonce\n    return public_key, filename, password, nonce\n```"}
{"task_id": "BigCodeBench/584", "solution": "import rsa\nimport urllib.request\nfrom hashlib import sha256\ndef task_func(url):\n    try:\n        # Generate RSA public and private keys\n        (pubkey, privkey) = rsa.newkeys(2048)\n        \n        # Retrieve the content from the specified URL\n        with urllib.request.urlopen(url) as response:\n            content = response.read()\n        \n        # Calculate its SHA256 hash\n        hash = sha256(content).hexdigest()\n        \n        # Sign the hash with the private key\n        signature = rsa.sign(hash.encode(), privkey, 'SHA-256')\n        \n        # Return the public key and the signed hash as a hexadecimal string\n        return pubkey, signature.hex(), content\n    except ValueError as e:\n        raise ValueError(str(e))\n    except rsa.pkcs1.VerificationError as e:\n        raise rsa.pkcs1.VerificationError(str(e))\n    except urllib.error.URLError as e:\n        raise urllib.error.URLError(str(e))", "raw_solution": "import rsa\nimport urllib.request\nfrom hashlib import sha256\n\ndef task_func(url):\n    try:\n        # Generate RSA public and private keys\n        (pubkey, privkey) = rsa.newkeys(2048)\n        \n        # Retrieve the content from the specified URL\n        with urllib.request.urlopen(url) as response:\n            content = response.read()\n        \n        # Calculate its SHA256 hash\n        hash = sha256(content).hexdigest()\n        \n        # Sign the hash with the private key\n        signature = rsa.sign(hash.encode(), privkey, 'SHA-256')\n        \n        # Return the public key and the signed hash as a hexadecimal string\n        return pubkey, signature.hex(), content\n    except ValueError as e:\n        raise ValueError(str(e))\n    except rsa.pkcs1.VerificationError as e:\n        raise rsa.pkcs1.VerificationError(str(e))\n    except urllib.error.URLError as e:\n        raise urllib.error.URLError(str(e))\n```"}
{"task_id": "BigCodeBench/585", "solution": "import rsa\nimport os\nimport zipfile\nfrom base64 import b64encode\ndef task_func(directory):\n    # Generate RSA public and private keys\n    (public_key, private_key) = rsa.newkeys(2048)\n    \n    # Create a zip file to store the encrypted files\n    zip_file = zipfile.ZipFile('encrypted_files.zip', 'w')\n    \n    # Encrypt all files in the specified directory\n    for filename in os.listdir(directory):\n        file_path = os.path.join(directory, filename)\n        if os.path.isfile(file_path):\n            with open(file_path, 'rb') as f:\n                file_data = f.read()\n            encrypted_data = rsa.encrypt(file_data, public_key)\n            zip_file.writestr(filename, b64encode(encrypted_data))\n    \n    # Return the public key and the name of the zip file\n    return public_key, 'encrypted_files.zip'", "raw_solution": "import rsa\nimport os\nimport zipfile\nfrom base64 import b64encode\n\ndef task_func(directory):\n    # Generate RSA public and private keys\n    (public_key, private_key) = rsa.newkeys(2048)\n    \n    # Create a zip file to store the encrypted files\n    zip_file = zipfile.ZipFile('encrypted_files.zip', 'w')\n    \n    # Encrypt all files in the specified directory\n    for filename in os.listdir(directory):\n        file_path = os.path.join(directory, filename)\n        if os.path.isfile(file_path):\n            with open(file_path, 'rb') as f:\n                file_data = f.read()\n            encrypted_data = rsa.encrypt(file_data, public_key)\n            zip_file.writestr(filename, b64encode(encrypted_data))\n    \n    # Return the public key and the name of the zip file\n    return public_key, 'encrypted_files.zip'\n```"}
{"task_id": "BigCodeBench/586", "solution": "import rsa\nfrom cryptography.fernet import Fernet\nfrom base64 import b64encode\ndef task_func(file_path):\n    # Generate RSA public and private keys\n    (public_key, private_key) = rsa.newkeys(2048)\n    # Generate Fernet symmetric key\n    fernet = Fernet(b64encode(os.urandom(32)))\n    # Read file contents\n    with open(file_path, 'rb') as f:\n        file_contents = f.read()\n    # Encrypt file contents\n    encrypted_file_contents = fernet.encrypt(file_contents)\n    # Encrypt Fernet key with public RSA key\n    encrypted_key = rsa.encrypt(fernet.key, public_key)\n    # Save encrypted file contents and encrypted Fernet key to separate files\n    with open('encrypted_file.txt', 'wb') as f:\n        f.write(encrypted_file_contents)\n    with open('encrypted_key.txt', 'wb') as f:\n        f.write(encrypted_key)\n    # Return public key, filename of encrypted file, and filename of encrypted Fernet key\n    return public_key, 'encrypted_file.txt', 'encrypted_key.txt'", "raw_solution": "import rsa\nfrom cryptography.fernet import Fernet\nfrom base64 import b64encode\n\ndef task_func(file_path):\n    # Generate RSA public and private keys\n    (public_key, private_key) = rsa.newkeys(2048)\n    # Generate Fernet symmetric key\n    fernet = Fernet(b64encode(os.urandom(32)))\n    # Read file contents\n    with open(file_path, 'rb') as f:\n        file_contents = f.read()\n    # Encrypt file contents\n    encrypted_file_contents = fernet.encrypt(file_contents)\n    # Encrypt Fernet key with public RSA key\n    encrypted_key = rsa.encrypt(fernet.key, public_key)\n    # Save encrypted file contents and encrypted Fernet key to separate files\n    with open('encrypted_file.txt', 'wb') as f:\n        f.write(encrypted_file_contents)\n    with open('encrypted_key.txt', 'wb') as f:\n        f.write(encrypted_key)\n    # Return public key, filename of encrypted file, and filename of encrypted Fernet key\n    return public_key, 'encrypted_file.txt', 'encrypted_key.txt'\n```"}
{"task_id": "BigCodeBench/587", "solution": "import rsa\nimport os\nfrom cryptography.hazmat.backends import default_backend\nfrom cryptography.hazmat.primitives.ciphers import Cipher, algorithms, modes\nfrom cryptography.hazmat.primitives import padding\nfrom base64 import b64encode\ndef task_func(file_path):\n    # Generate RSA public and private keys\n    (pubkey, privkey) = rsa.newkeys(2048, backend=default_backend())\n    # Generate AES key\n    key = os.urandom(32)\n    # Encrypt file using AES\n    with open(file_path, 'rb') as f:\n        data = f.read()\n    cipher = Cipher(algorithms.AES(key), modes.CBC(os.urandom(16)), backend=default_backend())\n    padder = padding.PKCS7(128).padder()\n    padded_data = padder.update(data) + padder.finalize()\n    encryptor = cipher.encryptor()\n    encrypted_data = encryptor.update(padded_data) + encryptor.finalize()\n    # Encrypt AES key with public RSA key\n    encrypted_key = rsa.encrypt(key, pubkey)\n    # Save encrypted file and encrypted AES key\n    with open('encrypted_file', 'wb') as f:\n        f.write(encrypted_data)\n    with open('encrypted_key', 'wb') as f:\n        f.write(encrypted_key)\n    return pubkey, 'encrypted_file', 'encrypted_key'", "raw_solution": "import rsa\nimport os\nfrom cryptography.hazmat.backends import default_backend\nfrom cryptography.hazmat.primitives.ciphers import Cipher, algorithms, modes\nfrom cryptography.hazmat.primitives import padding\nfrom base64 import b64encode\n\ndef task_func(file_path):\n    # Generate RSA public and private keys\n    (pubkey, privkey) = rsa.newkeys(2048, backend=default_backend())\n    # Generate AES key\n    key = os.urandom(32)\n    # Encrypt file using AES\n    with open(file_path, 'rb') as f:\n        data = f.read()\n    cipher = Cipher(algorithms.AES(key), modes.CBC(os.urandom(16)), backend=default_backend())\n    padder = padding.PKCS7(128).padder()\n    padded_data = padder.update(data) + padder.finalize()\n    encryptor = cipher.encryptor()\n    encrypted_data = encryptor.update(padded_data) + encryptor.finalize()\n    # Encrypt AES key with public RSA key\n    encrypted_key = rsa.encrypt(key, pubkey)\n    # Save encrypted file and encrypted AES key\n    with open('encrypted_file', 'wb') as f:\n        f.write(encrypted_data)\n    with open('encrypted_key', 'wb') as f:\n        f.write(encrypted_key)\n    return pubkey, 'encrypted_file', 'encrypted_key'\n```"}
{"task_id": "BigCodeBench/588", "solution": "import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nRANGE = 100\nSIZE = 1000\ndef task_func():\n    # Generate random integers within the specified range\n    x = np.random.randint(0, RANGE, SIZE)\n    y = np.random.randint(0, RANGE, SIZE)\n    # Create a DataFrame with the generated random integers\n    df = pd.DataFrame({'X': x, 'Y': y})\n    # Plot the points using a scatter plot\n    sns.scatterplot(x='X', y='Y', data=df)\n    # Show the plot\n    plt.show()", "raw_solution": "import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n# Constants defining the range of random integers and the size of the DataFrame\nRANGE = 100\nSIZE = 1000\n\ndef task_func():\n    # Generate random integers within the specified range\n    x = np.random.randint(0, RANGE, SIZE)\n    y = np.random.randint(0, RANGE, SIZE)\n    # Create a DataFrame with the generated random integers\n    df = pd.DataFrame({'X': x, 'Y': y})\n    # Plot the points using a scatter plot\n    sns.scatterplot(x='X', y='Y', data=df)\n    # Show the plot\n    plt.show()\n```"}
{"task_id": "BigCodeBench/589", "solution": "import matplotlib.pyplot as plt\nimport numpy as np\nfrom sklearn.cluster import KMeans\nRANGE = 100\nSIZE = 1000\nCLUSTERS = 5\ndef task_func():\n    # Generate random points\n    data = np.random.rand(SIZE, 2) * RANGE\n\n    # Apply KMeans clustering\n    kmeans = KMeans(n_clusters=CLUSTERS, random_state=0).fit(data)\n\n    # Plot the results\n    plt.scatter(data[:, 0], data[:, 1], c=kmeans.labels_, cmap='viridis')\n    plt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], c='red', marker='x')\n    plt.show()\n\n    return (data, kmeans)", "raw_solution": "import matplotlib.pyplot as plt\nimport numpy as np\nfrom sklearn.cluster import KMeans\n\n# Constants for configuration\nRANGE = 100\nSIZE = 1000\nCLUSTERS = 5\n\ndef task_func():\n    # Generate random points\n    data = np.random.rand(SIZE, 2) * RANGE\n\n    # Apply KMeans clustering\n    kmeans = KMeans(n_clusters=CLUSTERS, random_state=0).fit(data)\n\n    # Plot the results\n    plt.scatter(data[:, 0], data[:, 1], c=kmeans.labels_, cmap='viridis')\n    plt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], c='red', marker='x')\n    plt.show()\n\n    return (data, kmeans)\n```"}
{"task_id": "BigCodeBench/590", "solution": "import urllib.request\nfrom pyquery import PyQuery as pq\nfrom datetime import datetime\nimport pandas as pd\ndef task_func(url):\n    if not url or not isinstance(url, str):\n        raise ValueError(\"Invalid or empty URL\")\n    try:\n        response = urllib.request.urlopen(url)\n        html = response.read()\n    except urllib.error.URLError as e:\n        raise URLError(\"Error fetching HTML content: \" + str(e))\n    pq_html = pq(html)\n    anchor_tags = pq_html('a')\n    data = []\n    for tag in anchor_tags:\n        text = tag.text()\n        href = tag.attr('href')\n        if text and href:\n            data.append({'text': text, 'href': href, 'fetch_time': datetime.now().strftime('%Y-%m-%d %H:%M:%S')})\n    return pd.DataFrame(data)", "raw_solution": "import urllib.request\nfrom pyquery import PyQuery as pq\nfrom datetime import datetime\nimport pandas as pd\n\ndef task_func(url):\n    if not url or not isinstance(url, str):\n        raise ValueError(\"Invalid or empty URL\")\n    try:\n        response = urllib.request.urlopen(url)\n        html = response.read()\n    except urllib.error.URLError as e:\n        raise URLError(\"Error fetching HTML content: \" + str(e))\n    pq_html = pq(html)\n    anchor_tags = pq_html('a')\n    data = []\n    for tag in anchor_tags:\n        text = tag.text()\n        href = tag.attr('href')\n        if text and href:\n            data.append({'text': text, 'href': href, 'fetch_time': datetime.now().strftime('%Y-%m-%d %H:%M:%S')})\n    return pd.DataFrame(data)\n```"}
{"task_id": "BigCodeBench/591", "solution": "from datetime import datetime\nfrom random import randint\nimport matplotlib.pyplot as plt\nimport pandas as pd\nTEMP_CATEGORIES = ['Cold', 'Normal', 'Hot']\nFILE_PATH = 'custom_data.csv'\ndef task_func(hours, file_path=FILE_PATH):\n    data = []\n    for i in range(hours):\n        time = datetime.now() + timedelta(hours=i)\n        temperature = randint(10, 30)\n        category = TEMP_CATEGORIES[randint(0, 2)]\n        data.append({'Time': time, 'Temperature': temperature, 'Category': category})\n    df = pd.DataFrame(data)\n    df.to_csv(file_path, index=False)\n    fig, ax = plt.subplots()\n    ax.plot(df['Time'], df['Temperature'], label='Temperature')\n    ax.set_xlabel('Time')\n    ax.set_ylabel('Temperature')\n    ax.set_title('Temperature Data')\n    ax.legend()\n    return (file_path, ax)", "raw_solution": "from datetime import datetime\nfrom random import randint\nimport matplotlib.pyplot as plt\nimport pandas as pd\nTEMP_CATEGORIES = ['Cold', 'Normal', 'Hot']\nFILE_PATH = 'custom_data.csv'\n\ndef task_func(hours, file_path=FILE_PATH):\n    data = []\n    for i in range(hours):\n        time = datetime.now() + timedelta(hours=i)\n        temperature = randint(10, 30)\n        category = TEMP_CATEGORIES[randint(0, 2)]\n        data.append({'Time': time, 'Temperature': temperature, 'Category': category})\n    df = pd.DataFrame(data)\n    df.to_csv(file_path, index=False)\n    fig, ax = plt.subplots()\n    ax.plot(df['Time'], df['Temperature'], label='Temperature')\n    ax.set_xlabel('Time')\n    ax.set_ylabel('Temperature')\n    ax.set_title('Temperature Data')\n    ax.legend()\n    return (file_path, ax)\n```"}
{"task_id": "BigCodeBench/592", "solution": "import csv\nimport os\nfrom datetime import datetime\nfrom random import randint\nSENSORS = ['Temperature', 'Humidity', 'Pressure']\nOUTPUT_DIR = './output'\ndef task_func(hours, output_dir=OUTPUT_DIR):\n    # Create output directory if it doesn't exist\n    if not os.path.exists(output_dir):\n        os.makedirs(output_dir)\n    # Generate sensor data\n    for i in range(hours):\n        # Create a new CSV file for each hour\n        filename = os.path.join(output_dir, f'sensor_data_{i+1}.csv')\n        with open(filename, 'w', newline='') as file:\n            writer = csv.writer(file)\n            # Write header\n            writer.writerow(['Time', 'Temperature', 'Humidity', 'Pressure'])\n            # Generate random data for each sensor\n            for sensor in SENSORS:\n                writer.writerow([datetime.now().strftime('%Y-%m-%d %H:%M:%S'), randint(10, 30), randint(30, 70), randint(1000, 1500)])", "raw_solution": "import csv\nimport os\nfrom datetime import datetime\nfrom random import randint\n# Constants\nSENSORS = ['Temperature', 'Humidity', 'Pressure']\nOUTPUT_DIR = './output'\ndef task_func(hours, output_dir=OUTPUT_DIR):\n    # Create output directory if it doesn't exist\n    if not os.path.exists(output_dir):\n        os.makedirs(output_dir)\n    # Generate sensor data\n    for i in range(hours):\n        # Create a new CSV file for each hour\n        filename = os.path.join(output_dir, f'sensor_data_{i+1}.csv')\n        with open(filename, 'w', newline='') as file:\n            writer = csv.writer(file)\n            # Write header\n            writer.writerow(['Time', 'Temperature', 'Humidity', 'Pressure'])\n            # Generate random data for each sensor\n            for sensor in SENSORS:\n                writer.writerow([datetime.now().strftime('%Y-%m-%d %H:%M:%S'), randint(10, 30), randint(30, 70), randint(1000, 1500)])\n```"}
{"task_id": "BigCodeBench/593", "solution": "import csv\nimport os\nfrom datetime import datetime\nfrom random import randint\nimport matplotlib.pyplot as plt\nimport pandas as pd\nVEHICLE_TYPES = ['Car', 'Bus', 'Truck', 'Bike']\nOUTPUT_DIR = './output'\ndef task_func(hours, output_dir=OUTPUT_DIR):\n    # Create output directory if it doesn't exist\n    if not os.path.exists(output_dir):\n        os.makedirs(output_dir)\n    # Generate traffic data\n    data = []\n    for i in range(hours):\n        time = datetime.now() + timedelta(hours=i)\n        car_count = randint(0, 100)\n        bus_count = randint(0, 100)\n        truck_count = randint(0, 100)\n        bike_count = randint(0, 100)\n        data.append([time, car_count, bus_count, truck_count, bike_count])\n    # Save data to CSV file\n    csv_file = os.path.join(output_dir, 'traffic_data.csv')\n    with open(csv_file, 'w', newline='') as f:\n        writer = csv.writer(f)\n        writer.writerow(['Time', 'Car', 'Bus', 'Truck', 'Bike'])\n        writer.writerows(data)\n    # Plot data\n    fig, ax = plt.subplots()\n    for vehicle_type in VEHICLE_TYPES:\n        ax.plot([d[0] for d in data], [d[vehicle_type] for d in data], label=vehicle_type)\n    ax.set_xlabel('Time')\n    ax.set_ylabel('Vehicle Count')\n    ax.set_title('Traffic Data')\n    ax.legend()\n    plt.savefig(os.path.join(output_dir, 'traffic_data_plot.png'))\n    return (csv_file, ax)", "raw_solution": "import csv\nimport os\nfrom datetime import datetime\nfrom random import randint\nimport matplotlib.pyplot as plt\nimport pandas as pd\n# Constants\nVEHICLE_TYPES = ['Car', 'Bus', 'Truck', 'Bike']\nOUTPUT_DIR = './output'\ndef task_func(hours, output_dir=OUTPUT_DIR):\n    # Create output directory if it doesn't exist\n    if not os.path.exists(output_dir):\n        os.makedirs(output_dir)\n    # Generate traffic data\n    data = []\n    for i in range(hours):\n        time = datetime.now() + timedelta(hours=i)\n        car_count = randint(0, 100)\n        bus_count = randint(0, 100)\n        truck_count = randint(0, 100)\n        bike_count = randint(0, 100)\n        data.append([time, car_count, bus_count, truck_count, bike_count])\n    # Save data to CSV file\n    csv_file = os.path.join(output_dir, 'traffic_data.csv')\n    with open(csv_file, 'w', newline='') as f:\n        writer = csv.writer(f)\n        writer.writerow(['Time', 'Car', 'Bus', 'Truck', 'Bike'])\n        writer.writerows(data)\n    # Plot data\n    fig, ax = plt.subplots()\n    for vehicle_type in VEHICLE_TYPES:\n        ax.plot([d[0] for d in data], [d[vehicle_type] for d in data], label=vehicle_type)\n    ax.set_xlabel('Time')\n    ax.set_ylabel('Vehicle Count')\n    ax.set_title('Traffic Data')\n    ax.legend()\n    plt.savefig(os.path.join(output_dir, 'traffic_data_plot.png'))\n    return (csv_file, ax)\n```"}
{"task_id": "BigCodeBench/594", "solution": "import csv\nimport os\nimport shutil\nfrom datetime import datetime\nfrom random import randint\nWEATHER_CONDITIONS = ['Sunny', 'Cloudy', 'Rainy', 'Snowy', 'Stormy']\nOUTPUT_DIR = './output'\ndef task_func(hours, output_dir=OUTPUT_DIR):\n    # Create output directory if it doesn't exist\n    if not os.path.exists(output_dir):\n        os.makedirs(output_dir)\n    \n    # Generate weather data\n    weather_data = []\n    for i in range(hours):\n        time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n        condition = WEATHER_CONDITIONS[randint(0, len(WEATHER_CONDITIONS) - 1)]\n        weather_data.append([time, condition])\n    \n    # Save weather data to CSV file\n    csv_file_path = os.path.join(output_dir, 'weather_data.csv')\n    with open(csv_file_path, 'w', newline='') as file:\n        writer = csv.writer(file)\n        writer.writerow(['Time', 'Condition'])\n        writer.writerows(weather_data)\n    \n    # Back up the file to a backup directory\n    backup_dir = os.path.join(output_dir, 'backup')\n    if not os.path.exists(backup_dir):\n        os.makedirs(backup_dir)\n    shutil.copy(csv_file_path, os.path.join(backup_dir, 'weather_data.csv'))\n    \n    return csv_file_path", "raw_solution": "import csv\nimport os\nimport shutil\nfrom datetime import datetime\nfrom random import randint\n# Constants\nWEATHER_CONDITIONS = ['Sunny', 'Cloudy', 'Rainy', 'Snowy', 'Stormy']\nOUTPUT_DIR = './output'\n\ndef task_func(hours, output_dir=OUTPUT_DIR):\n    # Create output directory if it doesn't exist\n    if not os.path.exists(output_dir):\n        os.makedirs(output_dir)\n    \n    # Generate weather data\n    weather_data = []\n    for i in range(hours):\n        time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n        condition = WEATHER_CONDITIONS[randint(0, len(WEATHER_CONDITIONS) - 1)]\n        weather_data.append([time, condition])\n    \n    # Save weather data to CSV file\n    csv_file_path = os.path.join(output_dir, 'weather_data.csv')\n    with open(csv_file_path, 'w', newline='') as file:\n        writer = csv.writer(file)\n        writer.writerow(['Time', 'Condition'])\n        writer.writerows(weather_data)\n    \n    # Back up the file to a backup directory\n    backup_dir = os.path.join(output_dir, 'backup')\n    if not os.path.exists(backup_dir):\n        os.makedirs(backup_dir)\n    shutil.copy(csv_file_path, os.path.join(backup_dir, 'weather_data.csv'))\n    \n    return csv_file_path\n```"}
{"task_id": "BigCodeBench/595", "solution": "import random\nimport bisect\nfrom array import array\ndef task_func(n=10, total=100):\n    while True:\n        numbers = array('i', [random.randint(1, total) for _ in range(n)])\n        if sum(numbers) == total:\n            break\n    numbers.sort()\n    insertion_position = bisect.bisect_left(numbers, random.randint(1, total))\n    return (numbers, insertion_position)", "raw_solution": "import random\nimport bisect\nfrom array import array\n\ndef task_func(n=10, total=100):\n    while True:\n        numbers = array('i', [random.randint(1, total) for _ in range(n)])\n        if sum(numbers) == total:\n            break\n    numbers.sort()\n    insertion_position = bisect.bisect_left(numbers, random.randint(1, total))\n    return (numbers, insertion_position)\n```"}
{"task_id": "BigCodeBench/596", "solution": "import time\nfrom datetime import datetime\nfrom random import randint\nimport matplotlib.pyplot as plt\ndef task_func(duration):\n    timestamps = []\n    values = []\n    start_time = datetime.now()\n    end_time = start_time + timedelta(seconds=duration)\n    while datetime.now() < end_time:\n        timestamps.append(datetime.now().strftime('%H:%M:%S.%f'))\n        values.append(randint(0, 100))\n        time.sleep(0.1)\n    return (timestamps, values)", "raw_solution": "import time\nfrom datetime import datetime\nfrom random import randint\nimport matplotlib.pyplot as plt\n\ndef task_func(duration):\n    timestamps = []\n    values = []\n    start_time = datetime.now()\n    end_time = start_time + timedelta(seconds=duration)\n    while datetime.now() < end_time:\n        timestamps.append(datetime.now().strftime('%H:%M:%S.%f'))\n        values.append(randint(0, 100))\n        time.sleep(0.1)\n    return (timestamps, values)\n```"}
{"task_id": "BigCodeBench/597", "solution": "import pandas as pd\nimport time\ndef task_func(data, letter):\n    # Convert the dict to a DataFrame\n    df = pd.DataFrame(data)\n    # Filter rows in this DataFrame\n    filtered_df = df[df['Name'].str.startswith(letter)]\n    # Return a Series of filtered 'Name' column\n    return filtered_df['Name']", "raw_solution": "import pandas as pd\nimport time\n# Constants\nLETTERS = list('abcdefghijklmnopqrstuvwxyz')\ndef task_func(data, letter):\n    # Convert the dict to a DataFrame\n    df = pd.DataFrame(data)\n    # Filter rows in this DataFrame\n    filtered_df = df[df['Name'].str.startswith(letter)]\n    # Return a Series of filtered 'Name' column\n    return filtered_df['Name']\n```"}
{"task_id": "BigCodeBench/598", "solution": "import pandas as pd\nimport time\ndef task_func(df, letter):\n    # Convert the dict to DataFrame\n    df = pd.DataFrame(df)\n    # Filter rows in which the values of the 'Word' column begin with a specified letter\n    df = df[df['Word'].str.startswith(letter)]\n    # Calculate the length of the words in the filtered column and return a dictionary of word lengths and their respective counts\n    word_lengths = df['Word'].str.len()\n    word_lengths = word_lengths.value_counts().to_dict()\n    return word_lengths", "raw_solution": "import pandas as pd\nimport time\ndef task_func(df, letter):\n    # Convert the dict to DataFrame\n    df = pd.DataFrame(df)\n    # Filter rows in which the values of the 'Word' column begin with a specified letter\n    df = df[df['Word'].str.startswith(letter)]\n    # Calculate the length of the words in the filtered column and return a dictionary of word lengths and their respective counts\n    word_lengths = df['Word'].str.len()\n    word_lengths = word_lengths.value_counts().to_dict()\n    return word_lengths\n```"}
{"task_id": "BigCodeBench/599", "solution": "import pandas as pd\nimport time\ndef task_func(df, letter):\n    # Convert the input dictionary into a DataFrame\n    df = pd.DataFrame(df)\n    \n    # Filter rows where 'Word' column values start with the specified letter\n    df = df[df['Word'].str.startswith(letter)]\n    \n    # Calculate the lengths of these words\n    df['Length'] = df['Word'].str.len()\n    \n    # Create a histogram plot of the word lengths\n    df['Length'].hist()\n    \n    # Return the histogram plot\n    return df['Length'].hist()", "raw_solution": "import pandas as pd\nimport time\ndef task_func(df, letter):\n    # Convert the input dictionary into a DataFrame\n    df = pd.DataFrame(df)\n    \n    # Filter rows where 'Word' column values start with the specified letter\n    df = df[df['Word'].str.startswith(letter)]\n    \n    # Calculate the lengths of these words\n    df['Length'] = df['Word'].str.len()\n    \n    # Create a histogram plot of the word lengths\n    df['Length'].hist()\n    \n    # Return the histogram plot\n    return df['Length'].hist()\n```"}
{"task_id": "BigCodeBench/600", "solution": "import numpy as np\nimport pandas as pd\ndef task_func(df, letter):\n    df = df[df['Word'].str.startswith(letter)]\n    word_lengths = df['Word'].str.len()\n    return {'mean': word_lengths.mean(), 'median': word_lengths.median(), 'mode': word_lengths.mode()[0]}", "raw_solution": "import numpy as np\nimport pandas as pd\n\ndef task_func(df, letter):\n    df = df[df['Word'].str.startswith(letter)]\n    word_lengths = df['Word'].str.len()\n    return {'mean': word_lengths.mean(), 'median': word_lengths.median(), 'mode': word_lengths.mode()[0]}\n```"}
{"task_id": "BigCodeBench/601", "solution": "import seaborn as sns\nimport time\ndef task_func(df, letter):\n    if df.empty or 'Word' not in df.columns:\n        return None\n    df = df[df['Word'].str.startswith(letter)]\n    lengths = df['Word'].str.len()\n    sns.boxplot(x=lengths)\n    return sns.plt", "raw_solution": "import seaborn as sns\nimport time\ndef task_func(df, letter):\n    if df.empty or 'Word' not in df.columns:\n        return None\n    df = df[df['Word'].str.startswith(letter)]\n    lengths = df['Word'].str.len()\n    sns.boxplot(x=lengths)\n    return sns.plt\n```"}
{"task_id": "BigCodeBench/602", "solution": "import numpy as np\nimport pandas as pd\nLETTERS = list('abcdefghijklmnopqrstuvwxyz')\nOUTPUT_DIR = './output'\ndef task_func(file_path, output_dir=OUTPUT_DIR):\n    # Create a 2D matrix populated exclusively with random lowercase letters\n    matrix = np.random.choice(LETTERS, (10, 10))\n    # Convert the matrix to a pandas DataFrame\n    df = pd.DataFrame(matrix)\n    # Write the DataFrame to a CSV file\n    df.to_csv(file_path, index=False)", "raw_solution": "import numpy as np\nimport pandas as pd\n# Constants\nLETTERS = list('abcdefghijklmnopqrstuvwxyz')\nOUTPUT_DIR = './output'\ndef task_func(file_path, output_dir=OUTPUT_DIR):\n    # Create a 2D matrix populated exclusively with random lowercase letters\n    matrix = np.random.choice(LETTERS, (10, 10))\n    # Convert the matrix to a pandas DataFrame\n    df = pd.DataFrame(matrix)\n    # Write the DataFrame to a CSV file\n    df.to_csv(file_path, index=False)\n```"}
{"task_id": "BigCodeBench/603", "solution": "import numpy as np\nimport pandas as pd\ndef task_func(matrix1, matrix2):\n    # Connect two 2D numeric arrays along the second axis (columns)\n    matrix = np.concatenate((matrix1, matrix2), axis=1)\n    \n    # Convert the matrix into a Pandas DataFrame\n    df = pd.DataFrame(matrix)\n    \n    # Return a string representation of the DataFrame without the index and header\n    return str(df).replace('\\n', '').replace('  ', '')", "raw_solution": "import numpy as np\nimport pandas as pd\n\ndef task_func(matrix1, matrix2):\n    # Connect two 2D numeric arrays along the second axis (columns)\n    matrix = np.concatenate((matrix1, matrix2), axis=1)\n    \n    # Convert the matrix into a Pandas DataFrame\n    df = pd.DataFrame(matrix)\n    \n    # Return a string representation of the DataFrame without the index and header\n    return str(df).replace('\\n', '').replace('  ', '')\n```"}
{"task_id": "BigCodeBench/604", "solution": "import subprocess\nimport logging\ndef task_func(filepath):\n    try:\n        logging.info(f\"Compiling {filepath}\")\n        subprocess.run([\"g++\", filepath], check=True)\n        logging.info(\"Compilation successful\")\n    except FileNotFoundError:\n        logging.error(\"Compiler not found\")\n    except subprocess.CalledProcessError:\n        logging.error(\"Compilation failed\")", "raw_solution": "import subprocess\nimport logging\n\ndef task_func(filepath):\n    try:\n        logging.info(f\"Compiling {filepath}\")\n        subprocess.run([\"g++\", filepath], check=True)\n        logging.info(\"Compilation successful\")\n    except FileNotFoundError:\n        logging.error(\"Compiler not found\")\n    except subprocess.CalledProcessError:\n        logging.error(\"Compilation failed\")\n```"}
{"task_id": "BigCodeBench/605", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\ndef task_func(matrix):\n    ax = plt.imshow(matrix, cmap='hot', interpolation='nearest')\n    plt.colorbar(ax)\n    return ax", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\n\ndef task_func(matrix):\n    ax = plt.imshow(matrix, cmap='hot', interpolation='nearest')\n    plt.colorbar(ax)\n    return ax\n```"}
{"task_id": "BigCodeBench/606", "solution": "import pandas as pd\nfrom scipy import stats\ndef task_func(matrix):\n    df = pd.DataFrame(matrix)\n    mean = df.mean()\n    std = df.std()\n    normalized = (df - mean) / std\n    return normalized", "raw_solution": "import pandas as pd\nfrom scipy import stats\n\ndef task_func(matrix):\n    df = pd.DataFrame(matrix)\n    mean = df.mean()\n    std = df.std()\n    normalized = (df - mean) / std\n    return normalized\n```"}
{"task_id": "BigCodeBench/607", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nfrom random import sample\ndef task_func(df: pd.DataFrame, tuples: list, n_plots: int) -> (pd.DataFrame, list):\n    # Remove rows from the DataFrame based on column values\n    df = df[~df.apply(tuple, axis=1).isin(tuples)]\n    # Generate random scatter plots\n    fig, axes = plt.subplots(n_plots, 1, figsize=(10, 10))\n    for i in range(n_plots):\n        # Generate random data\n        x = sample(range(100), 10)\n        y = sample(range(100), 10)\n        # Plot the data\n        axes[i].scatter(x, y)\n        axes[i].set_title(f'Plot {i+1}')\n    return df, axes", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nfrom random import sample\n# Constants for column names to use in plots\nCOLUMNS = ['A', 'B', 'C', 'D', 'E']\ndef task_func(df: pd.DataFrame, tuples: list, n_plots: int) -> (pd.DataFrame, list):\n    # Remove rows from the DataFrame based on column values\n    df = df[~df.apply(tuple, axis=1).isin(tuples)]\n    # Generate random scatter plots\n    fig, axes = plt.subplots(n_plots, 1, figsize=(10, 10))\n    for i in range(n_plots):\n        # Generate random data\n        x = sample(range(100), 10)\n        y = sample(range(100), 10)\n        # Plot the data\n        axes[i].scatter(x, y)\n        axes[i].set_title(f'Plot {i+1}')\n    return df, axes\n```"}
{"task_id": "BigCodeBench/608", "solution": "import seaborn as sns\nfrom random import sample\nCOLUMNS = ['A', 'B', 'C', 'D', 'E']\ndef task_func(df, tuples, n_plots):\n    # Remove rows based on values of multiple columns\n    df = df[~df.apply(tuple, axis=1).isin(tuples)]\n    # Create n random pairs of two columns against each other to generate pairplots\n    pairplots = []\n    for i in range(n_plots):\n        col1, col2 = sample(COLUMNS, 2)\n        pairplots.append(sns.pairplot(df, vars=[col1, col2]))\n    return df, pairplots", "raw_solution": "import seaborn as sns\nfrom random import sample\n# Constants\nCOLUMNS = ['A', 'B', 'C', 'D', 'E']\ndef task_func(df, tuples, n_plots):\n    # Remove rows based on values of multiple columns\n    df = df[~df.apply(tuple, axis=1).isin(tuples)]\n    # Create n random pairs of two columns against each other to generate pairplots\n    pairplots = []\n    for i in range(n_plots):\n        col1, col2 = sample(COLUMNS, 2)\n        pairplots.append(sns.pairplot(df, vars=[col1, col2]))\n    return df, pairplots\n```"}
{"task_id": "BigCodeBench/609", "solution": "from itertools import combinations\nfrom random import sample\ndef task_func(df, tuples, n_plots):\n    # Remove rows from the DataFrame based on the list of tuples\n    df = df[~df.isin(tuples).any(axis=1)]\n    \n    # Generate up to 'n_plots' scatter plots for random combinations of two columns from the remaining DataFrame\n    plots = []\n    for i in range(n_plots):\n        # Select two random columns from the DataFrame\n        cols = sample(df.columns, 2)\n        # Generate a scatter plot for the selected columns\n        plot = df.plot.scatter(x=cols[0], y=cols[1])\n        # Append the plot object to the list\n        plots.append((cols, plot))\n    \n    return df, plots", "raw_solution": "from itertools import combinations\nfrom random import sample\ndef task_func(df, tuples, n_plots):\n    # Remove rows from the DataFrame based on the list of tuples\n    df = df[~df.isin(tuples).any(axis=1)]\n    \n    # Generate up to 'n_plots' scatter plots for random combinations of two columns from the remaining DataFrame\n    plots = []\n    for i in range(n_plots):\n        # Select two random columns from the DataFrame\n        cols = sample(df.columns, 2)\n        # Generate a scatter plot for the selected columns\n        plot = df.plot.scatter(x=cols[0], y=cols[1])\n        # Append the plot object to the list\n        plots.append((cols, plot))\n    \n    return df, plots\n```"}
{"task_id": "BigCodeBench/610", "solution": "from random import sample\nimport seaborn as sns\nimport pandas as pd\nCOLUMNS = ['A', 'B', 'C', 'D', 'E']\ndef task_func(df: pd.DataFrame, tuples: list, n_plots: int) -> (pd.DataFrame, list):\n    # Remove rows based on values of multiple columns\n    df = df[~df.apply(tuple, axis=1).isin(tuples)]\n    \n    # Create n random joint plots of two columns against each other if the DataFrame is not empty\n    if not df.empty:\n        joint_plots = []\n        for i in range(n_plots):\n            cols = sample(COLUMNS, 2)\n            joint_plots.append(sns.JointGrid(df[cols[0]], df[cols[1]]))\n        return df, joint_plots\n    else:\n        return df, []", "raw_solution": "from random import sample\nimport seaborn as sns\nimport pandas as pd\n\n# Constants\nCOLUMNS = ['A', 'B', 'C', 'D', 'E']\n\ndef task_func(df: pd.DataFrame, tuples: list, n_plots: int) -> (pd.DataFrame, list):\n    # Remove rows based on values of multiple columns\n    df = df[~df.apply(tuple, axis=1).isin(tuples)]\n    \n    # Create n random joint plots of two columns against each other if the DataFrame is not empty\n    if not df.empty:\n        joint_plots = []\n        for i in range(n_plots):\n            cols = sample(COLUMNS, 2)\n            joint_plots.append(sns.JointGrid(df[cols[0]], df[cols[1]]))\n        return df, joint_plots\n    else:\n        return df, []\n```"}
{"task_id": "BigCodeBench/611", "solution": "from random import sample\nimport matplotlib.pyplot as plt\nCOLUMNS = ['A', 'B', 'C', 'D', 'E']\ndef task_func(df, tuples, n_plots):\n    # Remove rows based on values of multiple columns\n    df = df[df.apply(lambda row: all(row[col] in sample(COLUMNS, 2) for col in COLUMNS), axis=1)]\n    \n    # Create n random line plots of two columns against each other\n    plot_details = []\n    for i in range(n_plots):\n        col1, col2 = sample(COLUMNS, 2)\n        plot_details.append((col1, col2))\n        plt.plot(df[col1], df[col2])\n    plt.show()\n    return df, plot_details", "raw_solution": "from random import sample\nimport matplotlib.pyplot as plt\n# Constants\nCOLUMNS = ['A', 'B', 'C', 'D', 'E']\n\ndef task_func(df, tuples, n_plots):\n    # Remove rows based on values of multiple columns\n    df = df[df.apply(lambda row: all(row[col] in sample(COLUMNS, 2) for col in COLUMNS), axis=1)]\n    \n    # Create n random line plots of two columns against each other\n    plot_details = []\n    for i in range(n_plots):\n        col1, col2 = sample(COLUMNS, 2)\n        plot_details.append((col1, col2))\n        plt.plot(df[col1], df[col2])\n    plt.show()\n    return df, plot_details\n```"}
{"task_id": "BigCodeBench/612", "solution": "from random import choice\nimport numpy as np\nimport pandas as pd\nTEAMS = ['Team A', 'Team B', 'Team C', 'Team D', 'Team E']\nPENALTIES_COSTS = [100, 200, 300, 400, 500]\ndef task_func(goals, penalties, teams=TEAMS, penalties_costs=PENALTIES_COSTS):\n    # Fetch goal and penalty counts\n    goals = np.random.randint(0, 10, size=len(teams))\n    penalties = np.random.randint(0, 10, size=len(teams))\n    \n    # Calculate 'Penalties Cost' using a random multiplier from a predefined list\n    penalties_cost = np.random.choice(penalties_costs, size=len(teams))\n    \n    # Compute a 'Performance Score' as the non-negative difference between goals and penalties\n    performance_score = np.abs(goals - penalties)\n    \n    # Return a Dataframe with colomns 'Team', 'Goals', 'Penalties', 'Penalties Cost' and 'Performance Score'\n    return pd.DataFrame({\n        'Team': teams,\n        'Goals': goals,\n        'Penalties': penalties,\n        'Penalties Cost': penalties_cost,\n        'Performance Score': performance_score\n    })", "raw_solution": "from random import choice\nimport numpy as np\nimport pandas as pd\n# Constants\nTEAMS = ['Team A', 'Team B', 'Team C', 'Team D', 'Team E']\nPENALTIES_COSTS = [100, 200, 300, 400, 500]\n\ndef task_func(goals, penalties, teams=TEAMS, penalties_costs=PENALTIES_COSTS):\n    # Fetch goal and penalty counts\n    goals = np.random.randint(0, 10, size=len(teams))\n    penalties = np.random.randint(0, 10, size=len(teams))\n    \n    # Calculate 'Penalties Cost' using a random multiplier from a predefined list\n    penalties_cost = np.random.choice(penalties_costs, size=len(teams))\n    \n    # Compute a 'Performance Score' as the non-negative difference between goals and penalties\n    performance_score = np.abs(goals - penalties)\n    \n    # Return a Dataframe with colomns 'Team', 'Goals', 'Penalties', 'Penalties Cost' and 'Performance Score'\n    return pd.DataFrame({\n        'Team': teams,\n        'Goals': goals,\n        'Penalties': penalties,\n        'Penalties Cost': penalties_cost,\n        'Performance Score': performance_score\n    })\n```"}
{"task_id": "BigCodeBench/613", "solution": "import pandas as pd\nfrom matplotlib import pyplot as plt\nTEAMS = ['Team A', 'Team B', 'Team C', 'Team D', 'Team E']\nGOALS_RANGE = (-10, 10)\ndef task_func(goals, penalties):\n    # Calculate net scores\n    scores = [max(min(goal - penalty, GOALS_RANGE[1]), GOALS_RANGE[0]) for goal, penalty in zip(goals, penalties)]\n    # Create DataFrame\n    df = pd.DataFrame({'Team': TEAMS, 'Score': scores})\n    # Plot results\n    plt.figure(figsize=(10, 6))\n    plt.bar(df['Team'], df['Score'])\n    plt.xlabel('Team')\n    plt.ylabel('Score')\n    plt.title('Team Scores')\n    plt.show()\n    return df", "raw_solution": "import pandas as pd\nfrom matplotlib import pyplot as plt\n# Constants\nTEAMS = ['Team A', 'Team B', 'Team C', 'Team D', 'Team E']\nGOALS_RANGE = (-10, 10)\ndef task_func(goals, penalties):\n    # Calculate net scores\n    scores = [max(min(goal - penalty, GOALS_RANGE[1]), GOALS_RANGE[0]) for goal, penalty in zip(goals, penalties)]\n    # Create DataFrame\n    df = pd.DataFrame({'Team': TEAMS, 'Score': scores})\n    # Plot results\n    plt.figure(figsize=(10, 6))\n    plt.bar(df['Team'], df['Score'])\n    plt.xlabel('Team')\n    plt.ylabel('Score')\n    plt.title('Team Scores')\n    plt.show()\n    return df\n```"}
{"task_id": "BigCodeBench/614", "solution": "import pandas as pd\nimport seaborn as sns\ndef task_func(goals, penalties):\n    df = pd.DataFrame({'Team': goals, 'Penalties': penalties})\n    sns.pairplot(df, x_vars='Goals', y_vars='Penalties')\n    return df, sns.pairplot(df, x_vars='Goals', y_vars='Penalties')", "raw_solution": "import pandas as pd\nimport seaborn as sns\ndef task_func(goals, penalties):\n    df = pd.DataFrame({'Team': goals, 'Penalties': penalties})\n    sns.pairplot(df, x_vars='Goals', y_vars='Penalties')\n    return df, sns.pairplot(df, x_vars='Goals', y_vars='Penalties')\n```"}
{"task_id": "BigCodeBench/615", "solution": "from random import randint, seed\nimport pandas as pd\ndef task_func(goals, penalties, rng_seed=None):\n    if rng_seed is not None:\n        seed(rng_seed)\n    df = pd.DataFrame(columns=['Team', 'Match Result'])\n    for i in range(len(goals)):\n        team = 'Team ' + str(i + 1)\n        df = df.append({'Team': team, 'Match Result': randint(0, goals[i])}, ignore_index=True)\n        for j in range(penalties[i]):\n            df = df.append({'Team': team, 'Match Result': 0}, ignore_index=True)\n    df['Match Result'] = df['Match Result'] * 1000\n    return df", "raw_solution": "from random import randint, seed\nimport pandas as pd\n\n# Method\ndef task_func(goals, penalties, rng_seed=None):\n    if rng_seed is not None:\n        seed(rng_seed)\n    df = pd.DataFrame(columns=['Team', 'Match Result'])\n    for i in range(len(goals)):\n        team = 'Team ' + str(i + 1)\n        df = df.append({'Team': team, 'Match Result': randint(0, goals[i])}, ignore_index=True)\n        for j in range(penalties[i]):\n            df = df.append({'Team': team, 'Match Result': 0}, ignore_index=True)\n    df['Match Result'] = df['Match Result'] * 1000\n    return df\n```"}
{"task_id": "BigCodeBench/616", "solution": "from random import randint, seed\nimport matplotlib.pyplot as plt\nimport pandas as pd\nTEAMS = ['Team A', 'Team B', 'Team C', 'Team D', 'Team E']\nPENALTY_COST = 1000\ndef task_func(goals, penalties, teams=TEAMS, penalty_cost=PENALTY_COST, rng_seed=None):\n    if rng_seed is not None:\n        seed(rng_seed)\n    df = pd.DataFrame({'Team': teams, 'Goals': [randint(0, goals) for _ in range(len(teams))], 'Penalty Cost': [randint(0, penalty_cost) for _ in range(len(teams))]})\n    ax = df.plot(kind='bar', x='Team', y='Goals', color='blue', title='Football Match Results')\n    ax.set_xlabel('Team')\n    ax.set_ylabel('Goals')\n    ax.set_xticklabels(teams)\n    ax.set_yticks(range(goals + 1))\n    ax.set_yticklabels(range(goals + 1))\n    ax.set_ylim(0, goals + 1)\n    ax.set_xlim(0, len(teams))\n    ax.set_xticks(range(len(teams)))\n    ax.set_xticklabels(teams)\n    ax.set_yticks(range(goals + 1))\n    ax.set_yticklabels(range(goals + 1))\n    ax.set_ylim(0, goals + 1)\n    ax.set_xlim(0, len(teams))\n    ax.set_xticks(range(len(teams)))\n    ax.set_xticklabels(teams)\n    ax.set_yticks(range(goals + 1))\n    ax.set_yticklabels(range(goals + 1))\n    ax.set_ylim(0, goals + 1)\n    ax.set_xlim(0, len(teams))\n    ax.set_xticks(range(len(teams)))\n    ax.set_xticklabels(teams)\n    ax.set_yticks(range(goals + 1))\n    ax.set_yticklabels(range(goals + 1))\n    ax.set_ylim(0, goals + 1)\n    ax.set_xlim(0, len(teams))\n    ax.set_xticks(range(len(teams)))\n    ax.set_xticklabels(teams)\n    ax.set_yticks(range(goals + 1))\n    ax.set_yticklabels(range(goals + 1))\n    ax.set_ylim(0, goals + 1)\n    ax.set_xlim(0, len(teams))\n    ax.set_xticks(range(len(teams)))\n    ax.set_xticklabels(teams)\n    ax.set_yticks(range(goals + 1))\n    ax.set_yticklabels(range(goals + 1))\n    ax.set_ylim(0, goals + 1)\n    ax.set_xlim(0, len(teams))\n    ax.set_xticks(range(len(teams)))\n    ax.set_xticklabels(teams)\n    ax.set_yticks(range(goals + 1))\n    ax.set_yticklabels(range(goals + 1))\n    ax.set_ylim(0, goals + 1)\n    ax.set_xlim(0, len(teams))\n    ax.set_xticks(range(len(teams)))\n    ax.set_xticklabels(teams)\n    ax.set_yticks(range(goals + 1))\n    ax.set_yticklabels(range(goals + 1))\n    ax.set_ylim(0, goals + 1)\n    ax.set_xlim(0, len(teams))\n    ax.set_xticks(range(len(teams)))\n    ax.set_xticklabels(teams)\n    ax.set_yticks(range(goals + 1))\n    ax.set_yticklabels(range(goals + 1))\n    ax.set_ylim(0, goals + 1)\n    ax.set_xlim(0, len(teams))\n    ax.set_xticks(range(len(teams)))\n    ax.set_xticklabels(teams)\n    ax.set_yticks(range(goals + 1))\n    ax.set_yticklabels(range(goals + 1))\n    ax.set_ylim(0, goals + 1)\n    ax.set_xlim(0, len(teams))\n    ax.set_xticks(range(len(teams)))\n    ax.set_xticklabels(teams)\n    ax.set_yticks(range(goals + 1))\n    ax.set_yticklabels(range(goals + 1))\n    ax.set_ylim(0, goals + 1)\n    ax.set_xlim(0, len(teams))\n    ax.set_xticks(range(len(teams)))\n    ax.set_xticklabels(teams)\n    ax.set_yticks(range(goals + 1))\n    ax.set_yticklabels(range(goals + 1))\n    ax.set_ylim(0, goals + 1)\n    ax.set_xlim(0, len(teams))\n    ax.set_xticks(range(len(teams)))\n    ax.set_xticklabels(teams)\n    ax.set_yticks(range(goals + 1))\n    ax.set_yticklabels(range(goals + 1))\n    ax.set_ylim(0, goals + 1)\n    ax.set_xlim(0, len(teams))\n    ax.set_xticks(range(len(teams)))\n    ax.set_xticklabels(teams)\n    ax.set_yticks(range(goals + 1))\n    ax.set_yticklabels(range(goals + 1))\n    ax.set_ylim(0, goals + 1)\n    ax.set_xlim(0, len(teams))\n    ax.set_xticks(range(len(teams)))\n    ax.set_xticklabels(teams)\n    ax.set_yticks(range(goals + 1))\n    ax.set_yticklabels(range(goals + 1))\n    ax.set_ylim(0, goals + 1)\n    ax.set_xlim(0, len(teams))\n    ax.set_xticks(range(len(teams)))\n    ax.set_xticklabels(teams)\n    ax.set_yticks(range(goals + 1))\n    ax.set_yticklabels(range(goals + 1))\n    ax.set_ylim(0, goals + 1)\n    ax.set_xlim(0, len(teams))\n    ax.set_xticks(range(len(teams)))", "raw_solution": "from random import randint, seed\nimport matplotlib.pyplot as plt\nimport pandas as pd\n# Constants (they can be overridden with default parameters)\nTEAMS = ['Team A', 'Team B', 'Team C', 'Team D', 'Team E']\nPENALTY_COST = 1000  # in dollars\ndef task_func(goals, penalties, teams=TEAMS, penalty_cost=PENALTY_COST, rng_seed=None):\n    if rng_seed is not None:\n        seed(rng_seed)\n    df = pd.DataFrame({'Team': teams, 'Goals': [randint(0, goals) for _ in range(len(teams))], 'Penalty Cost': [randint(0, penalty_cost) for _ in range(len(teams))]})\n    ax = df.plot(kind='bar', x='Team', y='Goals', color='blue', title='Football Match Results')\n    ax.set_xlabel('Team')\n    ax.set_ylabel('Goals')\n    ax.set_xticklabels(teams)\n    ax.set_yticks(range(goals + 1))\n    ax.set_yticklabels(range(goals + 1))\n    ax.set_ylim(0, goals + 1)\n    ax.set_xlim(0, len(teams))\n    ax.set_xticks(range(len(teams)))\n    ax.set_xticklabels(teams)\n    ax.set_yticks(range(goals + 1))\n    ax.set_yticklabels(range(goals + 1))\n    ax.set_ylim(0, goals + 1)\n    ax.set_xlim(0, len(teams))\n    ax.set_xticks(range(len(teams)))\n    ax.set_xticklabels(teams)\n    ax.set_yticks(range(goals + 1))\n    ax.set_yticklabels(range(goals + 1))\n    ax.set_ylim(0, goals + 1)\n    ax.set_xlim(0, len(teams))\n    ax.set_xticks(range(len(teams)))\n    ax.set_xticklabels(teams)\n    ax.set_yticks(range(goals + 1))\n    ax.set_yticklabels(range(goals + 1))\n    ax.set_ylim(0, goals + 1)\n    ax.set_xlim(0, len(teams))\n    ax.set_xticks(range(len(teams)))\n    ax.set_xticklabels(teams)\n    ax.set_yticks(range(goals + 1))\n    ax.set_yticklabels(range(goals + 1))\n    ax.set_ylim(0, goals + 1)\n    ax.set_xlim(0, len(teams))\n    ax.set_xticks(range(len(teams)))\n    ax.set_xticklabels(teams)\n    ax.set_yticks(range(goals + 1))\n    ax.set_yticklabels(range(goals + 1))\n    ax.set_ylim(0, goals + 1)\n    ax.set_xlim(0, len(teams))\n    ax.set_xticks(range(len(teams)))\n    ax.set_xticklabels(teams)\n    ax.set_yticks(range(goals + 1))\n    ax.set_yticklabels(range(goals + 1))\n    ax.set_ylim(0, goals + 1)\n    ax.set_xlim(0, len(teams))\n    ax.set_xticks(range(len(teams)))\n    ax.set_xticklabels(teams)\n    ax.set_yticks(range(goals + 1))\n    ax.set_yticklabels(range(goals + 1))\n    ax.set_ylim(0, goals + 1)\n    ax.set_xlim(0, len(teams))\n    ax.set_xticks(range(len(teams)))\n    ax.set_xticklabels(teams)\n    ax.set_yticks(range(goals + 1))\n    ax.set_yticklabels(range(goals + 1))\n    ax.set_ylim(0, goals + 1)\n    ax.set_xlim(0, len(teams))\n    ax.set_xticks(range(len(teams)))\n    ax.set_xticklabels(teams)\n    ax.set_yticks(range(goals + 1))\n    ax.set_yticklabels(range(goals + 1))\n    ax.set_ylim(0, goals + 1)\n    ax.set_xlim(0, len(teams))\n    ax.set_xticks(range(len(teams)))\n    ax.set_xticklabels(teams)\n    ax.set_yticks(range(goals + 1))\n    ax.set_yticklabels(range(goals + 1))\n    ax.set_ylim(0, goals + 1)\n    ax.set_xlim(0, len(teams))\n    ax.set_xticks(range(len(teams)))\n    ax.set_xticklabels(teams)\n    ax.set_yticks(range(goals + 1))\n    ax.set_yticklabels(range(goals + 1))\n    ax.set_ylim(0, goals + 1)\n    ax.set_xlim(0, len(teams))\n    ax.set_xticks(range(len(teams)))\n    ax.set_xticklabels(teams)\n    ax.set_yticks(range(goals + 1))\n    ax.set_yticklabels(range(goals + 1))\n    ax.set_ylim(0, goals + 1)\n    ax.set_xlim(0, len(teams))\n    ax.set_xticks(range(len(teams)))\n    ax.set_xticklabels(teams)\n    ax.set_yticks(range(goals + 1))\n    ax.set_yticklabels(range(goals + 1))\n    ax.set_ylim(0, goals + 1)\n    ax.set_xlim(0, len(teams))\n    ax.set_xticks(range(len(teams)))\n    ax.set_xticklabels(teams)\n    ax.set_yticks(range(goals + 1))\n    ax.set_yticklabels(range(goals + 1))\n    ax.set_ylim(0, goals + 1)\n    ax.set_xlim(0, len(teams))\n    ax.set_xticks(range(len(teams)))\n    ax.set_xticklabels(teams)\n    ax.set_yticks(range(goals + 1))\n    ax.set_yticklabels(range(goals + 1))\n    ax.set_ylim(0, goals + 1)\n    ax.set_xlim(0, len(teams))\n    ax.set_xticks(range(len(teams)))\n    ax.set_xticklabels(teams"}
{"task_id": "BigCodeBench/617", "solution": "from random import randint, seed\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport re\nTEAMS = ['Team A', 'Team B', 'Team C', 'Team D', 'Team E']\nPENALTY_COST = 1000\ndef task_func(goals, penalties, rng_seed=None, teams=TEAMS):\n    seed(rng_seed)\n    df = pd.DataFrame(columns=['Team', 'Goals', 'Penalty Cost'])\n    for team in teams:\n        df = df.append({'Team': team, 'Goals': randint(0, goals), 'Penalty Cost': PENALTY_COST * randint(0, penalties)}, ignore_index=True)\n    return df", "raw_solution": "from random import randint, seed\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport re\n# Constants\nTEAMS = ['Team A', 'Team B', 'Team C', 'Team D', 'Team E']\nPENALTY_COST = 1000  # in dollars\n\ndef task_func(goals, penalties, rng_seed=None, teams=TEAMS):\n    seed(rng_seed)\n    df = pd.DataFrame(columns=['Team', 'Goals', 'Penalty Cost'])\n    for team in teams:\n        df = df.append({'Team': team, 'Goals': randint(0, goals), 'Penalty Cost': PENALTY_COST * randint(0, penalties)}, ignore_index=True)\n    return df\n```"}
{"task_id": "BigCodeBench/618", "solution": "from random import randint\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport seaborn as sns\nTEAMS = ['Team A', 'Team B', 'Team C', 'Team D', 'Team E']\nPENALTY_COST = 1000\ndef task_func(goals, penalties):\n    # Generate random goals and penalties\n    goals = [randint(0, 5) for _ in range(len(TEAMS))]\n    penalties = [randint(0, 5) for _ in range(len(TEAMS))]\n    # Create a DataFrame\n    df = pd.DataFrame({'Team': TEAMS, 'Goals': goals, 'Penalties': penalties})\n    # Convert penalties to fines\n    df['Fines'] = df['Penalties'] * PENALTY_COST\n    # Plot goals and fines\n    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n    sns.barplot(x='Team', y='Goals', data=df, ax=ax1)\n    sns.barplot(x='Team', y='Fines', data=df, ax=ax2)\n    return df, [ax1, ax2]", "raw_solution": "from random import randint\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport seaborn as sns\n# Constants\nTEAMS = ['Team A', 'Team B', 'Team C', 'Team D', 'Team E']\nPENALTY_COST = 1000  # in dollars\ndef task_func(goals, penalties):\n    # Generate random goals and penalties\n    goals = [randint(0, 5) for _ in range(len(TEAMS))]\n    penalties = [randint(0, 5) for _ in range(len(TEAMS))]\n    # Create a DataFrame\n    df = pd.DataFrame({'Team': TEAMS, 'Goals': goals, 'Penalties': penalties})\n    # Convert penalties to fines\n    df['Fines'] = df['Penalties'] * PENALTY_COST\n    # Plot goals and fines\n    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n    sns.barplot(x='Team', y='Goals', data=df, ax=ax1)\n    sns.barplot(x='Team', y='Fines', data=df, ax=ax2)\n    return df, [ax1, ax2]\n```"}
{"task_id": "BigCodeBench/619", "solution": "from random import randint, seed\nimport pandas as pd\nfrom sklearn.linear_model import LinearRegression\nTEAMS = ['Team A', 'Team B', 'Team C', 'Team D', 'Team E']\ndef task_func(goals, penalties, rng_seed=None):\n    if rng_seed is not None:\n        seed(rng_seed)\n    # Simulate match results\n    match_results = []\n    for i in range(len(TEAMS)):\n        for j in range(len(TEAMS)):\n            if i != j:\n                match_results.append((TEAMS[i], TEAMS[j], randint(0, goals[i]), randint(0, penalties[i])))\n    # Create DataFrame\n    df = pd.DataFrame(match_results, columns=['Team', 'Opponent', 'Goals', 'Penalties'])\n    # Train linear regression model\n    X = df[['Goals']]\n    y = df['Penalties']\n    model = LinearRegression()\n    model.fit(X, y)\n    # Return results\n    return (tuple(df[['Team', 'Goals', 'Penalty Cost']]), model)", "raw_solution": "from random import randint, seed\nimport pandas as pd\nfrom sklearn.linear_model import LinearRegression\n# Constants\nTEAMS = ['Team A', 'Team B', 'Team C', 'Team D', 'Team E']\nPENALTY_COST = 1000  # in dollars\n\ndef task_func(goals, penalties, rng_seed=None):\n    if rng_seed is not None:\n        seed(rng_seed)\n    # Simulate match results\n    match_results = []\n    for i in range(len(TEAMS)):\n        for j in range(len(TEAMS)):\n            if i != j:\n                match_results.append((TEAMS[i], TEAMS[j], randint(0, goals[i]), randint(0, penalties[i])))\n    # Create DataFrame\n    df = pd.DataFrame(match_results, columns=['Team', 'Opponent', 'Goals', 'Penalties'])\n    # Train linear regression model\n    X = df[['Goals']]\n    y = df['Penalties']\n    model = LinearRegression()\n    model.fit(X, y)\n    # Return results\n    return (tuple(df[['Team', 'Goals', 'Penalty Cost']]), model)\n```"}
{"task_id": "BigCodeBench/620", "solution": "import numpy as np\nimport pandas as pd\nRANGE = (1, 100)\ndef task_func(L):\n    # Initialize an empty list to store the rows of the DataFrame\n    rows = []\n    # Iterate over the nested lists in L\n    for i in range(len(L)):\n        # Iterate over the nested lists in L[i]\n        for j in range(len(L[i])):\n            # Generate a random integer between RANGE[0] and RANGE[1]\n            row = [np.random.randint(RANGE[0], RANGE[1])]\n            # Append the row to the rows list\n            rows.append(row)\n    # Create a DataFrame from the rows list\n    df = pd.DataFrame(rows)\n    # Return the DataFrame\n    return df", "raw_solution": "import numpy as np\nimport pandas as pd\n# Constants\nRANGE = (1, 100)\ndef task_func(L):\n    # Initialize an empty list to store the rows of the DataFrame\n    rows = []\n    # Iterate over the nested lists in L\n    for i in range(len(L)):\n        # Iterate over the nested lists in L[i]\n        for j in range(len(L[i])):\n            # Generate a random integer between RANGE[0] and RANGE[1]\n            row = [np.random.randint(RANGE[0], RANGE[1])]\n            # Append the row to the rows list\n            rows.append(row)\n    # Create a DataFrame from the rows list\n    df = pd.DataFrame(rows)\n    # Return the DataFrame\n    return df\n```"}
{"task_id": "BigCodeBench/621", "solution": "from itertools import chain\nimport numpy as np\nfrom sklearn.preprocessing import StandardScaler\nimport matplotlib.pyplot as plt\ndef task_func(L):\n    # Flatten the list of lists\n    flat_list = list(chain(*L))\n    # Standardize the integers\n    scaler = StandardScaler()\n    standardized_list = scaler.fit_transform(np.array(flat_list).reshape(-1, 1))\n    # Plot the standardized values\n    plt.plot(standardized_list)\n    plt.show()", "raw_solution": "from itertools import chain\nimport numpy as np\nfrom sklearn.preprocessing import StandardScaler\nimport matplotlib.pyplot as plt\n\ndef task_func(L):\n    # Flatten the list of lists\n    flat_list = list(chain(*L))\n    # Standardize the integers\n    scaler = StandardScaler()\n    standardized_list = scaler.fit_transform(np.array(flat_list).reshape(-1, 1))\n    # Plot the standardized values\n    plt.plot(standardized_list)\n    plt.show()\n```"}
{"task_id": "BigCodeBench/622", "solution": "import matplotlib.pyplot as plt\nimport numpy as np\nfrom scipy.stats import norm\nfrom itertools import chain\ndef task_func(L):\n    # Flatten the list of lists\n    flat_list = list(chain(*L))\n    \n    # Fit a normal distribution to the data\n    mean, std = norm.fit(flat_list)\n    \n    # Plot the histogram with the fitted normal distribution overlay\n    plt.hist(flat_list, bins=30, density=True, alpha=0.6, color='g')\n    x = np.linspace(min(flat_list), max(flat_list), 100)\n    plt.plot(x, norm.pdf(x, mean, std), 'r--', linewidth=2)\n    plt.show()\n    return plt.gca()", "raw_solution": "import matplotlib.pyplot as plt\nimport numpy as np\nfrom scipy.stats import norm\nfrom itertools import chain\n\ndef task_func(L):\n    # Flatten the list of lists\n    flat_list = list(chain(*L))\n    \n    # Fit a normal distribution to the data\n    mean, std = norm.fit(flat_list)\n    \n    # Plot the histogram with the fitted normal distribution overlay\n    plt.hist(flat_list, bins=30, density=True, alpha=0.6, color='g')\n    x = np.linspace(min(flat_list), max(flat_list), 100)\n    plt.plot(x, norm.pdf(x, mean, std), 'r--', linewidth=2)\n    plt.show()\n    return plt.gca()\n```"}
{"task_id": "BigCodeBench/623", "solution": "from itertools import chain\nimport numpy as np\nfrom sklearn.cluster import KMeans\ndef task_func(L):\n    # Convert list of lists into a list of integers\n    data = list(chain(*L))\n    # Apply KMeans clustering\n    kmeans = KMeans(n_clusters=3).fit(data.reshape(-1, 1))\n    # Return a scatter plot 'matplotlib.axes.Axes' with data points color-coded by their cluster\n    return plt.scatter(data, kmeans.labels_)", "raw_solution": "from itertools import chain\nimport numpy as np\nfrom sklearn.cluster import KMeans\ndef task_func(L):\n    # Convert list of lists into a list of integers\n    data = list(chain(*L))\n    # Apply KMeans clustering\n    kmeans = KMeans(n_clusters=3).fit(data.reshape(-1, 1))\n    # Return a scatter plot 'matplotlib.axes.Axes' with data points color-coded by their cluster\n    return plt.scatter(data, kmeans.labels_)\n```"}
{"task_id": "BigCodeBench/624", "solution": "from sklearn.decomposition import PCA\nimport numpy as np\nimport matplotlib.pyplot as plt\nN_COMPONENTS = 2\ndef task_func(L):\n    # Convert list of lists to 2D numpy array\n    X = np.array(L)\n    # Apply PCA\n    pca = PCA(n_components=N_COMPONENTS)\n    X_pca = pca.fit_transform(X)\n    # Plot scatter plot\n    fig, ax = plt.subplots()\n    ax.scatter(X_pca[:, 0], X_pca[:, 1])\n    return (X_pca, ax)", "raw_solution": "from sklearn.decomposition import PCA\nimport numpy as np\nimport matplotlib.pyplot as plt\n# Constants\nN_COMPONENTS = 2\ndef task_func(L):\n    # Convert list of lists to 2D numpy array\n    X = np.array(L)\n    # Apply PCA\n    pca = PCA(n_components=N_COMPONENTS)\n    X_pca = pca.fit_transform(X)\n    # Plot scatter plot\n    fig, ax = plt.subplots()\n    ax.scatter(X_pca[:, 0], X_pca[:, 1])\n    return (X_pca, ax)\n```"}
{"task_id": "BigCodeBench/625", "solution": "import math\nfrom random import randint\nimport pandas as pd\ndef task_func(cities_list):\n    population = [randint(1000, 1000000) for _ in range(len(cities_list))]\n    return pd.DataFrame({'City': cities_list, 'Population': population})", "raw_solution": "import math\nfrom random import randint\nimport pandas as pd\n\ndef task_func(cities_list):\n    population = [randint(1000, 1000000) for _ in range(len(cities_list))]\n    return pd.DataFrame({'City': cities_list, 'Population': population})\n```"}
{"task_id": "BigCodeBench/626", "solution": "from random import choice\nimport pytz\nfrom dateutil.parser import parse\nTIMEZONES = ['America/New_York', 'Europe/London', 'Asia/Shanghai', 'Asia/Tokyo', 'Australia/Sydney']\ndef task_func(date_str, from_tz):\n    # Parse the input datetime string\n    dt = parse(date_str)\n    \n    # Get a random timezone\n    to_tz = choice(TIMEZONES)\n    \n    # Convert the datetime string to the random timezone\n    to_dt = dt.astimezone(pytz.timezone(to_tz))\n    \n    # Return the converted datetime string and the random timezone\n    return (to_dt.strftime('%Y-%m-%d %H:%M:%S'), to_tz)", "raw_solution": "from random import choice\nimport pytz\nfrom dateutil.parser import parse\n\n# Constants\nTIMEZONES = ['America/New_York', 'Europe/London', 'Asia/Shanghai', 'Asia/Tokyo', 'Australia/Sydney']\n\ndef task_func(date_str, from_tz):\n    # Parse the input datetime string\n    dt = parse(date_str)\n    \n    # Get a random timezone\n    to_tz = choice(TIMEZONES)\n    \n    # Convert the datetime string to the random timezone\n    to_dt = dt.astimezone(pytz.timezone(to_tz))\n    \n    # Return the converted datetime string and the random timezone\n    return (to_dt.strftime('%Y-%m-%d %H:%M:%S'), to_tz)\n```"}
{"task_id": "BigCodeBench/627", "solution": "from random import randint\nfrom statistics import mean\nimport pandas as pd\ndef task_func(products_list):\n    sales_data = []\n    for product in products_list:\n        sales = [randint(100, 1000) for _ in range(12)]\n        sales_data.append({'Product': product, 'Sales': sales})\n    sales_data = pd.DataFrame(sales_data)\n    sales_data['Average Sales'] = sales_data['Sales'].apply(mean)\n    return sales_data", "raw_solution": "from random import randint\nfrom statistics import mean\nimport pandas as pd\n\ndef task_func(products_list):\n    sales_data = []\n    for product in products_list:\n        sales = [randint(100, 1000) for _ in range(12)]\n        sales_data.append({'Product': product, 'Sales': sales})\n    sales_data = pd.DataFrame(sales_data)\n    sales_data['Average Sales'] = sales_data['Sales'].apply(mean)\n    return sales_data\n```"}
{"task_id": "BigCodeBench/628", "solution": "import math\nfrom random import randint\nimport matplotlib.pyplot as plt\ndef task_func():\n    # Generate random frequency, amplitude, and phase shift\n    freq = randint(1, 10)\n    amp = randint(1, 10)\n    phase = randint(0, 360)\n    \n    # Create time array\n    time = [i/100 for i in range(1000)]\n    \n    # Calculate sine wave\n    sine_wave = amp * math.sin(2 * math.pi * freq * time + phase)\n    \n    # Create plot\n    ax = plt.plot(time, sine_wave)\n    ax[0].set_title('Random Sine Wave')\n    ax[0].set_xlabel('Time')\n    ax[0].set_ylabel('Amplitude')\n    \n    return ax", "raw_solution": "import math\nfrom random import randint\nimport matplotlib.pyplot as plt\n\ndef task_func():\n    # Generate random frequency, amplitude, and phase shift\n    freq = randint(1, 10)\n    amp = randint(1, 10)\n    phase = randint(0, 360)\n    \n    # Create time array\n    time = [i/100 for i in range(1000)]\n    \n    # Calculate sine wave\n    sine_wave = amp * math.sin(2 * math.pi * freq * time + phase)\n    \n    # Create plot\n    ax = plt.plot(time, sine_wave)\n    ax[0].set_title('Random Sine Wave')\n    ax[0].set_xlabel('Time')\n    ax[0].set_ylabel('Amplitude')\n    \n    return ax\n```"}
{"task_id": "BigCodeBench/629", "solution": "import os\nimport time\nOUTPUT_DIR = './output'\ndef task_func(dataset, filename, output_dir=OUTPUT_DIR):\n    if not os.path.exists(output_dir):\n        os.makedirs(output_dir)\n    with open(os.path.join(output_dir, filename), 'w') as f:\n        for df in dataset:\n            f.write(df.to_csv(index=False, header=False))\n            f.write('------\\n')", "raw_solution": "import os\nimport time\nOUTPUT_DIR = './output'\ndef task_func(dataset, filename, output_dir=OUTPUT_DIR):\n    if not os.path.exists(output_dir):\n        os.makedirs(output_dir)\n    with open(os.path.join(output_dir, filename), 'w') as f:\n        for df in dataset:\n            f.write(df.to_csv(index=False, header=False))\n            f.write('------\\n')\n```"}
{"task_id": "BigCodeBench/630", "solution": "import pandas as pd\nimport os\nOUTPUT_DIR = './output'\ndef task_func(df, filename, output_dir=OUTPUT_DIR):\n    df.to_json(os.path.join(output_dir, filename), orient='records')\n    return os.path.join(output_dir, filename)", "raw_solution": "import pandas as pd\nimport os\nOUTPUT_DIR = './output'\n\ndef task_func(df, filename, output_dir=OUTPUT_DIR):\n    df.to_json(os.path.join(output_dir, filename), orient='records')\n    return os.path.join(output_dir, filename)\n```"}
{"task_id": "BigCodeBench/631", "solution": "import csv\nimport os\nOUTPUT_DIR = './output'\ndef task_func(df, filename, output_dir=OUTPUT_DIR):\n    df.to_csv(os.path.join(output_dir, filename), index=False)\n    return os.path.join(output_dir, filename)", "raw_solution": "import csv\nimport os\nOUTPUT_DIR = './output'\ndef task_func(df, filename, output_dir=OUTPUT_DIR):\n    df.to_csv(os.path.join(output_dir, filename), index=False)\n    return os.path.join(output_dir, filename)\n```"}
{"task_id": "BigCodeBench/632", "solution": "import pandas as pd\nimport time\nOUTPUT_DIR = './output'\ndef task_func(df: pd.DataFrame, filename: str) -> str:\n    df.to_json(OUTPUT_DIR + '/' + filename, orient='records', lines=True)\n    return OUTPUT_DIR + '/' + filename", "raw_solution": "import pandas as pd\nimport time\nOUTPUT_DIR = './output'\ndef task_func(df: pd.DataFrame, filename: str) -> str:\n    df.to_json(OUTPUT_DIR + '/' + filename, orient='records', lines=True)\n    return OUTPUT_DIR + '/' + filename\n```"}
{"task_id": "BigCodeBench/633", "solution": "import re\nfrom nltk.corpus import stopwords\ndef task_func(text: str) -> dict:\n    # Remove punctuation and convert to lowercase\n    text = re.sub(r'[^\\w\\s]', '', text).lower()\n    # Split text into words\n    words = text.split()\n    # Remove stopwords\n    words = [word for word in words if word not in stopwords.words('english')]\n    # Create frequency distribution\n    freq_dist = {}\n    for word in words:\n        if word in freq_dist:\n            freq_dist[word] += 1\n        else:\n            freq_dist[word] = 1\n    return freq_dist", "raw_solution": "import re\nfrom nltk.corpus import stopwords\n\ndef task_func(text: str) -> dict:\n    # Remove punctuation and convert to lowercase\n    text = re.sub(r'[^\\w\\s]', '', text).lower()\n    # Split text into words\n    words = text.split()\n    # Remove stopwords\n    words = [word for word in words if word not in stopwords.words('english')]\n    # Create frequency distribution\n    freq_dist = {}\n    for word in words:\n        if word in freq_dist:\n            freq_dist[word] += 1\n        else:\n            freq_dist[word] = 1\n    return freq_dist\n```"}
{"task_id": "BigCodeBench/634", "solution": "import itertools\nfrom typing import Any\nfrom scipy import stats\ndef task_func(input_list: list, repetitions: int) -> Any:\n    flattened_list = list(itertools.chain.from_iterable([input_list] * repetitions))\n    mode_result = stats.mode(flattened_list)\n    return mode_result", "raw_solution": "import itertools\nfrom typing import Any\nfrom scipy import stats\n\ndef task_func(input_list: list, repetitions: int) -> Any:\n    flattened_list = list(itertools.chain.from_iterable([input_list] * repetitions))\n    mode_result = stats.mode(flattened_list)\n    return mode_result\n```"}
{"task_id": "BigCodeBench/635", "solution": "import re\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom nltk.corpus import stopwords\ndef task_func(text, n=2):\n    # Removing duplicate consecutive words and stopwords defined by nltk.corpus\n    text = re.sub(r'\\b(\\w+)\\b\\s*\\b\\1\\b', r'\\1', text)\n    text = ' '.join([word for word in text.split() if word not in stopwords.words('english')])\n    \n    # Generating a square co-occurrence matrix of words\n    vectorizer = CountVectorizer(ngram_range=(n, n))\n    cooccurrence_matrix = vectorizer.fit_transform([text])\n    cooccurrence_matrix = cooccurrence_matrix.toarray()\n    \n    # Plotting this matrix\n    fig, ax = plt.subplots()\n    ax.imshow(cooccurrence_matrix, cmap='viridis')\n    ax.set_xticks(np.arange(cooccurrence_matrix.shape[1]))\n    ax.set_yticks(np.arange(cooccurrence_matrix.shape[0]))\n    ax.set_xticklabels(vectorizer.get_feature_names_out())\n    ax.set_yticklabels(vectorizer.get_feature_names_out())\n    plt.show()\n    \n    return (vectorizer.get_feature_names_out(), pd.DataFrame(cooccurrence_matrix, index=vectorizer.get_feature_names_out(), columns=vectorizer.get_feature_names_out()))", "raw_solution": "# Importing the required libraries\nimport re\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom nltk.corpus import stopwords\n\ndef task_func(text, n=2):\n    # Removing duplicate consecutive words and stopwords defined by nltk.corpus\n    text = re.sub(r'\\b(\\w+)\\b\\s*\\b\\1\\b', r'\\1', text)\n    text = ' '.join([word for word in text.split() if word not in stopwords.words('english')])\n    \n    # Generating a square co-occurrence matrix of words\n    vectorizer = CountVectorizer(ngram_range=(n, n))\n    cooccurrence_matrix = vectorizer.fit_transform([text])\n    cooccurrence_matrix = cooccurrence_matrix.toarray()\n    \n    # Plotting this matrix\n    fig, ax = plt.subplots()\n    ax.imshow(cooccurrence_matrix, cmap='viridis')\n    ax.set_xticks(np.arange(cooccurrence_matrix.shape[1]))\n    ax.set_yticks(np.arange(cooccurrence_matrix.shape[0]))\n    ax.set_xticklabels(vectorizer.get_feature_names_out())\n    ax.set_yticklabels(vectorizer.get_feature_names_out())\n    plt.show()\n    \n    return (vectorizer.get_feature_names_out(), pd.DataFrame(cooccurrence_matrix, index=vectorizer.get_feature_names_out(), columns=vectorizer.get_feature_names_out()))\n```"}
{"task_id": "BigCodeBench/636", "solution": "import matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nCOLUMNS = ['Column1', 'Column2', 'Column3', 'Column4', 'Column5']\ndef task_func(rows):\n    # Generate DataFrame with random integer values\n    df = pd.DataFrame(np.random.randint(0, 10, (rows, len(COLUMNS))), columns=COLUMNS)\n    # Count non-zero values in each column\n    non_zero_counts = df.count()\n    # Visualize this information using a bar plot\n    ax = non_zero_counts.plot(kind='bar')\n    plt.show()\n    return (df, ax)", "raw_solution": "import matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\n# Constants\nCOLUMNS = ['Column1', 'Column2', 'Column3', 'Column4', 'Column5']\ndef task_func(rows):\n    # Generate DataFrame with random integer values\n    df = pd.DataFrame(np.random.randint(0, 10, (rows, len(COLUMNS))), columns=COLUMNS)\n    # Count non-zero values in each column\n    non_zero_counts = df.count()\n    # Visualize this information using a bar plot\n    ax = non_zero_counts.plot(kind='bar')\n    plt.show()\n    return (df, ax)\n```"}
{"task_id": "BigCodeBench/637", "solution": "from random import sample\nfrom typing import Tuple\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\ndef task_func(num_students):\n    # Generate a list of student names\n    students = [f\"Student {i}\" for i in range(1, num_students + 1)]\n    \n    # Generate a list of course names\n    courses = [\"Math\", \"Science\", \"English\", \"History\", \"Art\"]\n    \n    # Generate a list of grades for each student in each course\n    grades = [[np.random.randint(0, 100) for _ in range(len(courses))] for _ in range(num_students)]\n    \n    # Create a DataFrame from the grades\n    df = pd.DataFrame(grades, index=students, columns=courses)\n    \n    # Calculate the average grade in each course\n    avg_grades = df.mean(axis=0)\n    \n    # Calculate the number of students with a passing grade (>= 60)\n    passing_grades = df[df >= 60].count(axis=0)\n    \n    # Create a bar plot with title 'Course-wise Average and Passing Grade Counts'\n    fig, ax = plt.subplots()\n    ax.bar(avg_grades.index, avg_grades.values, label='Average Grade')\n    ax.bar(passing_grades.index, passing_grades.values, label='Passing Grade Count')\n    ax.set_title('Course-wise Average and Passing Grade Counts')\n    ax.legend()\n    \n    return df, ax", "raw_solution": "from random import sample\nfrom typing import Tuple\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\n\ndef task_func(num_students):\n    # Generate a list of student names\n    students = [f\"Student {i}\" for i in range(1, num_students + 1)]\n    \n    # Generate a list of course names\n    courses = [\"Math\", \"Science\", \"English\", \"History\", \"Art\"]\n    \n    # Generate a list of grades for each student in each course\n    grades = [[np.random.randint(0, 100) for _ in range(len(courses))] for _ in range(num_students)]\n    \n    # Create a DataFrame from the grades\n    df = pd.DataFrame(grades, index=students, columns=courses)\n    \n    # Calculate the average grade in each course\n    avg_grades = df.mean(axis=0)\n    \n    # Calculate the number of students with a passing grade (>= 60)\n    passing_grades = df[df >= 60].count(axis=0)\n    \n    # Create a bar plot with title 'Course-wise Average and Passing Grade Counts'\n    fig, ax = plt.subplots()\n    ax.bar(avg_grades.index, avg_grades.values, label='Average Grade')\n    ax.bar(passing_grades.index, passing_grades.values, label='Passing Grade Count')\n    ax.set_title('Course-wise Average and Passing Grade Counts')\n    ax.legend()\n    \n    return df, ax\n```"}
{"task_id": "BigCodeBench/638", "solution": "import numpy as np\nimport pandas as pd\ndef task_func(num_teams=5, num_games=100):\n    teams = ['Team ' + str(i) for i in range(1, num_teams + 1)]\n    games = ['Game ' + str(i) for i in range(1, num_games + 1)]\n    scores = np.random.randint(0, 100, (num_teams, num_games))\n    df = pd.DataFrame(scores, index=teams, columns=games)\n    return df", "raw_solution": "import numpy as np\nimport pandas as pd\n\ndef task_func(num_teams=5, num_games=100):\n    teams = ['Team ' + str(i) for i in range(1, num_teams + 1)]\n    games = ['Game ' + str(i) for i in range(1, num_games + 1)]\n    scores = np.random.randint(0, 100, (num_teams, num_games))\n    df = pd.DataFrame(scores, index=teams, columns=games)\n    return df\n```"}
{"task_id": "BigCodeBench/639", "solution": "import numpy as np\nimport pandas as pd\nimport seaborn as sns\ndef task_func(num_samples=100, num_features=5):\n    # Generate random values\n    data = np.random.rand(num_samples, num_features)\n    # Create DataFrame\n    df = pd.DataFrame(data, columns=['Feature ' + str(i) for i in range(num_features)])\n    # Calculate correlation matrix\n    corr_matrix = df.corr()\n    # Create heatmap\n    sns.heatmap(corr_matrix, annot=True, cmap='coolwarm')\n    return df, sns.plt.gca()", "raw_solution": "import numpy as np\nimport pandas as pd\nimport seaborn as sns\n\ndef task_func(num_samples=100, num_features=5):\n    # Generate random values\n    data = np.random.rand(num_samples, num_features)\n    # Create DataFrame\n    df = pd.DataFrame(data, columns=['Feature ' + str(i) for i in range(num_features)])\n    # Calculate correlation matrix\n    corr_matrix = df.corr()\n    # Create heatmap\n    sns.heatmap(corr_matrix, annot=True, cmap='coolwarm')\n    return df, sns.plt.gca()\n```"}
{"task_id": "BigCodeBench/640", "solution": "import matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nPRODUCTS = ['Product' + str(i) for i in range(1, 6)]\nMONTHS = ['Month' + str(i) for i in range(1, 13)]\ndef task_func():\n    # Generate random sales figures for each product over 12 months\n    sales = np.random.randint(100, 1000, (len(PRODUCTS), len(MONTHS)))\n    df = pd.DataFrame(sales, columns=MONTHS, index=PRODUCTS)\n    \n    # Plot the total sales per product\n    plt.figure(figsize=(10, 6))\n    sns.lineplot(data=df, palette='viridis')\n    plt.title('Total Sales per Product')\n    plt.xlabel('Month')\n    plt.ylabel('Sales')\n    plt.show()\n    \n    # Plot the heatmap visualizing sales figures across products and months\n    plt.figure(figsize=(10, 6))\n    sns.heatmap(df, cmap='viridis')\n    plt.title('Sales Figures Across Products and Months')\n    plt.xlabel('Product')\n    plt.ylabel('Month')\n    plt.show()\n    \n    return df", "raw_solution": "import matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nPRODUCTS = ['Product' + str(i) for i in range(1, 6)]\nMONTHS = ['Month' + str(i) for i in range(1, 13)]\ndef task_func():\n    # Generate random sales figures for each product over 12 months\n    sales = np.random.randint(100, 1000, (len(PRODUCTS), len(MONTHS)))\n    df = pd.DataFrame(sales, columns=MONTHS, index=PRODUCTS)\n    \n    # Plot the total sales per product\n    plt.figure(figsize=(10, 6))\n    sns.lineplot(data=df, palette='viridis')\n    plt.title('Total Sales per Product')\n    plt.xlabel('Month')\n    plt.ylabel('Sales')\n    plt.show()\n    \n    # Plot the heatmap visualizing sales figures across products and months\n    plt.figure(figsize=(10, 6))\n    sns.heatmap(df, cmap='viridis')\n    plt.title('Sales Figures Across Products and Months')\n    plt.xlabel('Product')\n    plt.ylabel('Month')\n    plt.show()\n    \n    return df\n```"}
{"task_id": "BigCodeBench/641", "solution": "import os\nimport re\nimport pandas as pd\ndef task_func(pattern: str, directory: str, output_csv: str) -> pd.DataFrame:\n    # Create a list to store matched file paths\n    matched_paths = []\n    \n    # Walk through the directory\n    for root, dirs, files in os.walk(directory):\n        for file in files:\n            # Check if the file name matches the pattern\n            if re.match(pattern, file):\n                # Add the file path to the list\n                matched_paths.append(os.path.join(root, file))\n    \n    # Create a DataFrame from the list of matched file paths\n    df = pd.DataFrame({'File Path': matched_paths})\n    \n    # Save the DataFrame to a CSV file\n    df.to_csv(output_csv, index=False)\n    \n    # Return the DataFrame\n    return df", "raw_solution": "import os\nimport re\nimport pandas as pd\n\ndef task_func(pattern: str, directory: str, output_csv: str) -> pd.DataFrame:\n    # Create a list to store matched file paths\n    matched_paths = []\n    \n    # Walk through the directory\n    for root, dirs, files in os.walk(directory):\n        for file in files:\n            # Check if the file name matches the pattern\n            if re.match(pattern, file):\n                # Add the file path to the list\n                matched_paths.append(os.path.join(root, file))\n    \n    # Create a DataFrame from the list of matched file paths\n    df = pd.DataFrame({'File Path': matched_paths})\n    \n    # Save the DataFrame to a CSV file\n    df.to_csv(output_csv, index=False)\n    \n    # Return the DataFrame\n    return df\n```"}
{"task_id": "BigCodeBench/642", "solution": "import binascii\nimport hashlib\nimport re\ndef task_func(directory: str, pattern: str = r\"(?<!Distillr)\\\\AcroTray\\.exe\") -> dict:\n    files = {}\n    for root, dirs, files in os.walk(directory):\n        for file in files:\n            if re.search(pattern, file):\n                file_path = os.path.join(root, file)\n                with open(file_path, 'rb') as f:\n                    content = f.read()\n                    sha256 = hashlib.sha256(content).hexdigest()\n                    files[file_path] = sha256\n    return files", "raw_solution": "import binascii\nimport hashlib\nimport re\nOUTPUT_DIR = './output'\ndef task_func(directory: str, pattern: str = r\"(?<!Distillr)\\\\AcroTray\\.exe\") -> dict:\n    files = {}\n    for root, dirs, files in os.walk(directory):\n        for file in files:\n            if re.search(pattern, file):\n                file_path = os.path.join(root, file)\n                with open(file_path, 'rb') as f:\n                    content = f.read()\n                    sha256 = hashlib.sha256(content).hexdigest()\n                    files[file_path] = sha256\n    return files\n```"}
{"task_id": "BigCodeBench/643", "solution": "import re\nimport pandas as pd\nimport numpy as np\nDATA_PATTERN = r'>\\d+\\.\\d+<'\ndef task_func(dataframe, data_pattern=DATA_PATTERN):\n    # Replace each cell with the extracted numeric value or NaN\n    dataframe = dataframe.applymap(lambda x: re.search(data_pattern, str(x)).group(0) if re.search(data_pattern, str(x)) else np.nan)\n    return dataframe", "raw_solution": "import re\nimport pandas as pd\nimport numpy as np\n# Constants\nDATA_PATTERN = r'>\\d+\\.\\d+<'\ndef task_func(dataframe, data_pattern=DATA_PATTERN):\n    # Replace each cell with the extracted numeric value or NaN\n    dataframe = dataframe.applymap(lambda x: re.search(data_pattern, str(x)).group(0) if re.search(data_pattern, str(x)) else np.nan)\n    return dataframe\n```"}
{"task_id": "BigCodeBench/644", "solution": "import hashlib\nimport base64\ndef task_func(filename, data, password):\n    # Create a hash object\n    hash_object = hashlib.sha256(password.encode('utf-8'))\n    # Get the hexadecimal representation of the hash\n    password_hash = hash_object.hexdigest()\n    # Create a base64 encoded string from the password hash\n    password_hash_base64 = base64.b64encode(password_hash.encode('utf-8')).decode('utf-8')\n    # Encrypt the data using the password hash\n    encrypted_data = data.encode('utf-8')\n    for i in range(len(password_hash_base64)):\n        encrypted_data = encrypted_data + password_hash_base64[i].encode('utf-8')\n    # Write the encrypted data to a file\n    with open(filename, 'wb') as f:\n        f.write(encrypted_data)\n    # Return the encrypted data\n    return encrypted_data", "raw_solution": "import hashlib\nimport base64\ndef task_func(filename, data, password):\n    # Create a hash object\n    hash_object = hashlib.sha256(password.encode('utf-8'))\n    # Get the hexadecimal representation of the hash\n    password_hash = hash_object.hexdigest()\n    # Create a base64 encoded string from the password hash\n    password_hash_base64 = base64.b64encode(password_hash.encode('utf-8')).decode('utf-8')\n    # Encrypt the data using the password hash\n    encrypted_data = data.encode('utf-8')\n    for i in range(len(password_hash_base64)):\n        encrypted_data = encrypted_data + password_hash_base64[i].encode('utf-8')\n    # Write the encrypted data to a file\n    with open(filename, 'wb') as f:\n        f.write(encrypted_data)\n    # Return the encrypted data\n    return encrypted_data\n```"}
{"task_id": "BigCodeBench/645", "solution": "import os\nimport pandas as pd\ndef task_func(filename: str) -> pd.DataFrame:\n    if not os.path.exists(filename):\n        raise FileNotFoundError(\"File not found\")\n    df = pd.read_csv(filename)\n    os.remove(filename)\n    return df", "raw_solution": "import os\nimport pandas as pd\n\ndef task_func(filename: str) -> pd.DataFrame:\n    if not os.path.exists(filename):\n        raise FileNotFoundError(\"File not found\")\n    df = pd.read_csv(filename)\n    os.remove(filename)\n    return df\n```"}
{"task_id": "BigCodeBench/646", "solution": "import os\nimport pandas as pd\nfrom dateutil.parser import parse\nOUTPUT_DIR = './output'\ndef task_func(csv_path=os.path.join(OUTPUT_DIR, 'data.csv'), date_column='date'):\n    # Read the CSV file\n    df = pd.read_csv(csv_path)\n    \n    # Convert the date column to datetime objects\n    df[date_column] = df[date_column].apply(parse)\n    \n    # Extract the year from the datetime objects\n    df['year'] = df[date_column].dt.year\n    \n    # Draw a histogram of the year distribution\n    ax = df['year'].hist()\n    \n    return ax", "raw_solution": "import os\nimport pandas as pd\nfrom dateutil.parser import parse\nOUTPUT_DIR = './output'\ndef task_func(csv_path=os.path.join(OUTPUT_DIR, 'data.csv'), date_column='date'):\n    # Read the CSV file\n    df = pd.read_csv(csv_path)\n    \n    # Convert the date column to datetime objects\n    df[date_column] = df[date_column].apply(parse)\n    \n    # Extract the year from the datetime objects\n    df['year'] = df[date_column].dt.year\n    \n    # Draw a histogram of the year distribution\n    ax = df['year'].hist()\n    \n    return ax\n```"}
{"task_id": "BigCodeBench/647", "solution": "import pytz\nfrom dateutil.parser import parse\ndef task_func(date_str, from_tz, to_tz):\n    from_tz = pytz.timezone(from_tz)\n    to_tz = pytz.timezone(to_tz)\n    date = parse(date_str)\n    date = date.astimezone(from_tz)\n    date = date.astimezone(to_tz)\n    return (date - date.replace(tzinfo=None)).total_seconds()", "raw_solution": "import pytz\nfrom dateutil.parser import parse\n\ndef task_func(date_str, from_tz, to_tz):\n    from_tz = pytz.timezone(from_tz)\n    to_tz = pytz.timezone(to_tz)\n    date = parse(date_str)\n    date = date.astimezone(from_tz)\n    date = date.astimezone(to_tz)\n    return (date - date.replace(tzinfo=None)).total_seconds()\n```"}
{"task_id": "BigCodeBench/648", "solution": "from dateutil.parser import parse\nfrom datetime import timedelta\ndef task_func(date_str):\n    date = parse(date_str)\n    while date.weekday() >= 5:\n        date += timedelta(days=1)\n    return date", "raw_solution": "from dateutil.parser import parse\nfrom datetime import timedelta\n\ndef task_func(date_str):\n    date = parse(date_str)\n    while date.weekday() >= 5:\n        date += timedelta(days=1)\n    return date\n```"}
{"task_id": "BigCodeBench/649", "solution": "import numpy as np\nimport pandas as pd\nfrom dateutil.parser import parse\ndef task_func(dates_str_list):\n    dates = [parse(date_str) for date_str in dates_str_list]\n    weekdays = [date.weekday() for date in dates]\n    weekday_distribution = pd.Series(weekdays, index=['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday'])\n    return weekday_distribution", "raw_solution": "import numpy as np\nimport pandas as pd\nfrom dateutil.parser import parse\n\ndef task_func(dates_str_list):\n    dates = [parse(date_str) for date_str in dates_str_list]\n    weekdays = [date.weekday() for date in dates]\n    weekday_distribution = pd.Series(weekdays, index=['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday'])\n    return weekday_distribution\n```"}
{"task_id": "BigCodeBench/650", "solution": "from datetime import datetime\nimport pytz\nfrom dateutil.parser import parse\ndef task_func(date_str, tz_str):\n    # Parse the date string\n    date = parse(date_str)\n    \n    # Get the timezone object\n    tz = pytz.timezone(tz_str)\n    \n    # Get the current time in the specified timezone\n    now = datetime.now(tz)\n    \n    # Get the next New Year's Day in the specified timezone\n    next_new_year = date.replace(year=now.year + 1)\n    \n    # Calculate the time difference in seconds\n    time_diff = (next_new_year - now).total_seconds()\n    \n    return time_diff", "raw_solution": "from datetime import datetime\nimport pytz\nfrom dateutil.parser import parse\n\ndef task_func(date_str, tz_str):\n    # Parse the date string\n    date = parse(date_str)\n    \n    # Get the timezone object\n    tz = pytz.timezone(tz_str)\n    \n    # Get the current time in the specified timezone\n    now = datetime.now(tz)\n    \n    # Get the next New Year's Day in the specified timezone\n    next_new_year = date.replace(year=now.year + 1)\n    \n    # Calculate the time difference in seconds\n    time_diff = (next_new_year - now).total_seconds()\n    \n    return time_diff\n```"}
{"task_id": "BigCodeBench/651", "solution": "import pandas as pd\nimport time\ndef task_func(df, target_value):\n    if df.empty:\n        return pd.Series(), None\n    df = df[df.apply(lambda row: row == target_value, axis=1)]\n    counts = df.apply(lambda row: row.count(target_value), axis=0)\n    fig, ax = plt.subplots()\n    counts.plot(kind='bar', ax=ax)\n    return counts, ax", "raw_solution": "import pandas as pd\nimport time\ndef task_func(df, target_value):\n    if df.empty:\n        return pd.Series(), None\n    df = df[df.apply(lambda row: row == target_value, axis=1)]\n    counts = df.apply(lambda row: row.count(target_value), axis=0)\n    fig, ax = plt.subplots()\n    counts.plot(kind='bar', ax=ax)\n    return counts, ax\n```"}
{"task_id": "BigCodeBench/652", "solution": "import matplotlib.pyplot as plt\nimport numpy as np\nimport scipy.stats as stats\nTARGET_VALUE = '332'\nARRAY = np.array([['0', '1', '2'], ['a', 'bb', 'ccc'], ['332', '33', '2'], ['33', '22', '332']])\ndef task_func(target_value=TARGET_VALUE, array=ARRAY):\n    # Find the row indices in the array where the first cell matches target_value\n    indices = np.where(array[:, 0] == target_value)[0]\n    if len(indices) == 0:\n        return 'N/A'\n    # Perform statistical analysis on these indices and plot their distribution\n    mean = np.mean(indices)\n    variance = np.var(indices)\n    skewness = stats.skew(indices)\n    kurtosis = stats.kurtosis(indices)\n    plt.hist(indices, bins=10)\n    plt.title('Distribution of indices where the first cell matches target_value')\n    plt.xlabel('Index')\n    plt.ylabel('Frequency')\n    plt.show()\n    return (mean, variance, skewness, kurtosis)", "raw_solution": "import matplotlib.pyplot as plt\nimport numpy as np\nimport scipy.stats as stats\n# Constants\nTARGET_VALUE = '332'\nARRAY = np.array([['0', '1', '2'], ['a', 'bb', 'ccc'], ['332', '33', '2'], ['33', '22', '332']])\ndef task_func(target_value=TARGET_VALUE, array=ARRAY):\n    # Find the row indices in the array where the first cell matches target_value\n    indices = np.where(array[:, 0] == target_value)[0]\n    if len(indices) == 0:\n        return 'N/A'\n    # Perform statistical analysis on these indices and plot their distribution\n    mean = np.mean(indices)\n    variance = np.var(indices)\n    skewness = stats.skew(indices)\n    kurtosis = stats.kurtosis(indices)\n    plt.hist(indices, bins=10)\n    plt.title('Distribution of indices where the first cell matches target_value')\n    plt.xlabel('Index')\n    plt.ylabel('Frequency')\n    plt.show()\n    return (mean, variance, skewness, kurtosis)\n```"}
{"task_id": "BigCodeBench/653", "solution": "import matplotlib.pyplot as plt\nimport seaborn as sns\ndef task_func(dataframe, target_value='332'):\n    # Create a heatmap of the DataFrame\n    heatmap = sns.heatmap(dataframe == target_value, cmap='Blues')\n    # Get the axes object of the heatmap\n    axes = heatmap.axes\n    # Return the heatmap and axes objects\n    return dataframe == target_value, axes", "raw_solution": "import matplotlib.pyplot as plt\nimport seaborn as sns\ndef task_func(dataframe, target_value='332'):\n    # Create a heatmap of the DataFrame\n    heatmap = sns.heatmap(dataframe == target_value, cmap='Blues')\n    # Get the axes object of the heatmap\n    axes = heatmap.axes\n    # Return the heatmap and axes objects\n    return dataframe == target_value, axes\n```"}
{"task_id": "BigCodeBench/654", "solution": "import matplotlib.pyplot as plt\nimport scipy.optimize as optimize\nimport numpy as np\ndef task_func(array, target_value):\n    # Extract the indices where the first column matches the target value\n    indices = np.where(array[:, 0] == target_value)[0]\n    \n    # Fit an exponential decay function to the indices\n    popt, pcov = optimize.curve_fit(lambda x, a, b: a * np.exp(-b * x), indices, array[indices, 1])\n    \n    # Plot the original data and the fitted function\n    fig, ax = plt.subplots()\n    ax.scatter(array[:, 0], array[:, 1], label='Original data')\n    ax.plot(indices, array[indices, 1], 'o', label='Fitted function')\n    ax.plot(indices, popt[0] * np.exp(-popt[1] * indices), label='Fitted function (optimized)')\n    ax.legend()\n    plt.show()\n    \n    return popt, ax", "raw_solution": "import matplotlib.pyplot as plt\nimport scipy.optimize as optimize\nimport numpy as np\n\ndef task_func(array, target_value):\n    # Extract the indices where the first column matches the target value\n    indices = np.where(array[:, 0] == target_value)[0]\n    \n    # Fit an exponential decay function to the indices\n    popt, pcov = optimize.curve_fit(lambda x, a, b: a * np.exp(-b * x), indices, array[indices, 1])\n    \n    # Plot the original data and the fitted function\n    fig, ax = plt.subplots()\n    ax.scatter(array[:, 0], array[:, 1], label='Original data')\n    ax.plot(indices, array[indices, 1], 'o', label='Fitted function')\n    ax.plot(indices, popt[0] * np.exp(-popt[1] * indices), label='Fitted function (optimized)')\n    ax.legend()\n    plt.show()\n    \n    return popt, ax\n```"}
{"task_id": "BigCodeBench/655", "solution": "import re\nimport nltk\nfrom sklearn.decomposition import NMF\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nALPHANUMERIC = re.compile('[\\W_]+')\nSTOPWORDS = nltk.corpus.stopwords.words('english')\ndef task_func(texts, num_topics):\n    # Preprocess the texts\n    processed_texts = []\n    for text in texts:\n        processed_text = re.sub(ALPHANUMERIC, ' ', text.lower())\n        processed_text = ' '.join([word for word in processed_text.split() if word not in STOPWORDS])\n        processed_texts.append(processed_text)\n    # Vectorize the processed texts\n    vectorizer = TfidfVectorizer()\n    X = vectorizer.fit_transform(processed_texts)\n    # Apply NMF\n    nmf = NMF(n_components=num_topics, random_state=42)\n    W = nmf.fit_transform(X)\n    # Extract the topics\n    topics = []\n    for i in range(num_topics):\n        topic = [vectorizer.get_feature_names_out()[j] for j in nmf.components_[i].argsort()[:-10:-1]]\n        topics.append(topic)\n    return topics", "raw_solution": "import re\nimport nltk\nfrom sklearn.decomposition import NMF\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n# Ensure nltk's stopwords are downloaded\nnltk.download('stopwords')\n# Constants\nALPHANUMERIC = re.compile('[\\W_]+')\nSTOPWORDS = nltk.corpus.stopwords.words('english')\ndef task_func(texts, num_topics):\n    # Preprocess the texts\n    processed_texts = []\n    for text in texts:\n        processed_text = re.sub(ALPHANUMERIC, ' ', text.lower())\n        processed_text = ' '.join([word for word in processed_text.split() if word not in STOPWORDS])\n        processed_texts.append(processed_text)\n    # Vectorize the processed texts\n    vectorizer = TfidfVectorizer()\n    X = vectorizer.fit_transform(processed_texts)\n    # Apply NMF\n    nmf = NMF(n_components=num_topics, random_state=42)\n    W = nmf.fit_transform(X)\n    # Extract the topics\n    topics = []\n    for i in range(num_topics):\n        topic = [vectorizer.get_feature_names_out()[j] for j in nmf.components_[i].argsort()[:-10:-1]]\n        topics.append(topic)\n    return topics\n```"}
{"task_id": "BigCodeBench/656", "solution": "import re\nimport string\nimport nltk\nfrom nltk.sentiment.vader import SentimentIntensityAnalyzer\nALPHANUMERIC = re.compile('[\\W_]+')\nPUNCTUATIONS = string.punctuation\ndef task_func(text: str, sia: SentimentIntensityAnalyzer) -> dict:\n    text = text.lower()\n    text = ALPHANUMERIC.sub(' ', text)\n    text = text.translate(str.maketrans('', '', PUNCTUATIONS))\n    scores = sia.polarity_scores(text)\n    return scores", "raw_solution": "import re\nimport string\nimport nltk\nfrom nltk.sentiment.vader import SentimentIntensityAnalyzer\nnltk.download('vader_lexicon')\n# Constants\nALPHANUMERIC = re.compile('[\\W_]+')\nPUNCTUATIONS = string.punctuation\ndef task_func(text: str, sia: SentimentIntensityAnalyzer) -> dict:\n    text = text.lower()\n    text = ALPHANUMERIC.sub(' ', text)\n    text = text.translate(str.maketrans('', '', PUNCTUATIONS))\n    scores = sia.polarity_scores(text)\n    return scores\n```"}
{"task_id": "BigCodeBench/657", "solution": "import re\nimport nltk\nfrom gensim.models import Word2Vec\nALPHANUMERIC = re.compile('[\\W_]+')\ndef task_func(texts, stopwords=None):\n    # Clean texts\n    texts = [re.sub(ALPHANUMERIC, ' ', text).lower() for text in texts]\n    if stopwords is None:\n        stopwords = nltk.corpus.stopwords.words('english')\n    texts = [word for word in texts if word not in stopwords]\n    # Train Word2Vec model\n    model = Word2Vec(texts, min_count=1)\n    return model", "raw_solution": "import re\nimport nltk\nfrom gensim.models import Word2Vec\n# Constants\nALPHANUMERIC = re.compile('[\\W_]+')\ndef task_func(texts, stopwords=None):\n    # Clean texts\n    texts = [re.sub(ALPHANUMERIC, ' ', text).lower() for text in texts]\n    if stopwords is None:\n        stopwords = nltk.corpus.stopwords.words('english')\n    texts = [word for word in texts if word not in stopwords]\n    # Train Word2Vec model\n    model = Word2Vec(texts, min_count=1)\n    return model\n```"}
{"task_id": "BigCodeBench/658", "solution": "import re\nimport nltk\nimport pandas as pd\nfrom sklearn.feature_extraction.text import CountVectorizer\nALPHANUMERIC = re.compile('[\\W_]+')\nSTOPWORDS = nltk.corpus.stopwords.words('english')\ndef task_func(texts):\n    # Preprocess the text data\n    texts = [ALPHANUMERIC.sub('', text.lower()) for text in texts]\n    texts = [text for text in texts if text not in STOPWORDS]\n    # Create a CountVectorizer object\n    vectorizer = CountVectorizer()\n    # Fit and transform the text data\n    X = vectorizer.fit_transform(texts)\n    # Convert the resulting sparse matrix to a DataFrame\n    df = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names_out())\n    return df", "raw_solution": "import re\nimport nltk\nimport pandas as pd\nfrom sklearn.feature_extraction.text import CountVectorizer\n# Make sure to download NLTK stopwords\nnltk.download('stopwords')\n# Define a regex pattern for matching all non-alphanumeric characters\nALPHANUMERIC = re.compile('[\\W_]+')\n# Load NLTK's list of English stop words\nSTOPWORDS = nltk.corpus.stopwords.words('english')\ndef task_func(texts):\n    # Preprocess the text data\n    texts = [ALPHANUMERIC.sub('', text.lower()) for text in texts]\n    texts = [text for text in texts if text not in STOPWORDS]\n    # Create a CountVectorizer object\n    vectorizer = CountVectorizer()\n    # Fit and transform the text data\n    X = vectorizer.fit_transform(texts)\n    # Convert the resulting sparse matrix to a DataFrame\n    df = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names_out())\n    return df\n```"}
{"task_id": "BigCodeBench/659", "solution": "import matplotlib.pyplot as plt\nimport numpy as np\nimport scipy.stats as stats\ndef task_func(x, y, labels):\n    fig, ax = plt.subplots()\n    for i in range(len(x)):\n        ax.plot(x[i], y[i], label=labels[i])\n    ax.legend()\n    return fig", "raw_solution": "import matplotlib.pyplot as plt\nimport numpy as np\nimport scipy.stats as stats\ndef task_func(x, y, labels):\n    fig, ax = plt.subplots()\n    for i in range(len(x)):\n        ax.plot(x[i], y[i], label=labels[i])\n    ax.legend()\n    return fig\n```"}
{"task_id": "BigCodeBench/660", "solution": "import matplotlib.pyplot as plt\nimport numpy as np\nfrom sklearn.preprocessing import StandardScaler\ndef task_func(x, y, labels):\n    scaler = StandardScaler()\n    x_scaled = scaler.fit_transform(x)\n    y_scaled = scaler.fit_transform(y)\n    fig, ax = plt.subplots()\n    for i in range(len(x_scaled)):\n        ax.plot(x_scaled[i], y_scaled[i], label=labels[i])\n    ax.legend()\n    return fig", "raw_solution": "import matplotlib.pyplot as plt\nimport numpy as np\nfrom sklearn.preprocessing import StandardScaler\n\ndef task_func(x, y, labels):\n    scaler = StandardScaler()\n    x_scaled = scaler.fit_transform(x)\n    y_scaled = scaler.fit_transform(y)\n    fig, ax = plt.subplots()\n    for i in range(len(x_scaled)):\n        ax.plot(x_scaled[i], y_scaled[i], label=labels[i])\n    ax.legend()\n    return fig\n```"}
{"task_id": "BigCodeBench/661", "solution": "import pandas as pd\nimport seaborn as sns\nimport numpy as np\ndef task_func(x, y, labels):\n    # Create a dataframe with x and y values\n    df = pd.DataFrame({'x': x, 'y': y})\n    # Create a heatmap using seaborn\n    ax = sns.heatmap(df, annot=True, fmt='d', cmap='coolwarm', xticklabels=labels, yticklabels=labels)\n    return ax, df", "raw_solution": "import pandas as pd\nimport seaborn as sns\nimport numpy as np\n# Constants\nLABELS = ['H\\u2082O', 'O\\u2082', 'CO\\u2082', 'N\\u2082', 'Ar']\ndef task_func(x, y, labels):\n    # Create a dataframe with x and y values\n    df = pd.DataFrame({'x': x, 'y': y})\n    # Create a heatmap using seaborn\n    ax = sns.heatmap(df, annot=True, fmt='d', cmap='coolwarm', xticklabels=labels, yticklabels=labels)\n    return ax, df\n```"}
{"task_id": "BigCodeBench/662", "solution": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.decomposition import PCA\ndef task_func(x, y, labels):\n    # Perform PCA\n    pca = PCA(n_components=2)\n    pca.fit(np.column_stack((x, y)))\n    x_pca = pca.transform(x.reshape(-1, 1))\n    y_pca = pca.transform(y.reshape(-1, 1))\n    \n    # Plot the results\n    fig, ax = plt.subplots()\n    ax.scatter(x_pca, y_pca, c=labels, cmap='viridis')\n    ax.set_xlabel('Principal Component 1')\n    ax.set_ylabel('Principal Component 2')\n    ax.set_title('PCA of x and y')\n    return fig", "raw_solution": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.decomposition import PCA\n\ndef task_func(x, y, labels):\n    # Perform PCA\n    pca = PCA(n_components=2)\n    pca.fit(np.column_stack((x, y)))\n    x_pca = pca.transform(x.reshape(-1, 1))\n    y_pca = pca.transform(y.reshape(-1, 1))\n    \n    # Plot the results\n    fig, ax = plt.subplots()\n    ax.scatter(x_pca, y_pca, c=labels, cmap='viridis')\n    ax.set_xlabel('Principal Component 1')\n    ax.set_ylabel('Principal Component 2')\n    ax.set_title('PCA of x and y')\n    return fig\n```"}
{"task_id": "BigCodeBench/663", "solution": "import numpy as np\nfrom scipy.optimize import curve_fit\ndef task_func(x, y, labels):\n    # Define the exponential curve function\n    def exp_curve(x, a, b, c):\n        return a * np.exp(-b * x) + c\n    # Fit the exponential curve to each set of data\n    popt, pcov = curve_fit(exp_curve, x, y)\n    # Create a figure and plot the fitted curves\n    fig, ax = plt.subplots()\n    for i in range(len(x)):\n        ax.plot(x[i], y[i], 'o', label=labels[i])\n        ax.plot(x[i], exp_curve(x[i], *popt), label=f'fitted curve: {labels[i]}')\n    ax.legend()\n    return fig", "raw_solution": "import numpy as np\nfrom scipy.optimize import curve_fit\ndef task_func(x, y, labels):\n    # Define the exponential curve function\n    def exp_curve(x, a, b, c):\n        return a * np.exp(-b * x) + c\n    # Fit the exponential curve to each set of data\n    popt, pcov = curve_fit(exp_curve, x, y)\n    # Create a figure and plot the fitted curves\n    fig, ax = plt.subplots()\n    for i in range(len(x)):\n        ax.plot(x[i], y[i], 'o', label=labels[i])\n        ax.plot(x[i], exp_curve(x[i], *popt), label=f'fitted curve: {labels[i]}')\n    ax.legend()\n    return fig\n```"}
{"task_id": "BigCodeBench/664", "solution": "import statistics\nimport matplotlib.pyplot as plt\ndef task_func(sales_data):\n    # Calculate the mean and standard deviation for each product\n    means = [statistics.mean(sales) for sales in sales_data]\n    stds = [statistics.stdev(sales) for sales in sales_data]\n    \n    # Create a figure and axes object\n    fig, ax = plt.subplots()\n    \n    # Plot the sales trends for each product\n    for i in range(len(sales_data)):\n        ax.plot(range(1, 13), sales_data[i], label=f'Product {i+1}')\n    \n    # Add a legend\n    ax.legend()\n    \n    # Add a shaded area for the standard deviation\n    ax.fill_between(range(1, 13), means - stds, means + stds, alpha=0.2)\n    \n    # Set the x-axis label\n    ax.set_xlabel('Month')\n    \n    # Set the y-axis label\n    ax.set_ylabel('Sales')\n    \n    # Set the title\n    ax.set_title('Sales Trends for Five Products Over a Year')\n    \n    # Return the axes object\n    return ax", "raw_solution": "import statistics\nimport matplotlib.pyplot as plt\n\ndef task_func(sales_data):\n    # Calculate the mean and standard deviation for each product\n    means = [statistics.mean(sales) for sales in sales_data]\n    stds = [statistics.stdev(sales) for sales in sales_data]\n    \n    # Create a figure and axes object\n    fig, ax = plt.subplots()\n    \n    # Plot the sales trends for each product\n    for i in range(len(sales_data)):\n        ax.plot(range(1, 13), sales_data[i], label=f'Product {i+1}')\n    \n    # Add a legend\n    ax.legend()\n    \n    # Add a shaded area for the standard deviation\n    ax.fill_between(range(1, 13), means - stds, means + stds, alpha=0.2)\n    \n    # Set the x-axis label\n    ax.set_xlabel('Month')\n    \n    # Set the y-axis label\n    ax.set_ylabel('Sales')\n    \n    # Set the title\n    ax.set_title('Sales Trends for Five Products Over a Year')\n    \n    # Return the axes object\n    return ax\n```"}
{"task_id": "BigCodeBench/665", "solution": "import shutil\nimport os\nimport fnmatch\nimport itertools\ndef task_func(src_dir, dst_dir):\n    for root, dirs, files in os.walk(src_dir):\n        for file in files:\n            if fnmatch.fnmatch(file, '*.txt') or fnmatch.fnmatch(file, '*.docx'):\n                shutil.copy(os.path.join(root, file), dst_dir)\n    return dst_dir", "raw_solution": "import shutil\nimport os\nimport fnmatch\nimport itertools\ndef task_func(src_dir, dst_dir):\n    for root, dirs, files in os.walk(src_dir):\n        for file in files:\n            if fnmatch.fnmatch(file, '*.txt') or fnmatch.fnmatch(file, '*.docx'):\n                shutil.copy(os.path.join(root, file), dst_dir)\n    return dst_dir\n```"}
{"task_id": "BigCodeBench/666", "solution": "from itertools import combinations\nimport math\ndef task_func(seq, letter_weight_dict):\n    max_weight = 0\n    max_subseq = ''\n    for i in range(1, len(seq) + 1):\n        for subseq in combinations(seq, i):\n            weight = sum(letter_weight_dict[c] for c in subseq)\n            if weight > max_weight:\n                max_weight = weight\n                max_subseq = ''.join(subseq)\n    return max_subseq", "raw_solution": "from itertools import combinations\nimport math\ndef task_func(seq, letter_weight_dict):\n    max_weight = 0\n    max_subseq = ''\n    for i in range(1, len(seq) + 1):\n        for subseq in combinations(seq, i):\n            weight = sum(letter_weight_dict[c] for c in subseq)\n            if weight > max_weight:\n                max_weight = weight\n                max_subseq = ''.join(subseq)\n    return max_subseq\n```"}
{"task_id": "BigCodeBench/667", "solution": "import heapq\nimport collections\ndef task_func(x, n):\n    # Count the frequency of each letter in the dictionary\n    letter_counts = collections.Counter(x)\n    # Use a heap to find the n most frequent letters\n    most_common_letters = heapq.nlargest(n, letter_counts.items(), key=lambda x: x[1])\n    # Return the list of the n most frequent letters\n    return [letter for letter, count in most_common_letters]", "raw_solution": "import heapq\nimport collections\ndef task_func(x, n):\n    # Count the frequency of each letter in the dictionary\n    letter_counts = collections.Counter(x)\n    # Use a heap to find the n most frequent letters\n    most_common_letters = heapq.nlargest(n, letter_counts.items(), key=lambda x: x[1])\n    # Return the list of the n most frequent letters\n    return [letter for letter, count in most_common_letters]\n```"}
{"task_id": "BigCodeBench/668", "solution": "import itertools\nimport math\ndef task_func(x):\n    # Find all possible subsequences of the dictionary\n    subsequences = list(itertools.chain.from_iterable(itertools.combinations(x.keys(), r) for r in range(1, len(x) + 1)))\n    # Calculate the total length of each subsequence\n    total_lengths = [sum(x[k] for k in subseq) for subseq in subsequences]\n    # Find the subsequence with the minimum total length\n    min_subseq = subsequences[total_lengths.index(min(total_lengths))]\n    return list(min_subseq)", "raw_solution": "import itertools\nimport math\ndef task_func(x):\n    # Find all possible subsequences of the dictionary\n    subsequences = list(itertools.chain.from_iterable(itertools.combinations(x.keys(), r) for r in range(1, len(x) + 1)))\n    # Calculate the total length of each subsequence\n    total_lengths = [sum(x[k] for k in subseq) for subseq in subsequences]\n    # Find the subsequence with the minimum total length\n    min_subseq = subsequences[total_lengths.index(min(total_lengths))]\n    return list(min_subseq)\n```"}
{"task_id": "BigCodeBench/669", "solution": "import itertools\nimport math\ndef task_func(x):\n    # Get all possible pairs of keys\n    pairs = list(itertools.combinations(x.keys(), 2))\n    # Calculate the cosine of each pair\n    cosines = [(math.cos(x[pair[0]]), math.cos(x[pair[1]])) for pair in pairs]\n    # Find the pair with the highest sum of the cosine\n    max_pair = max(cosines, key=lambda x: x[0] + x[1])\n    return max_pair", "raw_solution": "import itertools\nimport math\ndef task_func(x):\n    # Get all possible pairs of keys\n    pairs = list(itertools.combinations(x.keys(), 2))\n    # Calculate the cosine of each pair\n    cosines = [(math.cos(x[pair[0]]), math.cos(x[pair[1]])) for pair in pairs]\n    # Find the pair with the highest sum of the cosine\n    max_pair = max(cosines, key=lambda x: x[0] + x[1])\n    return max_pair\n```"}
{"task_id": "BigCodeBench/670", "solution": "from itertools import combinations\nimport math\ndef task_func(x, w):\n    max_weight = 0\n    max_substr = ''\n    for i in range(1, len(x) + 1):\n        for comb in combinations(x, i):\n            weight = sum(w[c] for c in comb)\n            if weight > max_weight:\n                max_weight = weight\n                max_substr = ''.join(comb)\n    return max_substr", "raw_solution": "from itertools import combinations\nimport math\ndef task_func(x, w):\n    max_weight = 0\n    max_substr = ''\n    for i in range(1, len(x) + 1):\n        for comb in combinations(x, i):\n            weight = sum(w[c] for c in comb)\n            if weight > max_weight:\n                max_weight = weight\n                max_substr = ''.join(comb)\n    return max_substr\n```"}
{"task_id": "BigCodeBench/671", "solution": "import os\nimport random\nimport json\ndef task_func(directory, n):\n    os.makedirs(directory, exist_ok=True)\n    for i in range(n):\n        with open(os.path.join(directory, f'file_{i+1}.json'), 'w') as f:\n            f.write(json.dumps({'number': random.randint(1, 100)}))\n    for i in range(n):\n        with open(os.path.join(directory, f'file_{i+1}.json'), 'r') as f:\n            f.seek(0)", "raw_solution": "import os\nimport random\nimport json\n\ndef task_func(directory, n):\n    os.makedirs(directory, exist_ok=True)\n    for i in range(n):\n        with open(os.path.join(directory, f'file_{i+1}.json'), 'w') as f:\n            f.write(json.dumps({'number': random.randint(1, 100)}))\n    for i in range(n):\n        with open(os.path.join(directory, f'file_{i+1}.json'), 'r') as f:\n            f.seek(0)\n```"}
{"task_id": "BigCodeBench/672", "solution": "import csv\nimport sys\ndef task_func(filename):\n    with open(filename, 'r') as f:\n        reader = csv.reader(f)\n        lines = list(reader)\n    with open(filename, 'w') as f:\n        writer = csv.writer(f)\n        for line in reversed(lines):\n            writer.writerow(line)\n    f.seek(0)", "raw_solution": "import csv\nimport sys\n\ndef task_func(filename):\n    with open(filename, 'r') as f:\n        reader = csv.reader(f)\n        lines = list(reader)\n    with open(filename, 'w') as f:\n        writer = csv.writer(f)\n        for line in reversed(lines):\n            writer.writerow(line)\n    f.seek(0)\n```"}
{"task_id": "BigCodeBench/673", "solution": "import os\nimport random\ndef task_func(directory, n_files):\n    for i in range(1, n_files + 1):\n        file_name = f\"file_{i}.txt\"\n        with open(os.path.join(directory, file_name), \"w\") as f:\n            f.write(str(random.randint(0, 9)))\n        with open(os.path.join(directory, file_name), \"r\") as f:\n            f.seek(0)\n    return n_files", "raw_solution": "import os\nimport random\n\ndef task_func(directory, n_files):\n    for i in range(1, n_files + 1):\n        file_name = f\"file_{i}.txt\"\n        with open(os.path.join(directory, file_name), \"w\") as f:\n            f.write(str(random.randint(0, 9)))\n        with open(os.path.join(directory, file_name), \"r\") as f:\n            f.seek(0)\n    return n_files\n```"}
{"task_id": "BigCodeBench/674", "solution": "import pandas as pd\nimport os\ndef task_func(filename):\n    # Read the CSV file\n    df = pd.read_csv(filename)\n    # Reverse the order of the lines\n    df = df[::-1]\n    # Write the inverted lines back into the file\n    df.to_csv(filename, index=False)\n    # Move the cursor back to the beginning of the file\n    os.seek(0, os.SEEK_SET)\n    # Read the file again to check if the header is not inverted\n    df = pd.read_csv(filename)\n    # Check if the header is not inverted\n    if df.columns.tolist() != df.columns.tolist()[::-1]:\n        print(\"The header is not inverted.\")\n    else:\n        print(\"The header is inverted.\")\n    # Check if the file is empty\n    if df.empty:\n        print(\"The file is empty.\")\n    else:\n        print(\"The file is not empty.\")", "raw_solution": "import pandas as pd\nimport os\ndef task_func(filename):\n    # Read the CSV file\n    df = pd.read_csv(filename)\n    # Reverse the order of the lines\n    df = df[::-1]\n    # Write the inverted lines back into the file\n    df.to_csv(filename, index=False)\n    # Move the cursor back to the beginning of the file\n    os.seek(0, os.SEEK_SET)\n    # Read the file again to check if the header is not inverted\n    df = pd.read_csv(filename)\n    # Check if the header is not inverted\n    if df.columns.tolist() != df.columns.tolist()[::-1]:\n        print(\"The header is not inverted.\")\n    else:\n        print(\"The header is inverted.\")\n    # Check if the file is empty\n    if df.empty:\n        print(\"The file is empty.\")\n    else:\n        print(\"The file is not empty.\")\n```"}
{"task_id": "BigCodeBench/675", "solution": "import os\nimport random\ndef task_func(directory, n_files):\n    # Create the directory if it doesn't exist\n    if not os.path.exists(directory):\n        os.makedirs(directory)\n    \n    # Generate random strings\n    random_strings = [''.join(random.choices('abcdefghijklmnopqrstuvwxyz', k=10)) for _ in range(n_files)]\n    \n    # Write random strings to files\n    for i in range(n_files):\n        file_path = os.path.join(directory, f'file_{i+1}.txt')\n        with open(file_path, 'w') as f:\n            f.write(random_strings[i])\n    \n    # Reset the cursor to the beginning of each file\n    for i in range(n_files):\n        file_path = os.path.join(directory, f'file_{i+1}.txt')\n        with open(file_path, 'r+') as f:\n            f.seek(0)\n    \n    return directory", "raw_solution": "import os\nimport random\n\ndef task_func(directory, n_files):\n    # Create the directory if it doesn't exist\n    if not os.path.exists(directory):\n        os.makedirs(directory)\n    \n    # Generate random strings\n    random_strings = [''.join(random.choices('abcdefghijklmnopqrstuvwxyz', k=10)) for _ in range(n_files)]\n    \n    # Write random strings to files\n    for i in range(n_files):\n        file_path = os.path.join(directory, f'file_{i+1}.txt')\n        with open(file_path, 'w') as f:\n            f.write(random_strings[i])\n    \n    # Reset the cursor to the beginning of each file\n    for i in range(n_files):\n        file_path = os.path.join(directory, f'file_{i+1}.txt')\n        with open(file_path, 'r+') as f:\n            f.seek(0)\n    \n    return directory\n```"}
{"task_id": "BigCodeBench/676", "solution": "import pandas as pd\nimport random\ndef task_func(df):\n    df['winner'] = df.apply(lambda row: row['team1'] if row['score1'] > row['score2'] else row['team2'], axis=1)\n    df['winner'] = df['winner'].where(df['score1'] != df['score2'], random.choice([df['team1'], df['team2']]))\n    return df", "raw_solution": "import pandas as pd\nimport random\n\ndef task_func(df):\n    df['winner'] = df.apply(lambda row: row['team1'] if row['score1'] > row['score2'] else row['team2'], axis=1)\n    df['winner'] = df['winner'].where(df['score1'] != df['score2'], random.choice([df['team1'], df['team2']]))\n    return df\n```"}
{"task_id": "BigCodeBench/677", "solution": "import numpy as np\nimport pandas as pd\nfrom scipy.stats import linregress\ndef task_func(df):\n    # Perform linear regression\n    slope, intercept, r_value, p_value, std_err = linregress(df['x'], df['y'])\n    # Add predicted column to DataFrame\n    df['predicted'] = slope * df['x'] + intercept\n    return df", "raw_solution": "import numpy as np\nimport pandas as pd\nfrom scipy.stats import linregress\ndef task_func(df):\n    # Perform linear regression\n    slope, intercept, r_value, p_value, std_err = linregress(df['x'], df['y'])\n    # Add predicted column to DataFrame\n    df['predicted'] = slope * df['x'] + intercept\n    return df\n```"}
{"task_id": "BigCodeBench/678", "solution": "import pandas as pd\nimport json\nimport os\nimport shutil\ndef task_func(path):\n    if not os.path.exists(path):\n        os.makedirs(path)\n    if not os.path.exists(os.path.join(path, 'processed')):\n        os.makedirs(os.path.join(path, 'processed'))\n    files = sorted(os.listdir(path))\n    for file in files:\n        if file.endswith('.json'):\n            with open(os.path.join(path, file), 'r') as f:\n                data = json.load(f)\n            df = pd.DataFrame(data)\n            df['Source'] = file\n            df.to_csv(os.path.join(path, 'processed', file), index=False)\n    df = pd.DataFrame()\n    for file in os.listdir(os.path.join(path, 'processed')):\n        if file.endswith('.csv'):\n            df = pd.concat([df, pd.read_csv(os.path.join(path, 'processed', file))])\n    return df", "raw_solution": "import pandas as pd\nimport json\nimport os\nimport shutil\n\ndef task_func(path):\n    if not os.path.exists(path):\n        os.makedirs(path)\n    if not os.path.exists(os.path.join(path, 'processed')):\n        os.makedirs(os.path.join(path, 'processed'))\n    files = sorted(os.listdir(path))\n    for file in files:\n        if file.endswith('.json'):\n            with open(os.path.join(path, file), 'r') as f:\n                data = json.load(f)\n            df = pd.DataFrame(data)\n            df['Source'] = file\n            df.to_csv(os.path.join(path, 'processed', file), index=False)\n    df = pd.DataFrame()\n    for file in os.listdir(os.path.join(path, 'processed')):\n        if file.endswith('.csv'):\n            df = pd.concat([df, pd.read_csv(os.path.join(path, 'processed', file))])\n    return df\n```"}
{"task_id": "BigCodeBench/679", "solution": "import pandas as pd\nfrom collections import Counter\ndef task_func(df):\n    df['combination'] = df.apply(lambda row: tuple(sorted(row)), axis=1)\n    return dict(Counter(df['combination']))", "raw_solution": "import pandas as pd\nfrom collections import Counter\n\ndef task_func(df):\n    df['combination'] = df.apply(lambda row: tuple(sorted(row)), axis=1)\n    return dict(Counter(df['combination']))\n```"}
{"task_id": "BigCodeBench/680", "solution": "import pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing import StandardScaler\ndef task_func(df, features):\n    scaler = StandardScaler()\n    df[features] = scaler.fit_transform(df[features])\n    return df", "raw_solution": "import pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing import StandardScaler\n\ndef task_func(df, features):\n    scaler = StandardScaler()\n    df[features] = scaler.fit_transform(df[features])\n    return df\n```"}
{"task_id": "BigCodeBench/681", "solution": "import pandas as pd\nimport json\ndef task_func(file_path, key):\n    with open(file_path, 'r') as f:\n        data = json.load(f)\n    df = pd.DataFrame(data)\n    df = df.drop(columns=[key])\n    with open(file_path, 'w') as f:\n        json.dump(df.to_dict(orient='records'), f)\n    return df", "raw_solution": "import pandas as pd\nimport json\n\ndef task_func(file_path, key):\n    with open(file_path, 'r') as f:\n        data = json.load(f)\n    df = pd.DataFrame(data)\n    df = df.drop(columns=[key])\n    with open(file_path, 'w') as f:\n        json.dump(df.to_dict(orient='records'), f)\n    return df\n```"}
{"task_id": "BigCodeBench/682", "solution": "from collections import Counter\nimport math\ndef task_func(nested_dict):\n    result = {}\n    for key, value in nested_dict.items():\n        if key == \"ele\":\n            continue\n        if key in result:\n            result[key] += value\n        else:\n            result[key] = value\n    result = {key: math.sin(value) for key, value in result.items()}\n    return result", "raw_solution": "from collections import Counter\nimport math\n\ndef task_func(nested_dict):\n    result = {}\n    for key, value in nested_dict.items():\n        if key == \"ele\":\n            continue\n        if key in result:\n            result[key] += value\n        else:\n            result[key] = value\n    result = {key: math.sin(value) for key, value in result.items()}\n    return result\n```"}
{"task_id": "BigCodeBench/683", "solution": "import math\nimport yaml\ndef task_func(yaml_path, key):\n    with open(yaml_path, 'r') as file:\n        data = yaml.safe_load(file)\n    if key in data:\n        data[key] = math.cos(data[key])\n    with open(yaml_path, 'w') as file:\n        yaml.safe_dump(data, file)\n    return data", "raw_solution": "import math\nimport yaml\n\ndef task_func(yaml_path, key):\n    with open(yaml_path, 'r') as file:\n        data = yaml.safe_load(file)\n    if key in data:\n        data[key] = math.cos(data[key])\n    with open(yaml_path, 'w') as file:\n        yaml.safe_dump(data, file)\n    return data\n```"}
{"task_id": "BigCodeBench/684", "solution": "import pandas as pd\nimport numpy as np\ndef task_func(df, col):\n    df = df.drop(columns=[col])\n    df['IsEvenIndex'] = df.index % 2 == 0\n    return df", "raw_solution": "import pandas as pd\nimport numpy as np\ndef task_func(df, col):\n    df = df.drop(columns=[col])\n    df['IsEvenIndex'] = df.index % 2 == 0\n    return df\n```"}
{"task_id": "BigCodeBench/685", "solution": "from collections import Counter\nfrom itertools import chain\ndef task_func(list_of_lists):\n    merged_list = list(chain(*list_of_lists))\n    return Counter(merged_list)", "raw_solution": "from collections import Counter\nfrom itertools import chain\n\ndef task_func(list_of_lists):\n    merged_list = list(chain(*list_of_lists))\n    return Counter(merged_list)\n```"}
{"task_id": "BigCodeBench/686", "solution": "import numpy as np\nfrom sklearn.preprocessing import OneHotEncoder\ndef task_func(list_of_lists):\n    merged_list = [item for sublist in list_of_lists for item in sublist]\n    one_hot = OneHotEncoder(sparse=False).fit_transform(np.array(merged_list).reshape(-1, 1))\n    return one_hot", "raw_solution": "import numpy as np\nfrom sklearn.preprocessing import OneHotEncoder\n\ndef task_func(list_of_lists):\n    merged_list = [item for sublist in list_of_lists for item in sublist]\n    one_hot = OneHotEncoder(sparse=False).fit_transform(np.array(merged_list).reshape(-1, 1))\n    return one_hot\n```"}
{"task_id": "BigCodeBench/687", "solution": "import numpy as np\nfrom scipy.stats import mode\ndef task_func(list_of_lists):\n    merged_list = [item for sublist in list_of_lists for item in sublist]\n    mode_value, mode_count = mode(merged_list)\n    return (mode_value, mode_count)", "raw_solution": "import numpy as np\nfrom scipy.stats import mode\n\ndef task_func(list_of_lists):\n    merged_list = [item for sublist in list_of_lists for item in sublist]\n    mode_value, mode_count = mode(merged_list)\n    return (mode_value, mode_count)\n```"}
{"task_id": "BigCodeBench/688", "solution": "import pandas as pd\nfrom sklearn.preprocessing import StandardScaler\ndef task_func(df):\n    scaler = StandardScaler()\n    df_standardized = scaler.fit_transform(df)\n    return pd.DataFrame(df_standardized, columns=df.columns)", "raw_solution": "import pandas as pd\nfrom sklearn.preprocessing import StandardScaler\n\ndef task_func(df):\n    scaler = StandardScaler()\n    df_standardized = scaler.fit_transform(df)\n    return pd.DataFrame(df_standardized, columns=df.columns)\n```"}
{"task_id": "BigCodeBench/689", "solution": "import numpy as np\nfrom scipy import stats\ndef task_func(df):\n    p_values = {}\n    for col in df.columns:\n        stat, p = stats.shapiro(df[col])\n        p_values[col] = p\n    return p_values", "raw_solution": "import numpy as np\nfrom scipy import stats\ndef task_func(df):\n    p_values = {}\n    for col in df.columns:\n        stat, p = stats.shapiro(df[col])\n        p_values[col] = p\n    return p_values\n```"}
{"task_id": "BigCodeBench/690", "solution": "import pandas as pd\nfrom sklearn.linear_model import LinearRegression\ndef task_func(df):\n    model = LinearRegression()\n    model.fit(df[['X']], df[['Y']])\n    return model", "raw_solution": "import pandas as pd\nfrom sklearn.linear_model import LinearRegression\nROWS = 100\nCOLUMNS = ['X', 'Y']\ndef task_func(df):\n    model = LinearRegression()\n    model.fit(df[['X']], df[['Y']])\n    return model\n```"}
{"task_id": "BigCodeBench/691", "solution": "import pandas as pd\nfrom sklearn.cluster import KMeans\nfrom sklearn.preprocessing import StandardScaler\ndef task_func(df):\n    scaler = StandardScaler()\n    scaled_df = scaler.fit_transform(df)\n    kmeans = KMeans(n_clusters=3)\n    labels = kmeans.fit_predict(scaled_df)\n    return labels", "raw_solution": "import pandas as pd\nfrom sklearn.cluster import KMeans\nfrom sklearn.preprocessing import StandardScaler\n\ndef task_func(df):\n    scaler = StandardScaler()\n    scaled_df = scaler.fit_transform(df)\n    kmeans = KMeans(n_clusters=3)\n    labels = kmeans.fit_predict(scaled_df)\n    return labels\n```"}
{"task_id": "BigCodeBench/692", "solution": "import math\nimport pandas as pd\ndef task_func(tuples_list):\n    df = pd.DataFrame([math.sin(x) for x in tuples_list])\n    return df", "raw_solution": "import math\nimport pandas as pd\n\ndef task_func(tuples_list):\n    df = pd.DataFrame([math.sin(x) for x in tuples_list])\n    return df\n```"}
{"task_id": "BigCodeBench/693", "solution": "import pandas as pd\nfrom sklearn.preprocessing import StandardScaler\ndef task_func(tuples_list, columns):\n    df = pd.DataFrame(tuples_list, columns=columns)\n    scaler = StandardScaler()\n    df_scaled = scaler.fit_transform(df)\n    return pd.DataFrame(df_scaled, columns=columns)", "raw_solution": "import pandas as pd\nfrom sklearn.preprocessing import StandardScaler\n\ndef task_func(tuples_list, columns):\n    df = pd.DataFrame(tuples_list, columns=columns)\n    scaler = StandardScaler()\n    df_scaled = scaler.fit_transform(df)\n    return pd.DataFrame(df_scaled, columns=columns)\n```"}
{"task_id": "BigCodeBench/694", "solution": "import itertools\nimport random\ndef task_func(t, n):\n    # Generate all combinations of length n\n    combinations = list(itertools.combinations(t, n))\n    # Return a random combination of length n\n    return random.choice(combinations)", "raw_solution": "import itertools\nimport random\n\ndef task_func(t, n):\n    # Generate all combinations of length n\n    combinations = list(itertools.combinations(t, n))\n    # Return a random combination of length n\n    return random.choice(combinations)\n```"}
{"task_id": "BigCodeBench/695", "solution": "import numpy as np\nfrom sklearn.decomposition import PCA\ndef task_func(tuples_list, n_components):\n    # Convert tuples to numpy array\n    data = np.array(tuples_list)\n    \n    # Perform PCA\n    pca = PCA(n_components=n_components)\n    transformed_data = pca.fit_transform(data)\n    \n    return transformed_data", "raw_solution": "import numpy as np\nfrom sklearn.decomposition import PCA\n\ndef task_func(tuples_list, n_components):\n    # Convert tuples to numpy array\n    data = np.array(tuples_list)\n    \n    # Perform PCA\n    pca = PCA(n_components=n_components)\n    transformed_data = pca.fit_transform(data)\n    \n    return transformed_data\n```"}
{"task_id": "BigCodeBench/696", "solution": "import numpy as np\nimport math\nimport random\nfrom random import uniform\ndef task_func(radius, num_points):\n    points = []\n    for i in range(num_points):\n        x = uniform(-radius, radius)\n        y = uniform(-radius, radius)\n        if math.sqrt(x**2 + y**2) <= radius:\n            points.append((x, y))\n    return points", "raw_solution": "import numpy as np\nimport math\nimport random\nfrom random import uniform\ndef task_func(radius, num_points):\n    points = []\n    for i in range(num_points):\n        x = uniform(-radius, radius)\n        y = uniform(-radius, radius)\n        if math.sqrt(x**2 + y**2) <= radius:\n            points.append((x, y))\n    return points\n```"}
{"task_id": "BigCodeBench/697", "solution": "import numpy as np\nfrom sklearn.linear_model import LinearRegression\ndef task_func(df):\n    X = df['feature'].values.reshape(-1, 1)\n    y = df['value'].values\n    model = LinearRegression()\n    model.fit(X, y)\n    result = {'coefficients': model.coef_[0], 'intercept': model.intercept_}\n    return result", "raw_solution": "import numpy as np\nfrom sklearn.linear_model import LinearRegression\n\ndef task_func(df):\n    X = df['feature'].values.reshape(-1, 1)\n    y = df['value'].values\n    model = LinearRegression()\n    model.fit(X, y)\n    result = {'coefficients': model.coef_[0], 'intercept': model.intercept_}\n    return result\n```"}
{"task_id": "BigCodeBench/698", "solution": "import pandas as pd\nfrom sklearn.model_selection import train_test_split\ndef task_func(df):\n    X = df.drop('target', axis=1)\n    y = df['target']\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n    return (X_train, X_test, y_train, y_test)", "raw_solution": "import pandas as pd\nfrom sklearn.model_selection import train_test_split\n\ndef task_func(df):\n    X = df.drop('target', axis=1)\n    y = df['target']\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n    return (X_train, X_test, y_train, y_test)\n```"}
{"task_id": "BigCodeBench/699", "solution": "import pandas as pd\nfrom sklearn.cluster import KMeans\ndef task_func(x_list, y_list, n_clusters=2, random_state=0):\n    df = pd.DataFrame({'x': x_list, 'y': y_list})\n    kmeans = KMeans(n_clusters=n_clusters, random_state=random_state)\n    labels = kmeans.labels_\n    centroids = kmeans.cluster_centers_\n    return labels, centroids", "raw_solution": "import pandas as pd\nfrom sklearn.cluster import KMeans\n\ndef task_func(x_list, y_list, n_clusters=2, random_state=0):\n    df = pd.DataFrame({'x': x_list, 'y': y_list})\n    kmeans = KMeans(n_clusters=n_clusters, random_state=random_state)\n    labels = kmeans.labels_\n    centroids = kmeans.cluster_centers_\n    return labels, centroids\n```"}
{"task_id": "BigCodeBench/700", "solution": "import pandas as pd\nimport numpy as np\ndef task_func(data, cols):\n    df = pd.DataFrame(data, columns=cols)\n    correlation_matrix = df[cols].corr()\n    return correlation_matrix", "raw_solution": "import pandas as pd\nimport numpy as np\ndef task_func(data, cols):\n    df = pd.DataFrame(data, columns=cols)\n    correlation_matrix = df[cols].corr()\n    return correlation_matrix\n```"}
{"task_id": "BigCodeBench/701", "solution": "import pandas as pd\nfrom sklearn.linear_model import LinearRegression\ndef task_func(df, target):\n    X = df.drop(target, axis=1)\n    y = df[target]\n    model = LinearRegression()\n    model.fit(X, y)\n    score = model.score(X, y)\n    return score", "raw_solution": "import pandas as pd\nfrom sklearn.linear_model import LinearRegression\ndef task_func(df, target):\n    X = df.drop(target, axis=1)\n    y = df[target]\n    model = LinearRegression()\n    model.fit(X, y)\n    score = model.score(X, y)\n    return score\n```"}
{"task_id": "BigCodeBench/702", "solution": "import pandas as pd\nfrom sklearn.decomposition import PCA\ndef task_func(df):\n    pca = PCA(n_components=2)\n    df_pca = pca.fit_transform(df)\n    df_pca = pd.DataFrame(df_pca, columns=['PC1', 'PC2'])\n    return df_pca", "raw_solution": "import pandas as pd\nfrom sklearn.decomposition import PCA\n\ndef task_func(df):\n    pca = PCA(n_components=2)\n    df_pca = pca.fit_transform(df)\n    df_pca = pd.DataFrame(df_pca, columns=['PC1', 'PC2'])\n    return df_pca\n```"}
{"task_id": "BigCodeBench/703", "solution": "import pandas as pd\nfrom sklearn.cluster import DBSCAN\ndef task_func(data, cols):\n    df = pd.DataFrame(data, columns=cols)\n    model = DBSCAN(eps=3, min_samples=2)\n    df['Cluster'] = model.fit_predict(df)\n    return df", "raw_solution": "import pandas as pd\nfrom sklearn.cluster import DBSCAN\n\ndef task_func(data, cols):\n    df = pd.DataFrame(data, columns=cols)\n    model = DBSCAN(eps=3, min_samples=2)\n    df['Cluster'] = model.fit_predict(df)\n    return df\n```"}
{"task_id": "BigCodeBench/704", "solution": "import pandas as pd\nfrom itertools import combinations\ndef task_func(data, cols, percentage):\n    corr_combinations = []\n    for col1, col2 in combinations(cols, 2):\n        corr = data[col1].corr(data[col2])\n        if abs(corr) > percentage:\n            corr_combinations.append((col1, col2))\n    return corr_combinations", "raw_solution": "import pandas as pd\nfrom itertools import combinations\n# Constants\nMIN_PERCENTAGE = 0.75\ndef task_func(data, cols, percentage):\n    corr_combinations = []\n    for col1, col2 in combinations(cols, 2):\n        corr = data[col1].corr(data[col2])\n        if abs(corr) > percentage:\n            corr_combinations.append((col1, col2))\n    return corr_combinations\n```"}
{"task_id": "BigCodeBench/705", "solution": "import numpy as np\nfrom scipy import stats\ndef task_func(df, column, alpha):\n    # Perform Shapiro-Wilk test\n    stat, p = stats.shapiro(df[column])\n    # Check if p-value is less than alpha\n    return p < alpha", "raw_solution": "import numpy as np\nfrom scipy import stats\ndef task_func(df, column, alpha):\n    # Perform Shapiro-Wilk test\n    stat, p = stats.shapiro(df[column])\n    # Check if p-value is less than alpha\n    return p < alpha\n```"}
{"task_id": "BigCodeBench/706", "solution": "import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\ndef task_func(data, columns, target_column):\n    # Split the data into training and testing sets\n    X_train, X_test, y_train, y_test = train_test_split(data[columns], data[target_column], test_size=0.2, random_state=42)\n    \n    # Create a logistic regression model\n    model = LogisticRegression()\n    \n    # Train the model\n    model.fit(X_train, y_train)\n    \n    # Make predictions\n    y_pred = model.predict(X_test)\n    \n    # Calculate accuracy\n    accuracy = accuracy_score(y_test, y_pred)\n    \n    return accuracy", "raw_solution": "import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\n\ndef task_func(data, columns, target_column):\n    # Split the data into training and testing sets\n    X_train, X_test, y_train, y_test = train_test_split(data[columns], data[target_column], test_size=0.2, random_state=42)\n    \n    # Create a logistic regression model\n    model = LogisticRegression()\n    \n    # Train the model\n    model.fit(X_train, y_train)\n    \n    # Make predictions\n    y_pred = model.predict(X_test)\n    \n    # Calculate accuracy\n    accuracy = accuracy_score(y_test, y_pred)\n    \n    return accuracy\n```"}
{"task_id": "BigCodeBench/707", "solution": "import json\nimport numpy as np\ndef task_func(df):\n    df['IntCol'] = np.log10(df['IntCol'])\n    with open('IntCol.json', 'w') as f:\n        json.dump(df['IntCol'].tolist(), f)\n    return df", "raw_solution": "import json\nimport numpy as np\ndef task_func(df):\n    df['IntCol'] = np.log10(df['IntCol'])\n    with open('IntCol.json', 'w') as f:\n        json.dump(df['IntCol'].tolist(), f)\n    return df\n```"}
{"task_id": "BigCodeBench/708", "solution": "import json\nimport csv\nimport os\nimport base64\ndef task_func(raw_string, filename, output_dir):\n    # Decode the base64-encoded JSON string\n    data = base64.b64decode(raw_string).decode('utf-8')\n    # Parse the JSON data\n    data = json.loads(data)\n    # Create the output directory if it doesn't exist\n    if not os.path.exists(output_dir):\n        os.makedirs(output_dir)\n    # Create the output file path\n    file_path = os.path.join(output_dir, filename)\n    # Write the data to the CSV file\n    with open(file_path, 'w', newline='') as f:\n        writer = csv.writer(f)\n        writer.writerow(data.keys())\n        writer.writerow(data.values())\n    return file_path", "raw_solution": "import json\nimport csv\nimport os\nimport base64\ndef task_func(raw_string, filename, output_dir):\n    # Decode the base64-encoded JSON string\n    data = base64.b64decode(raw_string).decode('utf-8')\n    # Parse the JSON data\n    data = json.loads(data)\n    # Create the output directory if it doesn't exist\n    if not os.path.exists(output_dir):\n        os.makedirs(output_dir)\n    # Create the output file path\n    file_path = os.path.join(output_dir, filename)\n    # Write the data to the CSV file\n    with open(file_path, 'w', newline='') as f:\n        writer = csv.writer(f)\n        writer.writerow(data.keys())\n        writer.writerow(data.values())\n    return file_path\n```"}
{"task_id": "BigCodeBench/709", "solution": "import base64\nimport re\nfrom html import unescape\nimport textwrap\ndef task_func(raw_string, line_length):\n    # Decode the raw string from base64\n    decoded_string = base64.b64decode(raw_string).decode('utf-8')\n    \n    # Decouple HTML entities\n    decoded_string = unescape(decoded_string)\n    \n    # Replace multiple spaces with a single space\n    decoded_string = re.sub(r'\\s+', ' ', decoded_string)\n    \n    # Strip leading and subsequent spaces\n    decoded_string = decoded_string.strip()\n    \n    # Wrap text to a certain line length\n    wrapped_text = textwrap.fill(decoded_string, width=line_length)\n    \n    return wrapped_text", "raw_solution": "import base64\nimport re\nfrom html import unescape\nimport textwrap\n\ndef task_func(raw_string, line_length):\n    # Decode the raw string from base64\n    decoded_string = base64.b64decode(raw_string).decode('utf-8')\n    \n    # Decouple HTML entities\n    decoded_string = unescape(decoded_string)\n    \n    # Replace multiple spaces with a single space\n    decoded_string = re.sub(r'\\s+', ' ', decoded_string)\n    \n    # Strip leading and subsequent spaces\n    decoded_string = decoded_string.strip()\n    \n    # Wrap text to a certain line length\n    wrapped_text = textwrap.fill(decoded_string, width=line_length)\n    \n    return wrapped_text\n```"}
{"task_id": "BigCodeBench/710", "solution": "import pandas as pd\nfrom sklearn.preprocessing import MinMaxScaler\ndef task_func(data_path):\n    df = pd.read_csv(data_path)\n    scaler = MinMaxScaler()\n    df = scaler.fit_transform(df)\n    return df", "raw_solution": "import pandas as pd\nfrom sklearn.preprocessing import MinMaxScaler\n\ndef task_func(data_path):\n    df = pd.read_csv(data_path)\n    scaler = MinMaxScaler()\n    df = scaler.fit_transform(df)\n    return df\n```"}
{"task_id": "BigCodeBench/711", "solution": "import json\nimport csv\ndef task_func(json_file, csv_file):\n    with open(json_file, 'r') as f:\n        data = json.load(f)\n    with open(csv_file, 'w', newline='') as f:\n        writer = csv.writer(f)\n        writer.writerow(data.keys())\n        writer.writerows(data.values())\n    return csv_file", "raw_solution": "import json\nimport csv\n\ndef task_func(json_file, csv_file):\n    with open(json_file, 'r') as f:\n        data = json.load(f)\n    with open(csv_file, 'w', newline='') as f:\n        writer = csv.writer(f)\n        writer.writerow(data.keys())\n        writer.writerows(data.values())\n    return csv_file\n```"}
{"task_id": "BigCodeBench/712", "solution": "import os\nimport shutil\nimport glob\ndef task_func(source_dir, dest_dir, extension):\n    count = 0\n    for file in glob.glob(os.path.join(source_dir, f'*.{extension}')):\n        shutil.move(file, dest_dir)\n        count += 1\n    return count", "raw_solution": "import os\nimport shutil\nimport glob\n\ndef task_func(source_dir, dest_dir, extension):\n    count = 0\n    for file in glob.glob(os.path.join(source_dir, f'*.{extension}')):\n        shutil.move(file, dest_dir)\n        count += 1\n    return count\n```"}
{"task_id": "BigCodeBench/713", "solution": "import os\nimport re\ndef task_func(log_file_path: str, keywords: list):\n    formatted_lines = []", "raw_solution": "import os\nimport re\n\ndef task_func(log_file_path: str, keywords: list):\n    formatted_lines = []\n    with open(log_file_path, 'r') as f:\n        for line in f:\n            for keyword in keywords:\n                if re.search(keyword, line):\n                    formatted_lines.append(f\"{keyword:<20}{re.search(r'\\[(.*?)\\]', line).group(1):<20}{line.strip()}\")\n    return formatted_lines\n```"}
{"task_id": "BigCodeBench/714", "solution": "import sys\nfrom pathlib import Path\nPATH_TO_APPEND = '/path/to/whatever'\ndef task_func(path_to_append=PATH_TO_APPEND):\n    # Append the path to sys.path\n    sys.path.append(path_to_append)\n    \n    # Create the directory if it does not exist\n    path = Path(path_to_append)\n    if not path.exists():\n        path.mkdir(parents=True)\n    \n    return path_to_append", "raw_solution": "import sys\nfrom pathlib import Path\n\n# Constants\nPATH_TO_APPEND = '/path/to/whatever'\n\ndef task_func(path_to_append=PATH_TO_APPEND):\n    # Append the path to sys.path\n    sys.path.append(path_to_append)\n    \n    # Create the directory if it does not exist\n    path = Path(path_to_append)\n    if not path.exists():\n        path.mkdir(parents=True)\n    \n    return path_to_append\n```"}
{"task_id": "BigCodeBench/715", "solution": "import sys\nimport subprocess\nPYTHON_VERSION = '3.8'\nPATH_TO_APPEND = '/path/to/whatever'\ndef task_func(python_version=PYTHON_VERSION, path_to_append=PATH_TO_APPEND):\n    # Switch to the specified Python version\n    subprocess.run(['python', '-m', 'pip', 'install', 'python=={}'.format(python_version)])\n    # Add the specified path to sys.path\n    sys.path.append(path_to_append)\n    # Return the Python version that was switched to\n    return python_version", "raw_solution": "import sys\nimport subprocess\n# Constants\nPYTHON_VERSION = '3.8'\nPATH_TO_APPEND = '/path/to/whatever'\ndef task_func(python_version=PYTHON_VERSION, path_to_append=PATH_TO_APPEND):\n    # Switch to the specified Python version\n    subprocess.run(['python', '-m', 'pip', 'install', 'python=={}'.format(python_version)])\n    # Add the specified path to sys.path\n    sys.path.append(path_to_append)\n    # Return the Python version that was switched to\n    return python_version\n```"}
{"task_id": "BigCodeBench/716", "solution": "import sys\nimport json\nfrom datetime import datetime\nPATH_TO_APPEND = '/path/to/whatever'\nJSON_FILE = '/path/to/json_file.json'\ndef task_func(path_to_append=PATH_TO_APPEND, json_file=JSON_FILE):\n    # Append the given path to Python's sys.path\n    sys.path.append(path_to_append)\n    \n    # Update the JSON file with the current date and time\n    with open(json_file, 'r') as f:\n        json_data = json.load(f)\n    json_data['last_updated'] = datetime.now().isoformat()\n    with open(json_file, 'w') as f:\n        json.dump(json_data, f)\n    \n    return json_data", "raw_solution": "import sys\nimport json\nfrom datetime import datetime\n\n# Constants\nPATH_TO_APPEND = '/path/to/whatever'\nJSON_FILE = '/path/to/json_file.json'\n\ndef task_func(path_to_append=PATH_TO_APPEND, json_file=JSON_FILE):\n    # Append the given path to Python's sys.path\n    sys.path.append(path_to_append)\n    \n    # Update the JSON file with the current date and time\n    with open(json_file, 'r') as f:\n        json_data = json.load(f)\n    json_data['last_updated'] = datetime.now().isoformat()\n    with open(json_file, 'w') as f:\n        json.dump(json_data, f)\n    \n    return json_data\n```"}
{"task_id": "BigCodeBench/717", "solution": "import sys\nfrom configparser import ConfigParser\nPATH_TO_APPEND = '/path/to/whatever'\nCONFIG_FILE = '/path/to/config.ini'\ndef task_func(path_to_append=PATH_TO_APPEND, config_file=CONFIG_FILE):\n    # Add the path to sys.path\n    sys.path.append(path_to_append)\n    \n    # Create a ConfigParser object\n    config = ConfigParser()\n    \n    # Read the configuration file\n    config.read(config_file)\n    \n    # Update the configuration\n    config['DEFAULT']['new_key'] = 'new_value'\n    \n    # Write the updated configuration back to the file\n    with open(config_file, 'w') as configfile:\n        config.write(configfile)\n    \n    # Return the updated configuration and the path to the configuration file\n    return config, config_file", "raw_solution": "import sys\nfrom configparser import ConfigParser\n\n# Constants\nPATH_TO_APPEND = '/path/to/whatever'\nCONFIG_FILE = '/path/to/config.ini'\n\ndef task_func(path_to_append=PATH_TO_APPEND, config_file=CONFIG_FILE):\n    # Add the path to sys.path\n    sys.path.append(path_to_append)\n    \n    # Create a ConfigParser object\n    config = ConfigParser()\n    \n    # Read the configuration file\n    config.read(config_file)\n    \n    # Update the configuration\n    config['DEFAULT']['new_key'] = 'new_value'\n    \n    # Write the updated configuration back to the file\n    with open(config_file, 'w') as configfile:\n        config.write(configfile)\n    \n    # Return the updated configuration and the path to the configuration file\n    return config, config_file\n```"}
{"task_id": "BigCodeBench/718", "solution": "import re\nimport numpy as np\nfrom scipy.stats import ttest_rel\ndef task_func(text1, text2):\n    # Remove non-alphanumeric characters and convert to lowercase\n    text1 = re.sub(r'[^a-zA-Z0-9\\s]', '', text1).lower()\n    text2 = re.sub(r'[^a-zA-Z0-9\\s]', '', text2).lower()\n    \n    # Split text into words\n    words1 = text1.split()\n    words2 = text2.split()\n    \n    # Check if the number of words is the same\n    if len(words1) != len(words2):\n        return np.nan, np.nan\n    \n    # Perform paired t-test\n    t_statistic, p_value = ttest_rel(words1, words2)\n    \n    return t_statistic, p_value", "raw_solution": "import re\nimport numpy as np\nfrom scipy.stats import ttest_rel\n\ndef task_func(text1, text2):\n    # Remove non-alphanumeric characters and convert to lowercase\n    text1 = re.sub(r'[^a-zA-Z0-9\\s]', '', text1).lower()\n    text2 = re.sub(r'[^a-zA-Z0-9\\s]', '', text2).lower()\n    \n    # Split text into words\n    words1 = text1.split()\n    words2 = text2.split()\n    \n    # Check if the number of words is the same\n    if len(words1) != len(words2):\n        return np.nan, np.nan\n    \n    # Perform paired t-test\n    t_statistic, p_value = ttest_rel(words1, words2)\n    \n    return t_statistic, p_value\n```"}
{"task_id": "BigCodeBench/719", "solution": "import re\nimport os\nimport glob\ndef task_func(directory, word):\n    count = 0\n    for file in glob.glob(os.path.join(directory, '**/*'), recursive=True):\n        if re.search(word, open(file, 'r').read()):\n            count += 1\n    return count", "raw_solution": "import re\nimport os\nimport glob\n\ndef task_func(directory, word):\n    count = 0\n    for file in glob.glob(os.path.join(directory, '**/*'), recursive=True):\n        if re.search(word, open(file, 'r').read()):\n            count += 1\n    return count\n```"}
{"task_id": "BigCodeBench/720", "solution": "import os\nimport csv\nimport random\nfrom datetime import datetime\ndef task_func():\n    # Create a CSV file\n    file_path = \"task_func_data/Output.txt\"\n    with open(file_path, \"w\") as file:\n        writer = csv.writer(file)\n        writer.writerow([\"Temperature\", \"Humidity\"])\n        for i in range(100):\n            temperature = random.uniform(20, 30)\n            humidity = random.uniform(40, 60)\n            writer.writerow([temperature, humidity])\n    # Return the path to the CSV file before deletion\n    return file_path", "raw_solution": "import os\nimport csv\nimport random\nfrom datetime import datetime\n\ndef task_func():\n    # Create a CSV file\n    file_path = \"task_func_data/Output.txt\"\n    with open(file_path, \"w\") as file:\n        writer = csv.writer(file)\n        writer.writerow([\"Temperature\", \"Humidity\"])\n        for i in range(100):\n            temperature = random.uniform(20, 30)\n            humidity = random.uniform(40, 60)\n            writer.writerow([temperature, humidity])\n    # Return the path to the CSV file before deletion\n    return file_path\n```"}
{"task_id": "BigCodeBench/721", "solution": "import os\nimport csv\nfrom collections import Counter\ndef task_func(file_path):\n    if not os.path.exists(file_path):\n        return None\n    with open(file_path, 'r') as f:\n        reader = csv.reader(f)\n        words = [word.lower() for row in reader for word in row if word]\n        word_counts = Counter(words)\n        most_common_word = word_counts.most_common(1)[0]\n        return most_common_word", "raw_solution": "import os\nimport csv\nfrom collections import Counter\n\ndef task_func(file_path):\n    if not os.path.exists(file_path):\n        return None\n    with open(file_path, 'r') as f:\n        reader = csv.reader(f)\n        words = [word.lower() for row in reader for word in row if word]\n        word_counts = Counter(words)\n        most_common_word = word_counts.most_common(1)[0]\n        return most_common_word\n```"}
{"task_id": "BigCodeBench/722", "solution": "import urllib.request\nimport os\nimport re\nTARGET_FILE = 'downloaded_file.txt'\nSEARCH_PATTERN = r'\\bERROR\\b'\ndef task_func(url):\n    # Download the file\n    urllib.request.urlretrieve(url, TARGET_FILE)\n    # Open the file and search for occurrences of the word 'ERROR'\n    with open(TARGET_FILE, 'r') as f:\n        text = f.read()\n        occurrences = len(re.findall(SEARCH_PATTERN, text))\n    # Return the number of occurrences\n    return occurrences", "raw_solution": "import urllib.request\nimport os\nimport re\n# Constants\nTARGET_FILE = 'downloaded_file.txt'\nSEARCH_PATTERN = r'\\bERROR\\b'\ndef task_func(url):\n    # Download the file\n    urllib.request.urlretrieve(url, TARGET_FILE)\n    # Open the file and search for occurrences of the word 'ERROR'\n    with open(TARGET_FILE, 'r') as f:\n        text = f.read()\n        occurrences = len(re.findall(SEARCH_PATTERN, text))\n    # Return the number of occurrences\n    return occurrences\n```"}
{"task_id": "BigCodeBench/723", "solution": "import urllib.request\nfrom bs4 import BeautifulSoup\nimport csv\nimport os\nCSV_FILE_PATH = 'scraped_data.csv'\ndef task_func(url):\n    # Open the URL and read the HTML content\n    with urllib.request.urlopen(url) as response:\n        html_content = response.read()\n    # Parse the HTML content using BeautifulSoup\n    soup = BeautifulSoup(html_content, 'html.parser')\n    # Find all the data you want to scrape\n    data = []\n    for item in soup.find_all('div', class_='item'):\n        data.append({\n            'title': item.find('h2').text,\n            'description': item.find('p').text\n        })\n    # Write the scraped data to a CSV file\n    with open(CSV_FILE_PATH, 'w', newline='') as file:\n        writer = csv.DictWriter(file, fieldnames=['title', 'description'])\n        writer.writeheader()\n        writer.writerows(data)\n    return CSV_FILE_PATH", "raw_solution": "import urllib.request\nfrom bs4 import BeautifulSoup\nimport csv\nimport os\n# Constants\nCSV_FILE_PATH = 'scraped_data.csv'\ndef task_func(url):\n    # Open the URL and read the HTML content\n    with urllib.request.urlopen(url) as response:\n        html_content = response.read()\n    # Parse the HTML content using BeautifulSoup\n    soup = BeautifulSoup(html_content, 'html.parser')\n    # Find all the data you want to scrape\n    data = []\n    for item in soup.find_all('div', class_='item'):\n        data.append({\n            'title': item.find('h2').text,\n            'description': item.find('p').text\n        })\n    # Write the scraped data to a CSV file\n    with open(CSV_FILE_PATH, 'w', newline='') as file:\n        writer = csv.DictWriter(file, fieldnames=['title', 'description'])\n        writer.writeheader()\n        writer.writerows(data)\n    return CSV_FILE_PATH\n```"}
{"task_id": "BigCodeBench/724", "solution": "import os\nimport json\ndef task_func(config_path: str) -> dict:\n    if not os.path.exists(config_path):\n        raise FileNotFoundError(\"Configuration file does not exist\")\n    with open(config_path, 'r') as f:\n        config = json.load(f)\n    return config", "raw_solution": "import os\nimport json\n\ndef task_func(config_path: str) -> dict:\n    if not os.path.exists(config_path):\n        raise FileNotFoundError(\"Configuration file does not exist\")\n    with open(config_path, 'r') as f:\n        config = json.load(f)\n    return config\n```"}
{"task_id": "BigCodeBench/725", "solution": "import codecs\nimport os\nimport glob\nDIRECTORY_PATH = './files/'\ndef task_func(directory=DIRECTORY_PATH, from_encoding='cp1251', to_encoding='utf8'):\n    # Iterate over all files in the directory\n    for file_path in glob.glob(os.path.join(directory, '*')):\n        # Check if the file is a text file\n        if file_path.endswith('.txt'):\n            # Open the file in read mode with the original encoding\n            with codecs.open(file_path, 'r', from_encoding) as f:\n                # Read the file content\n                content = f.read()\n            # Open the file in write mode with the new encoding\n            with codecs.open(file_path, 'w', to_encoding) as f:\n                # Write the file content\n                f.write(content)", "raw_solution": "import codecs\nimport os\nimport glob\n# Constants\nDIRECTORY_PATH = './files/'\ndef task_func(directory=DIRECTORY_PATH, from_encoding='cp1251', to_encoding='utf8'):\n    # Iterate over all files in the directory\n    for file_path in glob.glob(os.path.join(directory, '*')):\n        # Check if the file is a text file\n        if file_path.endswith('.txt'):\n            # Open the file in read mode with the original encoding\n            with codecs.open(file_path, 'r', from_encoding) as f:\n                # Read the file content\n                content = f.read()\n            # Open the file in write mode with the new encoding\n            with codecs.open(file_path, 'w', to_encoding) as f:\n                # Write the file content\n                f.write(content)\n```"}
{"task_id": "BigCodeBench/726", "solution": "import re\nimport random\nfrom nltk.corpus import words\nfrom random import sample\nimport nltk\nSAMPLE_ENGLISH_WORDS = set(words.words())\ndef task_func(s, n):\n    # Split the string into words\n    words = re.findall(r'\\b\\w+\\b', s.lower())\n    # Filter out non-English words\n    english_words = [word for word in words if word in SAMPLE_ENGLISH_WORDS]\n    # Return up to n different English words\n    return sample(english_words, min(n, len(english_words)))", "raw_solution": "import re\nimport random\nfrom nltk.corpus import words\nfrom random import sample\n# Ensure the words corpus is downloaded\nimport nltk\nnltk.download('words')\n# Constants\nSAMPLE_ENGLISH_WORDS = set(words.words())  # Correct initialization\ndef task_func(s, n):\n    # Split the string into words\n    words = re.findall(r'\\b\\w+\\b', s.lower())\n    # Filter out non-English words\n    english_words = [word for word in words if word in SAMPLE_ENGLISH_WORDS]\n    # Return up to n different English words\n    return sample(english_words, min(n, len(english_words)))\n```"}
{"task_id": "BigCodeBench/727", "solution": "import re\nfrom sklearn.feature_extraction.text import CountVectorizer\nimport numpy as np\ndef task_func(s: str) -> np.ndarray:\n    # Split the string into words\n    words = re.findall(r'\\b\\w+\\b', s)\n    # Create a CountVectorizer object\n    vectorizer = CountVectorizer()\n    # Fit the vectorizer to the words\n    vectorizer.fit(words)\n    # Transform the words into a matrix\n    X = vectorizer.transform(words)\n    # Return the matrix as a numpy array\n    return X.toarray()", "raw_solution": "import re\nfrom sklearn.feature_extraction.text import CountVectorizer\nimport numpy as np\n# Constants\nSENTENCES = ['This is a sentence', 'Another sentence here', 'More sentences']\ndef task_func(s: str) -> np.ndarray:\n    # Split the string into words\n    words = re.findall(r'\\b\\w+\\b', s)\n    # Create a CountVectorizer object\n    vectorizer = CountVectorizer()\n    # Fit the vectorizer to the words\n    vectorizer.fit(words)\n    # Transform the words into a matrix\n    X = vectorizer.transform(words)\n    # Return the matrix as a numpy array\n    return X.toarray()\n```"}
{"task_id": "BigCodeBench/728", "solution": "import csv\nimport io\ndef task_func(filename='sample.csv', from_encoding='cp1251', to_encoding='utf8', delimiter=','):\n    with open(filename, 'r', encoding=from_encoding) as f:\n        reader = csv.DictReader(f, delimiter=delimiter)\n        data = list(reader)\n    with io.StringIO() as f:\n        writer = csv.DictWriter(f, fieldnames=data[0].keys(), delimiter=delimiter)\n        writer.writeheader()\n        writer.writerows(data)\n        converted_data = f.getvalue()\n    return (data, converted_data)", "raw_solution": "import csv\nimport io\ndef task_func(filename='sample.csv', from_encoding='cp1251', to_encoding='utf8', delimiter=','):\n    with open(filename, 'r', encoding=from_encoding) as f:\n        reader = csv.DictReader(f, delimiter=delimiter)\n        data = list(reader)\n    with io.StringIO() as f:\n        writer = csv.DictWriter(f, fieldnames=data[0].keys(), delimiter=delimiter)\n        writer.writeheader()\n        writer.writerows(data)\n        converted_data = f.getvalue()\n    return (data, converted_data)\n```"}
{"task_id": "BigCodeBench/729", "solution": "import pickle\nimport os\nimport random\nimport string\ndef task_func(strings, filename=None):\n    if filename is None:\n        filename = ''.join(random.choices(string.ascii_letters + string.digits, k=10))\n    with open(filename, 'wb') as f:\n        pickle.dump(strings, f)\n    with open(filename, 'rb') as f:\n        loaded_strings = pickle.load(f)\n    return loaded_strings", "raw_solution": "import pickle\nimport os\nimport random\nimport string\n\ndef task_func(strings, filename=None):\n    if filename is None:\n        filename = ''.join(random.choices(string.ascii_letters + string.digits, k=10))\n    with open(filename, 'wb') as f:\n        pickle.dump(strings, f)\n    with open(filename, 'rb') as f:\n        loaded_strings = pickle.load(f)\n    return loaded_strings\n```"}
{"task_id": "BigCodeBench/730", "solution": "import pickle\nimport os\nFILE_NAME = 'save.pkl'\ndef task_func(dt):\n    # Save the datetime object \"dt\" in the pickle file \"save.pkl\"\n    with open(FILE_NAME, 'wb') as f:\n        pickle.dump(dt, f)\n    # Read the datetime object back for validation\n    with open(FILE_NAME, 'rb') as f:\n        loaded_dt = pickle.load(f)\n    return loaded_dt", "raw_solution": "import pickle\nimport os\n# Constants\nFILE_NAME = 'save.pkl'\ndef task_func(dt):\n    # Save the datetime object \"dt\" in the pickle file \"save.pkl\"\n    with open(FILE_NAME, 'wb') as f:\n        pickle.dump(dt, f)\n    # Read the datetime object back for validation\n    with open(FILE_NAME, 'rb') as f:\n        loaded_dt = pickle.load(f)\n    return loaded_dt\n```"}
{"task_id": "BigCodeBench/731", "solution": "import pickle\nimport os\nfrom sklearn.datasets import make_classification\nFILE_NAME = 'save.pkl'\ndef task_func(data, target):\n    # Save the data and target to a pickle file\n    with open(FILE_NAME, 'wb') as f:\n        pickle.dump((data, target), f)\n    # Read the data and target from the pickle file\n    with open(FILE_NAME, 'rb') as f:\n        loaded_data, loaded_target = pickle.load(f)\n    return (loaded_data, loaded_target)", "raw_solution": "import pickle\nimport os\nfrom sklearn.datasets import make_classification\n# Constants\nFILE_NAME = 'save.pkl'\nDATA, TARGET = make_classification(n_samples=100, n_features=20, n_informative=2, n_redundant=10, n_classes=2, random_state=1)\ndef task_func(data, target):\n    # Save the data and target to a pickle file\n    with open(FILE_NAME, 'wb') as f:\n        pickle.dump((data, target), f)\n    # Read the data and target from the pickle file\n    with open(FILE_NAME, 'rb') as f:\n        loaded_data, loaded_target = pickle.load(f)\n    return (loaded_data, loaded_target)\n```"}
{"task_id": "BigCodeBench/732", "solution": "import re\nimport string\nfrom nltk.stem import PorterStemmer\nfrom collections import Counter\nSTEMMER = PorterStemmer()\ndef task_func(content):\n    # Remove punctuation and convert to lowercase\n    content = re.sub(r'[^\\w\\s]', '', content.lower())\n    # Split the sentence into words\n    words = content.split()\n    # Stem every word except the last\n    stems = [STEMMER.stem(word) for word in words[:-1]]\n    # Count the frequency of each stem\n    stem_counts = Counter(stems)\n    return stem_counts", "raw_solution": "import re\nimport string\nfrom nltk.stem import PorterStemmer\nfrom collections import Counter\nSTEMMER = PorterStemmer()\ndef task_func(content):\n    # Remove punctuation and convert to lowercase\n    content = re.sub(r'[^\\w\\s]', '', content.lower())\n    # Split the sentence into words\n    words = content.split()\n    # Stem every word except the last\n    stems = [STEMMER.stem(word) for word in words[:-1]]\n    # Count the frequency of each stem\n    stem_counts = Counter(stems)\n    return stem_counts\n```"}
{"task_id": "BigCodeBench/733", "solution": "import re\nimport string\ndef task_func(content):\n    # Remove punctuation and convert to lowercase\n    content = re.sub(r'[^\\w\\s]', '', content.lower())\n    # Split the sentence into words\n    words = content.split()\n    # Remove the last word\n    words = words[:-1]\n    # Count the remaining words\n    count = len(words)\n    return count", "raw_solution": "import re\nimport string\ndef task_func(content):\n    # Remove punctuation and convert to lowercase\n    content = re.sub(r'[^\\w\\s]', '', content.lower())\n    # Split the sentence into words\n    words = content.split()\n    # Remove the last word\n    words = words[:-1]\n    # Count the remaining words\n    count = len(words)\n    return count\n```"}
{"task_id": "BigCodeBench/734", "solution": "import nltk\nfrom collections import Counter\ndef task_func(content):\n    # Tokenize the sentence\n    tokens = nltk.word_tokenize(content)\n    # Remove the last word\n    tokens = tokens[:-1]\n    # Tag the remaining words with POS\n    tagged = nltk.pos_tag(tokens)\n    # Count the POS tags\n    pos_counts = Counter(tag for word, tag in tagged)\n    return dict(pos_counts)", "raw_solution": "import nltk\n# Download necessary NLTK data (if not already present)\nnltk.download('punkt')\nnltk.download('averaged_perceptron_tagger')\nfrom collections import Counter\n\ndef task_func(content):\n    # Tokenize the sentence\n    tokens = nltk.word_tokenize(content)\n    # Remove the last word\n    tokens = tokens[:-1]\n    # Tag the remaining words with POS\n    tagged = nltk.pos_tag(tokens)\n    # Count the POS tags\n    pos_counts = Counter(tag for word, tag in tagged)\n    return dict(pos_counts)\n```"}
{"task_id": "BigCodeBench/735", "solution": "import numpy as np\nfrom itertools import chain\ndef task_func(L):\n    # Flatten the nested list\n    flat_list = list(chain.from_iterable(L))\n    # Calculate the mean and variance\n    mean = np.mean(flat_list)\n    variance = np.var(flat_list)\n    # Return the result as a dictionary\n    return {'mean': mean, 'variance': variance}", "raw_solution": "import numpy as np\nfrom itertools import chain\n\ndef task_func(L):\n    # Flatten the nested list\n    flat_list = list(chain.from_iterable(L))\n    # Calculate the mean and variance\n    mean = np.mean(flat_list)\n    variance = np.var(flat_list)\n    # Return the result as a dictionary\n    return {'mean': mean, 'variance': variance}\n```"}
{"task_id": "BigCodeBench/736", "solution": "import numpy as np\nfrom scipy import stats\ndef task_func(L):\n    # Flatten the nested list\n    flat_list = [item for sublist in L for item in sublist]\n    # Calculate the mode\n    mode = stats.mode(flat_list)[0][0]\n    return mode", "raw_solution": "import numpy as np\nfrom scipy import stats\n\ndef task_func(L):\n    # Flatten the nested list\n    flat_list = [item for sublist in L for item in sublist]\n    # Calculate the mode\n    mode = stats.mode(flat_list)[0][0]\n    return mode\n```"}
{"task_id": "BigCodeBench/737", "solution": "import numpy as np\nimport math\ndef task_func(L):\n    # Flatten the nested list\n    flat_list = [item for sublist in L for item in sublist]\n    # Sort the list\n    flat_list.sort()\n    # Calculate the median\n    n = len(flat_list)\n    if n % 2 == 0:\n        median = (flat_list[n//2-1] + flat_list[n//2]) / 2\n    else:\n        median = flat_list[n//2]\n    return median", "raw_solution": "import numpy as np\nimport math\ndef task_func(L):\n    # Flatten the nested list\n    flat_list = [item for sublist in L for item in sublist]\n    # Sort the list\n    flat_list.sort()\n    # Calculate the median\n    n = len(flat_list)\n    if n % 2 == 0:\n        median = (flat_list[n//2-1] + flat_list[n//2]) / 2\n    else:\n        median = flat_list[n//2]\n    return median\n```"}
{"task_id": "BigCodeBench/738", "solution": "import numpy as np\nfrom scipy.stats import iqr\ndef task_func(L):\n    # Flatten the nested list\n    flat_list = [item for sublist in L for item in sublist]\n    # Calculate the interquartile range\n    iqr_value = iqr(flat_list)\n    return iqr_value", "raw_solution": "import numpy as np\nfrom scipy.stats import iqr\n\ndef task_func(L):\n    # Flatten the nested list\n    flat_list = [item for sublist in L for item in sublist]\n    # Calculate the interquartile range\n    iqr_value = iqr(flat_list)\n    return iqr_value\n```"}
{"task_id": "BigCodeBench/739", "solution": "import struct\nimport random\nKEYS = ['470FC614', '4A0FC614', '4B9FC614', '4C8FC614', '4D7FC614']\ndef task_func(hex_key=None):\n    if hex_key is None:\n        hex_key = random.choice(KEYS)\n    # Convert hex key to float\n    float_num = struct.unpack('!f', bytes.fromhex(hex_key))[0]\n    # Round float number to 2 decimal places\n    rounded_float = round(float_num, 2)\n    return rounded_float", "raw_solution": "import struct\nimport random\n# Constants\nKEYS = ['470FC614', '4A0FC614', '4B9FC614', '4C8FC614', '4D7FC614']\ndef task_func(hex_key=None):\n    if hex_key is None:\n        hex_key = random.choice(KEYS)\n    # Convert hex key to float\n    float_num = struct.unpack('!f', bytes.fromhex(hex_key))[0]\n    # Round float number to 2 decimal places\n    rounded_float = round(float_num, 2)\n    return rounded_float\n```"}
{"task_id": "BigCodeBench/740", "solution": "from collections import Counter\nimport heapq\ndef task_func(my_dict):\n    # Count the frequency of each letter in the dictionary\n    letter_counts = Counter(my_dict.values())\n    # Find the 3 most common letters\n    most_common_letters = heapq.nlargest(3, letter_counts, key=letter_counts.get)\n    return most_common_letters", "raw_solution": "from collections import Counter\nimport heapq\n# Constants\nLETTERS = list('abcdefghijklmnopqrstuvwxyz')\ndef task_func(my_dict):\n    # Count the frequency of each letter in the dictionary\n    letter_counts = Counter(my_dict.values())\n    # Find the 3 most common letters\n    most_common_letters = heapq.nlargest(3, letter_counts, key=letter_counts.get)\n    return most_common_letters\n```"}
{"task_id": "BigCodeBench/741", "solution": "from itertools import groupby\nfrom operator import itemgetter\nKEY_FUNC = itemgetter(0)\ndef task_func(my_dict):\n    aggregated_dict = {}\n    for key, group in groupby(sorted(my_dict.items(), key=KEY_FUNC), key=KEY_FUNC):\n        aggregated_dict[key] = [value for key, value in group]\n    return aggregated_dict", "raw_solution": "from itertools import groupby\nfrom operator import itemgetter\n# Constants\nKEY_FUNC = itemgetter(0)\ndef task_func(my_dict):\n    aggregated_dict = {}\n    for key, group in groupby(sorted(my_dict.items(), key=KEY_FUNC), key=KEY_FUNC):\n        aggregated_dict[key] = [value for key, value in group]\n    return aggregated_dict\n```"}
{"task_id": "BigCodeBench/742", "solution": "import pandas as pd\nfrom sklearn.preprocessing import MinMaxScaler\ndef task_func(list_of_pairs):\n    if not list_of_pairs:\n        raise Exception(\"Exception: If the input array is empty.\")\n    if not all(isinstance(x, (int, float)) for x in list_of_pairs):\n        raise ValueError(\"ValueError: If Values are not numeric.\")\n    df = pd.DataFrame(list_of_pairs, columns=['Category', 'Value'])\n    scaler = MinMaxScaler()\n    df['Value'] = scaler.fit_transform(df[['Value']])\n    return df", "raw_solution": "import pandas as pd\nfrom sklearn.preprocessing import MinMaxScaler\n\ndef task_func(list_of_pairs):\n    if not list_of_pairs:\n        raise Exception(\"Exception: If the input array is empty.\")\n    if not all(isinstance(x, (int, float)) for x in list_of_pairs):\n        raise ValueError(\"ValueError: If Values are not numeric.\")\n    df = pd.DataFrame(list_of_pairs, columns=['Category', 'Value'])\n    scaler = MinMaxScaler()\n    df['Value'] = scaler.fit_transform(df[['Value']])\n    return df\n```"}
{"task_id": "BigCodeBench/743", "solution": "import json\nimport os\nPREFIXES = [\"is_\", \"has_\", \"can_\", \"should_\"]\ndef task_func(directory):\n    # Initialize a dictionary to store the count of each prefix\n    prefix_counts = {prefix: 0 for prefix in PREFIXES}\n    # Iterate over all files in the directory\n    for filename in os.listdir(directory):\n        # Check if the file is a JSON file\n        if filename.endswith('.json'):\n            # Open the JSON file\n            with open(os.path.join(directory, filename), 'r') as f:\n                # Load the JSON data\n                data = json.load(f)\n                # Iterate over all keys in the JSON data\n                for key in data.keys():\n                    # Check if the key starts with any of the prefixes\n                    for prefix in PREFIXES:\n                        if key.startswith(prefix):\n                            # Increment the count for the prefix\n                            prefix_counts[prefix] += 1\n    # Return the dictionary of statistics\n    return prefix_counts", "raw_solution": "import json\nimport os\n# Constants\nPREFIXES = [\"is_\", \"has_\", \"can_\", \"should_\"]\ndef task_func(directory):\n    # Initialize a dictionary to store the count of each prefix\n    prefix_counts = {prefix: 0 for prefix in PREFIXES}\n    # Iterate over all files in the directory\n    for filename in os.listdir(directory):\n        # Check if the file is a JSON file\n        if filename.endswith('.json'):\n            # Open the JSON file\n            with open(os.path.join(directory, filename), 'r') as f:\n                # Load the JSON data\n                data = json.load(f)\n                # Iterate over all keys in the JSON data\n                for key in data.keys():\n                    # Check if the key starts with any of the prefixes\n                    for prefix in PREFIXES:\n                        if key.startswith(prefix):\n                            # Increment the count for the prefix\n                            prefix_counts[prefix] += 1\n    # Return the dictionary of statistics\n    return prefix_counts\n```"}
{"task_id": "BigCodeBench/744", "solution": "import nltk\nfrom string import punctuation\nimport pandas as pd\ndef task_func(text):\n    if not isinstance(text, str):\n        raise ValueError(\"text is not a string\")\n    words = nltk.word_tokenize(text)\n    words = [word for word in words if word[0] == '$']\n    words = [word for word in words if word not in punctuation]\n    word_freq = nltk.FreqDist(words)\n    df = pd.DataFrame({\"Word\": word_freq.keys(), \"Frequency\": word_freq.values()})\n    return df", "raw_solution": "import nltk\nfrom string import punctuation\nimport pandas as pd\n\ndef task_func(text):\n    if not isinstance(text, str):\n        raise ValueError(\"text is not a string\")\n    words = nltk.word_tokenize(text)\n    words = [word for word in words if word[0] == '$']\n    words = [word for word in words if word not in punctuation]\n    word_freq = nltk.FreqDist(words)\n    df = pd.DataFrame({\"Word\": word_freq.keys(), \"Frequency\": word_freq.values()})\n    return df\n```"}
{"task_id": "BigCodeBench/745", "solution": "import subprocess\nimport random\nSCRIPTS = ['script1.sh', 'script2.sh', 'script3.sh']\nSCRIPTS_DIR = '/path/to/scripts'\ndef task_func():\n    # Randomly select a script from the list\n    script = random.choice(SCRIPTS)\n    # Construct the full path to the script\n    script_path = f\"{SCRIPTS_DIR}/{script}\"\n    # Execute the script\n    subprocess.run(['bash', script_path])\n    # Return the full path of the script that was executed\n    return script_path", "raw_solution": "import subprocess\nimport random\n# Constants\nSCRIPTS = ['script1.sh', 'script2.sh', 'script3.sh']\nSCRIPTS_DIR = '/path/to/scripts'  \n\ndef task_func():\n    # Randomly select a script from the list\n    script = random.choice(SCRIPTS)\n    # Construct the full path to the script\n    script_path = f\"{SCRIPTS_DIR}/{script}\"\n    # Execute the script\n    subprocess.run(['bash', script_path])\n    # Return the full path of the script that was executed\n    return script_path\n```"}
{"task_id": "BigCodeBench/746", "solution": "import numpy as np\nimport pandas as pd\nfrom sklearn.linear_model import LinearRegression\ndef task_func(df, target_column, target_values=None):\n    if not isinstance(df, pd.DataFrame):\n        raise ValueError(\"If df is not a DataFrame or if target_column is not a string or if target_values is not an array-like object\")\n    if not isinstance(target_column, str):\n        raise ValueError(\"If df is not a DataFrame or if target_column is not a string or if target_values is not an array-like object\")\n    if not isinstance(target_values, np.ndarray):\n        raise ValueError(\"If df is not a DataFrame or if target_column is not a string or if target_values is not an array-like object\")\n    df = df.dropna(subset=[target_column])\n    df[target_column] = df[target_column].astype(int)\n    df = df[df[target_column].isin(target_values)]\n    df = df.fillna(0)\n    X = df.drop(columns=[target_column])\n    y = df[target_column]\n    model = LinearRegression()\n    model.fit(X, y)\n    return model", "raw_solution": "import numpy as np\nimport pandas as pd\nfrom sklearn.linear_model import LinearRegression\n\ndef task_func(df, target_column, target_values=None):\n    if not isinstance(df, pd.DataFrame):\n        raise ValueError(\"If df is not a DataFrame or if target_column is not a string or if target_values is not an array-like object\")\n    if not isinstance(target_column, str):\n        raise ValueError(\"If df is not a DataFrame or if target_column is not a string or if target_values is not an array-like object\")\n    if not isinstance(target_values, np.ndarray):\n        raise ValueError(\"If df is not a DataFrame or if target_column is not a string or if target_values is not an array-like object\")\n    df = df.dropna(subset=[target_column])\n    df[target_column] = df[target_column].astype(int)\n    df = df[df[target_column].isin(target_values)]\n    df = df.fillna(0)\n    X = df.drop(columns=[target_column])\n    y = df[target_column]\n    model = LinearRegression()\n    model.fit(X, y)\n    return model\n```"}
{"task_id": "BigCodeBench/747", "solution": "import re\nimport math\ndef task_func(s):\n    count = 0\n    sqrt_sum = 0\n    for item in re.findall(r'[-+]?\\d*\\.?\\d+', s):\n        if '.' in item:\n            sqrt_sum += math.sqrt(float(item))\n        else:\n            sqrt_sum += math.sqrt(int(item))\n        count += 1\n    return count, sqrt_sum", "raw_solution": "import re\nimport math\ndef task_func(s):\n    count = 0\n    sqrt_sum = 0\n    for item in re.findall(r'[-+]?\\d*\\.?\\d+', s):\n        if '.' in item:\n            sqrt_sum += math.sqrt(float(item))\n        else:\n            sqrt_sum += math.sqrt(int(item))\n        count += 1\n    return count, sqrt_sum\n```"}
{"task_id": "BigCodeBench/748", "solution": "import pandas as pd\nfrom sklearn.preprocessing import StandardScaler\ndef task_func(df, age, weight):\n    if 'Age' not in df.columns or 'Weight' not in df.columns:\n        raise KeyError(\"The input DataFrame does not contain the required columns 'Age' and 'Weight'\")\n    df = df[(df['Age'] < age) & (df['Weight'] > weight)]\n    scaler = StandardScaler()\n    df = scaler.fit_transform(df)\n    return pd.DataFrame(df, columns=df.columns)", "raw_solution": "import pandas as pd\nfrom sklearn.preprocessing import StandardScaler\n\ndef task_func(df, age, weight):\n    if 'Age' not in df.columns or 'Weight' not in df.columns:\n        raise KeyError(\"The input DataFrame does not contain the required columns 'Age' and 'Weight'\")\n    df = df[(df['Age'] < age) & (df['Weight'] > weight)]\n    scaler = StandardScaler()\n    df = scaler.fit_transform(df)\n    return pd.DataFrame(df, columns=df.columns)\n```"}
{"task_id": "BigCodeBench/749", "solution": "from sklearn.preprocessing import MinMaxScaler\nimport numpy as np\ndef task_func(myList):\n    scaler = MinMaxScaler()\n    return scaler.fit_transform(myList.reshape(-1, 1)).flatten()", "raw_solution": "from sklearn.preprocessing import MinMaxScaler\nimport numpy as np\n\ndef task_func(myList):\n    scaler = MinMaxScaler()\n    return scaler.fit_transform(myList.reshape(-1, 1)).flatten()\n```"}
{"task_id": "BigCodeBench/750", "solution": "import pandas as pd\nimport statsmodels.api as sm\ndef task_func(df: pd.DataFrame, height: int, weight: int, columns: list) -> sm.regression.linear_model.RegressionResultsWrapper:\n    if df.empty:\n        return None\n    df = df[(df[columns[1]] > height) & (df[columns[2]] < weight)]\n    if df.empty:\n        return None\n    X = df[columns[1:]]\n    y = df[columns[0]]\n    X = sm.add_constant(X)\n    model = sm.OLS(y, X)\n    results = model.fit()\n    return results", "raw_solution": "import pandas as pd\nimport statsmodels.api as sm\n\ndef task_func(df: pd.DataFrame, height: int, weight: int, columns: list) -> sm.regression.linear_model.RegressionResultsWrapper:\n    if df.empty:\n        return None\n    df = df[(df[columns[1]] > height) & (df[columns[2]] < weight)]\n    if df.empty:\n        return None\n    X = df[columns[1:]]\n    y = df[columns[0]]\n    X = sm.add_constant(X)\n    model = sm.OLS(y, X)\n    results = model.fit()\n    return results\n```"}
{"task_id": "BigCodeBench/751", "solution": "import random\nfrom collections import Counter\ndef task_func(values, weights, n_samples):\n    # Check if the input lists are of the same length\n    if len(values) != len(weights):\n        raise ValueError(\"The input lists must be of the same length\")\n    \n    # Check if the input lists are non-empty\n    if len(values) == 0 or len(weights) == 0:\n        raise ValueError(\"The input lists must not be empty\")\n    \n    # Check if the input lists are valid\n    if not all(isinstance(x, (int, float)) for x in values):\n        raise ValueError(\"The input lists must contain only numeric values\")\n    if not all(isinstance(x, (int, float)) for x in weights):\n        raise ValueError(\"The input lists must contain only numeric values\")\n    if not all(x > 0 for x in weights):\n        raise ValueError(\"The input lists must contain only positive numeric values\")\n    \n    # Check if the input lists are valid\n    if not all(isinstance(x, (int, float)) for x in values):\n        raise ValueError(\"The input lists must contain only numeric values\")\n    if not all(isinstance(x, (int, float)) for x in weights):\n        raise ValueError(\"The input lists must contain only numeric values\")\n    if not all(x > 0 for x in weights):\n        raise ValueError(\"The input lists must contain only positive numeric values\")\n    \n    # Check if the input lists are valid\n    if not all(isinstance(x, (int, float)) for x in values):\n        raise ValueError(\"The input lists must contain only numeric values\")\n    if not all(isinstance(x, (int, float)) for x in weights):\n        raise ValueError(\"The input lists must contain only numeric values\")\n    if not all(x > 0 for x in weights):\n        raise ValueError(\"The input lists must contain only positive numeric values\")\n    \n    # Check if the input lists are valid\n    if not all(isinstance(x, (int, float)) for x in values):\n        raise ValueError(\"The input lists must contain only numeric values\")\n    if not all(isinstance(x, (int, float)) for x in weights):\n        raise ValueError(\"The input lists must contain only numeric values\")\n    if not all(x > 0 for x in weights):\n        raise ValueError(\"The input lists must contain only positive numeric values\")\n    \n    # Check if the input lists are valid\n    if not all(isinstance(x, (int, float)) for x in values):\n        raise ValueError(\"The input lists must contain only numeric values\")\n    if not all(isinstance(x, (int, float)) for x in weights):\n        raise ValueError(\"The input lists must contain only numeric values\")\n    if not all(x > 0 for x in weights):\n        raise ValueError(\"The input lists must contain only positive numeric values\")\n    \n    # Check if the input lists are valid\n    if not all(isinstance(x, (int, float)) for x in values):\n        raise ValueError(\"The input lists must contain only numeric values\")\n    if not all(isinstance(x, (int, float)) for x in weights):\n        raise ValueError(\"The input lists must contain only numeric values\")\n    if not all(x > 0 for x in weights):\n        raise ValueError(\"The input lists must contain only positive numeric values\")\n    \n    # Check if the input lists are valid\n    if not all(isinstance(x, (int, float)) for x in values):\n        raise ValueError(\"The input lists must contain only numeric values\")\n    if not all(isinstance(x, (int, float)) for x in weights):\n        raise ValueError(\"The input lists must contain only numeric values\")\n    if not all(x > 0 for x in weights):\n        raise ValueError(\"The input lists must contain only positive numeric values\")\n    \n    # Check if the input lists are valid\n    if not all(isinstance(x, (int, float)) for x in values):\n        raise ValueError(\"The input lists must contain only numeric values\")\n    if not all(isinstance(x, (int, float)) for x in weights):\n        raise ValueError(\"The input lists must contain only numeric values\")\n    if not all(x > 0 for x in weights):\n        raise ValueError(\"The input lists must contain only positive numeric values\")\n    \n    # Check if the input lists are valid\n    if not all(isinstance(x, (int, float)) for x in values):\n        raise ValueError(\"The input lists must contain only numeric values\")\n    if not all(isinstance(x, (int, float)) for x in weights):\n        raise ValueError(\"The input lists must contain only numeric values\")\n    if not all(x > 0 for x in weights):\n        raise ValueError(\"The input lists must contain only positive numeric values\")\n    \n    # Check if the input lists are valid\n    if not all(isinstance(x, (int, float)) for x in values):\n        raise ValueError(\"The input lists must contain only numeric values\")\n    if not all(isinstance(x, (int, float)) for x in weights):\n        raise ValueError(\"The input lists must contain only numeric values\")\n    if not all(x > 0 for x in weights):\n        raise ValueError(\"The input lists must contain only positive numeric values\")\n    \n    # Check if the input lists are valid\n    if not all(isinstance(x, (int, float)) for x in values):\n        raise ValueError(\"The input lists must contain only numeric values\")\n    if not all(isinstance(x, (int, float)) for x in weights):\n        raise ValueError(\"The input lists must contain only numeric values\")\n    if not all(x > 0 for x in weights):\n        raise ValueError(\"The input lists must contain only positive numeric values\")\n    \n    # Check if the input lists are valid\n    if not all(isinstance(x, (int, float)) for x in values):\n        raise ValueError(\"The input lists must contain only numeric values\")\n    if not all(isinstance(x, (int, float)) for x in weights):\n        raise ValueError(\"The input lists must contain only numeric values\")\n    if not all(x > 0 for x in weights):\n        raise ValueError(\"The input lists must contain only positive numeric values\")\n    \n    # Check if the input lists are valid", "raw_solution": "import random\nfrom collections import Counter\n\ndef task_func(values, weights, n_samples):\n    # Check if the input lists are of the same length\n    if len(values) != len(weights):\n        raise ValueError(\"The input lists must be of the same length\")\n    \n    # Check if the input lists are non-empty\n    if len(values) == 0 or len(weights) == 0:\n        raise ValueError(\"The input lists must not be empty\")\n    \n    # Check if the input lists are valid\n    if not all(isinstance(x, (int, float)) for x in values):\n        raise ValueError(\"The input lists must contain only numeric values\")\n    if not all(isinstance(x, (int, float)) for x in weights):\n        raise ValueError(\"The input lists must contain only numeric values\")\n    if not all(x > 0 for x in weights):\n        raise ValueError(\"The input lists must contain only positive numeric values\")\n    \n    # Check if the input lists are valid\n    if not all(isinstance(x, (int, float)) for x in values):\n        raise ValueError(\"The input lists must contain only numeric values\")\n    if not all(isinstance(x, (int, float)) for x in weights):\n        raise ValueError(\"The input lists must contain only numeric values\")\n    if not all(x > 0 for x in weights):\n        raise ValueError(\"The input lists must contain only positive numeric values\")\n    \n    # Check if the input lists are valid\n    if not all(isinstance(x, (int, float)) for x in values):\n        raise ValueError(\"The input lists must contain only numeric values\")\n    if not all(isinstance(x, (int, float)) for x in weights):\n        raise ValueError(\"The input lists must contain only numeric values\")\n    if not all(x > 0 for x in weights):\n        raise ValueError(\"The input lists must contain only positive numeric values\")\n    \n    # Check if the input lists are valid\n    if not all(isinstance(x, (int, float)) for x in values):\n        raise ValueError(\"The input lists must contain only numeric values\")\n    if not all(isinstance(x, (int, float)) for x in weights):\n        raise ValueError(\"The input lists must contain only numeric values\")\n    if not all(x > 0 for x in weights):\n        raise ValueError(\"The input lists must contain only positive numeric values\")\n    \n    # Check if the input lists are valid\n    if not all(isinstance(x, (int, float)) for x in values):\n        raise ValueError(\"The input lists must contain only numeric values\")\n    if not all(isinstance(x, (int, float)) for x in weights):\n        raise ValueError(\"The input lists must contain only numeric values\")\n    if not all(x > 0 for x in weights):\n        raise ValueError(\"The input lists must contain only positive numeric values\")\n    \n    # Check if the input lists are valid\n    if not all(isinstance(x, (int, float)) for x in values):\n        raise ValueError(\"The input lists must contain only numeric values\")\n    if not all(isinstance(x, (int, float)) for x in weights):\n        raise ValueError(\"The input lists must contain only numeric values\")\n    if not all(x > 0 for x in weights):\n        raise ValueError(\"The input lists must contain only positive numeric values\")\n    \n    # Check if the input lists are valid\n    if not all(isinstance(x, (int, float)) for x in values):\n        raise ValueError(\"The input lists must contain only numeric values\")\n    if not all(isinstance(x, (int, float)) for x in weights):\n        raise ValueError(\"The input lists must contain only numeric values\")\n    if not all(x > 0 for x in weights):\n        raise ValueError(\"The input lists must contain only positive numeric values\")\n    \n    # Check if the input lists are valid\n    if not all(isinstance(x, (int, float)) for x in values):\n        raise ValueError(\"The input lists must contain only numeric values\")\n    if not all(isinstance(x, (int, float)) for x in weights):\n        raise ValueError(\"The input lists must contain only numeric values\")\n    if not all(x > 0 for x in weights):\n        raise ValueError(\"The input lists must contain only positive numeric values\")\n    \n    # Check if the input lists are valid\n    if not all(isinstance(x, (int, float)) for x in values):\n        raise ValueError(\"The input lists must contain only numeric values\")\n    if not all(isinstance(x, (int, float)) for x in weights):\n        raise ValueError(\"The input lists must contain only numeric values\")\n    if not all(x > 0 for x in weights):\n        raise ValueError(\"The input lists must contain only positive numeric values\")\n    \n    # Check if the input lists are valid\n    if not all(isinstance(x, (int, float)) for x in values):\n        raise ValueError(\"The input lists must contain only numeric values\")\n    if not all(isinstance(x, (int, float)) for x in weights):\n        raise ValueError(\"The input lists must contain only numeric values\")\n    if not all(x > 0 for x in weights):\n        raise ValueError(\"The input lists must contain only positive numeric values\")\n    \n    # Check if the input lists are valid\n    if not all(isinstance(x, (int, float)) for x in values):\n        raise ValueError(\"The input lists must contain only numeric values\")\n    if not all(isinstance(x, (int, float)) for x in weights):\n        raise ValueError(\"The input lists must contain only numeric values\")\n    if not all(x > 0 for x in weights):\n        raise ValueError(\"The input lists must contain only positive numeric values\")\n    \n    # Check if the input lists are valid\n    if not all(isinstance(x, (int, float)) for x in values):\n        raise ValueError(\"The input lists must contain only numeric values\")\n    if not all(isinstance(x, (int, float)) for x in weights):\n        raise ValueError(\"The input lists must contain only numeric values\")\n    if not all(x > 0 for x in weights):\n        raise ValueError(\"The input lists must contain only positive numeric values\")\n    \n    # Check if the input lists are valid"}
{"task_id": "BigCodeBench/752", "solution": "import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nimport numpy as np\ndef task_func(data, target_column, test_size=0.2, random_state = 0) -> float:\n    if not isinstance(data, pd.DataFrame):\n        raise ValueError(\"If data is not a DataFrame.\")\n    if data.empty:\n        raise ValueError(\"If data is empty.\")\n    if target_column not in data.columns:\n        raise ValueError(\"If target_column ist not a column of data.\")\n    if not data.select_dtypes(include=[np.number]).empty:\n        raise ValueError(\"If data contains values that are not numeric.\")\n    if not isinstance(random_state, int):\n        raise ValueError(\"If random_state is not an integer.\")\n    if not 0 <= test_size <= 1:\n        raise ValueError(\"If test_size is not between 0 and 1.\")\n    X_train, X_test, y_train, y_test = train_test_split(data.drop(target_column, axis=1), data[target_column], test_size=test_size, random_state=random_state)\n    model = LinearRegression()\n    model.fit(X_train, y_train)\n    return model.score(X_test, y_test)", "raw_solution": "import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nimport numpy as np\n\ndef task_func(data, target_column, test_size=0.2, random_state = 0) -> float:\n    if not isinstance(data, pd.DataFrame):\n        raise ValueError(\"If data is not a DataFrame.\")\n    if data.empty:\n        raise ValueError(\"If data is empty.\")\n    if target_column not in data.columns:\n        raise ValueError(\"If target_column ist not a column of data.\")\n    if not data.select_dtypes(include=[np.number]).empty:\n        raise ValueError(\"If data contains values that are not numeric.\")\n    if not isinstance(random_state, int):\n        raise ValueError(\"If random_state is not an integer.\")\n    if not 0 <= test_size <= 1:\n        raise ValueError(\"If test_size is not between 0 and 1.\")\n    X_train, X_test, y_train, y_test = train_test_split(data.drop(target_column, axis=1), data[target_column], test_size=test_size, random_state=random_state)\n    model = LinearRegression()\n    model.fit(X_train, y_train)\n    return model.score(X_test, y_test)\n```"}
{"task_id": "BigCodeBench/753", "solution": "import math\nimport random\nimport statistics\nRADIUS = 5\ndef task_func(n):\n    # Generate n random points within a circle of radius RADIUS\n    points = []\n    for i in range(n):\n        while True:\n            x = random.uniform(-RADIUS, RADIUS)\n            y = random.uniform(-RADIUS, RADIUS)\n            if x**2 + y**2 <= RADIUS**2:\n                points.append((x, y))\n                break\n    # Calculate the average distance from the center of the circle\n    distances = [math.sqrt(x**2 + y**2) for x, y in points]\n    return statistics.mean(distances)", "raw_solution": "import math\nimport random\nimport statistics\n# Constants\nRADIUS = 5\ndef task_func(n):\n    # Generate n random points within a circle of radius RADIUS\n    points = []\n    for i in range(n):\n        while True:\n            x = random.uniform(-RADIUS, RADIUS)\n            y = random.uniform(-RADIUS, RADIUS)\n            if x**2 + y**2 <= RADIUS**2:\n                points.append((x, y))\n                break\n    # Calculate the average distance from the center of the circle\n    distances = [math.sqrt(x**2 + y**2) for x, y in points]\n    return statistics.mean(distances)\n```"}
{"task_id": "BigCodeBench/754", "solution": "import numpy as np\nimport pandas as pd\nfrom datetime import datetime\nDATE_FORMAT = '%Y-%m-%d %H:%M:%S'\ndef task_func(result):\n    if not result['from_user'].apply(lambda x: isinstance(x, (int, float))).all():\n        raise ValueError('If the \"from_user\" values are not numeric.')\n    summary = pd.Series({\n        'mean': result['from_user'].mean(),\n        'median': result['from_user'].median(),\n        'min': result['from_user'].min(),\n        'max': result['from_user'].max(),\n        'std': result['from_user'].std(),\n        'current_time': datetime.now().strftime(DATE_FORMAT)\n    })\n    return summary", "raw_solution": "import numpy as np\nimport pandas as pd\nfrom datetime import datetime\n# Constants\nDATE_FORMAT = '%Y-%m-%d %H:%M:%S'\ndef task_func(result):\n    if not result['from_user'].apply(lambda x: isinstance(x, (int, float))).all():\n        raise ValueError('If the \"from_user\" values are not numeric.')\n    summary = pd.Series({\n        'mean': result['from_user'].mean(),\n        'median': result['from_user'].median(),\n        'min': result['from_user'].min(),\n        'max': result['from_user'].max(),\n        'std': result['from_user'].std(),\n        'current_time': datetime.now().strftime(DATE_FORMAT)\n    })\n    return summary\n```"}
{"task_id": "BigCodeBench/755", "solution": "import os\nimport glob\ndef task_func(directory_path):\n    new_filenames = []\n    for filename in glob.glob(os.path.join(directory_path, '*.*')):\n        new_filename = filename[::-1].replace('.', '.')\n        new_filenames.append(new_filename)\n    return new_filenames", "raw_solution": "import os\nimport glob\n\ndef task_func(directory_path):\n    new_filenames = []\n    for filename in glob.glob(os.path.join(directory_path, '*.*')):\n        new_filename = filename[::-1].replace('.', '.')\n        new_filenames.append(new_filename)\n    return new_filenames\n```"}
{"task_id": "BigCodeBench/756", "solution": "import shutil\nfrom pathlib import Path\nfrom typing import List\ndef task_func(source_dir: str, target_dir: str, extensions: List[str]) -> int:\n    if not Path(source_dir).exists() or not Path(target_dir).exists():\n        raise ValueError(\"If source_dir or target_dir does not exist.\")\n    count = 0\n    for file in Path(source_dir).glob('**/*'):\n        if file.suffix in extensions:\n            shutil.move(file, target_dir)\n            count += 1\n    return count", "raw_solution": "import shutil\nfrom pathlib import Path\nfrom typing import List\n\ndef task_func(source_dir: str, target_dir: str, extensions: List[str]) -> int:\n    if not Path(source_dir).exists() or not Path(target_dir).exists():\n        raise ValueError(\"If source_dir or target_dir does not exist.\")\n    count = 0\n    for file in Path(source_dir).glob('**/*'):\n        if file.suffix in extensions:\n            shutil.move(file, target_dir)\n            count += 1\n    return count\n```"}
{"task_id": "BigCodeBench/757", "solution": "import numpy as np\nimport datetime\ndef task_func(arr):\n    return np.array([s[::-1] for s in arr])", "raw_solution": "import numpy as np\nimport datetime\ndef task_func(arr):\n    return np.array([s[::-1] for s in arr])\n```"}
{"task_id": "BigCodeBench/758", "solution": "import pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing import LabelEncoder\ndef task_func(num_samples, countries=['Russia', 'China', 'USA', 'India', 'Brazil'], \n           ages=np.arange(18, 60), genders=['Male', 'Female'], rng_seed=None):\n    if not isinstance(num_samples, int):\n        raise ValueError(\"If num_samples is not an integer.\")\n    rng = np.random.default_rng(rng_seed)\n    country = rng.choice(countries, num_samples)\n    age = rng.choice(ages, num_samples)\n    gender = rng.choice(genders, num_samples)\n    demographics = pd.DataFrame({'Country': country, 'Age': age, 'Gender': gender})\n    return demographics", "raw_solution": "import pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing import LabelEncoder\n\ndef task_func(num_samples, countries=['Russia', 'China', 'USA', 'India', 'Brazil'], \n           ages=np.arange(18, 60), genders=['Male', 'Female'], rng_seed=None):\n    if not isinstance(num_samples, int):\n        raise ValueError(\"If num_samples is not an integer.\")\n    rng = np.random.default_rng(rng_seed)\n    country = rng.choice(countries, num_samples)\n    age = rng.choice(ages, num_samples)\n    gender = rng.choice(genders, num_samples)\n    demographics = pd.DataFrame({'Country': country, 'Age': age, 'Gender': gender})\n    return demographics\n```"}
{"task_id": "BigCodeBench/759", "solution": "import os\nimport shutil\nimport fnmatch\ndef task_func(source_directory, destination_directory, file_pattern):\n    moved_files = []\n    for root, dirs, files in os.walk(source_directory):\n        for filename in fnmatch.filter(files, file_pattern):\n            src = os.path.join(root, filename)\n            dst = os.path.join(destination_directory, filename)\n            shutil.move(src, dst)\n            moved_files.append(filename)\n    return moved_files", "raw_solution": "import os\nimport shutil\nimport fnmatch\n\ndef task_func(source_directory, destination_directory, file_pattern):\n    moved_files = []\n    for root, dirs, files in os.walk(source_directory):\n        for filename in fnmatch.filter(files, file_pattern):\n            src = os.path.join(root, filename)\n            dst = os.path.join(destination_directory, filename)\n            shutil.move(src, dst)\n            moved_files.append(filename)\n    return moved_files\n```"}
{"task_id": "BigCodeBench/760", "solution": "import pandas as pd\nimport numpy as np\nimport codecs\nimport re\nimport datetime\ndef task_func(start_year=1980, end_year=2000, email_domain='example.com',\n           latin_names=['Sopet\u00f3n', 'M\u00e9ndez', 'G\u00f3mez', 'P\u00e9rez', 'Mu\u00f1oz'],\n           other_names=['Smith', 'Johnson', 'Williams', 'Brown', 'Jones'], \n           rng_seed=None):\n    if rng_seed is not None:\n        np.random.seed(rng_seed)\n    names = latin_names + other_names\n    df = pd.DataFrame({\n        'ID': np.random.randint(1, 101, 100),\n        'Name': np.random.choice(names, 100),\n        'Date of Birth': [datetime.datetime(start_year + np.random.randint(0, 220), \n                                           np.random.randint(1, 12), \n                                           np.random.randint(1, 28)) \n                           for _ in range(100)],\n        'Email': [f'{name.lower()}{np.random.randint(1000, 9999)}@{email_domain}' \n                  for name in df['Name']]\n    })\n    df['Name'] = df['Name'].apply(lambda x: re.sub(r'[^a-zA-Z\\s]', '', x))\n    return df", "raw_solution": "import pandas as pd\nimport numpy as np\nimport codecs\nimport re\nimport datetime\ndef task_func(start_year=1980, end_year=2000, email_domain='example.com',\n           latin_names=['Sopet\u00f3n', 'M\u00e9ndez', 'G\u00f3mez', 'P\u00e9rez', 'Mu\u00f1oz'],\n           other_names=['Smith', 'Johnson', 'Williams', 'Brown', 'Jones'], \n           rng_seed=None):\n    if rng_seed is not None:\n        np.random.seed(rng_seed)\n    names = latin_names + other_names\n    df = pd.DataFrame({\n        'ID': np.random.randint(1, 101, 100),\n        'Name': np.random.choice(names, 100),\n        'Date of Birth': [datetime.datetime(start_year + np.random.randint(0, 220), \n                                           np.random.randint(1, 12), \n                                           np.random.randint(1, 28)) \n                           for _ in range(100)],\n        'Email': [f'{name.lower()}{np.random.randint(1000, 9999)}@{email_domain}' \n                  for name in df['Name']]\n    })\n    df['Name'] = df['Name'].apply(lambda x: re.sub(r'[^a-zA-Z\\s]', '', x))\n    return df\n```"}
{"task_id": "BigCodeBench/761", "solution": "import json\nimport re\nfrom collections import Counter\nREPLACE_NONE = \"None\"\ndef task_func(json_str):\n    # Remove None values\n    json_data = json.loads(json_str)\n    json_data = {k: v for k, v in json_data.items() if v is not None}\n    # Count the frequency of each unique value\n    value_counts = Counter(json_data.values())\n    # Replace all email addresses with the placeholder \"None\"\n    json_data = {k: REPLACE_NONE if isinstance(v, str) and re.match(r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b', v) else v for k, v in json_data.items()}\n    return {\"data\": json_data, \"value_counts\": value_counts}", "raw_solution": "import json\nimport re\nfrom collections import Counter\n# Constants\nREPLACE_NONE = \"None\"\ndef task_func(json_str):\n    # Remove None values\n    json_data = json.loads(json_str)\n    json_data = {k: v for k, v in json_data.items() if v is not None}\n    # Count the frequency of each unique value\n    value_counts = Counter(json_data.values())\n    # Replace all email addresses with the placeholder \"None\"\n    json_data = {k: REPLACE_NONE if isinstance(v, str) and re.match(r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b', v) else v for k, v in json_data.items()}\n    return {\"data\": json_data, \"value_counts\": value_counts}\n```"}
{"task_id": "BigCodeBench/762", "solution": "import codecs\nimport os\nimport zipfile\ndef task_func(directory_name=\"latin_files\",\n          content='Sopet\u00f3n',\n          file_names=['file1.txt', 'file2.txt', 'file3.txt'],\n          encoding=\"latin-1\"):\n    os.makedirs(directory_name, exist_ok=True)\n    for file_name in file_names:\n        with codecs.open(os.path.join(directory_name, file_name), 'w', encoding) as f:\n            f.write(content)\n    with zipfile.ZipFile(os.path.join(directory_name, 'directory.zip'), 'w') as zipf:\n        for root, dirs, files in os.walk(directory_name):\n            for file in files:\n                zipf.write(os.path.join(root, file), os.path.relpath(os.path.join(root, file), directory_name))\n    return os.path.join(directory_name, 'directory.zip')", "raw_solution": "import codecs\nimport os\nimport zipfile\ndef task_func(directory_name=\"latin_files\",\n          content='Sopet\u00f3n',\n          file_names=['file1.txt', 'file2.txt', 'file3.txt'],\n          encoding=\"latin-1\"):\n    os.makedirs(directory_name, exist_ok=True)\n    for file_name in file_names:\n        with codecs.open(os.path.join(directory_name, file_name), 'w', encoding) as f:\n            f.write(content)\n    with zipfile.ZipFile(os.path.join(directory_name, 'directory.zip'), 'w') as zipf:\n        for root, dirs, files in os.walk(directory_name):\n            for file in files:\n                zipf.write(os.path.join(root, file), os.path.relpath(os.path.join(root, file), directory_name))\n    return os.path.join(directory_name, 'directory.zip')\n```"}
{"task_id": "BigCodeBench/763", "solution": "import numpy as np\nfrom collections import defaultdict\nimport json\nimport csv\ndef task_func(input_file, output_file):\n    # Read the input JSON file\n    with open(input_file, 'r') as f:\n        data = json.load(f)\n    \n    # Calculate the mean and median for each key\n    results = defaultdict(lambda: {'mean': 0, 'median': 0})\n    for d in data:\n        for key, value in d.items():\n            results[key]['mean'] += value\n            results[key]['median'] += np.median([value])\n    \n    # Write the results to a CSV file\n    with open(output_file, 'w', newline='') as f:\n        writer = csv.DictWriter(f, fieldnames=['key', 'mean', 'median'])\n        writer.writeheader()\n        for key, value in results.items():\n            writer.writerow({'key': key, 'mean': value['mean'], 'median': value['median']})", "raw_solution": "import numpy as np\nfrom collections import defaultdict\nimport json\nimport csv\n\n# Constants\ndef task_func(input_file, output_file):\n    # Read the input JSON file\n    with open(input_file, 'r') as f:\n        data = json.load(f)\n    \n    # Calculate the mean and median for each key\n    results = defaultdict(lambda: {'mean': 0, 'median': 0})\n    for d in data:\n        for key, value in d.items():\n            results[key]['mean'] += value\n            results[key]['median'] += np.median([value])\n    \n    # Write the results to a CSV file\n    with open(output_file, 'w', newline='') as f:\n        writer = csv.DictWriter(f, fieldnames=['key', 'mean', 'median'])\n        writer.writeheader()\n        for key, value in results.items():\n            writer.writerow({'key': key, 'mean': value['mean'], 'median': value['median']})\n```"}
{"task_id": "BigCodeBench/764", "solution": "import csv\nimport random\ndef task_func(csv_file='names.csv', \n          latin_names=['Sopet\u00f3n', 'M\u00e9ndez', 'G\u00f3mez', 'P\u00e9rez', 'Mu\u00f1oz'],\n          names=['Smith', 'Johnson', 'Williams', 'Brown', 'Jones'],\n          encoding='latin-1', rng_seed=None):\n    if not isinstance(csv_file, str):\n        raise TypeError('If csv_file is not a string.')\n    if not isinstance(latin_names, list):\n        raise TypeError('If latin_names is not an array.')\n    if not isinstance(names, list):\n        raise TypeError('If names is not an array.')\n    if rng_seed is not None:\n        random.seed(rng_seed)\n    with open(csv_file, 'w', newline='', encoding=encoding) as csvfile:\n        writer = csv.writer(csvfile)\n        if len(latin_names) == 0:\n            writer.writerow(['Name', 'Age'])\n        else:\n            names = random.sample(latin_names, len(latin_names) // 2) + random.sample(names, len(names) // 2)\n            random.shuffle(names)\n            for i in range(len(names)):\n                writer.writerow([names[i], random.randint(20, 50)])\n    return csv_file", "raw_solution": "import csv\nimport random\n\ndef task_func(csv_file='names.csv', \n          latin_names=['Sopet\u00f3n', 'M\u00e9ndez', 'G\u00f3mez', 'P\u00e9rez', 'Mu\u00f1oz'],\n          names=['Smith', 'Johnson', 'Williams', 'Brown', 'Jones'],\n          encoding='latin-1', rng_seed=None):\n    if not isinstance(csv_file, str):\n        raise TypeError('If csv_file is not a string.')\n    if not isinstance(latin_names, list):\n        raise TypeError('If latin_names is not an array.')\n    if not isinstance(names, list):\n        raise TypeError('If names is not an array.')\n    if rng_seed is not None:\n        random.seed(rng_seed)\n    with open(csv_file, 'w', newline='', encoding=encoding) as csvfile:\n        writer = csv.writer(csvfile)\n        if len(latin_names) == 0:\n            writer.writerow(['Name', 'Age'])\n        else:\n            names = random.sample(latin_names, len(latin_names) // 2) + random.sample(names, len(names) // 2)\n            random.shuffle(names)\n            for i in range(len(names)):\n                writer.writerow([names[i], random.randint(20, 50)])\n    return csv_file\n```"}
{"task_id": "BigCodeBench/765", "solution": "import os\nfrom pathlib import Path\nimport shutil\ndef task_func(kwargs, target_dir=\"non_none_files\"):\n    copied_files = []\n    for file_path in kwargs['files']:\n        if os.path.exists(file_path):\n            if os.path.getsize(file_path) > 0:\n                shutil.copy(file_path, target_dir)\n                copied_files.append(file_path)\n    return copied_files", "raw_solution": "import os\nfrom pathlib import Path\nimport shutil\n\ndef task_func(kwargs, target_dir=\"non_none_files\"):\n    copied_files = []\n    for file_path in kwargs['files']:\n        if os.path.exists(file_path):\n            if os.path.getsize(file_path) > 0:\n                shutil.copy(file_path, target_dir)\n                copied_files.append(file_path)\n    return copied_files\n```"}
{"task_id": "BigCodeBench/766", "solution": "import re\nimport collections\ndef task_func(string, patterns=['nnn', 'aaa', 'sss', 'ddd', 'fff']):\n    if not isinstance(string, str):\n        raise TypeError('If string is not a str.')\n    if not isinstance(patterns, list):\n        raise TypeError('If patterns is not a list of str.')\n    return collections.Counter(re.findall(pattern, string))", "raw_solution": "import re\nimport collections\ndef task_func(string, patterns=['nnn', 'aaa', 'sss', 'ddd', 'fff']):\n    if not isinstance(string, str):\n        raise TypeError('If string is not a str.')\n    if not isinstance(patterns, list):\n        raise TypeError('If patterns is not a list of str.')\n    return collections.Counter(re.findall(pattern, string))\n```"}
{"task_id": "BigCodeBench/767", "solution": "from collections import Counter\nimport random\nimport string\nLETTERS = string.ascii_letters\ndef task_func(list_of_lists):\n    # Replace each sublist with a random letter\n    random_letters = [random.choice(LETTERS) for _ in range(len(list_of_lists))]\n    # Create a new list with the random letters\n    new_list = [random_letters] * len(list_of_lists)\n    # Count the occurrences of each letter\n    letter_counts = Counter(''.join(new_list))\n    return letter_counts", "raw_solution": "from collections import Counter\nimport random\nimport string\n# Constants\nLETTERS = string.ascii_letters\n\ndef task_func(list_of_lists):\n    # Replace each sublist with a random letter\n    random_letters = [random.choice(LETTERS) for _ in range(len(list_of_lists))]\n    # Create a new list with the random letters\n    new_list = [random_letters] * len(list_of_lists)\n    # Count the occurrences of each letter\n    letter_counts = Counter(''.join(new_list))\n    return letter_counts\n```"}
{"task_id": "BigCodeBench/768", "solution": "import re\nimport os\nimport glob\ndef task_func(dir_path):\n    if not os.path.exists(dir_path):\n        raise ValueError(\"Directory in dir_path does not exist.\")\n    error_count = {}\n    for file_path in glob.glob(os.path.join(dir_path, '**/*.txt'), recursive=True):\n        with open(file_path, 'r') as f:\n            text = f.read()\n            error_count[file_path] = len(re.findall(r'\\berror\\b', text, re.IGNORECASE))\n    return error_count", "raw_solution": "import re\nimport os\nimport glob\n\ndef task_func(dir_path):\n    if not os.path.exists(dir_path):\n        raise ValueError(\"Directory in dir_path does not exist.\")\n    error_count = {}\n    for file_path in glob.glob(os.path.join(dir_path, '**/*.txt'), recursive=True):\n        with open(file_path, 'r') as f:\n            text = f.read()\n            error_count[file_path] = len(re.findall(r'\\berror\\b', text, re.IGNORECASE))\n    return error_count\n```"}
{"task_id": "BigCodeBench/769", "solution": "from collections import Counter\nimport itertools\nimport operator\ndef task_func(list_of_menuitems):\n    # Flatten the list\n    flat_list = list(itertools.chain(*list_of_menuitems))\n    # Count the occurrences of each item\n    item_counts = Counter(flat_list)\n    # Find the most common item\n    most_common_item = item_counts.most_common(1)[0][0]\n    return most_common_item", "raw_solution": "from collections import Counter\nimport itertools\nimport operator\ndef task_func(list_of_menuitems):\n    # Flatten the list\n    flat_list = list(itertools.chain(*list_of_menuitems))\n    # Count the occurrences of each item\n    item_counts = Counter(flat_list)\n    # Find the most common item\n    most_common_item = item_counts.most_common(1)[0][0]\n    return most_common_item\n```"}
{"task_id": "BigCodeBench/770", "solution": "import numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\ndef task_func(num_samples=500, noise_strength=1, random_seed=None, test_size=0.2):\n    if test_size < 2:\n        raise ValueError(\"If test set size is smaller than 2.\")\n    X = np.random.rand(num_samples, 1)\n    y = 2 * X + np.random.normal(0, noise_strength, num_samples)\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_seed)\n    model = LinearRegression()\n    model.fit(X_train, y_train)\n    return model.score(X_test, y_test), model", "raw_solution": "import numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\ndef task_func(num_samples=500, noise_strength=1, random_seed=None, test_size=0.2):\n    if test_size < 2:\n        raise ValueError(\"If test set size is smaller than 2.\")\n    X = np.random.rand(num_samples, 1)\n    y = 2 * X + np.random.normal(0, noise_strength, num_samples)\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_seed)\n    model = LinearRegression()\n    model.fit(X_train, y_train)\n    return model.score(X_test, y_test), model\n```"}
{"task_id": "BigCodeBench/771", "solution": "import re\nimport os\nfrom pathlib import Path\nimport csv\ndef task_func(directory: str, pattern: str = r'^(.*?)-\\d+\\.csv$') -> list:\n    new_files = []\n    for filename in os.listdir(directory):\n        if re.match(pattern, filename):\n            new_filename = re.sub(pattern, r'\\1-new.csv', filename)\n            new_files.append(new_filename)\n            with open(os.path.join(directory, filename), 'r') as f:\n                reader = csv.reader(f)\n                with open(os.path.join(directory, new_filename), 'w', newline='') as f:\n                    writer = csv.writer(f)\n                    writer.writerows(reader)\n    return new_files", "raw_solution": "import re\nimport os\nfrom pathlib import Path\nimport csv\n\ndef task_func(directory: str, pattern: str = r'^(.*?)-\\d+\\.csv$') -> list:\n    new_files = []\n    for filename in os.listdir(directory):\n        if re.match(pattern, filename):\n            new_filename = re.sub(pattern, r'\\1-new.csv', filename)\n            new_files.append(new_filename)\n            with open(os.path.join(directory, filename), 'r') as f:\n                reader = csv.reader(f)\n                with open(os.path.join(directory, new_filename), 'w', newline='') as f:\n                    writer = csv.writer(f)\n                    writer.writerows(reader)\n    return new_files\n```"}
{"task_id": "BigCodeBench/772", "solution": "import numpy as np\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import mean_squared_error\ndef task_func(num_samples=1000, k=5, d=2, random_seed=None):\n    np.random.seed(random_seed)\n    data = np.random.normal(size=(num_samples, d))\n    linear_transformation = np.random.normal(size=(d, d))\n    transformed_data = np.dot(data, linear_transformation)\n    scaler = StandardScaler()\n    standardized_data = scaler.fit_transform(transformed_data)\n    mse = mean_squared_error(data, standardized_data)\n    return mse", "raw_solution": "import numpy as np\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import mean_squared_error\n\ndef task_func(num_samples=1000, k=5, d=2, random_seed=None):\n    np.random.seed(random_seed)\n    data = np.random.normal(size=(num_samples, d))\n    linear_transformation = np.random.normal(size=(d, d))\n    transformed_data = np.dot(data, linear_transformation)\n    scaler = StandardScaler()\n    standardized_data = scaler.fit_transform(transformed_data)\n    mse = mean_squared_error(data, standardized_data)\n    return mse\n```"}
{"task_id": "BigCodeBench/773", "solution": "import os\nimport re\nimport shutil\nSOURCE_DIR = '/source/dir'\nTARGET_DIR = '/target/dir'\nFILE_PATTERN = re.compile(r'^(.*?)-\\d+\\.json$')\ndef task_func():\n    # Check if source directory exists\n    if not os.path.exists(SOURCE_DIR):\n        print(f\"Source directory {SOURCE_DIR} does not exist.\")\n        return None\n    # Check if target directory exists\n    if not os.path.exists(TARGET_DIR):\n        os.makedirs(TARGET_DIR)\n    # Iterate over all files in source directory\n    for filename in os.listdir(SOURCE_DIR):\n        # Check if file is a json file\n        if filename.endswith('.json'):\n            # Split filename by last occurrence of '-'\n            match = FILE_PATTERN.match(filename)\n            if match:\n                prefix = match.group(1)\n                # Create new filename\n                new_filename = f\"{prefix}.json\"\n                # Construct full paths\n                source_path = os.path.join(SOURCE_DIR, filename)\n                target_path = os.path.join(TARGET_DIR, new_filename)\n                # Move file to target directory\n                shutil.move(source_path, target_path)\n    return None", "raw_solution": "import os\nimport re\nimport shutil\n# Constants\nSOURCE_DIR = '/source/dir'\nTARGET_DIR = '/target/dir'\nFILE_PATTERN = re.compile(r'^(.*?)-\\d+\\.json$')\ndef task_func():\n    # Check if source directory exists\n    if not os.path.exists(SOURCE_DIR):\n        print(f\"Source directory {SOURCE_DIR} does not exist.\")\n        return None\n    # Check if target directory exists\n    if not os.path.exists(TARGET_DIR):\n        os.makedirs(TARGET_DIR)\n    # Iterate over all files in source directory\n    for filename in os.listdir(SOURCE_DIR):\n        # Check if file is a json file\n        if filename.endswith('.json'):\n            # Split filename by last occurrence of '-'\n            match = FILE_PATTERN.match(filename)\n            if match:\n                prefix = match.group(1)\n                # Create new filename\n                new_filename = f\"{prefix}.json\"\n                # Construct full paths\n                source_path = os.path.join(SOURCE_DIR, filename)\n                target_path = os.path.join(TARGET_DIR, new_filename)\n                # Move file to target directory\n                shutil.move(source_path, target_path)\n    return None\n```"}
{"task_id": "BigCodeBench/774", "solution": "import numpy as np\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.ensemble import RandomForestRegressor\ndef task_func(num_samples=100, n_estimators=100, random_seed=None, cv=5):\n    if num_samples / cv < 2:\n        raise ValueError(\"If num_samples / cv < 2\")\n    X = np.random.randn(num_samples, 5)\n    y = np.sum(X, axis=1) + np.random.randn(num_samples)\n    model = RandomForestRegressor(n_estimators=n_estimators, random_state=random_seed)\n    scores = cross_val_score(model, X, y, cv=cv)\n    return np.mean(scores), model", "raw_solution": "import numpy as np\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.ensemble import RandomForestRegressor\ndef task_func(num_samples=100, n_estimators=100, random_seed=None, cv=5):\n    if num_samples / cv < 2:\n        raise ValueError(\"If num_samples / cv < 2\")\n    X = np.random.randn(num_samples, 5)\n    y = np.sum(X, axis=1) + np.random.randn(num_samples)\n    model = RandomForestRegressor(n_estimators=n_estimators, random_state=random_seed)\n    scores = cross_val_score(model, X, y, cv=cv)\n    return np.mean(scores), model\n```"}
{"task_id": "BigCodeBench/775", "solution": "from string import ascii_lowercase\nimport re\nfrom collections import Counter\nLETTERS_PATTERN = re.compile(r'^(.*?)-[a-z]$')\ndef task_func(string):\n    # Find the last occurrence of '-' in the string\n    match = LETTERS_PATTERN.search(string)\n    if match:\n        # Split the string at the last occurrence of '-'\n        prefix = match.group(1)\n        # Count the frequency of each lowercase letter in the prefix\n        return dict(Counter(prefix))\n    else:\n        # Return an empty dictionary if no '-' is found\n        return {}", "raw_solution": "from string import ascii_lowercase\nimport re\nfrom collections import Counter\n\n# Constants\nLETTERS_PATTERN = re.compile(r'^(.*?)-[a-z]$')\nLETTERS = ascii_lowercase\n\ndef task_func(string):\n    # Find the last occurrence of '-' in the string\n    match = LETTERS_PATTERN.search(string)\n    if match:\n        # Split the string at the last occurrence of '-'\n        prefix = match.group(1)\n        # Count the frequency of each lowercase letter in the prefix\n        return dict(Counter(prefix))\n    else:\n        # Return an empty dictionary if no '-' is found\n        return {}\n```"}
{"task_id": "BigCodeBench/776", "solution": "import pandas as pd\nfrom sklearn.linear_model import LinearRegression\ndef task_func(file_path, output_path=None, sort_key='title', linear_regression=False, x_column=None, y_column=None):\n    try:\n        df = pd.read_csv(file_path)\n        df = df.sort_values(by=sort_key)\n        if output_path is not None:\n            df.to_csv(output_path, index=False)\n        if linear_regression:\n            if x_column is None or y_column is None:\n                raise ValueError(\"Specified columns for linear regression do not exist in the dataframe\")\n            X = df[x_column].values.reshape(-1, 1)\n            y = df[y_column].values\n            model = LinearRegression().fit(X, y)\n            return model\n        return df\n    except Exception as e:\n        raise Exception(f\"Error: {e}\")", "raw_solution": "import pandas as pd\nfrom sklearn.linear_model import LinearRegression\n\ndef task_func(file_path, output_path=None, sort_key='title', linear_regression=False, x_column=None, y_column=None):\n    try:\n        df = pd.read_csv(file_path)\n        df = df.sort_values(by=sort_key)\n        if output_path is not None:\n            df.to_csv(output_path, index=False)\n        if linear_regression:\n            if x_column is None or y_column is None:\n                raise ValueError(\"Specified columns for linear regression do not exist in the dataframe\")\n            X = df[x_column].values.reshape(-1, 1)\n            y = df[y_column].values\n            model = LinearRegression().fit(X, y)\n            return model\n        return df\n    except Exception as e:\n        raise Exception(f\"Error: {e}\")\n```"}
{"task_id": "BigCodeBench/777", "solution": "import re\nimport os\nimport zipfile\ndef task_func(directory, pattern=r'^(.*?)-\\d+\\.zip$'):\n    # Get all zip files in the directory\n    zip_files = [f for f in os.listdir(directory) if re.match(pattern, f)]\n    # Create a list to store the directories where the files were extracted\n    extracted_dirs = []\n    # Loop through each zip file\n    for zip_file in zip_files:\n        # Split the filename the last time \"-\" occurs\n        filename = os.path.splitext(zip_file)[0]\n        # Get the prefix part of the filename as the directory to extract\n        prefix = filename.split('-')[0]\n        # Create the directory if it doesn't exist\n        if not os.path.exists(prefix):\n            os.makedirs(prefix)\n        # Extract the zip file to the directory\n        with zipfile.ZipFile(os.path.join(directory, zip_file), 'r') as zip_ref:\n            zip_ref.extractall(prefix)\n        # Add the directory to the list of extracted directories\n        extracted_dirs.append(prefix)\n    # Return the list of directories where the files were extracted\n    return extracted_dirs", "raw_solution": "import re\nimport os\nimport zipfile\ndef task_func(directory, pattern=r'^(.*?)-\\d+\\.zip$'):\n    # Get all zip files in the directory\n    zip_files = [f for f in os.listdir(directory) if re.match(pattern, f)]\n    # Create a list to store the directories where the files were extracted\n    extracted_dirs = []\n    # Loop through each zip file\n    for zip_file in zip_files:\n        # Split the filename the last time \"-\" occurs\n        filename = os.path.splitext(zip_file)[0]\n        # Get the prefix part of the filename as the directory to extract\n        prefix = filename.split('-')[0]\n        # Create the directory if it doesn't exist\n        if not os.path.exists(prefix):\n            os.makedirs(prefix)\n        # Extract the zip file to the directory\n        with zipfile.ZipFile(os.path.join(directory, zip_file), 'r') as zip_ref:\n            zip_ref.extractall(prefix)\n        # Add the directory to the list of extracted directories\n        extracted_dirs.append(prefix)\n    # Return the list of directories where the files were extracted\n    return extracted_dirs\n```"}
{"task_id": "BigCodeBench/778", "solution": "from collections import defaultdict\nfrom operator import itemgetter\nfrom itertools import groupby\ndef task_func(news_articles):\n    if not all(isinstance(article, dict) for article in news_articles):\n        raise ValueError(\"If dictionary keys do not match the requirements.\")\n    sorted_articles = defaultdict(list)\n    for article in sorted(news_articles, key=itemgetter('category', 'title')):\n        sorted_articles[article['category']].append(article)\n    return sorted_articles", "raw_solution": "from collections import defaultdict\nfrom operator import itemgetter\nfrom itertools import groupby\n\ndef task_func(news_articles):\n    if not all(isinstance(article, dict) for article in news_articles):\n        raise ValueError(\"If dictionary keys do not match the requirements.\")\n    sorted_articles = defaultdict(list)\n    for article in sorted(news_articles, key=itemgetter('category', 'title')):\n        sorted_articles[article['category']].append(article)\n    return sorted_articles\n```"}
{"task_id": "BigCodeBench/779", "solution": "import os\nimport shutil\ndef get_unique_backup_dir():\n    return \"/fake/backup/path\"\ndef task_func(directory):\n    # Create backup directory\n    backup_dir = get_unique_backup_dir()\n    os.makedirs(backup_dir, exist_ok=True)\n    # Copy directory contents to backup\n    try:\n        shutil.copytree(directory, backup_dir)\n    except Exception as e:\n        return backup_dir, [str(e)]\n    # Clean directory\n    try:\n        shutil.rmtree(directory)\n    except Exception as e:\n        return backup_dir, [str(e)]\n    return backup_dir, []", "raw_solution": "import os\nimport shutil\n# Constants\nBACKUP_DIR = '/tmp/backup'\ndef get_unique_backup_dir():\n    return \"/fake/backup/path\"\ndef task_func(directory):\n    # Create backup directory\n    backup_dir = get_unique_backup_dir()\n    os.makedirs(backup_dir, exist_ok=True)\n    # Copy directory contents to backup\n    try:\n        shutil.copytree(directory, backup_dir)\n    except Exception as e:\n        return backup_dir, [str(e)]\n    # Clean directory\n    try:\n        shutil.rmtree(directory)\n    except Exception as e:\n        return backup_dir, [str(e)]\n    return backup_dir, []\n```"}
{"task_id": "BigCodeBench/780", "solution": "import pandas as pd\nimport pytz\ndef task_func(articles, timezone):\n    if not isinstance(articles, list) or not all(isinstance(article, dict) for article in articles):\n        raise TypeError(\"articles is not a list of dictionaries\")\n    if not articles:\n        raise ValueError(\"empty list is passed as articles\")\n    if not all(key in article for key in ['published_time', 'category'] for article in articles):\n        raise ValueError(\"dictionary keys do not match the requirements\")\n    timezone = pytz.timezone(timezone)\n    articles = [article for article in articles if article['published_time'] is not None]\n    articles = [article for article in articles if article['category'] is not None]\n    articles = [article for article in articles if article['published_time'] is not None]\n    articles = [article for article in articles if article['category'] is not None]\n    articles = [article for article in articles if article['published_time'] is not None]\n    articles = [article for article in articles if article['category'] is not None]\n    articles = [article for article in articles if article['published_time'] is not None]\n    articles = [article for article in articles if article['category'] is not None]\n    articles = [article for article in articles if article['published_time'] is not None]\n    articles = [article for article in articles if article['category'] is not None]\n    articles = [article for article in articles if article['published_time'] is not None]\n    articles = [article for article in articles if article['category'] is not None]\n    articles = [article for article in articles if article['published_time'] is not None]\n    articles = [article for article in articles if article['category'] is not None]\n    articles = [article for article in articles if article['published_time'] is not None]\n    articles = [article for article in articles if article['category'] is not None]\n    articles = [article for article in articles if article['published_time'] is not None]\n    articles = [article for article in articles if article['category'] is not None]\n    articles = [article for article in articles if article['published_time'] is not None]\n    articles = [article for article in articles if article['category'] is not None]\n    articles = [article for article in articles if article['published_time'] is not None]\n    articles = [article for article in articles if article['category'] is not None]\n    articles = [article for article in articles if article['published_time'] is not None]\n    articles = [article for article in articles if article['category'] is not None]\n    articles = [article for article in articles if article['published_time'] is not None]\n    articles = [article for article in articles if article['category'] is not None]\n    articles = [article for article in articles if article['published_time'] is not None]\n    articles = [article for article in articles if article['category'] is not None]\n    articles = [article for article in articles if article['published_time'] is not None]\n    articles = [article for article in articles if article['category'] is not None]\n    articles = [article for article in articles if article['published_time'] is not None]\n    articles = [article for article in articles if article['category'] is not None]\n    articles = [article for article in articles if article['published_time'] is not None]\n    articles = [article for article in articles if article['category'] is not None]\n    articles = [article for article in articles if article['published_time'] is not None]\n    articles = [article for article in articles if article['category'] is not None]\n    articles = [article for article in articles if article['published_time'] is not None]\n    articles = [article for article in articles if article['category'] is not None]\n    articles = [article for article in articles if article['published_time'] is not None]\n    articles = [article for article in articles if article['category'] is not None]\n    articles = [article for article in articles if article['published_time'] is not None]\n    articles = [article for article in articles if article['category'] is not None]\n    articles = [article for article in articles if article['published_time'] is not None]\n    articles = [article for article in articles if article['category'] is not None]\n    articles = [article for article in articles if article['published_time'] is not None]\n    articles = [article for article in articles if article['category'] is not None]\n    articles = [article for article in articles if article['published_time'] is not None]\n    articles = [article for article in articles if article['category'] is not None]\n    articles = [article for article in articles if article['published_time'] is not None]\n    articles = [article for article in articles if article['category'] is not None]\n    articles = [article for article in articles if article['published_time'] is not None]\n    articles = [article for article in articles if article['category'] is not None]\n    articles = [article for article in articles if article['published_time'] is not None]\n    articles = [article for article in articles if article['category'] is not None]\n    articles = [article for article in articles if article['published_time'] is not None]\n    articles = [article for article in articles if article['category'] is not None]\n    articles = [article for article in articles if article['published_time'] is not None]\n    articles = [article for article in articles if article['category'] is not None]\n    articles = [article for article in articles if article['published_time'] is not None]\n    articles = [article for article in articles if article['category'] is not None]\n    articles = [article for article in articles if article['published_time'] is not None]\n    articles = [article for article in articles if article['category'] is not None]\n    articles = [article for article in articles if article['published_time'] is not None]", "raw_solution": "import pandas as pd\nimport pytz\n\ndef task_func(articles, timezone):\n    if not isinstance(articles, list) or not all(isinstance(article, dict) for article in articles):\n        raise TypeError(\"articles is not a list of dictionaries\")\n    if not articles:\n        raise ValueError(\"empty list is passed as articles\")\n    if not all(key in article for key in ['published_time', 'category'] for article in articles):\n        raise ValueError(\"dictionary keys do not match the requirements\")\n    timezone = pytz.timezone(timezone)\n    articles = [article for article in articles if article['published_time'] is not None]\n    articles = [article for article in articles if article['category'] is not None]\n    articles = [article for article in articles if article['published_time'] is not None]\n    articles = [article for article in articles if article['category'] is not None]\n    articles = [article for article in articles if article['published_time'] is not None]\n    articles = [article for article in articles if article['category'] is not None]\n    articles = [article for article in articles if article['published_time'] is not None]\n    articles = [article for article in articles if article['category'] is not None]\n    articles = [article for article in articles if article['published_time'] is not None]\n    articles = [article for article in articles if article['category'] is not None]\n    articles = [article for article in articles if article['published_time'] is not None]\n    articles = [article for article in articles if article['category'] is not None]\n    articles = [article for article in articles if article['published_time'] is not None]\n    articles = [article for article in articles if article['category'] is not None]\n    articles = [article for article in articles if article['published_time'] is not None]\n    articles = [article for article in articles if article['category'] is not None]\n    articles = [article for article in articles if article['published_time'] is not None]\n    articles = [article for article in articles if article['category'] is not None]\n    articles = [article for article in articles if article['published_time'] is not None]\n    articles = [article for article in articles if article['category'] is not None]\n    articles = [article for article in articles if article['published_time'] is not None]\n    articles = [article for article in articles if article['category'] is not None]\n    articles = [article for article in articles if article['published_time'] is not None]\n    articles = [article for article in articles if article['category'] is not None]\n    articles = [article for article in articles if article['published_time'] is not None]\n    articles = [article for article in articles if article['category'] is not None]\n    articles = [article for article in articles if article['published_time'] is not None]\n    articles = [article for article in articles if article['category'] is not None]\n    articles = [article for article in articles if article['published_time'] is not None]\n    articles = [article for article in articles if article['category'] is not None]\n    articles = [article for article in articles if article['published_time'] is not None]\n    articles = [article for article in articles if article['category'] is not None]\n    articles = [article for article in articles if article['published_time'] is not None]\n    articles = [article for article in articles if article['category'] is not None]\n    articles = [article for article in articles if article['published_time'] is not None]\n    articles = [article for article in articles if article['category'] is not None]\n    articles = [article for article in articles if article['published_time'] is not None]\n    articles = [article for article in articles if article['category'] is not None]\n    articles = [article for article in articles if article['published_time'] is not None]\n    articles = [article for article in articles if article['category'] is not None]\n    articles = [article for article in articles if article['published_time'] is not None]\n    articles = [article for article in articles if article['category'] is not None]\n    articles = [article for article in articles if article['published_time'] is not None]\n    articles = [article for article in articles if article['category'] is not None]\n    articles = [article for article in articles if article['published_time'] is not None]\n    articles = [article for article in articles if article['category'] is not None]\n    articles = [article for article in articles if article['published_time'] is not None]\n    articles = [article for article in articles if article['category'] is not None]\n    articles = [article for article in articles if article['published_time'] is not None]\n    articles = [article for article in articles if article['category'] is not None]\n    articles = [article for article in articles if article['published_time'] is not None]\n    articles = [article for article in articles if article['category'] is not None]\n    articles = [article for article in articles if article['published_time'] is not None]\n    articles = [article for article in articles if article['category'] is not None]\n    articles = [article for article in articles if article['published_time'] is not None]\n    articles = [article for article in articles if article['category'] is not None]\n    articles = [article for article in articles if article['published_time'] is not None]\n    articles = [article for article in articles if article['category'] is not None]\n    articles = [article for article in articles if article['published_time'] is not None]\n    articles = [article for article in articles if article['category'] is not None]\n    articles = [article for article in articles if article['published_time'] is not None]\n    articles = [article for article in articles if article['category'] is not None]\n    articles = [article for article in articles if article['published_time'] is not None]\n    articles = ["}
{"task_id": "BigCodeBench/781", "solution": "import os\nfrom datetime import datetime\ndef task_func(filepath: str) -> dict:\n    if not os.path.exists(filepath):\n        return {'size': 0, 'date': '0000-00-00 00:00:00'}\n    size = os.path.getsize(filepath)\n    date = datetime.fromtimestamp(os.path.getmtime(filepath)).strftime('%Y-%m-%d %H:%M:%S')\n    return {'size': size, 'date': date}", "raw_solution": "import os\nfrom datetime import datetime\n\ndef task_func(filepath: str) -> dict:\n    if not os.path.exists(filepath):\n        return {'size': 0, 'date': '0000-00-00 00:00:00'}\n    size = os.path.getsize(filepath)\n    date = datetime.fromtimestamp(os.path.getmtime(filepath)).strftime('%Y-%m-%d %H:%M:%S')\n    return {'size': size, 'date': date}\n```"}
{"task_id": "BigCodeBench/782", "solution": "import random\nimport pandas as pd\nimport numpy as np\ndef task_func(n,\n          domain=\"samplewebsite.com\",\n          categories=['Sports', 'Technology', 'Health', 'Science', 'Business'],\n          random_seed=None):\n    if random_seed is not None:\n        random.seed(random_seed)\n    df = pd.DataFrame(columns=['title', 'title_url', 'id', 'category', 'views'])\n    for i in range(n):\n        title = f\"Article {i}\"\n        title_url = f\"{domain}/{title}\"\n        id = i\n        category = random.choice(categories)\n        views = np.random.poisson(lam=1000)\n        df = df.append({'title': title, 'title_url': title_url, 'id': id, 'category': category, 'views': views}, ignore_index=True)\n    return df", "raw_solution": "import random\nimport pandas as pd\nimport numpy as np\n\ndef task_func(n,\n          domain=\"samplewebsite.com\",\n          categories=['Sports', 'Technology', 'Health', 'Science', 'Business'],\n          random_seed=None):\n    if random_seed is not None:\n        random.seed(random_seed)\n    df = pd.DataFrame(columns=['title', 'title_url', 'id', 'category', 'views'])\n    for i in range(n):\n        title = f\"Article {i}\"\n        title_url = f\"{domain}/{title}\"\n        id = i\n        category = random.choice(categories)\n        views = np.random.poisson(lam=1000)\n        df = df.append({'title': title, 'title_url': title_url, 'id': id, 'category': category, 'views': views}, ignore_index=True)\n    return df\n```"}
{"task_id": "BigCodeBench/783", "solution": "import os\nimport shutil\ndef task_func(src_dir, dest_dir, extension):\n    files_moved = 0\n    for root, dirs, files in os.walk(src_dir):\n        for file in files:\n            if file.endswith(extension):\n                src_path = os.path.join(root, file)\n                dest_path = os.path.join(dest_dir, file)\n                shutil.move(src_path, dest_path)\n                files_moved += 1\n    return files_moved", "raw_solution": "import os\nimport shutil\n\ndef task_func(src_dir, dest_dir, extension):\n    files_moved = 0\n    for root, dirs, files in os.walk(src_dir):\n        for file in files:\n            if file.endswith(extension):\n                src_path = os.path.join(root, file)\n                dest_path = os.path.join(dest_dir, file)\n                shutil.move(src_path, dest_path)\n                files_moved += 1\n    return files_moved\n```"}
{"task_id": "BigCodeBench/784", "solution": "import pandas as pd\nimport random\nimport csv\ndef task_func(n, \n           categories=['Sports', 'Technology', 'Business', 'Politics', 'Entertainment'],\n           news_sites=['New York Times', 'USA Today', 'Apple News', 'CNN', 'BBC'],\n           likert_scale=['Strongly Disagree', 'Disagree', 'Neither Agree nor Disagree', 'Agree', 'Strongly Agree'],\n           file_path='news_survey_data.csv',\n           random_seed=None):\n    if random_seed is not None:\n        random.seed(random_seed)\n    df = pd.DataFrame(columns=['Site', 'Category', 'Response', 'Value'])\n    for i in range(n):\n        site = random.choice(news_sites)\n        category = random.choice(categories)\n        response = random.choice(likert_scale)\n        value = random.randint(1, 5)\n        df = df.append({'Site': site, 'Category': category, 'Response': response, 'Value': value}, ignore_index=True)\n    df.to_csv(file_path, index=False)\n    return df", "raw_solution": "import pandas as pd\nimport random\nimport csv\n\ndef task_func(n, \n           categories=['Sports', 'Technology', 'Business', 'Politics', 'Entertainment'],\n           news_sites=['New York Times', 'USA Today', 'Apple News', 'CNN', 'BBC'],\n           likert_scale=['Strongly Disagree', 'Disagree', 'Neither Agree nor Disagree', 'Agree', 'Strongly Agree'],\n           file_path='news_survey_data.csv',\n           random_seed=None):\n    if random_seed is not None:\n        random.seed(random_seed)\n    df = pd.DataFrame(columns=['Site', 'Category', 'Response', 'Value'])\n    for i in range(n):\n        site = random.choice(news_sites)\n        category = random.choice(categories)\n        response = random.choice(likert_scale)\n        value = random.randint(1, 5)\n        df = df.append({'Site': site, 'Category': category, 'Response': response, 'Value': value}, ignore_index=True)\n    df.to_csv(file_path, index=False)\n    return df\n```"}
{"task_id": "BigCodeBench/785", "solution": "import subprocess\nimport os\nimport glob\nARCHIVE_DIR = '/tmp/archive'\ndef task_func(pattern):\n    # Create archive directory if it does not exist\n    if not os.path.exists(ARCHIVE_DIR):\n        os.makedirs(ARCHIVE_DIR)\n    # Create archive file path\n    archive_file = os.path.join(ARCHIVE_DIR, 'archive.tar.gz')\n    # Create archive\n    subprocess.run(['tar', '-czvf', archive_file, pattern])\n    # Delete original files\n    for file in glob.glob(pattern):\n        os.remove(file)\n    return archive_file", "raw_solution": "import subprocess\nimport os\nimport glob\n# Constants\nARCHIVE_DIR = '/tmp/archive'\ndef task_func(pattern):\n    # Create archive directory if it does not exist\n    if not os.path.exists(ARCHIVE_DIR):\n        os.makedirs(ARCHIVE_DIR)\n    # Create archive file path\n    archive_file = os.path.join(ARCHIVE_DIR, 'archive.tar.gz')\n    # Create archive\n    subprocess.run(['tar', '-czvf', archive_file, pattern])\n    # Delete original files\n    for file in glob.glob(pattern):\n        os.remove(file)\n    return archive_file\n```"}
{"task_id": "BigCodeBench/786", "solution": "import pandas as pd\nimport csv\nimport random\ndef task_func(\n    n, \n    countries=['USA', 'UK', 'China', 'India', 'Germany'], \n    products=['Product A', 'Product B', 'Product C', 'Product D', 'Product E'], \n    output_path=None,\n    random_seed=None):\n    random.seed(random_seed)\n    df = pd.DataFrame({\n        'Country': random.choices(countries, k=n),\n        'Product': random.choices(products, k=n),\n        'Sales': [random.randint(1, 100) for _ in range(n)]\n    })\n    if output_path:\n        df.to_csv(output_path, index=False)\n    return df", "raw_solution": "import pandas as pd\nimport csv\nimport random\n\ndef task_func(\n    n, \n    countries=['USA', 'UK', 'China', 'India', 'Germany'], \n    products=['Product A', 'Product B', 'Product C', 'Product D', 'Product E'], \n    output_path=None,\n    random_seed=None):\n    random.seed(random_seed)\n    df = pd.DataFrame({\n        'Country': random.choices(countries, k=n),\n        'Product': random.choices(products, k=n),\n        'Sales': [random.randint(1, 100) for _ in range(n)]\n    })\n    if output_path:\n        df.to_csv(output_path, index=False)\n    return df\n```"}
{"task_id": "BigCodeBench/787", "solution": "import numpy as np\nfrom itertools import combinations\ndef task_func(array1, array2):\n    if len(array1) != len(array2):\n        raise ValueError(\"If the input arrays have different lengths.\")\n    max_distance = 0\n    for point1, point2 in combinations(zip(array1, array2), 2):\n        distance = np.linalg.norm(np.array(point1) - np.array(point2))\n        if distance > max_distance:\n            max_distance = distance\n    return max_distance", "raw_solution": "import numpy as np\nfrom itertools import combinations\n\ndef task_func(array1, array2):\n    if len(array1) != len(array2):\n        raise ValueError(\"If the input arrays have different lengths.\")\n    max_distance = 0\n    for point1, point2 in combinations(zip(array1, array2), 2):\n        distance = np.linalg.norm(np.array(point1) - np.array(point2))\n        if distance > max_distance:\n            max_distance = distance\n    return max_distance\n```"}
{"task_id": "BigCodeBench/788", "solution": "import heapq\nfrom scipy import stats\ndef task_func(df, col1, col2, N=10):\n    if col1 not in df.columns or col2 not in df.columns:\n        raise ValueError(\"If specified columns are not in the provided DataFrame.\")\n    if N <= 1:\n        raise ValueError(\"If N is <= 1.\")\n    diff = abs(df[col1] - df[col2])\n    largest_diff = heapq.nlargest(N, diff)\n    t_statistic, p_value = stats.ttest_ind(df[col1][diff.isin(largest_diff)], df[col2][diff.isin(largest_diff)])\n    return p_value", "raw_solution": "import heapq\nfrom scipy import stats\ndef task_func(df, col1, col2, N=10):\n    if col1 not in df.columns or col2 not in df.columns:\n        raise ValueError(\"If specified columns are not in the provided DataFrame.\")\n    if N <= 1:\n        raise ValueError(\"If N is <= 1.\")\n    diff = abs(df[col1] - df[col2])\n    largest_diff = heapq.nlargest(N, diff)\n    t_statistic, p_value = stats.ttest_ind(df[col1][diff.isin(largest_diff)], df[col2][diff.isin(largest_diff)])\n    return p_value\n```"}
{"task_id": "BigCodeBench/789", "solution": "import numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\nARRAY_LENGTH = 10\ndef task_func():\n    # Generate a random array\n    array = np.random.rand(ARRAY_LENGTH)\n    # Create a MinMaxScaler object\n    scaler = MinMaxScaler()\n    # Fit and transform the array\n    scaled_array = scaler.fit_transform(array.reshape(-1, 1))\n    return scaled_array", "raw_solution": "import numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\n# Constants\nARRAY_LENGTH = 10\ndef task_func():\n    # Generate a random array\n    array = np.random.rand(ARRAY_LENGTH)\n    # Create a MinMaxScaler object\n    scaler = MinMaxScaler()\n    # Fit and transform the array\n    scaled_array = scaler.fit_transform(array.reshape(-1, 1))\n    return scaled_array\n```"}
{"task_id": "BigCodeBench/790", "solution": "import heapq\nfrom sklearn.preprocessing import StandardScaler\ndef task_func(df, col1, col2, N=10):\n    if col1 not in df.columns or col2 not in df.columns:\n        raise ValueError(\"If specified columns are not in the provided DataFrame.\")\n    scaler = StandardScaler()\n    df[col1] = scaler.fit_transform(df[col1].values.reshape(-1, 1))\n    df[col2] = scaler.fit_transform(df[col2].values.reshape(-1, 1))\n    diff = df[col1] - df[col2]\n    indices = heapq.nlargest(N, range(len(diff)), key=lambda i: diff.iloc[i])\n    return indices", "raw_solution": "import heapq\nfrom sklearn.preprocessing import StandardScaler\ndef task_func(df, col1, col2, N=10):\n    if col1 not in df.columns or col2 not in df.columns:\n        raise ValueError(\"If specified columns are not in the provided DataFrame.\")\n    scaler = StandardScaler()\n    df[col1] = scaler.fit_transform(df[col1].values.reshape(-1, 1))\n    df[col2] = scaler.fit_transform(df[col2].values.reshape(-1, 1))\n    diff = df[col1] - df[col2]\n    indices = heapq.nlargest(N, range(len(diff)), key=lambda i: diff.iloc[i])\n    return indices\n```"}
{"task_id": "BigCodeBench/791", "solution": "from collections import Counter\nimport random\nfrom itertools import cycle\ndef task_func(l):\n    # Create a counter from the list\n    counter = Counter(l)\n    \n    # Shuffle the list\n    shuffled_list = random.sample(l, len(l))\n    \n    # Cycle the shuffled list\n    cycled_list = cycle(shuffled_list)\n    \n    # Move the first 3 elements to the end of the list", "raw_solution": "from collections import Counter\nimport random\nfrom itertools import cycle\n\n# Constants\nELEMENTS = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J']\n\ndef task_func(l):\n    # Create a counter from the list\n    counter = Counter(l)\n    \n    # Shuffle the list\n    shuffled_list = random.sample(l, len(l))\n    \n    # Cycle the shuffled list\n    cycled_list = cycle(shuffled_list)\n    \n    # Move the first 3 elements to the end of the list\n    first_3_elements = next(cycled_list) for _ in range(3)\n    remaining_elements = [next(cycled_list) for _ in range(len(l) - 3)]\n    cycled_list = cycle(first_3_elements + remaining_elements)\n    \n    # Return the counter\n    return counter\n```"}
{"task_id": "BigCodeBench/792", "solution": "import heapq\nfrom sklearn.linear_model import LinearRegression\ndef task_func(df, feature, target, n=10):\n    if feature not in df.columns or target not in df.columns:\n        raise ValueError(\"If specified columns are not in the provided DataFrame.\")\n    X = df[[feature]]\n    y = df[[target]]\n    model = LinearRegression()\n    model.fit(X, y)\n    residuals = model.predict(X) - y\n    indices = heapq.nlargest(n, range(len(residuals)), key=lambda i: residuals[i])\n    return indices, model", "raw_solution": "import heapq\nfrom sklearn.linear_model import LinearRegression\ndef task_func(df, feature, target, n=10):\n    if feature not in df.columns or target not in df.columns:\n        raise ValueError(\"If specified columns are not in the provided DataFrame.\")\n    X = df[[feature]]\n    y = df[[target]]\n    model = LinearRegression()\n    model.fit(X, y)\n    residuals = model.predict(X) - y\n    indices = heapq.nlargest(n, range(len(residuals)), key=lambda i: residuals[i])\n    return indices, model\n```"}
{"task_id": "BigCodeBench/793", "solution": "import numpy as np\nimport random\nELEMENTS = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J']\ndef task_func(l=None):\n    if l is None:\n        l = random.sample(ELEMENTS, 10)\n    arr = np.array(l)\n    arr = np.roll(arr, 3)\n    return arr", "raw_solution": "import numpy as np\nimport random\n# Constants\nELEMENTS = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J']\ndef task_func(l=None):\n    if l is None:\n        l = random.sample(ELEMENTS, 10)\n    arr = np.array(l)\n    arr = np.roll(arr, 3)\n    return arr\n```"}
{"task_id": "BigCodeBench/794", "solution": "import string\nimport random\ndef task_func(length, random_seed=None):\n    if random_seed is not None:\n        random.seed(random_seed)\n    BRACKETS = \"(){}[]\"\n    string = \"\"\n    for i in range(length):\n        if random.random() < 0.5:\n            string += random.choice(BRACKETS)\n        else:\n            string += random.choice(string.ascii_lowercase)\n    return string", "raw_solution": "import string\nimport random\n\ndef task_func(length, random_seed=None):\n    if random_seed is not None:\n        random.seed(random_seed)\n    BRACKETS = \"(){}[]\"\n    string = \"\"\n    for i in range(length):\n        if random.random() < 0.5:\n            string += random.choice(BRACKETS)\n        else:\n            string += random.choice(string.ascii_lowercase)\n    return string\n```"}
{"task_id": "BigCodeBench/795", "solution": "from collections import deque\nimport math\ndef task_func(l):\n    dq = deque(l)\n    dq.rotate(3)\n    if any(isinstance(i, (int, float)) for i in dq):\n        print(math.sqrt(sum(dq)))\n    return dq", "raw_solution": "from collections import deque\nimport math\n\ndef task_func(l):\n    dq = deque(l)\n    dq.rotate(3)\n    if any(isinstance(i, (int, float)) for i in dq):\n        print(math.sqrt(sum(dq)))\n    return dq\n```"}
{"task_id": "BigCodeBench/796", "solution": "import os\nimport re\nBRACKET_PATTERN = '[(){}\\\\[\\\\]]'\ndef task_func(directory):\n    file_paths = []\n    for root, dirs, files in os.walk(directory):\n        for file in files:\n            if re.search(BRACKET_PATTERN, file):\n                file_paths.append(os.path.join(root, file))\n    return file_paths", "raw_solution": "import os\nimport re\n\nBRACKET_PATTERN = '[(){}\\\\[\\\\]]'\n\ndef task_func(directory):\n    file_paths = []\n    for root, dirs, files in os.walk(directory):\n        for file in files:\n            if re.search(BRACKET_PATTERN, file):\n                file_paths.append(os.path.join(root, file))\n    return file_paths\n```"}
{"task_id": "BigCodeBench/797", "solution": "import re\nimport pandas as pd\ndef task_func(df: pd.DataFrame) -> int:\n    if not isinstance(df, pd.DataFrame):\n        raise TypeError('If input is not a DataFrame')\n    pattern = r'\\(\\)|\\{\\}|[\\[\\]]'\n    return len(re.findall(pattern, df['Test'].str.cat()))", "raw_solution": "import re\nimport pandas as pd\n\ndef task_func(df: pd.DataFrame) -> int:\n    if not isinstance(df, pd.DataFrame):\n        raise TypeError('If input is not a DataFrame')\n    pattern = r'\\(\\)|\\{\\}|[\\[\\]]'\n    return len(re.findall(pattern, df['Test'].str.cat()))\n```"}
{"task_id": "BigCodeBench/798", "solution": "import os\nimport shutil\nBACKUP_DIR = '/tmp/backup'\ndef task_func(directory):\n    if not os.path.exists(BACKUP_DIR):\n        return 'Backup directory {} does not exist. Cannot rollback update.'.format(BACKUP_DIR)\n    if not os.path.exists(directory):\n        return 'Directory {} does not exist. Cannot rollback update.'.format(directory)\n    try:\n        shutil.rmtree(directory)\n        os.rename(BACKUP_DIR, directory)\n        return directory\n    except Exception as e:\n        return 'Failed to rollback update: {}'.format(e)", "raw_solution": "import os\nimport shutil\n# Constants\nBACKUP_DIR = '/tmp/backup'\ndef task_func(directory):\n    if not os.path.exists(BACKUP_DIR):\n        return 'Backup directory {} does not exist. Cannot rollback update.'.format(BACKUP_DIR)\n    if not os.path.exists(directory):\n        return 'Directory {} does not exist. Cannot rollback update.'.format(directory)\n    try:\n        shutil.rmtree(directory)\n        os.rename(BACKUP_DIR, directory)\n        return directory\n    except Exception as e:\n        return 'Failed to rollback update: {}'.format(e)\n```"}
{"task_id": "BigCodeBench/799", "solution": "import pandas as pd\nfrom random import seed, choices\ndef task_func(L, num_dataframes=5, random_seed=None):\n    if not L:\n        return pd.DataFrame()\n    seed(random_seed)\n    df_list = []\n    for i in range(num_dataframes):\n        df = pd.DataFrame(choices(L, k=3))\n        df.columns = [chr(ord('a') + i) for i in range(3)]\n        df_list.append(df)\n    common_rows = df_list[0]\n    for df in df_list[1:]:\n        common_rows = common_rows[common_rows.isin(df)]\n    return common_rows, df_list", "raw_solution": "import pandas as pd\nfrom random import seed, choices\n\ndef task_func(L, num_dataframes=5, random_seed=None):\n    if not L:\n        return pd.DataFrame()\n    seed(random_seed)\n    df_list = []\n    for i in range(num_dataframes):\n        df = pd.DataFrame(choices(L, k=3))\n        df.columns = [chr(ord('a') + i) for i in range(3)]\n        df_list.append(df)\n    common_rows = df_list[0]\n    for df in df_list[1:]:\n        common_rows = common_rows[common_rows.isin(df)]\n    return common_rows, df_list\n```"}
{"task_id": "BigCodeBench/800", "solution": "import csv\nimport os\nfrom collections import Counter\nCSV_FILE_PATH = 'match_data.csv'\ndef task_func(goals, penalties, csv_file_path=CSV_FILE_PATH):\n    with open(csv_file_path, 'r') as file:\n        reader = csv.reader(file)\n        data = list(reader)\n    goals = Counter([row[1] for row in data])\n    penalties = Counter([row[2] for row in data])\n    goals.update(goals)\n    penalties.update(penalties)\n    return goals, penalties", "raw_solution": "import csv\nimport os\nfrom collections import Counter\n# Constants\nCSV_FILE_PATH = 'match_data.csv'\ndef create_test_csv(filename, content):\n    with open(filename, 'w', newline='') as file:\n        writer = csv.writer(file)\n        writer.writerows(content)\n# Example usage in a test setup:\ndef setup_csv():\n    content = [\n        ['team', 'goals', 'penalties'],\n        ['Team A', '2', '1'],\n        ['Team B', '1', '2'],\n        ['Team C', '3', '0']\n    ]\n    create_test_csv('test_data/test_case_2.csv', content)\ndef task_func(goals, penalties, csv_file_path=CSV_FILE_PATH):\n    with open(csv_file_path, 'r') as file:\n        reader = csv.reader(file)\n        data = list(reader)\n    goals = Counter([row[1] for row in data])\n    penalties = Counter([row[2] for row in data])\n    goals.update(goals)\n    penalties.update(penalties)\n    return goals, penalties\n```"}
{"task_id": "BigCodeBench/801", "solution": "import collections\nimport numpy as np\ndef task_func(file_name):\n    if not file_name:\n        return {}\n    with open(file_name, 'r') as f:\n        lines = f.readlines()\n    if not lines:\n        return {}\n    columns = lines[0].strip().split(',')\n    counts = {col: collections.Counter() for col in columns}\n    for line in lines[1:]:\n        values = line.strip().split(',')\n        for i, col in enumerate(columns):\n            counts[col][values[i]] += 1\n    most_common = {col: counts[col].most_common(1)[0][0] for col in columns}\n    return most_common", "raw_solution": "import collections\nimport numpy as np\ndef task_func(file_name):\n    if not file_name:\n        return {}\n    with open(file_name, 'r') as f:\n        lines = f.readlines()\n    if not lines:\n        return {}\n    columns = lines[0].strip().split(',')\n    counts = {col: collections.Counter() for col in columns}\n    for line in lines[1:]:\n        values = line.strip().split(',')\n        for i, col in enumerate(columns):\n            counts[col][values[i]] += 1\n    most_common = {col: counts[col].most_common(1)[0][0] for col in columns}\n    return most_common\n```"}
{"task_id": "BigCodeBench/802", "solution": "import numpy as np\nimport itertools\ndef task_func(dimension, seed=42):\n    np.random.seed(seed)\n    matrix = np.random.randint(1, 101, size=(dimension, dimension))\n    flat_list = list(itertools.chain(*matrix))\n    return matrix, flat_list", "raw_solution": "import numpy as np\nimport itertools\ndef task_func(dimension, seed=42):\n    np.random.seed(seed)\n    matrix = np.random.randint(1, 101, size=(dimension, dimension))\n    flat_list = list(itertools.chain(*matrix))\n    return matrix, flat_list\n```"}
{"task_id": "BigCodeBench/803", "solution": "import pandas as pd\nfrom sklearn.preprocessing import MinMaxScaler\ndef task_func(file_name: str) -> pd.DataFrame:\n    df = pd.read_csv(file_name)\n    numeric_columns = df.select_dtypes(include=['number']).columns\n    scaler = MinMaxScaler()\n    df[numeric_columns] = scaler.fit_transform(df[numeric_columns])\n    return df", "raw_solution": "import pandas as pd\nfrom sklearn.preprocessing import MinMaxScaler\n\ndef task_func(file_name: str) -> pd.DataFrame:\n    df = pd.read_csv(file_name)\n    numeric_columns = df.select_dtypes(include=['number']).columns\n    scaler = MinMaxScaler()\n    df[numeric_columns] = scaler.fit_transform(df[numeric_columns])\n    return df\n```"}
{"task_id": "BigCodeBench/804", "solution": "import os\nfrom datetime import datetime\nLOG_DIR = './logs'\ndef task_func(metrics, filename, log_dir=LOG_DIR):\n    # Create log directory if it does not exist\n    if not os.path.exists(log_dir):\n        os.makedirs(log_dir)\n    # Create log file if it does not exist\n    log_file = os.path.join(log_dir, filename)\n    if not os.path.exists(log_file):\n        with open(log_file, 'w') as f:\n            f.write('')\n    # Write metrics to log file\n    with open(log_file, 'a') as f:\n        f.write(f'{datetime.now()} - {metrics}\\n')\n    # Return True if metrics were successfully written to the file, False otherwise\n    return os.path.exists(log_file)", "raw_solution": "import os\nfrom datetime import datetime\n# Constants\nLOG_DIR = './logs'\ndef task_func(metrics, filename, log_dir=LOG_DIR):\n    # Create log directory if it does not exist\n    if not os.path.exists(log_dir):\n        os.makedirs(log_dir)\n    # Create log file if it does not exist\n    log_file = os.path.join(log_dir, filename)\n    if not os.path.exists(log_file):\n        with open(log_file, 'w') as f:\n            f.write('')\n    # Write metrics to log file\n    with open(log_file, 'a') as f:\n        f.write(f'{datetime.now()} - {metrics}\\n')\n    # Return True if metrics were successfully written to the file, False otherwise\n    return os.path.exists(log_file)\n```"}
{"task_id": "BigCodeBench/805", "solution": "import pandas as pd\nimport random\ndef task_func(dictionary, item, seed):\n    random.seed(seed)\n    df = pd.DataFrame(dictionary)\n    locations = [(i, j) for i, row in df.iterrows() for j, val in row.items() if val == item]\n    count = len(locations)\n    for i, j in locations:\n        df.at[i, j] += random.randint(0, 9)\n    return locations, count, df", "raw_solution": "import pandas as pd\nimport random\n\ndef task_func(dictionary, item, seed):\n    random.seed(seed)\n    df = pd.DataFrame(dictionary)\n    locations = [(i, j) for i, row in df.iterrows() for j, val in row.items() if val == item]\n    count = len(locations)\n    for i, j in locations:\n        df.at[i, j] += random.randint(0, 9)\n    return locations, count, df\n```"}
{"task_id": "BigCodeBench/806", "solution": "import re\nimport nltk\nfrom nltk.corpus import stopwords\nfrom collections import Counter\nSTOPWORDS = set(stopwords.words('english'))\ndef task_func(text, n=2):\n    # Remove punctuation and convert to lowercase\n    text = re.sub(r'[^\\w\\s]', '', text).lower()\n    # Remove stopwords\n    text = ' '.join([word for word in text.split() if word not in STOPWORDS])\n    # Generate n-grams\n    ngrams = nltk.ngrams(text.split(), n)\n    # Count n-grams\n    ngram_counts = Counter(ngrams)\n    return ngram_counts", "raw_solution": "import re\nimport nltk\nnltk.download('stopwords')\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n# Constants\nSTOPWORDS = set(stopwords.words('english'))\ndef task_func(text, n=2):\n    # Remove punctuation and convert to lowercase\n    text = re.sub(r'[^\\w\\s]', '', text).lower()\n    # Remove stopwords\n    text = ' '.join([word for word in text.split() if word not in STOPWORDS])\n    # Generate n-grams\n    ngrams = nltk.ngrams(text.split(), n)\n    # Count n-grams\n    ngram_counts = Counter(ngrams)\n    return ngram_counts\n```"}
{"task_id": "BigCodeBench/807", "solution": "import numpy as np\nfrom scipy.stats import norm\ndef task_func(data: np.ndarray, threshold: float = 2.0) -> list:\n    if np.std(data) == 0:\n        return []\n    mean = np.mean(data)\n    var = np.var(data)\n    z_scores = norm.ppf((data - mean) / np.sqrt(var))\n    outliers = np.where(np.abs(z_scores) > threshold)[0]\n    return outliers.tolist()", "raw_solution": "import numpy as np\nfrom scipy.stats import norm\n\ndef task_func(data: np.ndarray, threshold: float = 2.0) -> list:\n    if np.std(data) == 0:\n        return []\n    mean = np.mean(data)\n    var = np.var(data)\n    z_scores = norm.ppf((data - mean) / np.sqrt(var))\n    outliers = np.where(np.abs(z_scores) > threshold)[0]\n    return outliers.tolist()\n```"}
{"task_id": "BigCodeBench/808", "solution": "import re\nimport nltk\nfrom nltk.corpus import stopwords\nfrom textblob import TextBlob\nSTOPWORDS = set(stopwords.words('english'))\ndef task_func(text):\n    # Remove punctuation and convert to lowercase\n    text = re.sub(r'[^\\w\\s]', '', text).lower()\n    # Remove stopwords\n    text = ' '.join([word for word in text.split() if word not in STOPWORDS])\n    # Analyze sentiment\n    blob = TextBlob(text)\n    sentiment = blob.sentiment.polarity\n    return sentiment", "raw_solution": "import re\nimport nltk\nnltk.download('stopwords')\nfrom nltk.corpus import stopwords\nfrom textblob import TextBlob\n# Constants\nSTOPWORDS = set(stopwords.words('english'))\ndef task_func(text):\n    # Remove punctuation and convert to lowercase\n    text = re.sub(r'[^\\w\\s]', '', text).lower()\n    # Remove stopwords\n    text = ' '.join([word for word in text.split() if word not in STOPWORDS])\n    # Analyze sentiment\n    blob = TextBlob(text)\n    sentiment = blob.sentiment.polarity\n    return sentiment\n```"}
{"task_id": "BigCodeBench/809", "solution": "import numpy as np\nfrom sklearn.cluster import KMeans\ndef task_func(data, n_clusters):\n    kmeans = KMeans(n_clusters=n_clusters)\n    kmeans.fit(data)\n    cluster = kmeans.labels_\n    cluster_list = list(cluster.values())\n    cluster_list.sort(key=lambda x: x[0])\n    return cluster_list", "raw_solution": "import numpy as np\nfrom sklearn.cluster import KMeans\ndef task_func(data, n_clusters):\n    kmeans = KMeans(n_clusters=n_clusters)\n    kmeans.fit(data)\n    cluster = kmeans.labels_\n    cluster_list = list(cluster.values())\n    cluster_list.sort(key=lambda x: x[0])\n    return cluster_list\n```"}
{"task_id": "BigCodeBench/810", "solution": "import re\nimport os\nimport subprocess\ndef task_func(dir_path, exe_pattern, execute_files=True):\n    # Create a list to store the results\n    results = []\n    \n    # Get all files in the directory\n    files = os.listdir(dir_path)\n    \n    # Loop through each file\n    for file in files:\n        # Check if the file matches the regular expression pattern\n        if re.match(exe_pattern, file):\n            # Construct the full path to the file\n            file_path = os.path.join(dir_path, file)\n            \n            # Check if the file is an executable\n            if os.path.isfile(file_path) and os.access(file_path, os.X_OK):\n                # Execute the file if execute_files is True\n                if execute_files:\n                    # Run the file and capture the standard output\n                    output = subprocess.run([file_path], capture_output=True, text=True)\n                    # Append the standard output to the results list\n                    results.append(output.stdout)\n                # Append the file path to the results list\n                else:\n                    results.append(file_path)\n    \n    # Return the results list\n    return results", "raw_solution": "import re\nimport os\nimport subprocess\n\ndef task_func(dir_path, exe_pattern, execute_files=True):\n    # Create a list to store the results\n    results = []\n    \n    # Get all files in the directory\n    files = os.listdir(dir_path)\n    \n    # Loop through each file\n    for file in files:\n        # Check if the file matches the regular expression pattern\n        if re.match(exe_pattern, file):\n            # Construct the full path to the file\n            file_path = os.path.join(dir_path, file)\n            \n            # Check if the file is an executable\n            if os.path.isfile(file_path) and os.access(file_path, os.X_OK):\n                # Execute the file if execute_files is True\n                if execute_files:\n                    # Run the file and capture the standard output\n                    output = subprocess.run([file_path], capture_output=True, text=True)\n                    # Append the standard output to the results list\n                    results.append(output.stdout)\n                # Append the file path to the results list\n                else:\n                    results.append(file_path)\n    \n    # Return the results list\n    return results\n```"}
{"task_id": "BigCodeBench/811", "solution": "import pandas as pd\nfrom random import randint, seed\ndef task_func(dictionary, item, sample_size=None, random_seed=None):\n    seed(random_seed)\n    df = pd.DataFrame(dictionary)\n    positions = [(i, j) for i, row in df.iterrows() for j, val in row.items() if val == item]\n    if sample_size:\n        positions = positions[randint(0, len(positions) - 1):randint(0, len(positions) - 1) + sample_size]\n    return positions, df", "raw_solution": "import pandas as pd\nfrom random import randint, seed\n\ndef task_func(dictionary, item, sample_size=None, random_seed=None):\n    seed(random_seed)\n    df = pd.DataFrame(dictionary)\n    positions = [(i, j) for i, row in df.iterrows() for j, val in row.items() if val == item]\n    if sample_size:\n        positions = positions[randint(0, len(positions) - 1):randint(0, len(positions) - 1) + sample_size]\n    return positions, df\n```"}
{"task_id": "BigCodeBench/812", "solution": "import re\nfrom pathlib import Path\nimport tarfile\nPATTERN = r\"(?<!Distillr)\\\\\\\\AcroTray\\.exe\"\nDIRECTORY = r\"C:\\\\SomeDir\\\\\"\ndef task_func(directory=DIRECTORY, file_pattern=PATTERN):\n    # Find all files that match the pattern\n    files = [f for f in Path(directory).glob(file_pattern)]\n    # Create a tar file\n    tar = tarfile.open(\"acrotray_files.tar.gz\", \"w:gz\")\n    for f in files:\n        tar.add(f)\n    tar.close()\n    return tar.name", "raw_solution": "import re\nfrom pathlib import Path\nimport tarfile\n# Constants\nPATTERN = r\"(?<!Distillr)\\\\\\\\AcroTray\\.exe\"\nDIRECTORY = r\"C:\\\\SomeDir\\\\\"\ndef task_func(directory=DIRECTORY, file_pattern=PATTERN):\n    # Find all files that match the pattern\n    files = [f for f in Path(directory).glob(file_pattern)]\n    # Create a tar file\n    tar = tarfile.open(\"acrotray_files.tar.gz\", \"w:gz\")\n    for f in files:\n        tar.add(f)\n    tar.close()\n    return tar.name\n```"}
{"task_id": "BigCodeBench/813", "solution": "from itertools import combinations\nimport pandas as pd\ndef task_func(number_list, element):\n    if not number_list:\n        return pd.DataFrame(columns=['Combinations'], index=[])\n    result = []\n    for comb in combinations(number_list, 3):\n        if sum(comb) == element:\n            result.append(comb)\n    return pd.DataFrame(result, columns=['Combinations'])", "raw_solution": "from itertools import combinations\nimport pandas as pd\n\ndef task_func(number_list, element):\n    if not number_list:\n        return pd.DataFrame(columns=['Combinations'], index=[])\n    result = []\n    for comb in combinations(number_list, 3):\n        if sum(comb) == element:\n            result.append(comb)\n    return pd.DataFrame(result, columns=['Combinations'])\n```"}
{"task_id": "BigCodeBench/814", "solution": "import re\nimport os\nimport shutil\ndef task_func(source_dir, target_dir, file_pattern=r'\\b[A-Za-z0-9]+\\.(txt|doc|docx)\\b'):\n    # Create a configuration file\n    config_file = os.path.join(target_dir, 'config.txt')\n    with open(config_file, 'w') as f:\n        for root, dirs, files in os.walk(source_dir):\n            for file in files:\n                if re.match(file_pattern, file):\n                    f.write(os.path.join(root, file) + '\\n')\n    return config_file", "raw_solution": "import re\nimport os\nimport shutil\n\ndef task_func(source_dir, target_dir, file_pattern=r'\\b[A-Za-z0-9]+\\.(txt|doc|docx)\\b'):\n    # Create a configuration file\n    config_file = os.path.join(target_dir, 'config.txt')\n    with open(config_file, 'w') as f:\n        for root, dirs, files in os.walk(source_dir):\n            for file in files:\n                if re.match(file_pattern, file):\n                    f.write(os.path.join(root, file) + '\\n')\n    return config_file\n```"}
{"task_id": "BigCodeBench/815", "solution": "import pandas as pd\nimport numpy as np\ndef task_func(test_scores, student):\n    if student not in test_scores['Student']:\n        raise ValueError('student is not present in the test_scores dataframe')\n    df = pd.DataFrame(test_scores)\n    avg_score = df[df['Student'] == student]['Score'].mean()\n    std_dev = df[df['Student'] == student]['Score'].std()\n    return np.array([avg_score, std_dev]), df", "raw_solution": "import pandas as pd\nimport numpy as np\n\ndef task_func(test_scores, student):\n    if student not in test_scores['Student']:\n        raise ValueError('student is not present in the test_scores dataframe')\n    df = pd.DataFrame(test_scores)\n    avg_score = df[df['Student'] == student]['Score'].mean()\n    std_dev = df[df['Student'] == student]['Score'].std()\n    return np.array([avg_score, std_dev]), df\n```"}
{"task_id": "BigCodeBench/816", "solution": "from collections import Counter\nimport random\nHAND_RANKS = ['2', '3', '4', '5', '6', '7', '8', '9', '10', 'J', 'Q', 'K', 'A']\nSUITS = ['H', 'D', 'C', 'S']\ndef task_func():\n    # Create a random poker hand\n    hand = [random.choice(HAND_RANKS) + random.choice(SUITS) for _ in range(5)]\n    \n    # Count the frequency of each card rank\n    rank_count = Counter(hand)\n    \n    return hand, rank_count", "raw_solution": "from collections import Counter\nimport random\n\n# Constants\nHAND_RANKS = ['2', '3', '4', '5', '6', '7', '8', '9', '10', 'J', 'Q', 'K', 'A']\nSUITS = ['H', 'D', 'C', 'S']\n\ndef task_func():\n    # Create a random poker hand\n    hand = [random.choice(HAND_RANKS) + random.choice(SUITS) for _ in range(5)]\n    \n    # Count the frequency of each card rank\n    rank_count = Counter(hand)\n    \n    return hand, rank_count\n```"}
{"task_id": "BigCodeBench/817", "solution": "from collections import Counter\nimport logging\ndef task_func(letter_list, element, log_path):\n    logging.basicConfig(filename=log_path, encoding='utf-8', level=logging.DEBUG)\n    logging.info(f\"Function called with list: {letter_list} and element: {element}\")\n    if element not in letter_list:\n        logging.error(f\"The element is not in the letter list.\")\n        raise ValueError(\"The element is not in the letter list.\")\n    element_frequency = Counter(letter_list)[element]\n    logging.info(f\"Frequency of '{element}' is {element_frequency}\")\n    logging.shutdown()\n    return element_frequency", "raw_solution": "from collections import Counter\nimport logging\n\ndef task_func(letter_list, element, log_path):\n    logging.basicConfig(filename=log_path, encoding='utf-8', level=logging.DEBUG)\n    logging.info(f\"Function called with list: {letter_list} and element: {element}\")\n    if element not in letter_list:\n        logging.error(f\"The element is not in the letter list.\")\n        raise ValueError(\"The element is not in the letter list.\")\n    element_frequency = Counter(letter_list)[element]\n    logging.info(f\"Frequency of '{element}' is {element_frequency}\")\n    logging.shutdown()\n    return element_frequency\n```"}
{"task_id": "BigCodeBench/818", "solution": "import re\nimport string\ndef task_func(text):\n    cleaned_words = re.findall(r'\\b\\w+\\b', text.lower())\n    return cleaned_words", "raw_solution": "import re\nimport string\n# Constants\nPUNCTUATION = string.punctuation\ndef task_func(text):\n    cleaned_words = re.findall(r'\\b\\w+\\b', text.lower())\n    return cleaned_words\n```"}
{"task_id": "BigCodeBench/819", "solution": "import time\nimport random\ndef task_func(iterations=5, min_delay=1.0, max_delay=2.0, seed=None):\n    if not isinstance(iterations, int) or iterations <= 0:\n        raise ValueError(\"iterations must be a positive integer\")\n    if not isinstance(min_delay, float) or min_delay <= 0:\n        raise ValueError(\"min_delay must be a positive floating point value\")\n    if not isinstance(max_delay, float) or max_delay <= 0:\n        raise ValueError(\"max_delay must be a positive floating point value\")\n    if seed is not None:\n        random.seed(seed)\n    messages = []\n    total_delay = 0.0\n    for i in range(iterations):\n        delay = random.uniform(min_delay, max_delay)\n        messages.append(f\"{delay:.2f} seconds have passed\")\n        total_delay += delay\n    return messages, total_delay", "raw_solution": "import time\nimport random\n\ndef task_func(iterations=5, min_delay=1.0, max_delay=2.0, seed=None):\n    if not isinstance(iterations, int) or iterations <= 0:\n        raise ValueError(\"iterations must be a positive integer\")\n    if not isinstance(min_delay, float) or min_delay <= 0:\n        raise ValueError(\"min_delay must be a positive floating point value\")\n    if not isinstance(max_delay, float) or max_delay <= 0:\n        raise ValueError(\"max_delay must be a positive floating point value\")\n    if seed is not None:\n        random.seed(seed)\n    messages = []\n    total_delay = 0.0\n    for i in range(iterations):\n        delay = random.uniform(min_delay, max_delay)\n        messages.append(f\"{delay:.2f} seconds have passed\")\n        total_delay += delay\n    return messages, total_delay\n```"}
{"task_id": "BigCodeBench/820", "solution": "import random\nimport string\nLETTERS = string.ascii_letters\ndef task_func(num_words, word_length):\n    if num_words < 0 or word_length < 0:\n        raise ValueError(\"If num_words or word_length is negative.\")\n    words = []\n    for _ in range(num_words):\n        word = ''.join(random.choice(LETTERS) for _ in range(word_length))\n        words.append(word)\n    return words", "raw_solution": "import random\nimport string\n# Constants\nLETTERS = string.ascii_letters\ndef task_func(num_words, word_length):\n    if num_words < 0 or word_length < 0:\n        raise ValueError(\"If num_words or word_length is negative.\")\n    words = []\n    for _ in range(num_words):\n        word = ''.join(random.choice(LETTERS) for _ in range(word_length))\n        words.append(word)\n    return words\n```"}
{"task_id": "BigCodeBench/821", "solution": "import time\nimport threading\ndef task_func(delay_time: float = 1.0, num_threads: int = 5):\n    completion_messages = []\n    threads = []\n    for i in range(num_threads):\n        thread = threading.Thread(target=delay, args=(delay_time, i))\n        threads.append(thread)\n        thread.start()\n    for thread in threads:\n        thread.join()\n        completion_messages.append(f'Delay in thread {thread.name} completed')\n    return completion_messages\ndef delay(delay_time: float, thread_id: int):\n    time.sleep(delay_time)\n    print(f'Delay in thread {thread_id} completed')", "raw_solution": "import time\nimport threading\n\ndef task_func(delay_time: float = 1.0, num_threads: int = 5):\n    completion_messages = []\n    threads = []\n    for i in range(num_threads):\n        thread = threading.Thread(target=delay, args=(delay_time, i))\n        threads.append(thread)\n        thread.start()\n    for thread in threads:\n        thread.join()\n        completion_messages.append(f'Delay in thread {thread.name} completed')\n    return completion_messages\n\ndef delay(delay_time: float, thread_id: int):\n    time.sleep(delay_time)\n    print(f'Delay in thread {thread_id} completed')\n```"}
{"task_id": "BigCodeBench/822", "solution": "import random\nimport string\nLETTERS = string.ascii_letters\nDIGITS = string.digits\ndef task_func(length, num_digits):\n    # Generate a random password with a specified length and number of digits\n    password = ''.join(random.choice(LETTERS + DIGITS) for _ in range(length))\n    # Shuffle the characters in the password to ensure variability\n    password = ''.join(random.sample(password, len(password)))\n    # Return the generated password\n    return password", "raw_solution": "import random\nimport string\n# Constants\nLETTERS = string.ascii_letters\nDIGITS = string.digits\ndef task_func(length, num_digits):\n    # Generate a random password with a specified length and number of digits\n    password = ''.join(random.choice(LETTERS + DIGITS) for _ in range(length))\n    # Shuffle the characters in the password to ensure variability\n    password = ''.join(random.sample(password, len(password)))\n    # Return the generated password\n    return password\n```"}
{"task_id": "BigCodeBench/823", "solution": "import time\nimport numpy as np\ndef task_func(samples=10, delay=0.1):\n    # Start the timer\n    start_time = time.time()\n    \n    # Perform the delay\n    for _ in range(samples):\n        time.sleep(delay)\n    \n    # Stop the timer\n    end_time = time.time()\n    \n    # Calculate the actual delay\n    actual_delay = end_time - start_time\n    \n    # Calculate the statistical properties of the delay times\n    mean_delay = actual_delay / samples\n    std_dev_delay = np.std(actual_delay)\n    \n    # Return the results\n    return (mean_delay, std_dev_delay)", "raw_solution": "import time\nimport numpy as np\n\ndef task_func(samples=10, delay=0.1):\n    # Start the timer\n    start_time = time.time()\n    \n    # Perform the delay\n    for _ in range(samples):\n        time.sleep(delay)\n    \n    # Stop the timer\n    end_time = time.time()\n    \n    # Calculate the actual delay\n    actual_delay = end_time - start_time\n    \n    # Calculate the statistical properties of the delay times\n    mean_delay = actual_delay / samples\n    std_dev_delay = np.std(actual_delay)\n    \n    # Return the results\n    return (mean_delay, std_dev_delay)\n```"}
{"task_id": "BigCodeBench/824", "solution": "import re\nimport string\ndef task_func(text):\n    words = re.findall(r'\\b\\w+\\b', text)\n    punctuation = re.findall(r'[^\\w\\s]', text)\n    return (len(words), len(punctuation))", "raw_solution": "import re\nimport string\n# Constants\nPUNCTUATION = string.punctuation\ndef task_func(text):\n    words = re.findall(r'\\b\\w+\\b', text)\n    punctuation = re.findall(r'[^\\w\\s]', text)\n    return (len(words), len(punctuation))\n```"}
{"task_id": "BigCodeBench/825", "solution": "import numpy as np\nfrom itertools import product\nimport string\ndef task_func(length, seed=None, alphabets=list(string.ascii_lowercase)):\n    np.random.seed(seed)\n    return [''.join(x) for x in product(alphabets, repeat=length)]", "raw_solution": "import numpy as np\nfrom itertools import product\nimport string\ndef task_func(length, seed=None, alphabets=list(string.ascii_lowercase)):\n    np.random.seed(seed)\n    return [''.join(x) for x in product(alphabets, repeat=length)]\n```"}
{"task_id": "BigCodeBench/826", "solution": "import re\nimport os\nimport shutil\ndef task_func(source_dir, target_dir, file_pattern=r'\\b[A-Za-z0-9]+\\.(txt|doc|docx)\\b'):\n    moved_files_count = 0\n    for file in os.listdir(source_dir):\n        if re.match(file_pattern, file):\n            source_file = os.path.join(source_dir, file)\n            target_file = os.path.join(target_dir, file)\n            shutil.move(source_file, target_file)\n            moved_files_count += 1\n    return moved_files_count", "raw_solution": "import re\nimport os\nimport shutil\n\ndef task_func(source_dir, target_dir, file_pattern=r'\\b[A-Za-z0-9]+\\.(txt|doc|docx)\\b'):\n    moved_files_count = 0\n    for file in os.listdir(source_dir):\n        if re.match(file_pattern, file):\n            source_file = os.path.join(source_dir, file)\n            target_file = os.path.join(target_dir, file)\n            shutil.move(source_file, target_file)\n            moved_files_count += 1\n    return moved_files_count\n```"}
{"task_id": "BigCodeBench/827", "solution": "import math\nfrom sympy import isprime\ndef task_func(input_list):\n    prime_list = [num for num in input_list if isprime(num)]\n    prime_list.sort(key=lambda x: math.degrees(math.atan2(0, x)))\n    return prime_list", "raw_solution": "import math\nfrom sympy import isprime\n\ndef task_func(input_list):\n    prime_list = [num for num in input_list if isprime(num)]\n    prime_list.sort(key=lambda x: math.degrees(math.atan2(0, x)))\n    return prime_list\n```"}
{"task_id": "BigCodeBench/828", "solution": "import os\nimport errno\nimport shutil\ndef task_func(filename, dest_dir):\n    try:\n        # Copy the file to the destination directory\n        shutil.copy(filename, dest_dir)\n        # Open the copied file in write mode\n        with open(os.path.join(dest_dir, os.path.basename(filename)), 'w') as f:\n            # Clear the content of the file\n            f.truncate(0)\n        # Return the absolute path to the copied file within the destination directory\n        return os.path.join(dest_dir, os.path.basename(filename))\n    except OSError as e:\n        # Raise the exception for: OSError: If the destination directory cannot be created and does not exist, or if the file cannot be copied for reasons other than a pre-existing directory.\n        if e.errno == errno.ENOENT:\n            raise OSError(f\"Destination directory {dest_dir} does not exist\")\n        elif e.errno == errno.EACCES:\n            raise OSError(f\"Permission denied to create directory {dest_dir}\")\n        elif e.errno == errno.EEXIST:\n            raise OSError(f\"File {filename} already exists in destination directory {dest_dir}\")\n        else:\n            raise OSError(f\"Error copying file {filename} to destination directory {dest_dir}: {e}\")", "raw_solution": "import os\nimport errno\nimport shutil\n\ndef task_func(filename, dest_dir):\n    try:\n        # Copy the file to the destination directory\n        shutil.copy(filename, dest_dir)\n        # Open the copied file in write mode\n        with open(os.path.join(dest_dir, os.path.basename(filename)), 'w') as f:\n            # Clear the content of the file\n            f.truncate(0)\n        # Return the absolute path to the copied file within the destination directory\n        return os.path.join(dest_dir, os.path.basename(filename))\n    except OSError as e:\n        # Raise the exception for: OSError: If the destination directory cannot be created and does not exist, or if the file cannot be copied for reasons other than a pre-existing directory.\n        if e.errno == errno.ENOENT:\n            raise OSError(f\"Destination directory {dest_dir} does not exist\")\n        elif e.errno == errno.EACCES:\n            raise OSError(f\"Permission denied to create directory {dest_dir}\")\n        elif e.errno == errno.EEXIST:\n            raise OSError(f\"File {filename} already exists in destination directory {dest_dir}\")\n        else:\n            raise OSError(f\"Error copying file {filename} to destination directory {dest_dir}: {e}\")\n```"}
{"task_id": "BigCodeBench/829", "solution": "import pandas as pd\nfrom statistics import mean\ndef task_func(df: pd.DataFrame) -> dict:\n    if 'Name' not in df.columns or 'Score' not in df.columns:\n        raise ValueError('If the DataFrame does not have the \\'Name\\' and \\'Score\\' columns.')\n    gen_dict = {}\n    for name, group in df.groupby('Name'):\n        gen_dict[name] = (name, mean(group['Score']))\n    return gen_dict", "raw_solution": "import pandas as pd\nfrom statistics import mean\ndef task_func(df: pd.DataFrame) -> dict:\n    if 'Name' not in df.columns or 'Score' not in df.columns:\n        raise ValueError('If the DataFrame does not have the \\'Name\\' and \\'Score\\' columns.')\n    gen_dict = {}\n    for name, group in df.groupby('Name'):\n        gen_dict[name] = (name, mean(group['Score']))\n    return gen_dict\n```"}
{"task_id": "BigCodeBench/830", "solution": "import json\nimport os\ndef task_func(filename, data):\n    # write the dictionary data to a file as a JSON object\n    with open(filename, 'w') as f:\n        json.dump(data, f)\n    # read the file back to verify the content\n    with open(filename, 'r') as f:\n        written_data = json.load(f)\n    # check if the file exists\n    if os.path.exists(filename):\n        return (True, written_data)\n    else:\n        return (False, None)", "raw_solution": "import json\nimport os\n\ndef task_func(filename, data):\n    # write the dictionary data to a file as a JSON object\n    with open(filename, 'w') as f:\n        json.dump(data, f)\n    # read the file back to verify the content\n    with open(filename, 'r') as f:\n        written_data = json.load(f)\n    # check if the file exists\n    if os.path.exists(filename):\n        return (True, written_data)\n    else:\n        return (False, None)\n```"}
{"task_id": "BigCodeBench/831", "solution": "import random\nimport math\ndef task_func(range_start=1, range_end=100, pairs_count=10, random_seed=None):\n    random.seed(random_seed)\n    pairs = []\n    for _ in range(pairs_count):\n        num1 = random.randint(range_start, range_end)\n        num2 = random.randint(range_start, range_end)\n        pairs.append((num1, num2, math.sqrt(abs(num1 - num2))))\n    return pairs", "raw_solution": "import random\nimport math\n\ndef task_func(range_start=1, range_end=100, pairs_count=10, random_seed=None):\n    random.seed(random_seed)\n    pairs = []\n    for _ in range(pairs_count):\n        num1 = random.randint(range_start, range_end)\n        num2 = random.randint(range_start, range_end)\n        pairs.append((num1, num2, math.sqrt(abs(num1 - num2))))\n    return pairs\n```"}
{"task_id": "BigCodeBench/832", "solution": "import pickle\nimport os\ndef task_func(filename, data):\n    if not os.path.exists(os.path.dirname(filename)):\n        os.makedirs(os.path.dirname(filename))\n    with open(filename, 'wb') as f:\n        pickle.dump(data, f)\n    return True", "raw_solution": "import pickle\nimport os\n\ndef task_func(filename, data):\n    if not os.path.exists(os.path.dirname(filename)):\n        os.makedirs(os.path.dirname(filename))\n    with open(filename, 'wb') as f:\n        pickle.dump(data, f)\n    return True\n```"}
{"task_id": "BigCodeBench/833", "solution": "import random\nfrom collections import Counter\nfrom statistics import mode\ndef task_func(list_length=1000, range_start=1, range_end=10, random_seed=None):\n    if random_seed is not None:\n        random.seed(random_seed)\n    numbers = [random.randint(range_start, range_end) for _ in range(list_length)]\n    numbers = Counter(numbers)\n    mode = mode(numbers)\n    numbers = [(num, numbers[num]) for num in numbers]\n    return mode, numbers", "raw_solution": "import random\nfrom collections import Counter\nfrom statistics import mode\n\ndef task_func(list_length=1000, range_start=1, range_end=10, random_seed=None):\n    if random_seed is not None:\n        random.seed(random_seed)\n    numbers = [random.randint(range_start, range_end) for _ in range(list_length)]\n    numbers = Counter(numbers)\n    mode = mode(numbers)\n    numbers = [(num, numbers[num]) for num in numbers]\n    return mode, numbers\n```"}
{"task_id": "BigCodeBench/834", "solution": "import binascii\nimport io\nimport gzip\ndef task_func(compressed_hex):\n    try:\n        # Convert the hexadecimal string to bytes\n        compressed_bytes = binascii.unhexlify(compressed_hex)\n        # Decompress the bytes\n        decompressed_bytes = gzip.decompress(compressed_bytes)\n        # Decode the decompressed bytes to UTF-8\n        decoded_string = decompressed_bytes.decode('utf-8')\n        return decoded_string\n    except Exception as e:\n        return str(e)", "raw_solution": "import binascii\nimport io\nimport gzip\ndef task_func(compressed_hex):\n    try:\n        # Convert the hexadecimal string to bytes\n        compressed_bytes = binascii.unhexlify(compressed_hex)\n        # Decompress the bytes\n        decompressed_bytes = gzip.decompress(compressed_bytes)\n        # Decode the decompressed bytes to UTF-8\n        decoded_string = decompressed_bytes.decode('utf-8')\n        return decoded_string\n    except Exception as e:\n        return str(e)\n```"}
{"task_id": "BigCodeBench/835", "solution": "import numpy as np\nimport pandas as pd\ndef task_func(n_rows, remove_cols, columns=['A', 'B', 'C', 'D', 'E'], random_seed=None):\n    np.random.seed(random_seed)\n    df = pd.DataFrame(np.random.randint(0, 101, (n_rows, len(columns))), columns=columns)\n    df = df.drop(columns=remove_cols)\n    return df", "raw_solution": "import numpy as np\nimport pandas as pd\ndef task_func(n_rows, remove_cols, columns=['A', 'B', 'C', 'D', 'E'], random_seed=None):\n    np.random.seed(random_seed)\n    df = pd.DataFrame(np.random.randint(0, 101, (n_rows, len(columns))), columns=columns)\n    df = df.drop(columns=remove_cols)\n    return df\n```"}
{"task_id": "BigCodeBench/836", "solution": "import os\nimport shutil\nimport csv\ndef task_func(target_value='332', csv_dir='./csv_files/', processed_dir='./processed_files/', simulate=False):\n    result = {}\n    for filename in os.listdir(csv_dir):\n        if filename.endswith('.csv'):\n            file_path = os.path.join(csv_dir, filename)\n            with open(file_path, newline='') as csvfile:\n                reader = csv.reader(csvfile)\n                for row_index, row in enumerate(reader):\n                    if row[0] == target_value:\n                        result[filename] = row_index\n                        if simulate:\n                            print(f\"Simulated moving {filename} to {processed_dir}\")\n                        else:\n                            shutil.move(file_path, os.path.join(processed_dir, filename))\n    return result", "raw_solution": "import os\nimport shutil\nimport csv\n\ndef task_func(target_value='332', csv_dir='./csv_files/', processed_dir='./processed_files/', simulate=False):\n    result = {}\n    for filename in os.listdir(csv_dir):\n        if filename.endswith('.csv'):\n            file_path = os.path.join(csv_dir, filename)\n            with open(file_path, newline='') as csvfile:\n                reader = csv.reader(csvfile)\n                for row_index, row in enumerate(reader):\n                    if row[0] == target_value:\n                        result[filename] = row_index\n                        if simulate:\n                            print(f\"Simulated moving {filename} to {processed_dir}\")\n                        else:\n                            shutil.move(file_path, os.path.join(processed_dir, filename))\n    return result\n```"}
{"task_id": "BigCodeBench/837", "solution": "import numpy as np\nimport pandas as pd\nfrom sklearn.preprocessing import StandardScaler\ndef task_func(n_rows, scale_cols, columns=['A', 'B', 'C', 'D', 'E'], random_seed=None):\n    np.random.seed(random_seed)\n    df = pd.DataFrame(np.random.rand(n_rows, len(columns)), columns=columns)\n    scaler = StandardScaler()\n    if scale_cols:\n        df[scale_cols] = scaler.fit_transform(df[scale_cols])\n    return df", "raw_solution": "import numpy as np\nimport pandas as pd\nfrom sklearn.preprocessing import StandardScaler\n\ndef task_func(n_rows, scale_cols, columns=['A', 'B', 'C', 'D', 'E'], random_seed=None):\n    np.random.seed(random_seed)\n    df = pd.DataFrame(np.random.rand(n_rows, len(columns)), columns=columns)\n    scaler = StandardScaler()\n    if scale_cols:\n        df[scale_cols] = scaler.fit_transform(df[scale_cols])\n    return df\n```"}
{"task_id": "BigCodeBench/838", "solution": "import re\nfrom nltk.stem import PorterStemmer\ndef task_func(text_series):\n    stemmer = PorterStemmer()\n    processed_series = text_series.str.lower().str.replace(r'[^a-zA-Z0-9\\s]', '').str.split().apply(lambda x: [stemmer.stem(word) for word in x])\n    return processed_series", "raw_solution": "import re\nfrom nltk.stem import PorterStemmer\n\ndef task_func(text_series):\n    stemmer = PorterStemmer()\n    processed_series = text_series.str.lower().str.replace(r'[^a-zA-Z0-9\\s]', '').str.split().apply(lambda x: [stemmer.stem(word) for word in x])\n    return processed_series\n```"}
{"task_id": "BigCodeBench/839", "solution": "import csv\nimport random\ndef task_func(file_path,\n          num_rows,\n          gender=['Male', 'Female', 'Non-Binary'],\n          countries=['USA', 'UK', 'Canada', 'Australia', 'India'],\n          seed=None):\n    if seed is not None:\n        random.seed(seed)\n    if num_rows <= 0:\n        with open(file_path, 'w', newline='') as f:\n            writer = csv.writer(f)\n            writer.writerow(['Name', 'Age', 'Gender', 'Country'])\n        return file_path\n    with open(file_path, 'w', newline='') as f:\n        writer = csv.writer(f)\n        writer.writerow(['Name', 'Age', 'Gender', 'Country'])\n        for i in range(num_rows):\n            name = ''.join(random.choices('ABCDEFGHIJKLMNOPQRSTUVWXYZ', k=5))\n            age = random.randint(20, 60)\n            gender = random.choice(gender)\n            country = random.choice(countries)\n            writer.writerow([name, age, gender, country])\n    return file_path", "raw_solution": "import csv\nimport random\n\ndef task_func(file_path,\n          num_rows,\n          gender=['Male', 'Female', 'Non-Binary'],\n          countries=['USA', 'UK', 'Canada', 'Australia', 'India'],\n          seed=None):\n    if seed is not None:\n        random.seed(seed)\n    if num_rows <= 0:\n        with open(file_path, 'w', newline='') as f:\n            writer = csv.writer(f)\n            writer.writerow(['Name', 'Age', 'Gender', 'Country'])\n        return file_path\n    with open(file_path, 'w', newline='') as f:\n        writer = csv.writer(f)\n        writer.writerow(['Name', 'Age', 'Gender', 'Country'])\n        for i in range(num_rows):\n            name = ''.join(random.choices('ABCDEFGHIJKLMNOPQRSTUVWXYZ', k=5))\n            age = random.randint(20, 60)\n            gender = random.choice(gender)\n            country = random.choice(countries)\n            writer.writerow([name, age, gender, country])\n    return file_path\n```"}
{"task_id": "BigCodeBench/840", "solution": "import pandas as pd\nimport numpy as np\ndef task_func(file_path, num_rows, data_dimensions=5, random_seed=None):\n    if random_seed is not None:\n        np.random.seed(random_seed)\n    df = pd.DataFrame(np.random.rand(num_rows, data_dimensions), columns=[f'Feature_{i+1}' for i in range(data_dimensions)])\n    df.to_csv(file_path, index=False)\n    return file_path", "raw_solution": "import pandas as pd\nimport numpy as np\ndef task_func(file_path, num_rows, data_dimensions=5, random_seed=None):\n    if random_seed is not None:\n        np.random.seed(random_seed)\n    df = pd.DataFrame(np.random.rand(num_rows, data_dimensions), columns=[f'Feature_{i+1}' for i in range(data_dimensions)])\n    df.to_csv(file_path, index=False)\n    return file_path\n```"}
{"task_id": "BigCodeBench/841", "solution": "import re\nimport json\nfrom collections import defaultdict\nimport string\ndef task_func(json_string):\n    try:\n        data = json.loads(json_string)\n        text = data['text']\n        text = text.lower()\n        text = re.sub(r'[^\\w\\s]', '', text)\n        words = text.split()\n        word_count = defaultdict(int)\n        for word in words:\n            word_count[word] += 1\n        return dict(word_count)\n    except (json.JSONDecodeError, KeyError):\n        return {}", "raw_solution": "import re\nimport json\nfrom collections import defaultdict\nimport string\n\ndef task_func(json_string):\n    try:\n        data = json.loads(json_string)\n        text = data['text']\n        text = text.lower()\n        text = re.sub(r'[^\\w\\s]', '', text)\n        words = text.split()\n        word_count = defaultdict(int)\n        for word in words:\n            word_count[word] += 1\n        return dict(word_count)\n    except (json.JSONDecodeError, KeyError):\n        return {}\n```"}
{"task_id": "BigCodeBench/842", "solution": "import sqlite3\nimport random\ndef task_func(db_path,\n          num_entries,\n          users=['Alice', 'Bob', 'Charlie', 'Dave', 'Eve'],\n          countries=['USA', 'UK', 'Canada', 'Australia', 'India'],\n          random_seed=None):\n    random.seed(random_seed)\n    conn = sqlite3.connect(db_path)\n    c = conn.cursor()\n    c.execute(\"CREATE TABLE users (id INTEGER PRIMARY KEY, name TEXT, age INTEGER, country TEXT)\")\n    for i in range(num_entries):\n        c.execute(\"INSERT INTO users (name, age, country) VALUES (?, ?, ?)\", (random.choice(users), random.randint(20, 60), random.choice(countries)))\n    conn.commit()\n    return db_path", "raw_solution": "import sqlite3\nimport random\n\ndef task_func(db_path,\n          num_entries,\n          users=['Alice', 'Bob', 'Charlie', 'Dave', 'Eve'],\n          countries=['USA', 'UK', 'Canada', 'Australia', 'India'],\n          random_seed=None):\n    random.seed(random_seed)\n    conn = sqlite3.connect(db_path)\n    c = conn.cursor()\n    c.execute(\"CREATE TABLE users (id INTEGER PRIMARY KEY, name TEXT, age INTEGER, country TEXT)\")\n    for i in range(num_entries):\n        c.execute(\"INSERT INTO users (name, age, country) VALUES (?, ?, ?)\", (random.choice(users), random.randint(20, 60), random.choice(countries)))\n    conn.commit()\n    return db_path\n```"}
{"task_id": "BigCodeBench/843", "solution": "import random\nimport re\nWORD_LIST = [\"sample\", \"text\", \"contains\", \"several\", \"words\", \"including\"]\ndef task_func(n_sentences):\n    sentences = []\n    for _ in range(n_sentences):\n        sentence = random.choice(WORD_LIST)\n        sentence = re.sub(r'[^a-z\\s]', '', sentence)\n        sentences.append(sentence)\n    return ' '.join(sentences)", "raw_solution": "import random\nimport re\n# Constants\nWORD_LIST = [\"sample\", \"text\", \"contains\", \"several\", \"words\", \"including\"]\ndef task_func(n_sentences):\n    sentences = []\n    for _ in range(n_sentences):\n        sentence = random.choice(WORD_LIST)\n        sentence = re.sub(r'[^a-z\\s]', '', sentence)\n        sentences.append(sentence)\n    return ' '.join(sentences)\n```"}
{"task_id": "BigCodeBench/844", "solution": "import csv\nimport random\nfrom faker import Faker\ndef task_func(file_path, num_rows, random_seed=None):\n    if not isinstance(num_rows, int) or num_rows < 0:\n        raise ValueError('If num_rows is not an integer >= 0.')\n    fake = Faker()\n    if random_seed is not None:\n        random.seed(random_seed)\n    with open(file_path, 'w', newline='') as file:\n        writer = csv.writer(file)\n        writer.writerow(['Name', 'Age', 'Address', 'Email'])\n        for i in range(num_rows):\n            name = fake.name()\n            age = random.randint(20, 60)\n            address = fake.address().replace('\\n', ', ')\n            email = fake.email()\n            writer.writerow([name, age, address, email])\n    return file_path", "raw_solution": "import csv\nimport random\nfrom faker import Faker\n\ndef task_func(file_path, num_rows, random_seed=None):\n    if not isinstance(num_rows, int) or num_rows < 0:\n        raise ValueError('If num_rows is not an integer >= 0.')\n    fake = Faker()\n    if random_seed is not None:\n        random.seed(random_seed)\n    with open(file_path, 'w', newline='') as file:\n        writer = csv.writer(file)\n        writer.writerow(['Name', 'Age', 'Address', 'Email'])\n        for i in range(num_rows):\n            name = fake.name()\n            age = random.randint(20, 60)\n            address = fake.address().replace('\\n', ', ')\n            email = fake.email()\n            writer.writerow([name, age, address, email])\n    return file_path\n```"}
{"task_id": "BigCodeBench/845", "solution": "import re\nimport numpy as np\nfrom collections import Counter\nfrom Levenshtein import ratio\nALPHANUMERIC = re.compile('[\\W_]+')\ndef task_func(text1, text2):\n    # Clean the texts\n    text1 = ALPHANUMERIC.sub('', text1.lower())\n    text2 = ALPHANUMERIC.sub('', text2.lower())\n    # Compute the term frequency\n    tf1 = Counter(text1.split())\n    tf2 = Counter(text2.split())\n    # Compute the cosine similarity\n    numerator = sum(tf1.get(word, 0) * tf2.get(word, 0) for word in set(tf1) & set(tf2))\n    denominator = np.sqrt(sum(tf1.values()) * sum(tf2.values()))\n    cosine_similarity = numerator / denominator if denominator != 0 else 0\n    # Compute the Levenshtein ratio\n    levenshtein_ratio = ratio(text1, text2)\n    return (cosine_similarity, levenshtein_ratio)", "raw_solution": "import re\nimport numpy as np\nfrom collections import Counter\nfrom Levenshtein import ratio\n# Constants\nALPHANUMERIC = re.compile('[\\W_]+')\ndef task_func(text1, text2):\n    # Clean the texts\n    text1 = ALPHANUMERIC.sub('', text1.lower())\n    text2 = ALPHANUMERIC.sub('', text2.lower())\n    # Compute the term frequency\n    tf1 = Counter(text1.split())\n    tf2 = Counter(text2.split())\n    # Compute the cosine similarity\n    numerator = sum(tf1.get(word, 0) * tf2.get(word, 0) for word in set(tf1) & set(tf2))\n    denominator = np.sqrt(sum(tf1.values()) * sum(tf2.values()))\n    cosine_similarity = numerator / denominator if denominator != 0 else 0\n    # Compute the Levenshtein ratio\n    levenshtein_ratio = ratio(text1, text2)\n    return (cosine_similarity, levenshtein_ratio)\n```"}
{"task_id": "BigCodeBench/846", "solution": "import collections\nimport pandas as pd\ndef task_func(obj_list, attr):\n    if not obj_list:\n        return pd.DataFrame()\n    return pd.DataFrame(collections.Counter([getattr(obj, attr) for obj in obj_list]))", "raw_solution": "import collections\nimport pandas as pd\n\ndef task_func(obj_list, attr):\n    if not obj_list:\n        return pd.DataFrame()\n    return pd.DataFrame(collections.Counter([getattr(obj, attr) for obj in obj_list]))\n```"}
{"task_id": "BigCodeBench/847", "solution": "import re\nimport os\nimport string\nimport random\ndef task_func(input_string, directory='./text_files'):\n    # Split the input string into separate strings\n    strings = input_string.split('\\n')\n    \n    # Remove special characters from each string\n    cleaned_strings = []\n    for string in strings:\n        cleaned_string = re.sub(r'[^a-zA-Z0-9\\s]', '', string)\n        cleaned_strings.append(cleaned_string)\n    \n    # Save each string as a separate text file\n    file_paths = []\n    for i, cleaned_string in enumerate(cleaned_strings):\n        file_path = os.path.join(directory, f'string_{i+1}.txt')\n        with open(file_path, 'w') as f:\n            f.write(cleaned_string)\n        file_paths.append(file_path)\n    \n    return file_paths", "raw_solution": "import re\nimport os\nimport string\nimport random\ndef task_func(input_string, directory='./text_files'):\n    # Split the input string into separate strings\n    strings = input_string.split('\\n')\n    \n    # Remove special characters from each string\n    cleaned_strings = []\n    for string in strings:\n        cleaned_string = re.sub(r'[^a-zA-Z0-9\\s]', '', string)\n        cleaned_strings.append(cleaned_string)\n    \n    # Save each string as a separate text file\n    file_paths = []\n    for i, cleaned_string in enumerate(cleaned_strings):\n        file_path = os.path.join(directory, f'string_{i+1}.txt')\n        with open(file_path, 'w') as f:\n            f.write(cleaned_string)\n        file_paths.append(file_path)\n    \n    return file_paths\n```"}
{"task_id": "BigCodeBench/848", "solution": "import heapq\nimport random\ndef task_func(obj_list, attr, top_n=5, seed=None):\n    if not obj_list:\n        return [], None\n    if seed:\n        random.seed(seed)\n    attr_values = [getattr(obj, attr) for obj in obj_list]\n    if not attr_values:\n        return [], None\n    top_values = heapq.nlargest(top_n, attr_values)\n    random_value = random.choice(attr_values)\n    return top_values, random_value", "raw_solution": "import heapq\nimport random\n\ndef task_func(obj_list, attr, top_n=5, seed=None):\n    if not obj_list:\n        return [], None\n    if seed:\n        random.seed(seed)\n    attr_values = [getattr(obj, attr) for obj in obj_list]\n    if not attr_values:\n        return [], None\n    top_values = heapq.nlargest(top_n, attr_values)\n    random_value = random.choice(attr_values)\n    return top_values, random_value\n```"}
{"task_id": "BigCodeBench/849", "solution": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\nSTOPWORDS = set(stopwords.words('english'))\ndef task_func(input_string):\n    # Remove punctuation and convert to lowercase\n    input_string = re.sub(r'[^\\w\\s]', '', input_string).lower()\n    # Split the string into individual words\n    words = input_string.split()\n    # Remove stopwords\n    words = [word for word in words if word not in STOPWORDS]\n    # Count the frequency of each word\n    word_counts = Counter(words)\n    return word_counts", "raw_solution": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\nSTOPWORDS = set(stopwords.words('english'))\ndef task_func(input_string):\n    # Remove punctuation and convert to lowercase\n    input_string = re.sub(r'[^\\w\\s]', '', input_string).lower()\n    # Split the string into individual words\n    words = input_string.split()\n    # Remove stopwords\n    words = [word for word in words if word not in STOPWORDS]\n    # Count the frequency of each word\n    word_counts = Counter(words)\n    return word_counts\n```"}
{"task_id": "BigCodeBench/850", "solution": "import pandas as pd\nimport statistics\nimport random\ndef task_func(students, subjects, seed=None):\n    if seed is not None:\n        random.seed(seed)\n    grades = {}\n    for student in students:\n        grades[student] = {}\n        for subject in subjects:\n            grades[student][subject] = random.randint(0, 100)\n    df = pd.DataFrame(grades)\n    df['Average Grade'] = df.mean(axis=1)\n    return df", "raw_solution": "import pandas as pd\nimport statistics\nimport random\n\ndef task_func(students, subjects, seed=None):\n    if seed is not None:\n        random.seed(seed)\n    grades = {}\n    for student in students:\n        grades[student] = {}\n        for subject in subjects:\n            grades[student][subject] = random.randint(0, 100)\n    df = pd.DataFrame(grades)\n    df['Average Grade'] = df.mean(axis=1)\n    return df\n```"}
{"task_id": "BigCodeBench/851", "solution": "import textwrap\nimport re\ndef task_func(input_string, width):\n    return textwrap.fill(input_string, width)", "raw_solution": "import textwrap\nimport re\ndef task_func(input_string, width):\n    return textwrap.fill(input_string, width)\n```"}
{"task_id": "BigCodeBench/852", "solution": "import random\nimport string\ndef task_func(max_length, n_samples, seed=None):\n    if max_length < 1:\n        raise ValueError(\"max_length must be greater than 0\")\n    if seed is not None:\n        random.seed(seed)\n    return [''.join(random.choices(string.ascii_lowercase, k=random.randint(1, max_length))) for _ in range(n_samples)]", "raw_solution": "import random\nimport string\ndef task_func(max_length, n_samples, seed=None):\n    if max_length < 1:\n        raise ValueError(\"max_length must be greater than 0\")\n    if seed is not None:\n        random.seed(seed)\n    return [''.join(random.choices(string.ascii_lowercase, k=random.randint(1, max_length))) for _ in range(n_samples)]\n```"}
{"task_id": "BigCodeBench/853", "solution": "import os\nimport shutil\nimport string\nINVALID_CHARACTERS = string.punctuation + string.whitespace\ndef task_func(directory_path):\n    summary = {'Valid': 0, 'Invalid': 0}\n    for root, dirs, files in os.walk(directory_path):\n        for file in files:\n            if any(char in INVALID_CHARACTERS for char in file):\n                shutil.move(os.path.join(root, file), os.path.join(directory_path, 'Invalid'))\n                summary['Invalid'] += 1\n            else:\n                shutil.move(os.path.join(root, file), os.path.join(directory_path, 'Valid'))\n                summary['Valid'] += 1\n    return summary", "raw_solution": "import os\nimport shutil\nimport string\n# Constants\nINVALID_CHARACTERS = string.punctuation + string.whitespace\ndef task_func(directory_path):\n    summary = {'Valid': 0, 'Invalid': 0}\n    for root, dirs, files in os.walk(directory_path):\n        for file in files:\n            if any(char in INVALID_CHARACTERS for char in file):\n                shutil.move(os.path.join(root, file), os.path.join(directory_path, 'Invalid'))\n                summary['Invalid'] += 1\n            else:\n                shutil.move(os.path.join(root, file), os.path.join(directory_path, 'Valid'))\n                summary['Valid'] += 1\n    return summary\n```"}
{"task_id": "BigCodeBench/854", "solution": "from functools import reduce\nfrom itertools import permutations\nimport math\ndef task_func(numbers):\n    if not isinstance(numbers, list) or not all(isinstance(num, int) for num in numbers):\n        raise TypeError(\"If numbers is not a list of integers.\")\n    if any(num < 0 for num in numbers):\n        raise ValueError(\"If input numbers are negative.\")\n    if not numbers:\n        return [], []\n    perm = list(permutations(numbers))\n    fac = [reduce(lambda x, y: x * y, map(math.factorial, perm[i])) for i in range(len(perm))]\n    return fac, perm", "raw_solution": "from functools import reduce\nfrom itertools import permutations\nimport math\n\ndef task_func(numbers):\n    if not isinstance(numbers, list) or not all(isinstance(num, int) for num in numbers):\n        raise TypeError(\"If numbers is not a list of integers.\")\n    if any(num < 0 for num in numbers):\n        raise ValueError(\"If input numbers are negative.\")\n    if not numbers:\n        return [], []\n    perm = list(permutations(numbers))\n    fac = [reduce(lambda x, y: x * y, map(math.factorial, perm[i])) for i in range(len(perm))]\n    return fac, perm\n```"}
{"task_id": "BigCodeBench/855", "solution": "import random\nimport string\nimport collections\nVALID_CHARACTERS = string.ascii_letters + string.digits\ndef task_func(n_strings, string_length):\n    # Generate n random strings of a specified length\n    strings = [''.join(random.choice(VALID_CHARACTERS) for _ in range(string_length)) for _ in range(n_strings)]\n    \n    # Count the frequency of each character across all strings\n    char_counts = collections.Counter(''.join(strings))\n    \n    # Return the result as a dictionary\n    return dict(char_counts)", "raw_solution": "import random\nimport string\nimport collections\n\n# Constants\nVALID_CHARACTERS = string.ascii_letters + string.digits\n\ndef task_func(n_strings, string_length):\n    # Generate n random strings of a specified length\n    strings = [''.join(random.choice(VALID_CHARACTERS) for _ in range(string_length)) for _ in range(n_strings)]\n    \n    # Count the frequency of each character across all strings\n    char_counts = collections.Counter(''.join(strings))\n    \n    # Return the result as a dictionary\n    return dict(char_counts)\n```"}
{"task_id": "BigCodeBench/856", "solution": "from functools import reduce\nfrom itertools import combinations\nimport numpy as np\ndef task_func(shape=(3, 3), low=1, high=10, seed=None):\n    if high <= low:\n        raise ValueError(\"If high <= low\")\n    np.random.seed(seed)\n    matrix = np.random.randint(low, high, size=shape)\n    pairs = list(combinations(matrix, 2))\n    return reduce(lambda x, y: x + y[0] * y[1], pairs, 0), matrix", "raw_solution": "from functools import reduce\nfrom itertools import combinations\nimport numpy as np\n\ndef task_func(shape=(3, 3), low=1, high=10, seed=None):\n    if high <= low:\n        raise ValueError(\"If high <= low\")\n    np.random.seed(seed)\n    matrix = np.random.randint(low, high, size=shape)\n    pairs = list(combinations(matrix, 2))\n    return reduce(lambda x, y: x + y[0] * y[1], pairs, 0), matrix\n```"}
{"task_id": "BigCodeBench/857", "solution": "import warnings\nimport os\nimport glob\nimport shutil\nimport time\ndef task_func(SOURCE_DIR, DEST_DIR, EXTENSIONS):\n    transferred_files = []\n    for ext in EXTENSIONS:\n        files = glob.glob(os.path.join(SOURCE_DIR, f'*.{ext}'))\n        for file in files:\n            try:\n                shutil.copy(file, DEST_DIR)\n                transferred_files.append(os.path.basename(file))\n            except Exception as e:\n                warnings.warn(f'Failed to transfer {file}: {e}')\n    return transferred_files", "raw_solution": "import warnings\nimport os\nimport glob\nimport shutil\nimport time\ndef task_func(SOURCE_DIR, DEST_DIR, EXTENSIONS):\n    transferred_files = []\n    for ext in EXTENSIONS:\n        files = glob.glob(os.path.join(SOURCE_DIR, f'*.{ext}'))\n        for file in files:\n            try:\n                shutil.copy(file, DEST_DIR)\n                transferred_files.append(os.path.basename(file))\n            except Exception as e:\n                warnings.warn(f'Failed to transfer {file}: {e}')\n    return transferred_files\n```"}
{"task_id": "BigCodeBench/858", "solution": "import string\nimport random\nfrom collections import Counter\ndef task_func(n, seed=None):\n    if seed is not None:\n        random.seed(seed)\n    letters = [random.choice(string.ascii_lowercase) for _ in range(n)]\n    return Counter(letters)", "raw_solution": "import string\nimport random\nfrom collections import Counter\n\ndef task_func(n, seed=None):\n    if seed is not None:\n        random.seed(seed)\n    letters = [random.choice(string.ascii_lowercase) for _ in range(n)]\n    return Counter(letters)\n```"}
{"task_id": "BigCodeBench/859", "solution": "import warnings\nimport sklearn.model_selection as model_selection\nimport sklearn.svm as svm\nimport sklearn.datasets as datasets\nimport sklearn.metrics as metrics\ndef task_func():\n    warnings.filterwarnings('always')\n    iris = datasets.load_iris()\n    X = iris.data\n    y = iris.target\n    X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.33, random_state=42)\n    clf = svm.SVC(kernel='linear')\n    clf.fit(X_train, y_train)\n    y_pred = clf.predict(X_test)\n    accuracy = metrics.accuracy_score(y_test, y_pred)\n    if accuracy < 0.9:\n        warning_msg = 'The accuracy is less than 0.9.'\n    else:\n        warning_msg = None\n    return (accuracy, warning_msg)", "raw_solution": "import warnings\nimport sklearn.model_selection as model_selection\nimport sklearn.svm as svm\nimport sklearn.datasets as datasets\nimport sklearn.metrics as metrics\n\ndef task_func():\n    warnings.filterwarnings('always')\n    iris = datasets.load_iris()\n    X = iris.data\n    y = iris.target\n    X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.33, random_state=42)\n    clf = svm.SVC(kernel='linear')\n    clf.fit(X_train, y_train)\n    y_pred = clf.predict(X_test)\n    accuracy = metrics.accuracy_score(y_test, y_pred)\n    if accuracy < 0.9:\n        warning_msg = 'The accuracy is less than 0.9.'\n    else:\n        warning_msg = None\n    return (accuracy, warning_msg)\n```"}
{"task_id": "BigCodeBench/860", "solution": "import re\nimport random\nimport string\ndef task_func(n, pattern, seed=None):\n    if seed is not None:\n        random.seed(seed)\n    s = ''.join(random.choice(string.ascii_letters + string.digits) for _ in range(n))\n    return re.findall(pattern, s)", "raw_solution": "import re\nimport random\nimport string\ndef task_func(n, pattern, seed=None):\n    if seed is not None:\n        random.seed(seed)\n    s = ''.join(random.choice(string.ascii_letters + string.digits) for _ in range(n))\n    return re.findall(pattern, s)\n```"}
{"task_id": "BigCodeBench/861", "solution": "from collections import Counter\nfrom random import choice, seed\nPOSSIBLE_ITEMS = ['apple', 'banana', 'cherry', 'date', 'elderberry']\ndef task_func(list_of_lists):\n    baskets = []\n    for lst in list_of_lists:\n        seed(lst)\n        basket = Counter([choice(POSSIBLE_ITEMS) for _ in range(len(lst))])\n        baskets.append(basket)\n    return baskets", "raw_solution": "from collections import Counter\nfrom random import choice, seed\n\n# Constants\nPOSSIBLE_ITEMS = ['apple', 'banana', 'cherry', 'date', 'elderberry']\n\ndef task_func(list_of_lists):\n    baskets = []\n    for lst in list_of_lists:\n        seed(lst)\n        basket = Counter([choice(POSSIBLE_ITEMS) for _ in range(len(lst))])\n        baskets.append(basket)\n    return baskets\n```"}
{"task_id": "BigCodeBench/862", "solution": "import random\nimport string\nfrom collections import defaultdict\ndef task_func(n, seed=None):\n    if seed is not None:\n        random.seed(seed)\n    letters = string.ascii_lowercase\n    result = defaultdict(list)\n    for i in range(n):\n        letter = random.choice(letters)\n        result[letter].append(letter)\n    return result", "raw_solution": "import random\nimport string\nfrom collections import defaultdict\n\ndef task_func(n, seed=None):\n    if seed is not None:\n        random.seed(seed)\n    letters = string.ascii_lowercase\n    result = defaultdict(list)\n    for i in range(n):\n        letter = random.choice(letters)\n        result[letter].append(letter)\n    return result\n```"}
{"task_id": "BigCodeBench/863", "solution": "import numpy as np\nimport math\ndef task_func(list_of_lists):\n    sums = []\n    for lst in list_of_lists:\n        sums.append(sum([x**2 for x in lst]))\n    return sums", "raw_solution": "import numpy as np\nimport math\n# Constants\nPOSSIBLE_NUMBERS = np.arange(1, 11)\ndef task_func(list_of_lists):\n    sums = []\n    for lst in list_of_lists:\n        sums.append(sum([x**2 for x in lst]))\n    return sums\n```"}
{"task_id": "BigCodeBench/864", "solution": "import pandas as pd\nimport numpy as np\ndef task_func(fruit_data):\n    if len(fruit_data) == 0:\n        return pd.DataFrame()\n    fruit_df = pd.DataFrame(fruit_data, columns=['Fruit', 'Count'])\n    fruit_df['Total Count'] = fruit_df.groupby('Fruit')['Count'].transform('sum')\n    fruit_df['Average Count'] = fruit_df.groupby('Fruit')['Count'].transform('mean')\n    return fruit_df", "raw_solution": "import pandas as pd\nimport numpy as np\ndef task_func(fruit_data):\n    if len(fruit_data) == 0:\n        return pd.DataFrame()\n    fruit_df = pd.DataFrame(fruit_data, columns=['Fruit', 'Count'])\n    fruit_df['Total Count'] = fruit_df.groupby('Fruit')['Count'].transform('sum')\n    fruit_df['Average Count'] = fruit_df.groupby('Fruit')['Count'].transform('mean')\n    return fruit_df\n```"}
{"task_id": "BigCodeBench/865", "solution": "import pandas as pd\nimport numpy as np\nfrom scipy.stats import zscore\nfrom sklearn.preprocessing import MinMaxScaler\ndef task_func(data):\n    # Normalize counts using z-score normalization\n    normalized_counts = zscore([item[1] for item in data])\n    \n    # Normalize weights using min-max scaling\n    normalized_weights = MinMaxScaler().fit_transform([item[2] for item in data])\n    \n    # Create a pandas DataFrame with the items, normalized counts, and normalized weights\n    df = pd.DataFrame(data, columns=['Item', 'Count', 'Weight'])\n    df['Normalized Count'] = normalized_counts\n    df['Normalized Weight'] = normalized_weights\n    \n    return df", "raw_solution": "import pandas as pd\nimport numpy as np\nfrom scipy.stats import zscore\nfrom sklearn.preprocessing import MinMaxScaler\ndef task_func(data):\n    # Normalize counts using z-score normalization\n    normalized_counts = zscore([item[1] for item in data])\n    \n    # Normalize weights using min-max scaling\n    normalized_weights = MinMaxScaler().fit_transform([item[2] for item in data])\n    \n    # Create a pandas DataFrame with the items, normalized counts, and normalized weights\n    df = pd.DataFrame(data, columns=['Item', 'Count', 'Weight'])\n    df['Normalized Count'] = normalized_counts\n    df['Normalized Weight'] = normalized_weights\n    \n    return df\n```"}
{"task_id": "BigCodeBench/866", "solution": "import numpy as np\nfrom sklearn.cluster import KMeans\ndef task_func(data, n_clusters=2, random_state=0):\n    X = np.array([d[1:] for d in data])\n    kmeans = KMeans(n_clusters=n_clusters, random_state=random_state)\n    labels = kmeans.fit_predict(X)\n    return labels", "raw_solution": "import numpy as np\nfrom sklearn.cluster import KMeans\ndef task_func(data, n_clusters=2, random_state=0):\n    X = np.array([d[1:] for d in data])\n    kmeans = KMeans(n_clusters=n_clusters, random_state=random_state)\n    labels = kmeans.fit_predict(X)\n    return labels\n```"}
{"task_id": "BigCodeBench/867", "solution": "import re\nimport string\ndef task_func(text1, text2):\n    cleaned_text1 = re.sub(r'[^\\w\\s]', '', text1)\n    cleaned_text2 = re.sub(r'[^\\w\\s]', '', text2)\n    return (cleaned_text1, cleaned_text2)", "raw_solution": "import re\nimport string\ndef task_func(text1, text2):\n    cleaned_text1 = re.sub(r'[^\\w\\s]', '', text1)\n    cleaned_text2 = re.sub(r'[^\\w\\s]', '', text2)\n    return (cleaned_text1, cleaned_text2)\n```"}
{"task_id": "BigCodeBench/868", "solution": "from itertools import cycle\nfrom random import choice, seed\ndef task_func(n_colors, colors=['Red', 'Green', 'Blue', 'Yellow', 'Purple'], rng_seed=None):\n    if n_colors <= 0:\n        return []\n    if rng_seed is not None:\n        seed(rng_seed)\n    color_cycle = cycle(colors)\n    color_pattern = []\n    for i in range(n_colors):\n        if i % 2 == 0:\n            color_pattern.append(next(color_cycle))\n        else:\n            color_pattern.append(choice(colors))\n    return color_pattern", "raw_solution": "from itertools import cycle\nfrom random import choice, seed\ndef task_func(n_colors, colors=['Red', 'Green', 'Blue', 'Yellow', 'Purple'], rng_seed=None):\n    if n_colors <= 0:\n        return []\n    if rng_seed is not None:\n        seed(rng_seed)\n    color_cycle = cycle(colors)\n    color_pattern = []\n    for i in range(n_colors):\n        if i % 2 == 0:\n            color_pattern.append(next(color_cycle))\n        else:\n            color_pattern.append(choice(colors))\n    return color_pattern\n```"}
{"task_id": "BigCodeBench/869", "solution": "import pandas as pd\nfrom itertools import cycle\nfrom random import randint, seed\ndef task_func(\n    n_grades,\n    students=['Alice', 'Bob', 'Charlie', 'David', 'Eve'],\n    grade_range=range(1, 11),\n    rng_seed=None\n):\n    if not students:\n        raise ValueError('If list of students is empty.')\n    seed(rng_seed)\n    grades = cycle(grade_range)\n    grade_report = pd.DataFrame({'Student': students, 'Grade': [next(grades) for _ in range(n_grades)]})\n    return grade_report", "raw_solution": "import pandas as pd\nfrom itertools import cycle\nfrom random import randint, seed\n\ndef task_func(\n    n_grades,\n    students=['Alice', 'Bob', 'Charlie', 'David', 'Eve'],\n    grade_range=range(1, 11),\n    rng_seed=None\n):\n    if not students:\n        raise ValueError('If list of students is empty.')\n    seed(rng_seed)\n    grades = cycle(grade_range)\n    grade_report = pd.DataFrame({'Student': students, 'Grade': [next(grades) for _ in range(n_grades)]})\n    return grade_report\n```"}
{"task_id": "BigCodeBench/870", "solution": "import pandas as pd\nimport numpy as np\nimport itertools\ndef task_func(data_list=[('a', 1, 2.1), ('b', 2, 3.2), ('c', 3, 4.3), ('d', 4, 5.4), ('e', 5, 6.5)]):\n    df = pd.DataFrame()\n    for i, row in enumerate(data_list):\n        if isinstance(row[0], (int, float)):\n            df.loc[i, 'Mean Value'] = np.mean([x for x in row if isinstance(x, (int, float))])\n    return df", "raw_solution": "import pandas as pd\nimport numpy as np\nimport itertools\ndef task_func(data_list=[('a', 1, 2.1), ('b', 2, 3.2), ('c', 3, 4.3), ('d', 4, 5.4), ('e', 5, 6.5)]):\n    df = pd.DataFrame()\n    for i, row in enumerate(data_list):\n        if isinstance(row[0], (int, float)):\n            df.loc[i, 'Mean Value'] = np.mean([x for x in row if isinstance(x, (int, float))])\n    return df\n```"}
{"task_id": "BigCodeBench/871", "solution": "import numpy as np\nimport itertools\ndef task_func(data_list, file_name):\n    if not data_list:\n        return [], open(file_name, 'w').close()\n    with open(file_name, 'w') as f:\n        for i, tup in enumerate(data_list):\n            if len(tup) < 2:\n                continue\n            mean = np.nanmean([tup[j] for j in range(1, len(tup))])\n            f.write(f'Position {i+1}: {mean}\\n')\n    return [np.nanmean([tup[j] for j in range(1, len(tup))]) for tup in data_list]", "raw_solution": "import numpy as np\nimport itertools\n\ndef task_func(data_list, file_name):\n    if not data_list:\n        return [], open(file_name, 'w').close()\n    with open(file_name, 'w') as f:\n        for i, tup in enumerate(data_list):\n            if len(tup) < 2:\n                continue\n            mean = np.nanmean([tup[j] for j in range(1, len(tup))])\n            f.write(f'Position {i+1}: {mean}\\n')\n    return [np.nanmean([tup[j] for j in range(1, len(tup))]) for tup in data_list]\n```"}
{"task_id": "BigCodeBench/872", "solution": "import numpy as np\nimport itertools\ndef task_func(data_list):\n    if not data_list:\n        return []\n    data_list = list(itertools.zip_longest(*data_list))\n    means = []\n    for i in range(len(data_list[0])):\n        numeric_values = [float(x[i]) if isinstance(x[i], (int, float)) else 0 for x in data_list]\n        means.append(np.nanmean(numeric_values))\n    return means", "raw_solution": "import numpy as np\nimport itertools\n\ndef task_func(data_list):\n    if not data_list:\n        return []\n    data_list = list(itertools.zip_longest(*data_list))\n    means = []\n    for i in range(len(data_list[0])):\n        numeric_values = [float(x[i]) if isinstance(x[i], (int, float)) else 0 for x in data_list]\n        means.append(np.nanmean(numeric_values))\n    return means\n```"}
{"task_id": "BigCodeBench/873", "solution": "import csv\nimport os\ndef task_func(data, file_path, headers):\n    if file_path is None:\n        raise ValueError(\"If 'file_path' is None.\")\n    with open(file_path, 'w', newline='') as csvfile:\n        writer = csv.writer(csvfile)\n        writer.writerow(headers)\n        for row in data:\n            writer.writerow(row)\n    return os.path.abspath(file_path)", "raw_solution": "import csv\nimport os\n\ndef task_func(data, file_path, headers):\n    if file_path is None:\n        raise ValueError(\"If 'file_path' is None.\")\n    with open(file_path, 'w', newline='') as csvfile:\n        writer = csv.writer(csvfile)\n        writer.writerow(headers)\n        for row in data:\n            writer.writerow(row)\n    return os.path.abspath(file_path)\n```"}
{"task_id": "BigCodeBench/874", "solution": "from itertools import zip_longest\nfrom scipy.spatial import distance\ndef task_func(points):\n    if not points or len(points) == 1:\n        return []\n    return [distance.euclidean(p1, p2) for p1, p2 in zip_longest(points, points[1:])]", "raw_solution": "from itertools import zip_longest\nfrom scipy.spatial import distance\n\ndef task_func(points):\n    if not points or len(points) == 1:\n        return []\n    return [distance.euclidean(p1, p2) for p1, p2 in zip_longest(points, points[1:])]\n```"}
{"task_id": "BigCodeBench/875", "solution": "import pandas as pd\nimport random\ndef task_func(data, columns=['Name', 'Age', 'Occupation'], fill_missing=False, num_range=(0, 100), seed=None):\n    random.seed(seed)\n    df = pd.DataFrame(data, columns=columns)\n    if fill_missing:\n        df = df.fillna(random.randint(*num_range))\n    return df", "raw_solution": "import pandas as pd\nimport random\n\ndef task_func(data, columns=['Name', 'Age', 'Occupation'], fill_missing=False, num_range=(0, 100), seed=None):\n    random.seed(seed)\n    df = pd.DataFrame(data, columns=columns)\n    if fill_missing:\n        df = df.fillna(random.randint(*num_range))\n    return df\n```"}
{"task_id": "BigCodeBench/876", "solution": "import collections\nimport operator\nimport os\nimport shutil\ndef task_func(data_dict, source_directory, backup_directory):\n    updated_dict = data_dict.copy()\n    updated_dict['a'] = 1\n    value_frequencies = sorted(collections.Counter(data_dict.values()).items(), key=operator.itemgetter(1), reverse=True)\n    backup_status = True\n    for root, dirs, files in os.walk(source_directory):\n        for file in files:\n            src_file = os.path.join(root, file)\n            dst_file = os.path.join(backup_directory, file)\n            try:\n                shutil.copy(src_file, dst_file)\n            except Exception as e:\n                backup_status = False\n                print(f\"Failed to backup {src_file}: {e}\")\n    return updated_dict, value_frequencies, backup_status", "raw_solution": "import collections\nimport operator\nimport os\nimport shutil\n\ndef task_func(data_dict, source_directory, backup_directory):\n    updated_dict = data_dict.copy()\n    updated_dict['a'] = 1\n    value_frequencies = sorted(collections.Counter(data_dict.values()).items(), key=operator.itemgetter(1), reverse=True)\n    backup_status = True\n    for root, dirs, files in os.walk(source_directory):\n        for file in files:\n            src_file = os.path.join(root, file)\n            dst_file = os.path.join(backup_directory, file)\n            try:\n                shutil.copy(src_file, dst_file)\n            except Exception as e:\n                backup_status = False\n                print(f\"Failed to backup {src_file}: {e}\")\n    return updated_dict, value_frequencies, backup_status\n```"}
{"task_id": "BigCodeBench/877", "solution": "import pandas as pd\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\ndef task_func(data, n_components=2):\n    if not isinstance(data, pd.DataFrame):\n        raise ValueError(\"If input data is not a DataFrame or contains non-numeric data.\")\n    if data.empty:\n        raise ValueError(\"Input data is empty.\")\n    if n_components > data.shape[1]:\n        raise ValueError(\"If n_components is greater than the number of columns in the data.\")\n    scaler = StandardScaler()\n    scaled_data = scaler.fit_transform(data)\n    pca = PCA(n_components=n_components)\n    principal_components = pca.fit_transform(scaled_data)\n    return pd.DataFrame(principal_components, columns=['PC1', 'PC2'])", "raw_solution": "import pandas as pd\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\ndef task_func(data, n_components=2):\n    if not isinstance(data, pd.DataFrame):\n        raise ValueError(\"If input data is not a DataFrame or contains non-numeric data.\")\n    if data.empty:\n        raise ValueError(\"Input data is empty.\")\n    if n_components > data.shape[1]:\n        raise ValueError(\"If n_components is greater than the number of columns in the data.\")\n    scaler = StandardScaler()\n    scaled_data = scaler.fit_transform(data)\n    pca = PCA(n_components=n_components)\n    principal_components = pca.fit_transform(scaled_data)\n    return pd.DataFrame(principal_components, columns=['PC1', 'PC2'])\n```"}
{"task_id": "BigCodeBench/878", "solution": "import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_squared_error\ndef task_func(data, target, test_size=0.2, random_state=None):\n    if data.empty or target not in data.columns:\n        raise ValueError(\"If the input DataFrame is empty or the target column name is not in the DataFrame.\")\n    X = data.drop(target, axis=1)\n    y = data[target]\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n    model = RandomForestRegressor(random_state=random_state)\n    model.fit(X_train, y_train)\n    y_pred = model.predict(X_test)\n    mse = mean_squared_error(y_test, y_pred)\n    return mse, model, data", "raw_solution": "import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_squared_error\n\ndef task_func(data, target, test_size=0.2, random_state=None):\n    if data.empty or target not in data.columns:\n        raise ValueError(\"If the input DataFrame is empty or the target column name is not in the DataFrame.\")\n    X = data.drop(target, axis=1)\n    y = data[target]\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n    model = RandomForestRegressor(random_state=random_state)\n    model.fit(X_train, y_train)\n    y_pred = model.predict(X_test)\n    mse = mean_squared_error(y_test, y_pred)\n    return mse, model, data\n```"}
{"task_id": "BigCodeBench/879", "solution": "import pandas as pd\nimport numpy as np\nfrom scipy.stats import chi2_contingency\ndef task_func(data, col1, col2):\n    if data.empty:\n        raise ValueError(\"If 'data' is empty\")\n    if col1 not in data.columns or col2 not in data.columns:\n        raise ValueError(\"If 'col1' or 'col2' are not in 'data'\")\n    if data[col1].nunique() < 2 or data[col2].nunique() < 2:\n        raise ValueError(\"If one or both of the columns do not have multiple categories\")\n    if data[col1].nunique() < 5 or data[col2].nunique() < 5:\n        raise ValueError(\"Some categories have less than 5 observations (violating the chi-square test assumptions)\")\n    contingency_table = pd.crosstab(data[col1], data[col2])\n    chi2, p, dof, expected = chi2_contingency(contingency_table)\n    return p", "raw_solution": "import pandas as pd\nimport numpy as np\nfrom scipy.stats import chi2_contingency\n\ndef task_func(data, col1, col2):\n    if data.empty:\n        raise ValueError(\"If 'data' is empty\")\n    if col1 not in data.columns or col2 not in data.columns:\n        raise ValueError(\"If 'col1' or 'col2' are not in 'data'\")\n    if data[col1].nunique() < 2 or data[col2].nunique() < 2:\n        raise ValueError(\"If one or both of the columns do not have multiple categories\")\n    if data[col1].nunique() < 5 or data[col2].nunique() < 5:\n        raise ValueError(\"Some categories have less than 5 observations (violating the chi-square test assumptions)\")\n    contingency_table = pd.crosstab(data[col1], data[col2])\n    chi2, p, dof, expected = chi2_contingency(contingency_table)\n    return p\n```"}
{"task_id": "BigCodeBench/880", "solution": "import pandas as pd\nfrom sklearn.cluster import KMeans\ndef task_func(data, n_clusters=3, seed=None):\n    if not data.select_dtypes(include=['number']).empty:\n        model = KMeans(n_clusters=n_clusters, n_init=10, random_state=seed)\n        labels = model.fit_predict(data)\n        return labels, model\n    else:\n        raise ValueError('If the DataFrame contains non numeric entries.')", "raw_solution": "import pandas as pd\nfrom sklearn.cluster import KMeans\ndef task_func(data, n_clusters=3, seed=None):\n    if not data.select_dtypes(include=['number']).empty:\n        model = KMeans(n_clusters=n_clusters, n_init=10, random_state=seed)\n        labels = model.fit_predict(data)\n        return labels, model\n    else:\n        raise ValueError('If the DataFrame contains non numeric entries.')\n```"}
{"task_id": "BigCodeBench/881", "solution": "import pandas as pd\nimport random\ndef task_func(csv_file, column_name='data', pattern='\\d+[xX]', sample_size=None, seed=42):\n    df = pd.read_csv(csv_file)\n    matches = df[column_name].str.contains(pattern)\n    if sample_size is not None:\n        random.seed(seed)\n        indices = random.sample(range(len(matches)), sample_size)\n        return df.iloc[indices]\n    else:\n        return df[matches]", "raw_solution": "import pandas as pd\nimport random\ndef task_func(csv_file, column_name='data', pattern='\\d+[xX]', sample_size=None, seed=42):\n    df = pd.read_csv(csv_file)\n    matches = df[column_name].str.contains(pattern)\n    if sample_size is not None:\n        random.seed(seed)\n        indices = random.sample(range(len(matches)), sample_size)\n        return df.iloc[indices]\n    else:\n        return df[matches]\n```"}
{"task_id": "BigCodeBench/882", "solution": "import sqlite3\nimport pandas as pd\nimport os\ndef task_func(db_file, table_name, column_name, pattern='\\d+[xX]'):\n    if not os.path.exists(db_file):\n        raise ValueError('db_file does not exist.')\n    conn = sqlite3.connect(db_file)\n    df = pd.read_sql_query(f\"SELECT * FROM {table_name}\", conn)\n    matches = df[column_name].str.contains(pattern, regex=True)\n    return df[matches]", "raw_solution": "import sqlite3\nimport pandas as pd\nimport os\ndef task_func(db_file, table_name, column_name, pattern='\\d+[xX]'):\n    if not os.path.exists(db_file):\n        raise ValueError('db_file does not exist.')\n    conn = sqlite3.connect(db_file)\n    df = pd.read_sql_query(f\"SELECT * FROM {table_name}\", conn)\n    matches = df[column_name].str.contains(pattern, regex=True)\n    return df[matches]\n```"}
{"task_id": "BigCodeBench/883", "solution": "import pandas as pd\nfrom statsmodels.tsa.stattools import adfuller\ndef task_func(df: pd.DataFrame, column_a: str, column_b: str, column_c: str) -> bool:\n    # Filter rows where column_b is bigger than 50 and column_c is equal to 900\n    filtered_df = df[(df[column_b] > 50) & (df[column_c] == 900)]\n    \n    # Check if column_a is empty after filtering\n    if filtered_df.empty:\n        return True\n    \n    # Check if column_a values are constant\n    if filtered_df[column_a].nunique() == 1:\n        return True\n    \n    # Perform Augmented Dickey-Fuller test\n    result = adfuller(filtered_df[column_a])\n    \n    # Check if p_value is smaller than 0.05\n    if result[1] < 0.05:\n        return True\n    \n    return False", "raw_solution": "import pandas as pd\nfrom statsmodels.tsa.stattools import adfuller\n\ndef task_func(df: pd.DataFrame, column_a: str, column_b: str, column_c: str) -> bool:\n    # Filter rows where column_b is bigger than 50 and column_c is equal to 900\n    filtered_df = df[(df[column_b] > 50) & (df[column_c] == 900)]\n    \n    # Check if column_a is empty after filtering\n    if filtered_df.empty:\n        return True\n    \n    # Check if column_a values are constant\n    if filtered_df[column_a].nunique() == 1:\n        return True\n    \n    # Perform Augmented Dickey-Fuller test\n    result = adfuller(filtered_df[column_a])\n    \n    # Check if p_value is smaller than 0.05\n    if result[1] < 0.05:\n        return True\n    \n    return False\n```"}
{"task_id": "BigCodeBench/884", "solution": "import pandas as pd\nfrom scipy.stats import chi2_contingency\ndef task_func(df, columns=['A', 'B', 'C'], larger=50, equal=900):\n    if len(columns) != 3:\n        raise ValueError(\"The number of specified columns is not 3.\")\n    if not all(col in df.columns for col in columns):\n        raise ValueError(\"The specified columns are not contained in df.\")\n    if len(df[df[columns[1]] > larger]) < 1 or len(df[df[columns[2]] == equal]) < 1:\n        raise ValueError(\"If there's insufficient data for the test (no rows meeting the criteria).\")\n    contingency_table = pd.crosstab(df[columns[0]], df[columns[1]])\n    chi2, p, dof, expected = chi2_contingency(contingency_table)\n    return p", "raw_solution": "import pandas as pd\nfrom scipy.stats import chi2_contingency\n\ndef task_func(df, columns=['A', 'B', 'C'], larger=50, equal=900):\n    if len(columns) != 3:\n        raise ValueError(\"The number of specified columns is not 3.\")\n    if not all(col in df.columns for col in columns):\n        raise ValueError(\"The specified columns are not contained in df.\")\n    if len(df[df[columns[1]] > larger]) < 1 or len(df[df[columns[2]] == equal]) < 1:\n        raise ValueError(\"If there's insufficient data for the test (no rows meeting the criteria).\")\n    contingency_table = pd.crosstab(df[columns[0]], df[columns[1]])\n    chi2, p, dof, expected = chi2_contingency(contingency_table)\n    return p\n```"}
{"task_id": "BigCodeBench/885", "solution": "import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\ndef task_func(df, col_a='A', col_b='B', col_c='C', seed=None):\n    if df.empty or df.isnull().values.any():\n        return None\n    if col_a not in df.columns or col_b not in df.columns or col_c not in df.columns:\n        return None\n    df = df[(df[col_b] > 50) & (df[col_c] == 900)]\n    if df.empty:\n        return None\n    X = df[col_a].values.reshape(-1, 1)\n    y = df[col_b].values\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=seed)\n    model = LinearRegression()\n    model.fit(X_train, y_train)\n    predictions = model.predict(X_test)\n    return predictions, model", "raw_solution": "import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\n\ndef task_func(df, col_a='A', col_b='B', col_c='C', seed=None):\n    if df.empty or df.isnull().values.any():\n        return None\n    if col_a not in df.columns or col_b not in df.columns or col_c not in df.columns:\n        return None\n    df = df[(df[col_b] > 50) & (df[col_c] == 900)]\n    if df.empty:\n        return None\n    X = df[col_a].values.reshape(-1, 1)\n    y = df[col_b].values\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=seed)\n    model = LinearRegression()\n    model.fit(X_train, y_train)\n    predictions = model.predict(X_test)\n    return predictions, model\n```"}
{"task_id": "BigCodeBench/886", "solution": "import pandas as pd\nfrom collections import Counter\ndef task_func(data):\n    if not all(key in data for key in ['Name', 'Age', 'Score']):\n        raise ValueError('Dictionary does not have the required keys.')\n    df = pd.DataFrame(data)\n    df = df.sort_values(by=['Name', 'Age'])\n    avg_scores = df.groupby('Name')['Score'].mean()\n    most_common_age = df['Age'].value_counts().idxmax()\n    return df, avg_scores, most_common_age", "raw_solution": "import pandas as pd\nfrom collections import Counter\n\ndef task_func(data):\n    if not all(key in data for key in ['Name', 'Age', 'Score']):\n        raise ValueError('Dictionary does not have the required keys.')\n    df = pd.DataFrame(data)\n    df = df.sort_values(by=['Name', 'Age'])\n    avg_scores = df.groupby('Name')['Score'].mean()\n    most_common_age = df['Age'].value_counts().idxmax()\n    return df, avg_scores, most_common_age\n```"}
{"task_id": "BigCodeBench/887", "solution": "import pandas as pd\nimport numpy as np\nimport itertools\ndef task_func(T1, row_num=50, seed=None):\n    if seed is not None:\n        np.random.seed(seed)\n    T1 = list(itertools.chain(*T1))\n    T1 = [int(i) for i in T1]\n    num_cols = sum(T1)\n    df = pd.DataFrame(np.random.randint(0, 100, (row_num, num_cols)), columns=[f'Col_{i+1}' for i in range(num_cols)])\n    return df", "raw_solution": "import pandas as pd\nimport numpy as np\nimport itertools\ndef task_func(T1, row_num=50, seed=None):\n    if seed is not None:\n        np.random.seed(seed)\n    T1 = list(itertools.chain(*T1))\n    T1 = [int(i) for i in T1]\n    num_cols = sum(T1)\n    df = pd.DataFrame(np.random.randint(0, 100, (row_num, num_cols)), columns=[f'Col_{i+1}' for i in range(num_cols)])\n    return df\n```"}
{"task_id": "BigCodeBench/888", "solution": "import pandas as pd\nimport os\ndef task_func(data_dir: str, csv_files: list) -> pd.DataFrame:\n    if not csv_files:\n        return pd.DataFrame()\n    df = pd.read_csv(os.path.join(data_dir, csv_files[0]))\n    for file in csv_files[1:]:\n        df = pd.concat([df, pd.read_csv(os.path.join(data_dir, file))])\n    return df", "raw_solution": "import pandas as pd\nimport os\n\ndef task_func(data_dir: str, csv_files: list) -> pd.DataFrame:\n    if not csv_files:\n        return pd.DataFrame()\n    df = pd.read_csv(os.path.join(data_dir, csv_files[0]))\n    for file in csv_files[1:]:\n        df = pd.concat([df, pd.read_csv(os.path.join(data_dir, file))])\n    return df\n```"}
{"task_id": "BigCodeBench/889", "solution": "import os\nimport pandas as pd\nimport numpy as np\ndef task_func(data_dir: str, csv_file: str) -> pd.DataFrame:\n    if not os.path.exists(os.path.join(data_dir, csv_file)):\n        raise FileNotFoundError(\"File not found\")\n    df = pd.read_csv(os.path.join(data_dir, csv_file))\n    for col in df.select_dtypes(include=[np.number]).columns:\n        df[col].fillna(df[col].mean(), inplace=True)\n    return df", "raw_solution": "import os\nimport pandas as pd\nimport numpy as np\n\ndef task_func(data_dir: str, csv_file: str) -> pd.DataFrame:\n    if not os.path.exists(os.path.join(data_dir, csv_file)):\n        raise FileNotFoundError(\"File not found\")\n    df = pd.read_csv(os.path.join(data_dir, csv_file))\n    for col in df.select_dtypes(include=[np.number]).columns:\n        df[col].fillna(df[col].mean(), inplace=True)\n    return df\n```"}
{"task_id": "BigCodeBench/890", "solution": "import os\nimport random\nimport pandas as pd\ndef task_func(data_dir,\n          csv_files=['file1.csv', 'file2.csv', 'file3.csv'],\n          seed=None):\n    if seed is not None:\n        random.seed(seed)\n    selected_file = random.choice(csv_files)\n    if not os.path.exists(os.path.join(data_dir, selected_file)):\n        return ('', pd.DataFrame())\n    df = pd.read_csv(os.path.join(data_dir, selected_file))\n    if df.empty:\n        return ('', pd.DataFrame())\n    num_rows = random.randint(0, len(df))\n    selected_df = df.sample(n=num_rows)\n    return (selected_file, selected_df)", "raw_solution": "import os\nimport random\nimport pandas as pd\n\ndef task_func(data_dir,\n          csv_files=['file1.csv', 'file2.csv', 'file3.csv'],\n          seed=None):\n    if seed is not None:\n        random.seed(seed)\n    selected_file = random.choice(csv_files)\n    if not os.path.exists(os.path.join(data_dir, selected_file)):\n        return ('', pd.DataFrame())\n    df = pd.read_csv(os.path.join(data_dir, selected_file))\n    if df.empty:\n        return ('', pd.DataFrame())\n    num_rows = random.randint(0, len(df))\n    selected_df = df.sample(n=num_rows)\n    return (selected_file, selected_df)\n```"}
{"task_id": "BigCodeBench/891", "solution": "import pandas as pd\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\ndef task_func(csv_file_path, attribute, test_size=0.2, random_state=42):\n    df = pd.read_csv(csv_file_path)\n    X = df.drop(attribute, axis=1)\n    y = df[attribute]\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n    model = LinearRegression()\n    model.fit(X_train, y_train)\n    predictions = model.predict(X_test)\n    return model, predictions", "raw_solution": "import pandas as pd\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\ndef task_func(csv_file_path, attribute, test_size=0.2, random_state=42):\n    df = pd.read_csv(csv_file_path)\n    X = df.drop(attribute, axis=1)\n    y = df[attribute]\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n    model = LinearRegression()\n    model.fit(X_train, y_train)\n    predictions = model.predict(X_test)\n    return model, predictions\n```"}
{"task_id": "BigCodeBench/892", "solution": "import random\nfrom collections import Counter\ndef task_func(strings: list) -> dict:\n    pattern = \"hello\"\n    count = Counter()\n    for string in strings:\n        count[pattern] += string.count(pattern)\n    return dict(count)", "raw_solution": "import random\nfrom collections import Counter\n\ndef task_func(strings: list) -> dict:\n    pattern = \"hello\"\n    count = Counter()\n    for string in strings:\n        count[pattern] += string.count(pattern)\n    return dict(count)\n```"}
{"task_id": "BigCodeBench/893", "solution": "import re\nfrom datetime import time\ndef task_func(logs: list):\n    times = []\n    for log in logs:\n        match = re.search(r'\\[(\\d{2}:\\d{2}:\\d{2})\\]', log)\n        if match:\n            times.append(time.fromisoformat(match.group(1)))\n    if times:\n        return times, sum(times) / len(times)\n    else:\n        return times, 0", "raw_solution": "import re\nfrom datetime import time\n\ndef task_func(logs: list):\n    times = []\n    for log in logs:\n        match = re.search(r'\\[(\\d{2}:\\d{2}:\\d{2})\\]', log)\n        if match:\n            times.append(time.fromisoformat(match.group(1)))\n    if times:\n        return times, sum(times) / len(times)\n    else:\n        return times, 0\n```"}
{"task_id": "BigCodeBench/894", "solution": "import numpy as np\nimport matplotlib.pyplot as plt\nARRAY_SIZE = 10000\ndef task_func():\n    # Generate random integers\n    array = np.random.randint(1, 101, ARRAY_SIZE)\n    \n    # Calculate mean and standard deviation\n    mean = np.mean(array)\n    std_dev = np.std(array)\n    \n    # Draw histogram\n    fig, ax = plt.subplots()\n    ax.hist(array, bins=20, edgecolor='black')\n    ax.set_title('Histogram of Random Integers')\n    ax.set_xlabel('Value')\n    ax.set_ylabel('Frequency')\n    ax.axvline(mean, color='red', linestyle='--')\n    ax.axvline(mean - std_dev, color='purple', linestyle='--')\n    ax.axvline(mean + std_dev, color='purple', linestyle='--')\n    \n    return (array, mean, std_dev, ax)", "raw_solution": "import numpy as np\nimport matplotlib.pyplot as plt\n# Constants\nARRAY_SIZE = 10000\n\ndef task_func():\n    # Generate random integers\n    array = np.random.randint(1, 101, ARRAY_SIZE)\n    \n    # Calculate mean and standard deviation\n    mean = np.mean(array)\n    std_dev = np.std(array)\n    \n    # Draw histogram\n    fig, ax = plt.subplots()\n    ax.hist(array, bins=20, edgecolor='black')\n    ax.set_title('Histogram of Random Integers')\n    ax.set_xlabel('Value')\n    ax.set_ylabel('Frequency')\n    ax.axvline(mean, color='red', linestyle='--')\n    ax.axvline(mean - std_dev, color='purple', linestyle='--')\n    ax.axvline(mean + std_dev, color='purple', linestyle='--')\n    \n    return (array, mean, std_dev, ax)\n```"}
{"task_id": "BigCodeBench/895", "solution": "import numpy as np\nimport matplotlib.pyplot as plt\nARRAY_SIZE = 10000\ndef task_func():\n    # Generate random integers\n    array = np.random.randint(1, 101, ARRAY_SIZE)\n    \n    # Calculate mean and standard deviation\n    mean = np.mean(array)\n    std_dev = np.std(array)\n    \n    # Draw histogram\n    fig, ax = plt.subplots()\n    ax.hist(array, bins=20, color='blue')\n    ax.set_title('Histogram of Random Values')\n    ax.set_xlabel('Val')\n    ax.set_ylabel('Freq')\n    ax.axvline(mean, color='red', linestyle='--')\n    ax.axvline(mean - std_dev, color='purple', linestyle='--')\n    ax.axvline(mean + std_dev, color='purple', linestyle='--')\n    \n    return (array, mean, std_dev, ax)", "raw_solution": "import numpy as np\nimport matplotlib.pyplot as plt\n# Constants\nARRAY_SIZE = 10000\n\ndef task_func():\n    # Generate random integers\n    array = np.random.randint(1, 101, ARRAY_SIZE)\n    \n    # Calculate mean and standard deviation\n    mean = np.mean(array)\n    std_dev = np.std(array)\n    \n    # Draw histogram\n    fig, ax = plt.subplots()\n    ax.hist(array, bins=20, color='blue')\n    ax.set_title('Histogram of Random Values')\n    ax.set_xlabel('Val')\n    ax.set_ylabel('Freq')\n    ax.axvline(mean, color='red', linestyle='--')\n    ax.axvline(mean - std_dev, color='purple', linestyle='--')\n    ax.axvline(mean + std_dev, color='purple', linestyle='--')\n    \n    return (array, mean, std_dev, ax)\n```"}
{"task_id": "BigCodeBench/896", "solution": "from collections import Counter\nimport random\nimport itertools\ndef task_func(length, count, seed=0):\n    random.seed(seed)\n    letters = ['a', 'b', 'c', 'd', 'e']\n    strings = [''.join(random.choice(letters) for _ in range(length)) for _ in range(count)]\n    counter = Counter(''.join(strings))\n    return counter", "raw_solution": "from collections import Counter\nimport random\nimport itertools\n\ndef task_func(length, count, seed=0):\n    random.seed(seed)\n    letters = ['a', 'b', 'c', 'd', 'e']\n    strings = [''.join(random.choice(letters) for _ in range(length)) for _ in range(count)]\n    counter = Counter(''.join(strings))\n    return counter\n```"}
{"task_id": "BigCodeBench/897", "solution": "import numpy as np\nimport matplotlib.pyplot as plt\nimport random\nNUMBERS = list(range(1, 7))\ndef task_func(rolls, seed=None):\n    if seed is not None:\n        random.seed(seed)\n    # Simulate dice rolls\n    rolls = [random.choice(NUMBERS) for _ in range(rolls)]\n    # Calculate frequency of each result\n    freq = np.bincount(rolls)\n    # Create histogram\n    fig, ax = plt.subplots()\n    ax.bar(NUMBERS, freq, color='blue')\n    ax.set_title('Histogram of Dice Rolls')\n    ax.set_xlabel('Dice Value')\n    ax.set_ylabel('Frequency')\n    return freq, ax", "raw_solution": "import numpy as np\nimport matplotlib.pyplot as plt\nimport random\n# Constants\nNUMBERS = list(range(1, 7))  # Adjusting for dice rolls (1 to 6)\n\ndef task_func(rolls, seed=None):\n    if seed is not None:\n        random.seed(seed)\n    # Simulate dice rolls\n    rolls = [random.choice(NUMBERS) for _ in range(rolls)]\n    # Calculate frequency of each result\n    freq = np.bincount(rolls)\n    # Create histogram\n    fig, ax = plt.subplots()\n    ax.bar(NUMBERS, freq, color='blue')\n    ax.set_title('Histogram of Dice Rolls')\n    ax.set_xlabel('Dice Value')\n    ax.set_ylabel('Frequency')\n    return freq, ax\n```"}
{"task_id": "BigCodeBench/898", "solution": "from collections import Counter\nimport random\nLETTERS = ['a', 'b', 'c', 'd', 'e']\ndef task_func(count, seed=0):\n    random.seed(seed)\n    pairs = [(random.choice(LETTERS), random.choice(LETTERS)) for _ in range(count)]\n    return Counter(pairs)", "raw_solution": "from collections import Counter\nimport random\nLETTERS = ['a', 'b', 'c', 'd', 'e']\n\ndef task_func(count, seed=0):\n    random.seed(seed)\n    pairs = [(random.choice(LETTERS), random.choice(LETTERS)) for _ in range(count)]\n    return Counter(pairs)\n```"}
{"task_id": "BigCodeBench/899", "solution": "import numpy as np\nimport random\ndef task_func(length=10000, seed=0):\n    if length < 0:\n        raise ValueError(\"If length is negative.\")\n    random.seed(seed)\n    walk = np.zeros(length)\n    for i in range(length):\n        walk[i] = random.choice([-1, 1])\n    return walk", "raw_solution": "import numpy as np\nimport random\n\ndef task_func(length=10000, seed=0):\n    if length < 0:\n        raise ValueError(\"If length is negative.\")\n    random.seed(seed)\n    walk = np.zeros(length)\n    for i in range(length):\n        walk[i] = random.choice([-1, 1])\n    return walk\n```"}
{"task_id": "BigCodeBench/900", "solution": "import pandas as pd\nimport numpy as np\ndef task_func(d):\n    if not isinstance(d, list) or not all(isinstance(item, dict) for item in d):\n        raise ValueError(\"Input is not a list of dictionaries.\")\n    df = pd.DataFrame(d)\n    stats = {\n        'x': df['x'].describe(),\n        'y': df['y'].describe(),\n        'z': df['z'].describe()\n    }\n    return stats", "raw_solution": "import pandas as pd\nimport numpy as np\ndef task_func(d):\n    if not isinstance(d, list) or not all(isinstance(item, dict) for item in d):\n        raise ValueError(\"Input is not a list of dictionaries.\")\n    df = pd.DataFrame(d)\n    stats = {\n        'x': df['x'].describe(),\n        'y': df['y'].describe(),\n        'z': df['z'].describe()\n    }\n    return stats\n```"}
{"task_id": "BigCodeBench/901", "solution": "import pandas as pd\nfrom sklearn.preprocessing import MinMaxScaler\ndef task_func(d):\n    if not d:\n        return pd.DataFrame()\n    scaler = MinMaxScaler()\n    scaled_data = scaler.fit_transform(pd.DataFrame(d))\n    return pd.DataFrame(scaled_data, columns=[col for col in d[0].keys()])", "raw_solution": "import pandas as pd\nfrom sklearn.preprocessing import MinMaxScaler\n\n# Updated function to handle empty input list\ndef task_func(d):\n    if not d:\n        return pd.DataFrame()\n    scaler = MinMaxScaler()\n    scaled_data = scaler.fit_transform(pd.DataFrame(d))\n    return pd.DataFrame(scaled_data, columns=[col for col in d[0].keys()])\n```"}
{"task_id": "BigCodeBench/902", "solution": "import pandas as pd\nfrom collections import Counter\ndef task_func(d):\n    return {'x': Counter([d[i]['x'] for i in range(len(d))]),\n            'y': Counter([d[i]['y'] for i in range(len(d))]),\n            'z': Counter([d[i]['z'] for i in range(len(d))])}", "raw_solution": "import pandas as pd\nfrom collections import Counter\ndef task_func(d):\n    return {'x': Counter([d[i]['x'] for i in range(len(d))]),\n            'y': Counter([d[i]['y'] for i in range(len(d))]),\n            'z': Counter([d[i]['z'] for i in range(len(d))])}\n```"}
{"task_id": "BigCodeBench/903", "solution": "import pandas as pd\nfrom sklearn.linear_model import LinearRegression\ndef task_func(d, target='z'):\n    df = pd.DataFrame(d)\n    model = LinearRegression()\n    model.fit(df[['x']], df[target])\n    return model", "raw_solution": "import pandas as pd\nfrom sklearn.linear_model import LinearRegression\n\ndef task_func(d, target='z'):\n    df = pd.DataFrame(d)\n    model = LinearRegression()\n    model.fit(df[['x']], df[target])\n    return model\n```"}
{"task_id": "BigCodeBench/904", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\ndef task_func(d, keys=['x', 'y', 'z']):\n    df = pd.DataFrame(d)\n    ax = df[keys].plot()\n    return ax", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\ndef task_func(d, keys=['x', 'y', 'z']):\n    df = pd.DataFrame(d)\n    ax = df[keys].plot()\n    return ax\n```"}
{"task_id": "BigCodeBench/905", "solution": "import os\nimport glob\nimport csv\ndef task_func(directory_path, file_extension='.csv'):\n    data = {}\n    for file in glob.glob(os.path.join(directory_path, f'*{file_extension}')):\n        with open(file, 'r') as f:\n            reader = csv.reader(f)\n            data[os.path.splitext(os.path.basename(file))[0]] = list(reader)\n    return data", "raw_solution": "import os\nimport glob\nimport csv\ndef task_func(directory_path, file_extension='.csv'):\n    data = {}\n    for file in glob.glob(os.path.join(directory_path, f'*{file_extension}')):\n        with open(file, 'r') as f:\n            reader = csv.reader(f)\n            data[os.path.splitext(os.path.basename(file))[0]] = list(reader)\n    return data\n```"}
{"task_id": "BigCodeBench/906", "solution": "import zipfile\nimport os\nimport re\nimport shutil\ndef task_func(source_dir: str, target_dir: str, archive_name: str = 'archive.zip') -> str:\n    # Create a new zip file\n    zipf = zipfile.ZipFile(os.path.join(target_dir, archive_name), 'w', zipfile.ZIP_DEFLATED)\n    # Walk through the source directory\n    for root, dirs, files in os.walk(source_dir):\n        for file in files:\n            # Check if the file is processed\n            if file.endswith('_processed'):\n                # Add the file to the zip file\n                zipf.write(os.path.join(root, file), os.path.relpath(os.path.join(root, file), source_dir))\n    # Close the zip file\n    zipf.close()\n    # Return the path to the created archive\n    return os.path.join(target_dir, archive_name)", "raw_solution": "import zipfile\nimport os\nimport re\nimport shutil\ndef task_func(source_dir: str, target_dir: str, archive_name: str = 'archive.zip') -> str:\n    # Create a new zip file\n    zipf = zipfile.ZipFile(os.path.join(target_dir, archive_name), 'w', zipfile.ZIP_DEFLATED)\n    # Walk through the source directory\n    for root, dirs, files in os.walk(source_dir):\n        for file in files:\n            # Check if the file is processed\n            if file.endswith('_processed'):\n                # Add the file to the zip file\n                zipf.write(os.path.join(root, file), os.path.relpath(os.path.join(root, file), source_dir))\n    # Close the zip file\n    zipf.close()\n    # Return the path to the created archive\n    return os.path.join(target_dir, archive_name)\n```"}
{"task_id": "BigCodeBench/907", "solution": "import os\nimport re\ndef task_func(pattern: str, replacement: str, directory: str) -> bool:\n    try:\n        for filename in os.listdir(directory):\n            if re.search(pattern, filename):\n                new_filename = re.sub(pattern, replacement, filename)\n                os.rename(os.path.join(directory, filename), os.path.join(directory, new_filename))\n        return True\n    except Exception as e:\n        print(f\"Error: {e}\")\n        return False", "raw_solution": "import os\nimport re\ndef task_func(pattern: str, replacement: str, directory: str) -> bool:\n    try:\n        for filename in os.listdir(directory):\n            if re.search(pattern, filename):\n                new_filename = re.sub(pattern, replacement, filename)\n                os.rename(os.path.join(directory, filename), os.path.join(directory, new_filename))\n        return True\n    except Exception as e:\n        print(f\"Error: {e}\")\n        return False\n```"}
{"task_id": "BigCodeBench/908", "solution": "import os\nimport pandas as pd\nimport re\nimport matplotlib.pyplot as plt\ndef task_func(directory: str, pattern: str) -> list:\n    # Get all CSV files in the directory\n    csv_files = [f for f in os.listdir(directory) if re.match(pattern, f)]\n    \n    # Create a list to store the plots\n    plots = []\n    \n    # Loop through each CSV file\n    for file in csv_files:\n        # Read the CSV file\n        df = pd.read_csv(os.path.join(directory, file))\n        \n        # Create a plot\n        ax = df.plot(x='Month', y='Sales', kind='line')\n        \n        # Add title and labels\n        ax.set_title(file)\n        ax.set_xlabel('Month')\n        ax.set_ylabel('Sales')\n        \n        # Add the plot to the list\n        plots.append(ax)\n    \n    # Return the list of plots\n    return plots", "raw_solution": "import os\nimport pandas as pd\nimport re\nimport matplotlib.pyplot as plt\n\ndef task_func(directory: str, pattern: str) -> list:\n    # Get all CSV files in the directory\n    csv_files = [f for f in os.listdir(directory) if re.match(pattern, f)]\n    \n    # Create a list to store the plots\n    plots = []\n    \n    # Loop through each CSV file\n    for file in csv_files:\n        # Read the CSV file\n        df = pd.read_csv(os.path.join(directory, file))\n        \n        # Create a plot\n        ax = df.plot(x='Month', y='Sales', kind='line')\n        \n        # Add title and labels\n        ax.set_title(file)\n        ax.set_xlabel('Month')\n        ax.set_ylabel('Sales')\n        \n        # Add the plot to the list\n        plots.append(ax)\n    \n    # Return the list of plots\n    return plots\n```"}
{"task_id": "BigCodeBench/909", "solution": "import pandas as pd\nimport itertools\nfrom random import shuffle\ndef task_func(letters=['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I'], categories=['Category 1', 'Category 2', 'Category 3']):\n    shuffle(categories)\n    df = pd.DataFrame({'Letter': letters, 'Category': categories})\n    return df", "raw_solution": "import pandas as pd\nimport itertools\nfrom random import shuffle\n\ndef task_func(letters=['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I'], categories=['Category 1', 'Category 2', 'Category 3']):\n    shuffle(categories)\n    df = pd.DataFrame({'Letter': letters, 'Category': categories})\n    return df\n```"}
{"task_id": "BigCodeBench/910", "solution": "import numpy as np\nimport matplotlib.pyplot as plt\ndef task_func(letters, repetitions, colors):\n    if len(letters) == 0 or len(colors) == 0:\n        raise ValueError(\"Lists cannot be empty\")\n    if len(letters) != len(colors):\n        raise ValueError(\"Lengths of the input lists do not match\")\n    letter_freq = np.zeros(len(letters))\n    for i in range(len(letters)):\n        letter_freq[i] = letters.count(letters[i])\n    plt.bar(letters, letter_freq, color=colors)\n    plt.xlabel('Letters')\n    plt.ylabel('Frequency')\n    plt.title('Frequency of Letters')\n    return plt.gca()", "raw_solution": "import numpy as np\nimport matplotlib.pyplot as plt\n\ndef task_func(letters, repetitions, colors):\n    if len(letters) == 0 or len(colors) == 0:\n        raise ValueError(\"Lists cannot be empty\")\n    if len(letters) != len(colors):\n        raise ValueError(\"Lengths of the input lists do not match\")\n    letter_freq = np.zeros(len(letters))\n    for i in range(len(letters)):\n        letter_freq[i] = letters.count(letters[i])\n    plt.bar(letters, letter_freq, color=colors)\n    plt.xlabel('Letters')\n    plt.ylabel('Frequency')\n    plt.title('Frequency of Letters')\n    return plt.gca()\n```"}
{"task_id": "BigCodeBench/911", "solution": "from functools import reduce\nimport operator\nimport string\ndef task_func(letters):\n    letter_to_num = {letter: i + 1 for i, letter in enumerate(string.ascii_uppercase)}\n    return reduce(operator.mul, [letter_to_num[letter] for letter in letters])", "raw_solution": "from functools import reduce\nimport operator\nimport string\n\ndef task_func(letters):\n    letter_to_num = {letter: i + 1 for i, letter in enumerate(string.ascii_uppercase)}\n    return reduce(operator.mul, [letter_to_num[letter] for letter in letters])\n```"}
{"task_id": "BigCodeBench/912", "solution": "from collections import Counter\nimport itertools\ndef task_func(letters: list, repetitions: int) -> dict:\n    repeated_letters = itertools.cycle(letters) * repetitions\n    return dict(Counter(repeated_letters))", "raw_solution": "from collections import Counter\nimport itertools\n\ndef task_func(letters: list, repetitions: int) -> dict:\n    repeated_letters = itertools.cycle(letters) * repetitions\n    return dict(Counter(repeated_letters))\n```"}
{"task_id": "BigCodeBench/913", "solution": "from typing import List, Union\nimport numpy as np\nimport scipy.fft\ndef task_func(data: List[Union[int, str]], repetitions: int = 1):\n    if len(data) == 0 or repetitions <= 0:\n        return {'mode': [], 'count': []}\n    data = data * repetitions\n    data = np.array(data)\n    mode, count = np.unique(data, return_counts=True)\n    mode = np.sort(mode)\n    count = np.sort(count)\n    return {'mode': mode, 'count': count}", "raw_solution": "from typing import List, Union\nimport numpy as np\nimport scipy.fft\n\ndef task_func(data: List[Union[int, str]], repetitions: int = 1):\n    if len(data) == 0 or repetitions <= 0:\n        return {'mode': [], 'count': []}\n    data = data * repetitions\n    data = np.array(data)\n    mode, count = np.unique(data, return_counts=True)\n    mode = np.sort(mode)\n    count = np.sort(count)\n    return {'mode': mode, 'count': count}\n```"}
{"task_id": "BigCodeBench/914", "solution": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LinearRegression\ndef task_func(df):\n    # Generate future timestamps\n    future_timestamps = pd.date_range(start=df.index[-1], periods=7, freq='D')\n    \n    # Create a new DataFrame with future timestamps\n    future_df = pd.DataFrame(index=future_timestamps)\n    \n    # Predict stock closing prices for the next 7 days\n    model = LinearRegression()\n    model.fit(df.values.reshape(-1, 1), df['Close'].values)\n    predicted_prices = model.predict(future_df.values.reshape(-1, 1))\n    \n    # Plot the data\n    fig, ax = plt.subplots()\n    ax.plot(df.index, df['Close'], label='Actual Prices')\n    ax.plot(future_timestamps, predicted_prices, label='Predicted Prices')\n    ax.legend()\n    plt.show()\n    \n    return (predicted_prices, ax)", "raw_solution": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LinearRegression\n\ndef task_func(df):\n    # Generate future timestamps\n    future_timestamps = pd.date_range(start=df.index[-1], periods=7, freq='D')\n    \n    # Create a new DataFrame with future timestamps\n    future_df = pd.DataFrame(index=future_timestamps)\n    \n    # Predict stock closing prices for the next 7 days\n    model = LinearRegression()\n    model.fit(df.values.reshape(-1, 1), df['Close'].values)\n    predicted_prices = model.predict(future_df.values.reshape(-1, 1))\n    \n    # Plot the data\n    fig, ax = plt.subplots()\n    ax.plot(df.index, df['Close'], label='Actual Prices')\n    ax.plot(future_timestamps, predicted_prices, label='Predicted Prices')\n    ax.legend()\n    plt.show()\n    \n    return (predicted_prices, ax)\n```"}
{"task_id": "BigCodeBench/915", "solution": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import zscore\ndef task_func(df, z_threshold=2):\n    z_scores = zscore(df['closing_price'])\n    outliers = df[z_scores > z_threshold]\n    plt.figure(figsize=(10, 6))\n    plt.plot(df.index, df['closing_price'], label='Closing Price')\n    plt.scatter(outliers.index, outliers['closing_price'], color='red', label='Outliers')\n    plt.xlabel('Index')\n    plt.ylabel('Closing Price')\n    plt.title('Outliers in Closing Prices')\n    plt.legend()\n    return outliers, plt.gca()", "raw_solution": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import zscore\ndef task_func(df, z_threshold=2):\n    z_scores = zscore(df['closing_price'])\n    outliers = df[z_scores > z_threshold]\n    plt.figure(figsize=(10, 6))\n    plt.plot(df.index, df['closing_price'], label='Closing Price')\n    plt.scatter(outliers.index, outliers['closing_price'], color='red', label='Outliers')\n    plt.xlabel('Index')\n    plt.ylabel('Closing Price')\n    plt.title('Outliers in Closing Prices')\n    plt.legend()\n    return outliers, plt.gca()\n```"}
{"task_id": "BigCodeBench/916", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\ndef task_func(df: pd.DataFrame) -> tuple:\n    boxplot = sns.boxplot(data=df['Close'], palette='Set1')\n    boxplot.set_title('Box Plot of Closing Prices')\n    histogram = sns.histplot(data=df['Close'], kde=True, palette='Set1')\n    histogram.set_title('Histogram of Closing Prices')\n    return boxplot, histogram", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\ndef task_func(df: pd.DataFrame) -> tuple:\n    boxplot = sns.boxplot(data=df['Close'], palette='Set1')\n    boxplot.set_title('Box Plot of Closing Prices')\n    histogram = sns.histplot(data=df['Close'], kde=True, palette='Set1')\n    histogram.set_title('Histogram of Closing Prices')\n    return boxplot, histogram\n```"}
{"task_id": "BigCodeBench/917", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nfrom matplotlib.axes import Axes\nfrom statsmodels.tsa.arima.model import ARIMA\nfrom typing import List, Tuple\ndef task_func(df: pd.DataFrame) -> Tuple[List[float], Axes]:\n    # Fit ARIMA model\n    model = ARIMA(df['Close'], order=(1, 1, 1))\n    model_fit = model.fit(disp=0)\n    \n    # Forecast the next 7 days\n    forecast = model_fit.forecast(steps=7)\n    \n    # Plot the forecast\n    fig, ax = plt.subplots()\n    ax.plot(df.index, df['Close'], label='Actual')\n    ax.plot(df.index[-7:], forecast, label='Forecast')\n    ax.legend()\n    return forecast, ax", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nfrom matplotlib.axes import Axes\nfrom statsmodels.tsa.arima.model import ARIMA\nfrom typing import List, Tuple\n\ndef task_func(df: pd.DataFrame) -> Tuple[List[float], Axes]:\n    # Fit ARIMA model\n    model = ARIMA(df['Close'], order=(1, 1, 1))\n    model_fit = model.fit(disp=0)\n    \n    # Forecast the next 7 days\n    forecast = model_fit.forecast(steps=7)\n    \n    # Plot the forecast\n    fig, ax = plt.subplots()\n    ax.plot(df.index, df['Close'], label='Actual')\n    ax.plot(df.index[-7:], forecast, label='Forecast')\n    ax.legend()\n    return forecast, ax\n```"}
{"task_id": "BigCodeBench/918", "solution": "import pandas as pd\nimport re\ndef task_func(data, mapping):\n    # Create a copy of the DataFrame\n    df = data.copy()\n    # Iterate over each cell in the DataFrame\n    for i, row in df.iterrows():\n        for j, cell in row.iteritems():\n            # Check if the cell is a string\n            if isinstance(cell, str):\n                # Replace all acronyms in the string with their full words\n                df.at[i, j] = re.sub(r'\\b(' + '|'.join(mapping.keys()) + r')\\b', lambda x: mapping[x.group()], cell)\n    return df", "raw_solution": "import pandas as pd\nimport re\n# Function to replace acronyms in DataFrame\ndef task_func(data, mapping):\n    # Create a copy of the DataFrame\n    df = data.copy()\n    # Iterate over each cell in the DataFrame\n    for i, row in df.iterrows():\n        for j, cell in row.iteritems():\n            # Check if the cell is a string\n            if isinstance(cell, str):\n                # Replace all acronyms in the string with their full words\n                df.at[i, j] = re.sub(r'\\b(' + '|'.join(mapping.keys()) + r')\\b', lambda x: mapping[x.group()], cell)\n    return df\n```"}
{"task_id": "BigCodeBench/919", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nCATEGORIES = ['A', 'B', 'C', 'D', 'E']\ndef task_func(data, column):\n    df = pd.DataFrame(data)\n    category_counts = df[column].value_counts()\n    category_counts = category_counts.reindex(CATEGORIES, fill_value=0)\n    plt.bar(category_counts.index, category_counts.values)\n    plt.xlabel('Category')\n    plt.ylabel('Count')\n    plt.title(f'Distribution of {column}')\n    return plt.gca()", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\n\nCATEGORIES = ['A', 'B', 'C', 'D', 'E']\n\ndef task_func(data, column):\n    df = pd.DataFrame(data)\n    category_counts = df[column].value_counts()\n    category_counts = category_counts.reindex(CATEGORIES, fill_value=0)\n    plt.bar(category_counts.index, category_counts.values)\n    plt.xlabel('Category')\n    plt.ylabel('Count')\n    plt.title(f'Distribution of {column}')\n    return plt.gca()\n```"}
{"task_id": "BigCodeBench/920", "solution": "import pandas as pd\nimport seaborn as sns\ndef task_func(data):\n    corr = data.corr()\n    fig, ax = plt.subplots(figsize=(10, 10))\n    sns.heatmap(corr, annot=True, cmap='coolwarm', ax=ax)\n    ax.set_title('Correlation Matrix')\n    return ax", "raw_solution": "import pandas as pd\nimport seaborn as sns\ndef task_func(data):\n    corr = data.corr()\n    fig, ax = plt.subplots(figsize=(10, 10))\n    sns.heatmap(corr, annot=True, cmap='coolwarm', ax=ax)\n    ax.set_title('Correlation Matrix')\n    return ax\n```"}
{"task_id": "BigCodeBench/921", "solution": "import pandas as pd\nfrom sklearn.preprocessing import MinMaxScaler\ndef task_func(data, columns):\n    scaler = MinMaxScaler()\n    scaled_data = scaler.fit_transform(data[columns])\n    return pd.DataFrame(scaled_data, columns=columns)", "raw_solution": "import pandas as pd\nfrom sklearn.preprocessing import MinMaxScaler\n\ndef task_func(data, columns):\n    scaler = MinMaxScaler()\n    scaled_data = scaler.fit_transform(data[columns])\n    return pd.DataFrame(scaled_data, columns=columns)\n```"}
{"task_id": "BigCodeBench/922", "solution": "import pandas as pd\nimport re\nSTOPWORDS = set([\n    \"i\", \"me\", \"my\", \"myself\", \"we\", \"our\", \"ours\", \"ourselves\", \"you\", \"your\", \"yours\", \"yourself\",\n    \"yourselves\", \"he\", \"him\", \"his\", \"himself\", \"she\", \"her\", \"hers\", \"herself\", \"it\", \"its\", \"itself\",\n    \"they\", \"them\", \"their\", \"theirs\", \"themselves\", \"what\", \"which\", \"who\", \"whom\", \"this\", \"that\",\n    \"these\", \"those\", \"am\", \"is\", \"are\", \"was\", \"were\", \"be\", \"been\", \"being\", \"have\", \"has\", \"had\",\n    \"having\", \"do\", \"does\", \"did\", \"doing\", \"a\", \"an\", \"the\", \"and\", \"but\", \"if\", \"or\", \"because\",\n    \"as\", \"until\", \"while\", \"of\", \"at\", \"by\", \"for\", \"with\", \"about\", \"against\", \"between\", \"into\",\n    \"through\", \"during\", \"before\", \"after\", \"above\", \"below\", \"to\", \"from\", \"up\", \"down\", \"in\", \"out\",\n    \"on\", \"off\", \"over\", \"under\", \"again\", \"further\", \"then\", \"once\", \"here\", \"there\", \"when\", \"where\",\n    \"why\", \"how\", \"all\", \"any\", \"both\", \"each\", \"few\", \"more\", \"most\", \"other\", \"some\", \"such\", \"no\",\n    \"nor\", \"not\", \"only\", \"own\", \"same\", \"so\", \"than\", \"too\", \"very\", \"s\", \"t\", \"can\", \"will\", \"just\",\n    \"don\", \"should\", \"now\"\n])\ndef task_func(data, column):\n    # Remove English stopwords from the specified column\n    data[column] = data[column].apply(lambda x: ' '.join([word for word in x.split() if word not in STOPWORDS]))\n    return data", "raw_solution": "import pandas as pd\nimport re\n# Constants\nSTOPWORDS = set([\n    \"i\", \"me\", \"my\", \"myself\", \"we\", \"our\", \"ours\", \"ourselves\", \"you\", \"your\", \"yours\", \"yourself\",\n    \"yourselves\", \"he\", \"him\", \"his\", \"himself\", \"she\", \"her\", \"hers\", \"herself\", \"it\", \"its\", \"itself\",\n    \"they\", \"them\", \"their\", \"theirs\", \"themselves\", \"what\", \"which\", \"who\", \"whom\", \"this\", \"that\",\n    \"these\", \"those\", \"am\", \"is\", \"are\", \"was\", \"were\", \"be\", \"been\", \"being\", \"have\", \"has\", \"had\",\n    \"having\", \"do\", \"does\", \"did\", \"doing\", \"a\", \"an\", \"the\", \"and\", \"but\", \"if\", \"or\", \"because\",\n    \"as\", \"until\", \"while\", \"of\", \"at\", \"by\", \"for\", \"with\", \"about\", \"against\", \"between\", \"into\",\n    \"through\", \"during\", \"before\", \"after\", \"above\", \"below\", \"to\", \"from\", \"up\", \"down\", \"in\", \"out\",\n    \"on\", \"off\", \"over\", \"under\", \"again\", \"further\", \"then\", \"once\", \"here\", \"there\", \"when\", \"where\",\n    \"why\", \"how\", \"all\", \"any\", \"both\", \"each\", \"few\", \"more\", \"most\", \"other\", \"some\", \"such\", \"no\",\n    \"nor\", \"not\", \"only\", \"own\", \"same\", \"so\", \"than\", \"too\", \"very\", \"s\", \"t\", \"can\", \"will\", \"just\",\n    \"don\", \"should\", \"now\"\n])\ndef task_func(data, column):\n    # Remove English stopwords from the specified column\n    data[column] = data[column].apply(lambda x: ' '.join([word for word in x.split() if word not in STOPWORDS]))\n    return data\n```"}
{"task_id": "BigCodeBench/923", "solution": "import pandas as pd\nimport random\nimport re\ndef task_func(person_names, email_domains, num_records=5):\n    if len(person_names) < num_records or len(email_domains) == 0:\n        raise ValueError(\"Invalid input\")\n    emails = []\n    for i in range(num_records):\n        name = random.choice(person_names)\n        domain = random.choice(email_domains)\n        email = name + \"@\" + domain\n        emails.append(email)\n    df = pd.DataFrame({'Name': person_names, 'Email': emails})\n    df['Email'] = df['Email'].str.replace(\"@\", \"[at]\")\n    return df", "raw_solution": "import pandas as pd\nimport random\nimport re\n\ndef task_func(person_names, email_domains, num_records=5):\n    if len(person_names) < num_records or len(email_domains) == 0:\n        raise ValueError(\"Invalid input\")\n    emails = []\n    for i in range(num_records):\n        name = random.choice(person_names)\n        domain = random.choice(email_domains)\n        email = name + \"@\" + domain\n        emails.append(email)\n    df = pd.DataFrame({'Name': person_names, 'Email': emails})\n    df['Email'] = df['Email'].str.replace(\"@\", \"[at]\")\n    return df\n```"}
{"task_id": "BigCodeBench/924", "solution": "import pandas as pd\nimport os\nimport sys\ndef task_func(file_path: str, column_name: str) -> pd.DataFrame:\n    df = pd.read_csv(file_path)\n    df[column_name] = df[column_name].str.replace('\\n', '<br>')\n    return df", "raw_solution": "import pandas as pd\nimport os\nimport sys\ndef task_func(file_path: str, column_name: str) -> pd.DataFrame:\n    df = pd.read_csv(file_path)\n    df[column_name] = df[column_name].str.replace('\\n', '<br>')\n    return df\n```"}
{"task_id": "BigCodeBench/925", "solution": "import pandas as pd\nimport numpy as np\ndef task_func(data_size=1000, column_names=['A', 'B', 'C', 'D', 'E'], seed=0):\n    np.random.seed(seed)\n    df = pd.DataFrame(np.random.randint(1, 101, (data_size, len(column_names))), columns=column_names)\n    df.loc[df < 10, :] = -1\n    return df", "raw_solution": "import pandas as pd\nimport numpy as np\ndef task_func(data_size=1000, column_names=['A', 'B', 'C', 'D', 'E'], seed=0):\n    np.random.seed(seed)\n    df = pd.DataFrame(np.random.randint(1, 101, (data_size, len(column_names))), columns=column_names)\n    df.loc[df < 10, :] = -1\n    return df\n```"}
{"task_id": "BigCodeBench/926", "solution": "import pandas as pd\nimport sqlite3\ndef task_func(db_path: str, table_name: str, column_name: str) -> pd.DataFrame:\n    conn = sqlite3.connect(db_path)\n    df = pd.read_sql_query(f\"SELECT * FROM {table_name}\", conn)\n    df[column_name] = df[column_name].str.replace('\\n', '<br>')\n    return df", "raw_solution": "import pandas as pd\nimport sqlite3\n\ndef task_func(db_path: str, table_name: str, column_name: str) -> pd.DataFrame:\n    conn = sqlite3.connect(db_path)\n    df = pd.read_sql_query(f\"SELECT * FROM {table_name}\", conn)\n    df[column_name] = df[column_name].str.replace('\\n', '<br>')\n    return df\n```"}
{"task_id": "BigCodeBench/927", "solution": "import pandas as pd\nfrom sklearn.preprocessing import LabelEncoder\ndef task_func(file_path: str, column_name: str) -> pd.DataFrame:\n    df = pd.read_csv(file_path)\n    df[column_name] = df[column_name].str.replace('\\n', '<br>')\n    le = LabelEncoder()\n    df[column_name] = le.fit_transform(df[column_name])\n    return df", "raw_solution": "import pandas as pd\nfrom sklearn.preprocessing import LabelEncoder\n\ndef task_func(file_path: str, column_name: str) -> pd.DataFrame:\n    df = pd.read_csv(file_path)\n    df[column_name] = df[column_name].str.replace('\\n', '<br>')\n    le = LabelEncoder()\n    df[column_name] = le.fit_transform(df[column_name])\n    return df\n```"}
{"task_id": "BigCodeBench/928", "solution": "from collections import Counter\nimport itertools\nimport string\ndef task_func(word: str) -> dict:\n    return dict(Counter(itertools.combinations(word, 2)))", "raw_solution": "from collections import Counter\nimport itertools\nimport string\ndef task_func(word: str) -> dict:\n    return dict(Counter(itertools.combinations(word, 2)))\n```"}
{"task_id": "BigCodeBench/929", "solution": "import numpy as np\nfrom scipy import stats\ndef task_func(word: str) -> np.ndarray:\n    ascii_values = np.array([ord(c) for c in word])\n    differences = ascii_values[1:] - ascii_values[:-1]\n    return differences", "raw_solution": "import numpy as np\nfrom scipy import stats\n\ndef task_func(word: str) -> np.ndarray:\n    ascii_values = np.array([ord(c) for c in word])\n    differences = ascii_values[1:] - ascii_values[:-1]\n    return differences\n```"}
{"task_id": "BigCodeBench/930", "solution": "import random\nimport string\ndef task_func(word):\n    if not all(c in string.ascii_letters for c in word):\n        raise ValueError(\"If the input contains non-letter characters.\")\n    pairs = []\n    for i in range(len(word) - 1):\n        pairs.append(word[i:i+2])\n    return pairs", "raw_solution": "import random\nimport string\nPOSSIBLE_LETTERS = ['a', 'b', 'c']\n\ndef task_func(word):\n    if not all(c in string.ascii_letters for c in word):\n        raise ValueError(\"If the input contains non-letter characters.\")\n    pairs = []\n    for i in range(len(word) - 1):\n        pairs.append(word[i:i+2])\n    return pairs\n```"}
{"task_id": "BigCodeBench/931", "solution": "from collections import defaultdict\nimport re\ndef task_func(word: str) -> dict:\n    sanitized_word = re.sub(r'[^a-zA-Z]', '', word)\n    return defaultdict(int, {word[i:i+2]: sanitized_word.count(word[i:i+2]) for i in range(len(sanitized_word) - 1)})", "raw_solution": "from collections import defaultdict\nimport re\n\ndef task_func(word: str) -> dict:\n    sanitized_word = re.sub(r'[^a-zA-Z]', '', word)\n    return defaultdict(int, {word[i:i+2]: sanitized_word.count(word[i:i+2]) for i in range(len(sanitized_word) - 1)})\n```"}
{"task_id": "BigCodeBench/932", "solution": "from collections import Counter\nimport re\ndef task_func(word: str) -> list:\n    if len(word) < 2 or not re.match(r'^[a-z]+$', word):\n        return []\n    word = word.lower()\n    word = re.sub(r'[^a-z]', '', word)\n    word = word.replace(' ', '')\n    word = word.replace('-', '')\n    word = word.replace('_', '')\n    word = word.replace('.', '')\n    word = word.replace(',', '')\n    word = word.replace(';', '')\n    word = word.replace(':', '')\n    word = word.replace('!', '')\n    word = word.replace('?', '')\n    word = word.replace('(', '')\n    word = word.replace(')', '')\n    word = word.replace('[', '')\n    word = word.replace(']', '')\n    word = word.replace('{', '')\n    word = word.replace('}', '')\n    word = word.replace('<', '')\n    word = word.replace('>', '')\n    word = word.replace('|', '')\n    word = word.replace('~', '')\n    word = word.replace('^', '')\n    word = word.replace('&', '')\n    word = word.replace('*', '')\n    word = word.replace('+', '')\n    word = word.replace('%', '')\n    word = word.replace('$', '')\n    word = word.replace('#', '')\n    word = word.replace('@', '')\n    word = word.replace(';', '')\n    word = word.replace(':', '')\n    word = word.replace('!', '')\n    word = word.replace('?', '')\n    word = word.replace('(', '')\n    word = word.replace(')', '')\n    word = word.replace('[', '')\n    word = word.replace(']', '')\n    word = word.replace('{', '')\n    word = word.replace('}', '')\n    word = word.replace('<', '')\n    word = word.replace('>', '')\n    word = word.replace('|', '')\n    word = word.replace('~', '')\n    word = word.replace('^', '')\n    word = word.replace('&', '')\n    word = word.replace('*', '')\n    word = word.replace('+', '')\n    word = word.replace('%', '')\n    word = word.replace('$', '')\n    word = word.replace('#', '')\n    word = word.replace('@', '')\n    word = word.replace(';', '')\n    word = word.replace(':', '')\n    word = word.replace('!', '')\n    word = word.replace('?', '')\n    word = word.replace('(', '')\n    word = word.replace(')', '')\n    word = word.replace('[', '')\n    word = word.replace(']', '')\n    word = word.replace('{', '')\n    word = word.replace('}', '')\n    word = word.replace('<', '')\n    word = word.replace('>', '')\n    word = word.replace('|', '')\n    word = word.replace('~', '')\n    word = word.replace('^', '')\n    word = word.replace('&', '')\n    word = word.replace('*', '')\n    word = word.replace('+', '')\n    word = word.replace('%', '')\n    word = word.replace('$', '')\n    word = word.replace('#', '')\n    word = word.replace('@', '')\n    word = word.replace(';', '')\n    word = word.replace(':', '')\n    word = word.replace('!', '')\n    word = word.replace('?', '')\n    word = word.replace('(', '')\n    word = word.replace(')', '')\n    word = word.replace('[', '')\n    word = word.replace(']', '')\n    word = word.replace('{', '')\n    word = word.replace('}', '')\n    word = word.replace('<', '')\n    word = word.replace('>', '')\n    word = word.replace('|', '')\n    word = word.replace('~', '')\n    word = word.replace('^', '')\n    word = word.replace('&', '')\n    word = word.replace('*', '')\n    word = word.replace('+', '')\n    word = word.replace('%', '')\n    word = word.replace('$', '')\n    word = word.replace('#', '')\n    word = word.replace('@', '')\n    word = word.replace(';', '')\n    word = word.replace(':', '')\n    word = word.replace('!', '')\n    word = word.replace('?', '')\n    word = word.replace('(', '')\n    word = word.replace(')', '')\n    word = word.replace('[', '')\n    word = word.replace(']', '')\n    word = word.replace('{', '')\n    word = word.replace('}', '')\n    word = word.replace('<', '')\n    word = word.replace('>', '')\n    word = word.replace('|', '')\n    word = word.replace('~', '')\n    word = word.replace('^', '')\n    word = word.replace('&', '')\n    word = word.replace('*', '')\n    word = word.replace('+', '')\n    word = word.replace('%', '')\n    word = word.replace('$', '')\n    word = word.replace('#', '')\n    word = word.replace('@', '')\n    word = word.replace(';', '')\n    word = word.replace(':', '')\n    word = word.replace('!', '')\n    word = word.replace('?', '')\n    word = word.replace('(', '')\n    word = word.replace(')', '')\n    word = word.replace('[', '')\n    word = word.replace(']', '')\n    word = word.replace('{', '')\n    word = word.replace('}', '')\n    word = word.replace('<', '')\n    word = word.replace('>', '')\n    word = word.replace('|', '')\n    word = word.replace('~', '')\n    word = word.replace('^', '')\n    word = word.replace('&', '')\n    word = word.replace('*', '')\n    word = word.replace('+', '')\n    word = word.replace('%', '')\n    word = word.replace('$', '')\n    word = word.replace('#', '')\n    word = word.replace('@', '')\n    word = word.replace(';', '')\n    word = word.replace(':', '')\n    word = word.replace('!', '')\n    word = word.replace('?', '')\n    word = word.replace('(', '')\n    word = word.replace(')', '')\n    word = word.replace('[', '')\n    word = word.replace(']', '')\n    word = word.replace('{', '')\n    word = word.replace('}', '')\n    word = word.replace('<', '')\n    word = word.replace('>', '')\n    word = word.replace('|', '')\n    word = word.replace('~', '')\n    word = word.replace('^', '')\n    word = word.replace('&', '')\n    word = word.replace('*', '')\n    word = word", "raw_solution": "from collections import Counter\nimport re\n\ndef task_func(word: str) -> list:\n    if len(word) < 2 or not re.match(r'^[a-z]+$', word):\n        return []\n    word = word.lower()\n    word = re.sub(r'[^a-z]', '', word)\n    word = word.replace(' ', '')\n    word = word.replace('-', '')\n    word = word.replace('_', '')\n    word = word.replace('.', '')\n    word = word.replace(',', '')\n    word = word.replace(';', '')\n    word = word.replace(':', '')\n    word = word.replace('!', '')\n    word = word.replace('?', '')\n    word = word.replace('(', '')\n    word = word.replace(')', '')\n    word = word.replace('[', '')\n    word = word.replace(']', '')\n    word = word.replace('{', '')\n    word = word.replace('}', '')\n    word = word.replace('<', '')\n    word = word.replace('>', '')\n    word = word.replace('|', '')\n    word = word.replace('~', '')\n    word = word.replace('^', '')\n    word = word.replace('&', '')\n    word = word.replace('*', '')\n    word = word.replace('+', '')\n    word = word.replace('%', '')\n    word = word.replace('$', '')\n    word = word.replace('#', '')\n    word = word.replace('@', '')\n    word = word.replace(';', '')\n    word = word.replace(':', '')\n    word = word.replace('!', '')\n    word = word.replace('?', '')\n    word = word.replace('(', '')\n    word = word.replace(')', '')\n    word = word.replace('[', '')\n    word = word.replace(']', '')\n    word = word.replace('{', '')\n    word = word.replace('}', '')\n    word = word.replace('<', '')\n    word = word.replace('>', '')\n    word = word.replace('|', '')\n    word = word.replace('~', '')\n    word = word.replace('^', '')\n    word = word.replace('&', '')\n    word = word.replace('*', '')\n    word = word.replace('+', '')\n    word = word.replace('%', '')\n    word = word.replace('$', '')\n    word = word.replace('#', '')\n    word = word.replace('@', '')\n    word = word.replace(';', '')\n    word = word.replace(':', '')\n    word = word.replace('!', '')\n    word = word.replace('?', '')\n    word = word.replace('(', '')\n    word = word.replace(')', '')\n    word = word.replace('[', '')\n    word = word.replace(']', '')\n    word = word.replace('{', '')\n    word = word.replace('}', '')\n    word = word.replace('<', '')\n    word = word.replace('>', '')\n    word = word.replace('|', '')\n    word = word.replace('~', '')\n    word = word.replace('^', '')\n    word = word.replace('&', '')\n    word = word.replace('*', '')\n    word = word.replace('+', '')\n    word = word.replace('%', '')\n    word = word.replace('$', '')\n    word = word.replace('#', '')\n    word = word.replace('@', '')\n    word = word.replace(';', '')\n    word = word.replace(':', '')\n    word = word.replace('!', '')\n    word = word.replace('?', '')\n    word = word.replace('(', '')\n    word = word.replace(')', '')\n    word = word.replace('[', '')\n    word = word.replace(']', '')\n    word = word.replace('{', '')\n    word = word.replace('}', '')\n    word = word.replace('<', '')\n    word = word.replace('>', '')\n    word = word.replace('|', '')\n    word = word.replace('~', '')\n    word = word.replace('^', '')\n    word = word.replace('&', '')\n    word = word.replace('*', '')\n    word = word.replace('+', '')\n    word = word.replace('%', '')\n    word = word.replace('$', '')\n    word = word.replace('#', '')\n    word = word.replace('@', '')\n    word = word.replace(';', '')\n    word = word.replace(':', '')\n    word = word.replace('!', '')\n    word = word.replace('?', '')\n    word = word.replace('(', '')\n    word = word.replace(')', '')\n    word = word.replace('[', '')\n    word = word.replace(']', '')\n    word = word.replace('{', '')\n    word = word.replace('}', '')\n    word = word.replace('<', '')\n    word = word.replace('>', '')\n    word = word.replace('|', '')\n    word = word.replace('~', '')\n    word = word.replace('^', '')\n    word = word.replace('&', '')\n    word = word.replace('*', '')\n    word = word.replace('+', '')\n    word = word.replace('%', '')\n    word = word.replace('$', '')\n    word = word.replace('#', '')\n    word = word.replace('@', '')\n    word = word.replace(';', '')\n    word = word.replace(':', '')\n    word = word.replace('!', '')\n    word = word.replace('?', '')\n    word = word.replace('(', '')\n    word = word.replace(')', '')\n    word = word.replace('[', '')\n    word = word.replace(']', '')\n    word = word.replace('{', '')\n    word = word.replace('}', '')\n    word = word.replace('<', '')\n    word = word.replace('>', '')\n    word = word.replace('|', '')\n    word = word.replace('~', '')\n    word = word.replace('^', '')\n    word = word.replace('&', '')\n    word = word.replace('*', '')\n    word = word.replace('+', '')\n    word = word.replace('%', '')\n    word = word.replace('$', '')\n    word = word.replace('#', '')\n    word = word.replace('@', '')\n    word = word.replace(';', '')\n    word = word.replace(':', '')\n    word = word.replace('!', '')\n    word = word.replace('?', '')\n    word = word.replace('(', '')\n    word = word.replace(')', '')\n    word = word.replace('[', '')\n    word = word.replace(']', '')\n    word = word.replace('{', '')\n    word = word.replace('}', '')\n    word = word.replace('<', '')\n    word = word.replace('>', '')\n    word = word.replace('|', '')\n    word = word.replace('~', '')\n    word = word.replace('^', '')\n    word = word.replace('&', '')\n    word = word.replace('*', '')\n    word = word"}
{"task_id": "BigCodeBench/933", "solution": "import string\nimport wordninja\ndef task_func(word):\n    # Convert word to lowercase\n    word = word.lower()\n    # Create list of tuples with each tuple containing a letter from the word and its position in the alphabet\n    alphabet = string.ascii_lowercase\n    letter_positions = [(letter, alphabet.index(letter) + 1) for letter in word]\n    # Split the given word into a list of words\n    words = wordninja.split(word)\n    return letter_positions, words", "raw_solution": "import string\nimport wordninja\n\ndef task_func(word):\n    # Convert word to lowercase\n    word = word.lower()\n    # Create list of tuples with each tuple containing a letter from the word and its position in the alphabet\n    alphabet = string.ascii_lowercase\n    letter_positions = [(letter, alphabet.index(letter) + 1) for letter in word]\n    # Split the given word into a list of words\n    words = wordninja.split(word)\n    return letter_positions, words\n```"}
{"task_id": "BigCodeBench/934", "solution": "from collections import Counter\nimport hashlib\ndef task_func(word: str) -> dict:\n    pairs = Counter(word[i:i+2] for i in range(len(word)-1))\n    return {'md5': hashlib.md5(str(pairs).encode()).hexdigest()}", "raw_solution": "from collections import Counter\nimport hashlib\n\ndef task_func(word: str) -> dict:\n    pairs = Counter(word[i:i+2] for i in range(len(word)-1))\n    return {'md5': hashlib.md5(str(pairs).encode()).hexdigest()}\n```"}
{"task_id": "BigCodeBench/935", "solution": "import pandas as pd\nimport string\ndef task_func(word):\n    if not word.islower() or not word.isalpha():\n        raise ValueError(\"If the input word is not in lowercase or contains non-alphabetic characters.\")\n    df = pd.DataFrame({'Letter': list(word), 'Position': [ord(letter) - ord('a') + 1 for letter in word]})\n    return df", "raw_solution": "import pandas as pd\nimport string\n\ndef task_func(word):\n    if not word.islower() or not word.isalpha():\n        raise ValueError(\"If the input word is not in lowercase or contains non-alphabetic characters.\")\n    df = pd.DataFrame({'Letter': list(word), 'Position': [ord(letter) - ord('a') + 1 for letter in word]})\n    return df\n```"}
{"task_id": "BigCodeBench/936", "solution": "import numpy as np\nimport matplotlib.pyplot as plt\nimport string\nALPHABET = list(string.ascii_lowercase)\ndef task_func(word):\n    # Create a numpy array of zeros with the same length as the alphabet\n    positions = np.zeros(len(ALPHABET))\n    # Iterate over each letter in the word\n    for letter in word:\n        # Find the index of the letter in the alphabet\n        index = ALPHABET.index(letter)\n        # Set the corresponding position in the array to 1\n        positions[index] = 1\n    # Create a bar chart using matplotlib\n    plt.bar(ALPHABET, positions)\n    # Set the title and labels\n    plt.title('Positions of letters in the word')\n    plt.xlabel('Letters')\n    plt.ylabel('Positions')\n    # Show the plot\n    plt.show()\n    # Return the axes object\n    return plt.gca()", "raw_solution": "import numpy as np\nimport matplotlib.pyplot as plt\nimport string\n# Constants\nALPHABET = list(string.ascii_lowercase)\n\ndef task_func(word):\n    # Create a numpy array of zeros with the same length as the alphabet\n    positions = np.zeros(len(ALPHABET))\n    # Iterate over each letter in the word\n    for letter in word:\n        # Find the index of the letter in the alphabet\n        index = ALPHABET.index(letter)\n        # Set the corresponding position in the array to 1\n        positions[index] = 1\n    # Create a bar chart using matplotlib\n    plt.bar(ALPHABET, positions)\n    # Set the title and labels\n    plt.title('Positions of letters in the word')\n    plt.xlabel('Letters')\n    plt.ylabel('Positions')\n    # Show the plot\n    plt.show()\n    # Return the axes object\n    return plt.gca()\n```"}
{"task_id": "BigCodeBench/937", "solution": "import re\nfrom collections import Counter\ndef task_func(input_str):\n    # Remove all non-alphanumeric characters\n    input_str = re.sub(r'[^a-zA-Z0-9]', '', input_str)\n    # Convert to lowercase\n    input_str = input_str.lower()\n    # Count the frequency of each character\n    char_freq = Counter(input_str)\n    return char_freq", "raw_solution": "import re\nfrom collections import Counter\ndef task_func(input_str):\n    # Remove all non-alphanumeric characters\n    input_str = re.sub(r'[^a-zA-Z0-9]', '', input_str)\n    # Convert to lowercase\n    input_str = input_str.lower()\n    # Count the frequency of each character\n    char_freq = Counter(input_str)\n    return char_freq\n```"}
{"task_id": "BigCodeBench/938", "solution": "import re\nimport pandas as pd\ndef task_func(input_df):\n    # Remove special characters, punctuation marks, and spaces\n    input_df['clean_text'] = input_df['text'].str.replace(r'[^a-zA-Z0-9]', '', regex=True)\n    \n    # Calculate the length of the cleaned text\n    input_df['text_length'] = input_df['clean_text'].str.len()\n    \n    return input_df", "raw_solution": "import re\nimport pandas as pd\n\ndef task_func(input_df):\n    # Remove special characters, punctuation marks, and spaces\n    input_df['clean_text'] = input_df['text'].str.replace(r'[^a-zA-Z0-9]', '', regex=True)\n    \n    # Calculate the length of the cleaned text\n    input_df['text_length'] = input_df['clean_text'].str.len()\n    \n    return input_df\n```"}
{"task_id": "BigCodeBench/939", "solution": "import re\nimport os\nimport glob\ndef task_func(dir_path: str) -> list:\n    # Get all files in the directory\n    files = glob.glob(os.path.join(dir_path, '*'))\n    # Define a regular expression pattern to match special characters, punctuation marks, and spaces\n    pattern = re.compile('[^a-zA-Z0-9]')\n    # Rename all files by removing special characters, punctuation marks, and spaces\n    new_names = [pattern.sub('', os.path.splitext(os.path.basename(file))[0]) + os.path.splitext(os.path.basename(file))[1] for file in files]\n    return new_names", "raw_solution": "import re\nimport os\nimport glob\n\ndef task_func(dir_path: str) -> list:\n    # Get all files in the directory\n    files = glob.glob(os.path.join(dir_path, '*'))\n    # Define a regular expression pattern to match special characters, punctuation marks, and spaces\n    pattern = re.compile('[^a-zA-Z0-9]')\n    # Rename all files by removing special characters, punctuation marks, and spaces\n    new_names = [pattern.sub('', os.path.splitext(os.path.basename(file))[0]) + os.path.splitext(os.path.basename(file))[1] for file in files]\n    return new_names\n```"}
{"task_id": "BigCodeBench/940", "solution": "import re\nfrom nltk import word_tokenize\nfrom collections import Counter\ndef task_func(input_str):\n    # Remove all special characters, punctuation marks and spaces from the string\n    input_str = re.sub(r'[^\\w\\s]', '', input_str)\n    \n    # Tokenize the string into words\n    words = word_tokenize(input_str)\n    \n    # Count the frequency of each word\n    word_freq = Counter(words)\n    \n    return word_freq", "raw_solution": "import re\nfrom nltk import word_tokenize\nfrom collections import Counter\n\ndef task_func(input_str):\n    # Remove all special characters, punctuation marks and spaces from the string\n    input_str = re.sub(r'[^\\w\\s]', '', input_str)\n    \n    # Tokenize the string into words\n    words = word_tokenize(input_str)\n    \n    # Count the frequency of each word\n    word_freq = Counter(words)\n    \n    return word_freq\n```"}
{"task_id": "BigCodeBench/941", "solution": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\ndef task_func(start_date: str, periods: int, freq: str, random_seed: int = 0) -> (pd.DataFrame, plt.Axes):\n    np.random.seed(random_seed)\n    df = pd.DataFrame({'Date': pd.date_range(start=start_date, periods=periods, freq=freq)})\n    df['Sales'] = np.random.randint(100, 1000, periods)\n    fig, ax = plt.subplots()\n    ax.plot(df['Date'], df['Sales'])\n    return df, ax", "raw_solution": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef task_func(start_date: str, periods: int, freq: str, random_seed: int = 0) -> (pd.DataFrame, plt.Axes):\n    np.random.seed(random_seed)\n    df = pd.DataFrame({'Date': pd.date_range(start=start_date, periods=periods, freq=freq)})\n    df['Sales'] = np.random.randint(100, 1000, periods)\n    fig, ax = plt.subplots()\n    ax.plot(df['Date'], df['Sales'])\n    return df, ax\n```"}
{"task_id": "BigCodeBench/942", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nSTART_DATE = '2016-01-01'\nPERIODS = 13\nFREQ = 'WOM-2FRI'\nCATEGORIES = ['Electronics', 'Fashion', 'Home & Kitchen', 'Automotive', 'Sports']\ndef task_func(start_date=START_DATE, periods=PERIODS, freq=FREQ, categories=CATEGORIES):\n    # Generate sales data\n    sales_data = pd.DataFrame({\n        'Date': pd.date_range(start=start_date, periods=periods, freq=freq),\n        'Category': np.random.choice(categories, periods),\n        'Sales': np.random.randint(100, 1000, periods)\n    })\n    # Plot sales data\n    fig, ax = plt.subplots()\n    sales_data.groupby('Category')['Sales'].plot(kind='line', ax=ax)\n    ax.set_title('Sales Report')\n    ax.set_xlabel('Date')\n    ax.set_ylabel('Sales')\n    return sales_data, ax", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\n# Constants\nSTART_DATE = '2016-01-01'\nPERIODS = 13\nFREQ = 'WOM-2FRI'\nCATEGORIES = ['Electronics', 'Fashion', 'Home & Kitchen', 'Automotive', 'Sports']\ndef task_func(start_date=START_DATE, periods=PERIODS, freq=FREQ, categories=CATEGORIES):\n    # Generate sales data\n    sales_data = pd.DataFrame({\n        'Date': pd.date_range(start=start_date, periods=periods, freq=freq),\n        'Category': np.random.choice(categories, periods),\n        'Sales': np.random.randint(100, 1000, periods)\n    })\n    # Plot sales data\n    fig, ax = plt.subplots()\n    sales_data.groupby('Category')['Sales'].plot(kind='line', ax=ax)\n    ax.set_title('Sales Report')\n    ax.set_xlabel('Date')\n    ax.set_ylabel('Sales')\n    return sales_data, ax\n```"}
{"task_id": "BigCodeBench/943", "solution": "import pandas as pd\nimport numpy as np\nfrom statsmodels.tsa.seasonal import seasonal_decompose\ndef task_func(start_date='2016-01-01', periods=24, freq='M', model='additive'):\n    # Generate a sales time-series\n    sales = np.random.randint(100, 200, periods)\n    sales_series = pd.Series(sales, index=pd.date_range(start_date, periods=periods, freq=freq))\n    \n    # Decompose the time-series into trend, seasonal, and residual components\n    result = seasonal_decompose(sales_series, model=model)\n    \n    # Return the components as Pandas Series\n    return {'trend': result.trend, 'seasonal': result.seasonal, 'residual': result.resid}", "raw_solution": "import pandas as pd\nimport numpy as np\nfrom statsmodels.tsa.seasonal import seasonal_decompose\ndef task_func(start_date='2016-01-01', periods=24, freq='M', model='additive'):\n    # Generate a sales time-series\n    sales = np.random.randint(100, 200, periods)\n    sales_series = pd.Series(sales, index=pd.date_range(start_date, periods=periods, freq=freq))\n    \n    # Decompose the time-series into trend, seasonal, and residual components\n    result = seasonal_decompose(sales_series, model=model)\n    \n    # Return the components as Pandas Series\n    return {'trend': result.trend, 'seasonal': result.seasonal, 'residual': result.resid}\n```"}
{"task_id": "BigCodeBench/944", "solution": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\ndef task_func(start_date='2016-01-01', periods=13, freq='WOM-2FRI', seed=0):\n    np.random.seed(seed)\n    dates = pd.date_range(start=start_date, periods=periods, freq=freq)\n    prices = np.random.uniform(100, 500, periods)\n    df = pd.DataFrame({'Date': dates, 'Price': prices})\n    plt.plot(df['Date'], df['Price'])\n    return (df, plt.gca())", "raw_solution": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef task_func(start_date='2016-01-01', periods=13, freq='WOM-2FRI', seed=0):\n    np.random.seed(seed)\n    dates = pd.date_range(start=start_date, periods=periods, freq=freq)\n    prices = np.random.uniform(100, 500, periods)\n    df = pd.DataFrame({'Date': dates, 'Price': prices})\n    plt.plot(df['Date'], df['Price'])\n    return (df, plt.gca())\n```"}
{"task_id": "BigCodeBench/945", "solution": "import pandas as pd\nimport numpy as np\nfrom sklearn.linear_model import LinearRegression\ndef task_func(start_date='2016-01-01', periods=13, freq='WOM-2FRI', sales_data=None):\n    if sales_data is None:\n        # Generate sales data\n        sales_data = pd.date_range(start=start_date, periods=periods, freq=freq)\n        sales_data = pd.Series(np.random.randint(100, 200, periods), index=sales_data)\n    # Fit linear regression model\n    model = LinearRegression()\n    model.fit(sales_data.index.values.reshape(-1, 1), sales_data.values)\n    # Forecast future sales\n    future_sales = model.predict(pd.date_range(start=sales_data.index[-1], periods=periods, freq=freq).values.reshape(-1, 1))\n    return future_sales", "raw_solution": "import pandas as pd\nimport numpy as np\nfrom sklearn.linear_model import LinearRegression\n\ndef task_func(start_date='2016-01-01', periods=13, freq='WOM-2FRI', sales_data=None):\n    if sales_data is None:\n        # Generate sales data\n        sales_data = pd.date_range(start=start_date, periods=periods, freq=freq)\n        sales_data = pd.Series(np.random.randint(100, 200, periods), index=sales_data)\n    # Fit linear regression model\n    model = LinearRegression()\n    model.fit(sales_data.index.values.reshape(-1, 1), sales_data.values)\n    # Forecast future sales\n    future_sales = model.predict(pd.date_range(start=sales_data.index[-1], periods=periods, freq=freq).values.reshape(-1, 1))\n    return future_sales\n```"}
{"task_id": "BigCodeBench/946", "solution": "import numpy as np\nimport pandas as pd\nimport random\ndef task_func(rows=3, cols=2, min_val=0, max_val=100, seed=0):\n    random.seed(seed)\n    matrix = np.random.randint(min_val, max_val+1, (rows, cols))\n    df = pd.DataFrame(matrix)\n    return df", "raw_solution": "import numpy as np\nimport pandas as pd\nimport random\n\ndef task_func(rows=3, cols=2, min_val=0, max_val=100, seed=0):\n    random.seed(seed)\n    matrix = np.random.randint(min_val, max_val+1, (rows, cols))\n    df = pd.DataFrame(matrix)\n    return df\n```"}
{"task_id": "BigCodeBench/947", "solution": "import numpy as np\nimport random\nfrom datetime import datetime\ndef task_func(rows=3, columns=2, start_date=datetime(2021, 1, 1), end_date=datetime(2021, 12, 31), seed=0):\n    random.seed(seed)\n    dates = [datetime.strftime(start_date + datetime.timedelta(days=i), '%Y-%m-%d') for i in range((end_date - start_date).days + 1)]\n    np.random.shuffle(dates)\n    return np.array(dates[:rows * columns]).reshape(rows, columns)", "raw_solution": "import numpy as np\nimport random\nfrom datetime import datetime\n\ndef task_func(rows=3, columns=2, start_date=datetime(2021, 1, 1), end_date=datetime(2021, 12, 31), seed=0):\n    random.seed(seed)\n    dates = [datetime.strftime(start_date + datetime.timedelta(days=i), '%Y-%m-%d') for i in range((end_date - start_date).days + 1)]\n    np.random.shuffle(dates)\n    return np.array(dates[:rows * columns]).reshape(rows, columns)\n```"}
{"task_id": "BigCodeBench/948", "solution": "import numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\ndef task_func(rows=3, columns=2, seed=42):\n    np.random.seed(seed)\n    matrix = np.random.rand(rows, columns)\n    scaler = MinMaxScaler()\n    scaled_matrix = scaler.fit_transform(matrix)\n    return scaled_matrix", "raw_solution": "import numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\n\ndef task_func(rows=3, columns=2, seed=42):\n    np.random.seed(seed)\n    matrix = np.random.rand(rows, columns)\n    scaler = MinMaxScaler()\n    scaled_matrix = scaler.fit_transform(matrix)\n    return scaled_matrix\n```"}
{"task_id": "BigCodeBench/949", "solution": "import numpy as np\nimport pandas as pd\ndef task_func(rows, columns, seed=None):\n    if seed is not None:\n        np.random.seed(seed)\n    return pd.DataFrame(np.random.rand(rows, columns))", "raw_solution": "import numpy as np\nimport pandas as pd\n\ndef task_func(rows, columns, seed=None):\n    if seed is not None:\n        np.random.seed(seed)\n    return pd.DataFrame(np.random.rand(rows, columns))\n```"}
{"task_id": "BigCodeBench/950", "solution": "import numpy as np\nfrom scipy.linalg import svd\ndef task_func(rows=3, columns=2, seed=0):\n    np.random.seed(seed)\n    A = np.random.rand(rows, columns)\n    U, s, Vh = svd(A)\n    return (U, s, Vh)", "raw_solution": "import numpy as np\nfrom scipy.linalg import svd\ndef task_func(rows=3, columns=2, seed=0):\n    np.random.seed(seed)\n    A = np.random.rand(rows, columns)\n    U, s, Vh = svd(A)\n    return (U, s, Vh)\n```"}
{"task_id": "BigCodeBench/951", "solution": "import pandas as pd\nimport numpy as np\nimport random\nfrom random import randint, seed\nCATEGORIES = ['Electronics', 'Clothing', 'Home & Kitchen', 'Books', 'Toys & Games']\ndef task_func(mystrings, n_products, seed=0):\n    seed(seed)\n    df = pd.DataFrame(columns=['Product Name', 'Category', 'Price'])\n    for i in range(n_products):\n        product_name = mystrings[randint(0, len(mystrings) - 1)]\n        category = random.choice(CATEGORIES)\n        price = np.random.normal(50, 10)\n        df = df.append({'Product Name': product_name.replace(' ', '_'), 'Category': category, 'Price': price}, ignore_index=True)\n    return df", "raw_solution": "import pandas as pd\nimport numpy as np\nimport random\nfrom random import randint, seed\n# Constants\nCATEGORIES = ['Electronics', 'Clothing', 'Home & Kitchen', 'Books', 'Toys & Games']\ndef task_func(mystrings, n_products, seed=0):\n    seed(seed)\n    df = pd.DataFrame(columns=['Product Name', 'Category', 'Price'])\n    for i in range(n_products):\n        product_name = mystrings[randint(0, len(mystrings) - 1)]\n        category = random.choice(CATEGORIES)\n        price = np.random.normal(50, 10)\n        df = df.append({'Product Name': product_name.replace(' ', '_'), 'Category': category, 'Price': price}, ignore_index=True)\n    return df\n```"}
{"task_id": "BigCodeBench/952", "solution": "import pandas as pd\nimport random\nfrom datetime import datetime\ndef task_func(\n    task_list,\n    n_tasks,\n    employees=[\"John Doe\", \"Jane Smith\", \"James Brown\", \"Mary Johnson\", \"Robert Davis\"],\n    seed=None,\n):\n    if n_tasks < 0:\n        raise ValueError(\"n_tasks must be non-negative\")\n    random.seed(seed)\n    tasks = random.sample(task_list, n_tasks)\n    df = pd.DataFrame({\n        'Task Name': [task.replace(' ', '_') for task in tasks],\n        'Assigned To': random.choices(employees, k=n_tasks),\n        'Due Date': [datetime.now().date()] * n_tasks\n    })\n    return df", "raw_solution": "import pandas as pd\nimport random\nfrom datetime import datetime\n\ndef task_func(\n    task_list,\n    n_tasks,\n    employees=[\"John Doe\", \"Jane Smith\", \"James Brown\", \"Mary Johnson\", \"Robert Davis\"],\n    seed=None,\n):\n    if n_tasks < 0:\n        raise ValueError(\"n_tasks must be non-negative\")\n    random.seed(seed)\n    tasks = random.sample(task_list, n_tasks)\n    df = pd.DataFrame({\n        'Task Name': [task.replace(' ', '_') for task in tasks],\n        'Assigned To': random.choices(employees, k=n_tasks),\n        'Due Date': [datetime.now().date()] * n_tasks\n    })\n    return df\n```"}
{"task_id": "BigCodeBench/953", "solution": "import numpy as np\nimport matplotlib.pyplot as plt\nimport os\ndef task_func(mystrings, folder_path, seed=None):\n    if seed is not None:\n        np.random.seed(seed)\n    if not os.path.exists(folder_path):\n        os.makedirs(folder_path)\n    file_names = []\n    for title in mystrings:\n        data = np.random.rand(10)\n        plt.bar(range(10), data)\n        plt.title(title)\n        plt.savefig(os.path.join(folder_path, f\"{title}.png\"))\n        plt.close()\n        file_names.append(f\"{title}.png\")\n    return file_names", "raw_solution": "import numpy as np\nimport matplotlib.pyplot as plt\nimport os\ndef task_func(mystrings, folder_path, seed=None):\n    if seed is not None:\n        np.random.seed(seed)\n    if not os.path.exists(folder_path):\n        os.makedirs(folder_path)\n    file_names = []\n    for title in mystrings:\n        data = np.random.rand(10)\n        plt.bar(range(10), data)\n        plt.title(title)\n        plt.savefig(os.path.join(folder_path, f\"{title}.png\"))\n        plt.close()\n        file_names.append(f\"{title}.png\")\n    return file_names\n```"}
{"task_id": "BigCodeBench/954", "solution": "import random\nimport re\ndef task_func(target_words, n_sentences, vocabulary):\n    if n_sentences < 0 or len(vocabulary) == 0:\n        raise ValueError(\"Invalid input\")\n    sentences = []\n    for _ in range(n_sentences):\n        sentence = random.choice(vocabulary)\n        for word in target_words:\n            if word.lower() in sentence.lower():\n                sentence = re.sub(r'\\b' + re.escape(word.lower()) + r'\\b', '_', sentence)\n        sentences.append(sentence.lower())\n    return sentences", "raw_solution": "import random\nimport re\ndef task_func(target_words, n_sentences, vocabulary):\n    if n_sentences < 0 or len(vocabulary) == 0:\n        raise ValueError(\"Invalid input\")\n    sentences = []\n    for _ in range(n_sentences):\n        sentence = random.choice(vocabulary)\n        for word in target_words:\n            if word.lower() in sentence.lower():\n                sentence = re.sub(r'\\b' + re.escape(word.lower()) + r'\\b', '_', sentence)\n        sentences.append(sentence.lower())\n    return sentences\n```"}
{"task_id": "BigCodeBench/955", "solution": "import numpy as np\nimport matplotlib.pyplot as plt\nimport re\nfrom collections import Counter\ndef task_func(mystrings, text):\n    if not text:\n        raise ValueError(\"Input text is empty.\")\n    text = text.lower()\n    words = re.findall(r'\\b\\w+\\b', text)\n    words = [word.replace(' ', '_') for word in words]\n    word_counts = Counter(words)\n    plt.figure(figsize=(10, 5))\n    plt.bar(word_counts.keys(), word_counts.values())\n    plt.xlabel('Words')\n    plt.ylabel('Frequency')\n    plt.title('Frequency of each unique word')\n    plt.xticks(rotation=45)\n    plt.show()\n    return plt.axes()", "raw_solution": "import numpy as np\nimport matplotlib.pyplot as plt\nimport re\nfrom collections import Counter\ndef task_func(mystrings, text):\n    if not text:\n        raise ValueError(\"Input text is empty.\")\n    text = text.lower()\n    words = re.findall(r'\\b\\w+\\b', text)\n    words = [word.replace(' ', '_') for word in words]\n    word_counts = Counter(words)\n    plt.figure(figsize=(10, 5))\n    plt.bar(word_counts.keys(), word_counts.values())\n    plt.xlabel('Words')\n    plt.ylabel('Frequency')\n    plt.title('Frequency of each unique word')\n    plt.xticks(rotation=45)\n    plt.show()\n    return plt.axes()\n```"}
{"task_id": "BigCodeBench/956", "solution": "import re\nimport string\nimport random\ndef task_func(text: str, seed=None) -> str:\n    if seed is not None:\n        random.seed(seed)\n    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n    text = re.sub(r'\\s+', '_', text)\n    text = re.sub(r'___', '___', text)\n    text = re.sub(r'___', '___', text)\n    text = re.sub(r'___', '___', text)\n    text = re.sub(r'___', '___', text)\n    text = re.sub(r'___', '___', text)\n    text = re.sub(r'___', '___', text)\n    text = re.sub(r'___', '___', text)\n    text = re.sub(r'___', '___', text)\n    text = re.sub(r'___', '___', text)\n    text = re.sub(r'___', '___', text)\n    text = re.sub(r'___', '___', text)\n    text = re.sub(r'___', '___', text)\n    text = re.sub(r'___', '___', text)\n    text = re.sub(r'___', '___', text)\n    text = re.sub(r'___', '___', text)\n    text = re.sub(r'___', '___', text)\n    text = re.sub(r'___', '___', text)\n    text = re.sub(r'___', '___', text)\n    text = re.sub(r'___', '___', text)\n    text = re.sub(r'___', '___', text)\n    text = re.sub(r'___', '___', text)\n    text = re.sub(r'___', '___', text)\n    text = re.sub(r'___', '___', text)\n    text = re.sub(r'___', '___', text)\n    text = re.sub(r'___', '___', text)\n    text = re.sub(r'___', '___', text)\n    text = re.sub(r'___', '___', text)\n    text = re.sub(r'___', '___', text)\n    text = re.sub(r'___', '___', text)\n    text = re.sub(r'___', '___', text)\n    text = re.sub(r'___', '___', text)\n    text = re.sub(r'___', '___', text)\n    text = re.sub(r'___', '___', text)\n    text = re.sub(r'___', '___', text)\n    text = re.sub(r'___', '___', text)\n    text = re.sub(r'___', '___', text)\n    text = re.sub(r'___', '___', text)\n    text = re.sub(r'___', '___', text)\n    text = re.sub(r'___', '___', text)\n    text = re.sub(r'___', '___', text)\n    text = re.sub(r'___', '___', text)\n    text = re.sub(r'___', '___', text)\n    text = re.sub(r'___', '___', text)\n    text = re.sub(r'___', '___', text)\n    text = re.sub(r'___', '___', text)\n    text = re.sub(r'___', '___', text)\n    text = re.sub(r'___', '___', text)\n    text = re.sub(r'___', '___', text)\n    text = re.sub(r'___', '___', text)\n    text = re.sub(r'___', '___', text)\n    text = re.sub(r'___', '___', text)\n    text = re.sub(r'___', '___', text)\n    text = re.sub(r'___', '___', text)\n    text = re.sub(r'___', '___', text)\n    text = re.sub(r'___', '___', text)\n    text = re.sub(r'___', '___', text)\n    text = re.sub(r'___', '___', text)\n    text = re.sub(r'___', '___', text)\n    text = re.sub(r'___', '___', text)\n    text = re.sub(r'___', '___', text)\n    text = re.sub(r'___', '___', text)\n    text = re.sub(r'___', '___', text)\n    text = re.sub(r'___', '___', text)\n    text = re.sub(r'___', '___', text)\n    text = re.sub(r'___', '___', text)\n    text = re.sub(r'___', '___', text)\n    text = re.sub(r'___', '___', text)\n    text = re.sub(r'___', '___', text)\n    text = re.sub(r'___', '___', text)\n    text = re.sub(r'___', '___', text)\n    text = re.sub(r'___', '___', text)\n    text = re.sub(r'___', '___', text)\n    text = re.sub(r'___', '___', text)\n    text = re.sub(r'___', '___', text)\n    text = re.sub(r'___', '___', text)\n    text = re.sub(r'___', '___', text)\n    text = re.sub(r'___', '___', text)\n    text = re.sub(r'___', '___', text)\n    text = re.sub(r'___', '___', text)\n    text = re.sub(r'___', '___', text)\n    text = re.sub(r'___', '___', text)\n    text = re.sub(r'___', '___', text)\n    text = re.sub(r'___', '___', text)\n    text = re.sub(r'___', '___', text)\n    text = re.sub(r'___', '___', text)\n    text = re.sub(r'___', '___', text)", "raw_solution": "import re\nimport string\nimport random\n\ndef task_func(text: str, seed=None) -> str:\n    if seed is not None:\n        random.seed(seed)\n    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n    text = re.sub(r'\\s+', '_', text)\n    text = re.sub(r'___', '___', text)\n    text = re.sub(r'___', '___', text)\n    text = re.sub(r'___', '___', text)\n    text = re.sub(r'___', '___', text)\n    text = re.sub(r'___', '___', text)\n    text = re.sub(r'___', '___', text)\n    text = re.sub(r'___', '___', text)\n    text = re.sub(r'___', '___', text)\n    text = re.sub(r'___', '___', text)\n    text = re.sub(r'___', '___', text)\n    text = re.sub(r'___', '___', text)\n    text = re.sub(r'___', '___', text)\n    text = re.sub(r'___', '___', text)\n    text = re.sub(r'___', '___', text)\n    text = re.sub(r'___', '___', text)\n    text = re.sub(r'___', '___', text)\n    text = re.sub(r'___', '___', text)\n    text = re.sub(r'___', '___', text)\n    text = re.sub(r'___', '___', text)\n    text = re.sub(r'___', '___', text)\n    text = re.sub(r'___', '___', text)\n    text = re.sub(r'___', '___', text)\n    text = re.sub(r'___', '___', text)\n    text = re.sub(r'___', '___', text)\n    text = re.sub(r'___', '___', text)\n    text = re.sub(r'___', '___', text)\n    text = re.sub(r'___', '___', text)\n    text = re.sub(r'___', '___', text)\n    text = re.sub(r'___', '___', text)\n    text = re.sub(r'___', '___', text)\n    text = re.sub(r'___', '___', text)\n    text = re.sub(r'___', '___', text)\n    text = re.sub(r'___', '___', text)\n    text = re.sub(r'___', '___', text)\n    text = re.sub(r'___', '___', text)\n    text = re.sub(r'___', '___', text)\n    text = re.sub(r'___', '___', text)\n    text = re.sub(r'___', '___', text)\n    text = re.sub(r'___', '___', text)\n    text = re.sub(r'___', '___', text)\n    text = re.sub(r'___', '___', text)\n    text = re.sub(r'___', '___', text)\n    text = re.sub(r'___', '___', text)\n    text = re.sub(r'___', '___', text)\n    text = re.sub(r'___', '___', text)\n    text = re.sub(r'___', '___', text)\n    text = re.sub(r'___', '___', text)\n    text = re.sub(r'___', '___', text)\n    text = re.sub(r'___', '___', text)\n    text = re.sub(r'___', '___', text)\n    text = re.sub(r'___', '___', text)\n    text = re.sub(r'___', '___', text)\n    text = re.sub(r'___', '___', text)\n    text = re.sub(r'___', '___', text)\n    text = re.sub(r'___', '___', text)\n    text = re.sub(r'___', '___', text)\n    text = re.sub(r'___', '___', text)\n    text = re.sub(r'___', '___', text)\n    text = re.sub(r'___', '___', text)\n    text = re.sub(r'___', '___', text)\n    text = re.sub(r'___', '___', text)\n    text = re.sub(r'___', '___', text)\n    text = re.sub(r'___', '___', text)\n    text = re.sub(r'___', '___', text)\n    text = re.sub(r'___', '___', text)\n    text = re.sub(r'___', '___', text)\n    text = re.sub(r'___', '___', text)\n    text = re.sub(r'___', '___', text)\n    text = re.sub(r'___', '___', text)\n    text = re.sub(r'___', '___', text)\n    text = re.sub(r'___', '___', text)\n    text = re.sub(r'___', '___', text)\n    text = re.sub(r'___', '___', text)\n    text = re.sub(r'___', '___', text)\n    text = re.sub(r'___', '___', text)\n    text = re.sub(r'___', '___', text)\n    text = re.sub(r'___', '___', text)\n    text = re.sub(r'___', '___', text)\n    text = re.sub(r'___', '___', text)\n    text = re.sub(r'___', '___', text)\n    text = re.sub(r'___', '___', text)\n    text = re.sub(r'___', '___', text)\n    text = re.sub(r'___', '___', text)\n    text = re.sub(r'___', '___', text)\n    text = re.sub(r'___', '___', text)\n    text = re.sub(r'___', '___', text)\n    text = re.sub(r'___', '___"}
{"task_id": "BigCodeBench/957", "solution": "import string\nimport re\ndef task_func(text: str) -> tuple:\n    words = re.findall(r'\\b\\w+\\b', text)\n    chars = len(text)\n    unique_chars = len(set(text))\n    return (len(words), chars, unique_chars)", "raw_solution": "import string\nimport re\ndef task_func(text: str) -> tuple:\n    words = re.findall(r'\\b\\w+\\b', text)\n    chars = len(text)\n    unique_chars = len(set(text))\n    return (len(words), chars, unique_chars)\n```"}
{"task_id": "BigCodeBench/958", "solution": "import random\nimport re\ndef task_func(text, seed=None):\n    if seed is not None:\n        random.seed(seed)\n    words = re.findall(r'\\b\\w+\\b', text)\n    scrambled_words = []\n    for word in words:\n        if len(word) > 3:\n            scrambled_word = word[0] + ''.join(random.sample(word[1:-1], len(word[1:-1]))) + word[-1]\n            scrambled_words.append(scrambled_word)\n        else:\n            scrambled_words.append(word)\n    return ' '.join(scrambled_words)", "raw_solution": "import random\nimport re\n\ndef task_func(text, seed=None):\n    if seed is not None:\n        random.seed(seed)\n    words = re.findall(r'\\b\\w+\\b', text)\n    scrambled_words = []\n    for word in words:\n        if len(word) > 3:\n            scrambled_word = word[0] + ''.join(random.sample(word[1:-1], len(word[1:-1]))) + word[-1]\n            scrambled_words.append(scrambled_word)\n        else:\n            scrambled_words.append(word)\n    return ' '.join(scrambled_words)\n```"}
{"task_id": "BigCodeBench/959", "solution": "import string\nimport random\ndef task_func(text, seed=None):\n    if seed is not None:\n        random.seed(seed)\n    result = ''\n    for char in text:\n        if char.isalpha():\n            if char.islower():\n                result += string.ascii_lowercase[random.randint(0, 25)]\n            else:\n                result += string.ascii_uppercase[random.randint(0, 25)]\n        else:\n            result += char\n    return result", "raw_solution": "import string\nimport random\n\ndef task_func(text, seed=None):\n    if seed is not None:\n        random.seed(seed)\n    result = ''\n    for char in text:\n        if char.isalpha():\n            if char.islower():\n                result += string.ascii_lowercase[random.randint(0, 25)]\n            else:\n                result += string.ascii_uppercase[random.randint(0, 25)]\n        else:\n            result += char\n    return result\n```"}
{"task_id": "BigCodeBench/960", "solution": "import string\nimport random\ndef task_func(text, seed=None):\n    if not text:\n        raise ValueError(\"Input text is empty\")\n    random.seed(seed)\n    password = \"\"\n    for char in text:\n        if char in string.ascii_letters:\n            password += random.choice(string.ascii_lowercase)\n        elif char.isdigit():\n            password += str(random.randint(0, 9))\n        elif char.isspace():\n            password += str(random.randint(0, 9)) if random.choice([True, False]) else random.choice(string.ascii_lowercase)\n        else:\n            password += char\n    return password", "raw_solution": "import string\nimport random\n\ndef task_func(text, seed=None):\n    if not text:\n        raise ValueError(\"Input text is empty\")\n    random.seed(seed)\n    password = \"\"\n    for char in text:\n        if char in string.ascii_letters:\n            password += random.choice(string.ascii_lowercase)\n        elif char.isdigit():\n            password += str(random.randint(0, 9))\n        elif char.isspace():\n            password += str(random.randint(0, 9)) if random.choice([True, False]) else random.choice(string.ascii_lowercase)\n        else:\n            password += char\n    return password\n```"}
{"task_id": "BigCodeBench/961", "solution": "import os\nimport glob\nfrom collections import Counter\ndef task_func(directory, extensions=[\".txt\", \".docx\", \".xlsx\", \".csv\"], keep_zero=True):\n    if not os.path.exists(directory):\n        raise OSError(\"The specified directory does not exist.\")\n    counter = Counter()\n    for ext in extensions:\n        files = glob.glob(os.path.join(directory, f\"*{ext}\"))\n        counter.update(files)\n    if not keep_zero:\n        counter = {k: v for k, v in counter.items() if v > 0}\n    return counter", "raw_solution": "import os\nimport glob\nfrom collections import Counter\ndef task_func(directory, extensions=[\".txt\", \".docx\", \".xlsx\", \".csv\"], keep_zero=True):\n    if not os.path.exists(directory):\n        raise OSError(\"The specified directory does not exist.\")\n    counter = Counter()\n    for ext in extensions:\n        files = glob.glob(os.path.join(directory, f\"*{ext}\"))\n        counter.update(files)\n    if not keep_zero:\n        counter = {k: v for k, v in counter.items() if v > 0}\n    return counter\n```"}
{"task_id": "BigCodeBench/962", "solution": "import os\nfrom pathlib import Path\nimport glob\nimport shutil\ndef task_func(source_directory: str, target_directory: str):\n    if not os.path.exists(source_directory):\n        raise FileNotFoundError(\"Source directory does not exist.\")\n    source_files = glob.glob(os.path.join(source_directory, '*'))\n    target_files = glob.glob(os.path.join(target_directory, '*'))\n    moved_files = 0\n    for file in source_files:\n        if os.path.isfile(file):\n            file_name, file_extension = os.path.splitext(file)\n            if file_extension in ['.txt', '.docx', '.xlsx', '.csv']:\n                target_file = os.path.join(target_directory, file_name)\n                if os.path.exists(target_file):\n                    i = 1\n                    while os.path.exists(target_file):\n                        target_file = os.path.join(target_directory, f\"{file_name}-{i}{file_extension}\")\n                        i += 1\n                shutil.move(file, target_file)\n                moved_files += 1\n    return moved_files", "raw_solution": "import os\nfrom pathlib import Path\nimport glob\nimport shutil\ndef task_func(source_directory: str, target_directory: str):\n    if not os.path.exists(source_directory):\n        raise FileNotFoundError(\"Source directory does not exist.\")\n    source_files = glob.glob(os.path.join(source_directory, '*'))\n    target_files = glob.glob(os.path.join(target_directory, '*'))\n    moved_files = 0\n    for file in source_files:\n        if os.path.isfile(file):\n            file_name, file_extension = os.path.splitext(file)\n            if file_extension in ['.txt', '.docx', '.xlsx', '.csv']:\n                target_file = os.path.join(target_directory, file_name)\n                if os.path.exists(target_file):\n                    i = 1\n                    while os.path.exists(target_file):\n                        target_file = os.path.join(target_directory, f\"{file_name}-{i}{file_extension}\")\n                        i += 1\n                shutil.move(file, target_file)\n                moved_files += 1\n    return moved_files\n```"}
{"task_id": "BigCodeBench/963", "solution": "import os\nimport glob\nfrom pathlib import Path\nimport zipfile\ndef task_func(source_directory, target_directory, zip_name):\n    if not os.path.exists(source_directory):\n        raise OSError(\"The source_directory does not exist.\")\n    zip_path = os.path.join(target_directory, zip_name)\n    with zipfile.ZipFile(zip_path, 'w') as zipf:\n        for file_path in glob.glob(os.path.join(source_directory, '*')):\n            if os.path.splitext(file_path)[1] in ['.txt', '.docx', '.xlsx', '.csv']:\n                zipf.write(file_path, os.path.relpath(file_path, source_directory))\n    return zip_path", "raw_solution": "import os\nimport glob\nfrom pathlib import Path\nimport zipfile\ndef task_func(source_directory, target_directory, zip_name):\n    if not os.path.exists(source_directory):\n        raise OSError(\"The source_directory does not exist.\")\n    zip_path = os.path.join(target_directory, zip_name)\n    with zipfile.ZipFile(zip_path, 'w') as zipf:\n        for file_path in glob.glob(os.path.join(source_directory, '*')):\n            if os.path.splitext(file_path)[1] in ['.txt', '.docx', '.xlsx', '.csv']:\n                zipf.write(file_path, os.path.relpath(file_path, source_directory))\n    return zip_path\n```"}
{"task_id": "BigCodeBench/964", "solution": "import os\nfrom pathlib import Path\nimport pandas as pd\nimport docx\ndef task_func(source_directory: str, target_directory: str) -> int:\n    if not os.path.exists(source_directory):\n        raise FileNotFoundError(\"Source directory does not exist.\")\n    if not os.path.exists(target_directory):\n        os.makedirs(target_directory)\n    count = 0\n    for file in os.listdir(source_directory):\n        if file.endswith('.txt'):\n            with open(os.path.join(source_directory, file), 'r', encoding='utf-8') as f:\n                text = f.read()\n            df = pd.DataFrame({'Text': [text]})\n            df.to_csv(os.path.join(target_directory, file.replace('.txt', '.csv')), index=False)\n            count += 1\n        elif file.endswith('.docx'):\n            doc = docx.Document(os.path.join(source_directory, file))\n            text = '\\n'.join([paragraph.text for paragraph in doc.paragraphs])\n            df = pd.DataFrame({'Text': [text]})\n            df.to_csv(os.path.join(target_directory, file.replace('.docx', '.csv')), index=False)\n            count += 1\n        elif file.endswith('.xlsx'):\n            df = pd.read_excel(os.path.join(source_directory, file))\n            df.to_csv(os.path.join(target_directory, file.replace('.xlsx', '.csv')), index=False)\n            count += 1\n        elif file.endswith('.csv'):\n            pass\n        else:\n            continue\n    return count", "raw_solution": "import os\nfrom pathlib import Path\nimport pandas as pd\nimport docx\n\ndef task_func(source_directory: str, target_directory: str) -> int:\n    if not os.path.exists(source_directory):\n        raise FileNotFoundError(\"Source directory does not exist.\")\n    if not os.path.exists(target_directory):\n        os.makedirs(target_directory)\n    count = 0\n    for file in os.listdir(source_directory):\n        if file.endswith('.txt'):\n            with open(os.path.join(source_directory, file), 'r', encoding='utf-8') as f:\n                text = f.read()\n            df = pd.DataFrame({'Text': [text]})\n            df.to_csv(os.path.join(target_directory, file.replace('.txt', '.csv')), index=False)\n            count += 1\n        elif file.endswith('.docx'):\n            doc = docx.Document(os.path.join(source_directory, file))\n            text = '\\n'.join([paragraph.text for paragraph in doc.paragraphs])\n            df = pd.DataFrame({'Text': [text]})\n            df.to_csv(os.path.join(target_directory, file.replace('.docx', '.csv')), index=False)\n            count += 1\n        elif file.endswith('.xlsx'):\n            df = pd.read_excel(os.path.join(source_directory, file))\n            df.to_csv(os.path.join(target_directory, file.replace('.xlsx', '.csv')), index=False)\n            count += 1\n        elif file.endswith('.csv'):\n            pass\n        else:\n            continue\n    return count\n```"}
{"task_id": "BigCodeBench/965", "solution": "import os\nimport re\nimport shutil\ndef task_func(source_directory: str, target_directory: str, pattern: str = r\"\\d{4}\") -> int:\n    if not os.path.isdir(source_directory):\n        return 0\n    if not os.path.isdir(target_directory):\n        os.makedirs(target_directory)\n    count = 0\n    for filename in os.listdir(source_directory):\n        if re.match(pattern, filename):\n            src_path = os.path.join(source_directory, filename)\n            dst_path = os.path.join(target_directory, filename)\n            shutil.move(src_path, dst_path)\n            count += 1\n    return count", "raw_solution": "import os\nimport re\nimport shutil\n\ndef task_func(source_directory: str, target_directory: str, pattern: str = r\"\\d{4}\") -> int:\n    if not os.path.isdir(source_directory):\n        return 0\n    if not os.path.isdir(target_directory):\n        os.makedirs(target_directory)\n    count = 0\n    for filename in os.listdir(source_directory):\n        if re.match(pattern, filename):\n            src_path = os.path.join(source_directory, filename)\n            dst_path = os.path.join(target_directory, filename)\n            shutil.move(src_path, dst_path)\n            count += 1\n    return count\n```"}
{"task_id": "BigCodeBench/966", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\ndef task_func(df: pd.DataFrame) -> pd.DataFrame:\n    if df.empty or df.isnull().values.any():\n        raise ValueError(\"If the DataFrame is empty or contains non-numeric data.\")\n    cum_sum = df.cumsum()\n    fig, ax = plt.subplots()\n    ax.bar(cum_sum.index, cum_sum.values)\n    ax.set_title('Cumulative Sum per Column')\n    ax.set_xlabel('Index')\n    ax.set_ylabel('Cumulative Sum')\n    ax.legend()\n    return cum_sum, fig", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\n\ndef task_func(df: pd.DataFrame) -> pd.DataFrame:\n    if df.empty or df.isnull().values.any():\n        raise ValueError(\"If the DataFrame is empty or contains non-numeric data.\")\n    cum_sum = df.cumsum()\n    fig, ax = plt.subplots()\n    ax.bar(cum_sum.index, cum_sum.values)\n    ax.set_title('Cumulative Sum per Column')\n    ax.set_xlabel('Index')\n    ax.set_ylabel('Cumulative Sum')\n    ax.legend()\n    return cum_sum, fig\n```"}
{"task_id": "BigCodeBench/967", "solution": "import numpy as np\nfrom scipy import integrate\nimport matplotlib.pyplot as plt\ndef task_func(func, x_range=(-2, 2), num_points=1000):\n    x = np.linspace(x_range[0], x_range[1], num_points)\n    y = func(x)\n    y_integral = integrate.quad(func, x_range[0], x_range[1])[0]\n    plt.plot(x, y, label='Function')\n    plt.plot(x, y_integral, label='Integral')\n    plt.xlabel('x')\n    plt.ylabel('y')\n    plt.legend()\n    plt.show()", "raw_solution": "import numpy as np\nfrom scipy import integrate\nimport matplotlib.pyplot as plt\n\ndef task_func(func, x_range=(-2, 2), num_points=1000):\n    x = np.linspace(x_range[0], x_range[1], num_points)\n    y = func(x)\n    y_integral = integrate.quad(func, x_range[0], x_range[1])[0]\n    plt.plot(x, y, label='Function')\n    plt.plot(x, y_integral, label='Integral')\n    plt.xlabel('x')\n    plt.ylabel('y')\n    plt.legend()\n    plt.show()\n```"}
{"task_id": "BigCodeBench/968", "solution": "import pandas as pd\nimport seaborn as sns\ndef task_func(data):\n    if data.empty or data.select_dtypes(include=['number']).empty:\n        raise ValueError(\"DataFrame is empty or if no numeric columns are present.\")\n    heatmap = sns.heatmap(data.select_dtypes(include=['number']).cumsum(axis=0))\n    return heatmap", "raw_solution": "import pandas as pd\nimport seaborn as sns\n\ndef task_func(data):\n    if data.empty or data.select_dtypes(include=['number']).empty:\n        raise ValueError(\"DataFrame is empty or if no numeric columns are present.\")\n    heatmap = sns.heatmap(data.select_dtypes(include=['number']).cumsum(axis=0))\n    return heatmap\n```"}
{"task_id": "BigCodeBench/969", "solution": "import numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\nimport pandas as pd\ndef task_func(df: pd.DataFrame) -> pd.DataFrame:\n    if not isinstance(df, pd.DataFrame):\n        raise TypeError(\"The DataFrame contains non-numeric data types.\")\n    if df.empty or df.isnull().values.any():\n        raise ValueError(\"The DataFrame is empty or contains NaN values.\")\n    scaler = MinMaxScaler()\n    df = scaler.fit_transform(df)\n    df = pd.DataFrame(df, columns=df.columns)\n    return df", "raw_solution": "import numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\nimport pandas as pd\n\ndef task_func(df: pd.DataFrame) -> pd.DataFrame:\n    if not isinstance(df, pd.DataFrame):\n        raise TypeError(\"The DataFrame contains non-numeric data types.\")\n    if df.empty or df.isnull().values.any():\n        raise ValueError(\"The DataFrame is empty or contains NaN values.\")\n    scaler = MinMaxScaler()\n    df = scaler.fit_transform(df)\n    df = pd.DataFrame(df, columns=df.columns)\n    return df\n```"}
{"task_id": "BigCodeBench/970", "solution": "import numpy as np\nimport matplotlib.pyplot as plt\ndef task_func(data: np.ndarray) -> plt.Axes:\n    if np.any(data < 0) or np.any(np.isnan(data)):\n        raise ValueError(\"If the input array contains negative numbers or NaNs.\")\n    if not np.issubdtype(data.dtype, np.number):\n        raise TypeError(\"If the input array contains non-numeric inputs.\")\n    sorted_data = np.sort(data)\n    cumulative_prob = np.cumsum(sorted_data)\n    plt.plot(np.arange(len(sorted_data)), cumulative_prob, marker='o', linestyle='-')\n    plt.title(\"Cumulative Probability Plot\")\n    plt.xlabel(\"Index\")\n    plt.ylabel(\"Cumulative Probability\")\n    return plt.gca()", "raw_solution": "import numpy as np\nimport matplotlib.pyplot as plt\n\ndef task_func(data: np.ndarray) -> plt.Axes:\n    if np.any(data < 0) or np.any(np.isnan(data)):\n        raise ValueError(\"If the input array contains negative numbers or NaNs.\")\n    if not np.issubdtype(data.dtype, np.number):\n        raise TypeError(\"If the input array contains non-numeric inputs.\")\n    sorted_data = np.sort(data)\n    cumulative_prob = np.cumsum(sorted_data)\n    plt.plot(np.arange(len(sorted_data)), cumulative_prob, marker='o', linestyle='-')\n    plt.title(\"Cumulative Probability Plot\")\n    plt.xlabel(\"Index\")\n    plt.ylabel(\"Cumulative Probability\")\n    return plt.gca()\n```"}
{"task_id": "BigCodeBench/971", "solution": "import os\nfrom pathlib import Path\nfrom datetime import datetime, timezone\ndef task_func(directory_path: str):\n    if not os.path.exists(directory_path):\n        raise ValueError(\"The provided directory does not exist.\")\n    result = []\n    for file in os.listdir(directory_path):\n        file_path = Path(directory_path) / file\n        if file_path.is_file():\n            file_size = file_path.stat().st_size\n            creation_time = datetime.fromtimestamp(file_path.stat().st_ctime, timezone.utc).isoformat()\n            modification_time = datetime.fromtimestamp(file_path.stat().st_mtime, timezone.utc).isoformat()\n            result.append((file, file_size, creation_time, modification_time))\n    return result", "raw_solution": "import os\nfrom pathlib import Path\nfrom datetime import datetime, timezone\n\ndef task_func(directory_path: str):\n    if not os.path.exists(directory_path):\n        raise ValueError(\"The provided directory does not exist.\")\n    result = []\n    for file in os.listdir(directory_path):\n        file_path = Path(directory_path) / file\n        if file_path.is_file():\n            file_size = file_path.stat().st_size\n            creation_time = datetime.fromtimestamp(file_path.stat().st_ctime, timezone.utc).isoformat()\n            modification_time = datetime.fromtimestamp(file_path.stat().st_mtime, timezone.utc).isoformat()\n            result.append((file, file_size, creation_time, modification_time))\n    return result\n```"}
{"task_id": "BigCodeBench/972", "solution": "import pathlib\nimport os\ndef task_func(path: str, delimiter: str = os.path.sep) -> list:\n    if not isinstance(path, str):\n        raise ValueError(\"Path must be a string\")\n    if not isinstance(delimiter, str):\n        raise ValueError(\"Delimiter must be a string\")\n    if not os.path.isabs(path):\n        raise ValueError(\"Path must be absolute\")\n    if not os.path.exists(path):\n        raise ValueError(\"Path does not exist\")\n    if not os.path.isfile(path):\n        raise ValueError(\"Path is not a file\")\n    if not os.path.isdir(path):\n        raise ValueError(\"Path is not a directory\")\n    if not os.path.islink(path):\n        raise ValueError(\"Path is not a symbolic link\")\n    if not os.path.ismount(path):\n        raise ValueError(\"Path is not a mount point\")\n    if not os.path.isreadable(path):\n        raise ValueError(\"Path is not readable\")\n    if not os.path.isdir(path):\n        raise ValueError(\"Path is not a directory\")\n    if not os.path.isfile(path):\n        raise ValueError(\"Path is not a file\")\n    if not os.path.islink(path):\n        raise ValueError(\"Path is not a symbolic link\")\n    if not os.path.ismount(path):\n        raise ValueError(\"Path is not a mount point\")\n    if not os.path.isreadable(path):\n        raise ValueError(\"Path is not readable\")\n    if not os.path.isdir(path):\n        raise ValueError(\"Path is not a directory\")\n    if not os.path.isfile(path):\n        raise ValueError(\"Path is not a file\")\n    if not os.path.islink(path):\n        raise ValueError(\"Path is not a symbolic link\")\n    if not os.path.ismount(path):\n        raise ValueError(\"Path is not a mount point\")\n    if not os.path.isreadable(path):\n        raise ValueError(\"Path is not readable\")\n    if not os.path.isdir(path):\n        raise ValueError(\"Path is not a directory\")\n    if not os.path.isfile(path):\n        raise ValueError(\"Path is not a file\")\n    if not os.path.islink(path):\n        raise ValueError(\"Path is not a symbolic link\")\n    if not os.path.ismount(path):\n        raise ValueError(\"Path is not a mount point\")\n    if not os.path.isreadable(path):\n        raise ValueError(\"Path is not readable\")\n    if not os.path.isdir(path):\n        raise ValueError(\"Path is not a directory\")\n    if not os.path.isfile(path):\n        raise ValueError(\"Path is not a file\")\n    if not os.path.islink(path):\n        raise ValueError(\"Path is not a symbolic link\")\n    if not os.path.ismount(path):\n        raise ValueError(\"Path is not a mount point\")\n    if not os.path.isreadable(path):\n        raise ValueError(\"Path is not readable\")\n    if not os.path.isdir(path):\n        raise ValueError(\"Path is not a directory\")\n    if not os.path.isfile(path):\n        raise ValueError(\"Path is not a file\")\n    if not os.path.islink(path):\n        raise ValueError(\"Path is not a symbolic link\")\n    if not os.path.ismount(path):\n        raise ValueError(\"Path is not a mount point\")\n    if not os.path.isreadable(path):\n        raise ValueError(\"Path is not readable\")\n    if not os.path.isdir(path):\n        raise ValueError(\"Path is not a directory\")\n    if not os.path.isfile(path):\n        raise ValueError(\"Path is not a file\")\n    if not os.path.islink(path):\n        raise ValueError(\"Path is not a symbolic link\")\n    if not os.path.ismount(path):\n        raise ValueError(\"Path is not a mount point\")\n    if not os.path.isreadable(path):\n        raise ValueError(\"Path is not readable\")\n    if not os.path.isdir(path):\n        raise ValueError(\"Path is not a directory\")\n    if not os.path.isfile(path):\n        raise ValueError(\"Path is not a file\")\n    if not os.path.islink(path):\n        raise ValueError(\"Path is not a symbolic link\")\n    if not os.path.ismount(path):\n        raise ValueError(\"Path is not a mount point\")\n    if not os.path.isreadable(path):\n        raise ValueError(\"Path is not readable\")\n    if not os.path.isdir(path):\n        raise ValueError(\"Path is not a directory\")\n    if not os.path.isfile(path):\n        raise ValueError(\"Path is not a file\")\n    if not os.path.islink(path):\n        raise ValueError(\"Path is not a symbolic link\")\n    if not os.path.ismount(path):\n        raise ValueError(\"Path is not a mount point\")\n    if not os.path.isreadable(path):\n        raise ValueError(\"Path is not readable\")\n    if not os.path.isdir(path):\n        raise ValueError(\"Path is not a directory\")\n    if not os.path.isfile(path):\n        raise ValueError(\"Path is not a file\")\n    if not os.path.islink(path):\n        raise ValueError(\"Path is not a symbolic link\")\n    if not os.path.ismount(path):\n        raise ValueError(\"Path is not a mount point\")\n    if not os.path.isreadable(path):\n        raise ValueError(\"Path is not readable\")\n    if not os.path.isdir(path):\n        raise ValueError(\"Path is not a directory\")\n    if not os.path.isfile(path):\n        raise ValueError(\"Path is not a file\")\n    if not os.path.islink(path):\n        raise ValueError(\"Path is not a symbolic link\")\n    if not os.path.ismount(path):\n        raise ValueError(\"Path is not a mount point\")\n    if not os.path.isreadable(path):\n        raise ValueError(\"Path is not readable\")\n    if not os.path.isdir(path):\n        raise ValueError(\"Path is not a directory\")\n    if not os.path.isfile(path):\n        raise ValueError(\"Path is not a file\")\n    if not os.path.islink(path):\n        raise ValueError(\"Path is not a symbolic link\")\n    if not os.path.ismount(path):\n        raise ValueError(\"Path is not a mount point\")\n    if not os.path.isreadable(path):\n        raise ValueError(\"Path is not readable\")\n    if not os.path.isdir(path):\n        raise ValueError(\"Path is not a directory\")\n    if not os.path.isfile(path):\n        raise ValueError(\"Path is not a file\")", "raw_solution": "import pathlib\nimport os\ndef task_func(path: str, delimiter: str = os.path.sep) -> list:\n    if not isinstance(path, str):\n        raise ValueError(\"Path must be a string\")\n    if not isinstance(delimiter, str):\n        raise ValueError(\"Delimiter must be a string\")\n    if not os.path.isabs(path):\n        raise ValueError(\"Path must be absolute\")\n    if not os.path.exists(path):\n        raise ValueError(\"Path does not exist\")\n    if not os.path.isfile(path):\n        raise ValueError(\"Path is not a file\")\n    if not os.path.isdir(path):\n        raise ValueError(\"Path is not a directory\")\n    if not os.path.islink(path):\n        raise ValueError(\"Path is not a symbolic link\")\n    if not os.path.ismount(path):\n        raise ValueError(\"Path is not a mount point\")\n    if not os.path.isreadable(path):\n        raise ValueError(\"Path is not readable\")\n    if not os.path.isdir(path):\n        raise ValueError(\"Path is not a directory\")\n    if not os.path.isfile(path):\n        raise ValueError(\"Path is not a file\")\n    if not os.path.islink(path):\n        raise ValueError(\"Path is not a symbolic link\")\n    if not os.path.ismount(path):\n        raise ValueError(\"Path is not a mount point\")\n    if not os.path.isreadable(path):\n        raise ValueError(\"Path is not readable\")\n    if not os.path.isdir(path):\n        raise ValueError(\"Path is not a directory\")\n    if not os.path.isfile(path):\n        raise ValueError(\"Path is not a file\")\n    if not os.path.islink(path):\n        raise ValueError(\"Path is not a symbolic link\")\n    if not os.path.ismount(path):\n        raise ValueError(\"Path is not a mount point\")\n    if not os.path.isreadable(path):\n        raise ValueError(\"Path is not readable\")\n    if not os.path.isdir(path):\n        raise ValueError(\"Path is not a directory\")\n    if not os.path.isfile(path):\n        raise ValueError(\"Path is not a file\")\n    if not os.path.islink(path):\n        raise ValueError(\"Path is not a symbolic link\")\n    if not os.path.ismount(path):\n        raise ValueError(\"Path is not a mount point\")\n    if not os.path.isreadable(path):\n        raise ValueError(\"Path is not readable\")\n    if not os.path.isdir(path):\n        raise ValueError(\"Path is not a directory\")\n    if not os.path.isfile(path):\n        raise ValueError(\"Path is not a file\")\n    if not os.path.islink(path):\n        raise ValueError(\"Path is not a symbolic link\")\n    if not os.path.ismount(path):\n        raise ValueError(\"Path is not a mount point\")\n    if not os.path.isreadable(path):\n        raise ValueError(\"Path is not readable\")\n    if not os.path.isdir(path):\n        raise ValueError(\"Path is not a directory\")\n    if not os.path.isfile(path):\n        raise ValueError(\"Path is not a file\")\n    if not os.path.islink(path):\n        raise ValueError(\"Path is not a symbolic link\")\n    if not os.path.ismount(path):\n        raise ValueError(\"Path is not a mount point\")\n    if not os.path.isreadable(path):\n        raise ValueError(\"Path is not readable\")\n    if not os.path.isdir(path):\n        raise ValueError(\"Path is not a directory\")\n    if not os.path.isfile(path):\n        raise ValueError(\"Path is not a file\")\n    if not os.path.islink(path):\n        raise ValueError(\"Path is not a symbolic link\")\n    if not os.path.ismount(path):\n        raise ValueError(\"Path is not a mount point\")\n    if not os.path.isreadable(path):\n        raise ValueError(\"Path is not readable\")\n    if not os.path.isdir(path):\n        raise ValueError(\"Path is not a directory\")\n    if not os.path.isfile(path):\n        raise ValueError(\"Path is not a file\")\n    if not os.path.islink(path):\n        raise ValueError(\"Path is not a symbolic link\")\n    if not os.path.ismount(path):\n        raise ValueError(\"Path is not a mount point\")\n    if not os.path.isreadable(path):\n        raise ValueError(\"Path is not readable\")\n    if not os.path.isdir(path):\n        raise ValueError(\"Path is not a directory\")\n    if not os.path.isfile(path):\n        raise ValueError(\"Path is not a file\")\n    if not os.path.islink(path):\n        raise ValueError(\"Path is not a symbolic link\")\n    if not os.path.ismount(path):\n        raise ValueError(\"Path is not a mount point\")\n    if not os.path.isreadable(path):\n        raise ValueError(\"Path is not readable\")\n    if not os.path.isdir(path):\n        raise ValueError(\"Path is not a directory\")\n    if not os.path.isfile(path):\n        raise ValueError(\"Path is not a file\")\n    if not os.path.islink(path):\n        raise ValueError(\"Path is not a symbolic link\")\n    if not os.path.ismount(path):\n        raise ValueError(\"Path is not a mount point\")\n    if not os.path.isreadable(path):\n        raise ValueError(\"Path is not readable\")\n    if not os.path.isdir(path):\n        raise ValueError(\"Path is not a directory\")\n    if not os.path.isfile(path):\n        raise ValueError(\"Path is not a file\")\n    if not os.path.islink(path):\n        raise ValueError(\"Path is not a symbolic link\")\n    if not os.path.ismount(path):\n        raise ValueError(\"Path is not a mount point\")\n    if not os.path.isreadable(path):\n        raise ValueError(\"Path is not readable\")\n    if not os.path.isdir(path):\n        raise ValueError(\"Path is not a directory\")\n    if not os.path.isfile(path):\n        raise ValueError(\"Path is not a file\")\n    if not os.path.islink(path):\n        raise ValueError(\"Path is not a symbolic link\")\n    if not os.path.ismount(path):\n        raise ValueError(\"Path is not a mount point\")\n    if not os.path.isreadable(path):\n        raise ValueError(\"Path is not readable\")\n    if not os.path.isdir(path):\n        raise ValueError(\"Path is not a directory\")\n    if not os.path.isfile(path):\n        raise ValueError(\"Path is not a file\")\n    if not os.path.islink(path"}
{"task_id": "BigCodeBench/973", "solution": "import os\nimport shutil\ndef task_func(path, delimiter=\"/\"):\n    if not isinstance(path, str) or not path:\n        raise ValueError(\"If the 'path' is empty, not a string, or contain invalid components.\")\n    if not os.path.exists(path):\n        raise FileNotFoundError(\"If the 'path' does not exist in the filesystem.\")\n    path_components = path.split(delimiter)\n    disk_usage = []\n    for component in path_components:\n        total = os.path.getsize(component)\n        used = os.path.getsize(os.path.join(component, ''))\n        free = total - used\n        disk_usage.append((component, {'total': total, 'used': used, 'free': free}))\n    return disk_usage", "raw_solution": "import os\nimport shutil\ndef task_func(path, delimiter=\"/\"):\n    if not isinstance(path, str) or not path:\n        raise ValueError(\"If the 'path' is empty, not a string, or contain invalid components.\")\n    if not os.path.exists(path):\n        raise FileNotFoundError(\"If the 'path' does not exist in the filesystem.\")\n    path_components = path.split(delimiter)\n    disk_usage = []\n    for component in path_components:\n        total = os.path.getsize(component)\n        used = os.path.getsize(os.path.join(component, ''))\n        free = total - used\n        disk_usage.append((component, {'total': total, 'used': used, 'free': free}))\n    return disk_usage\n```"}
{"task_id": "BigCodeBench/974", "solution": "import shutil\nimport pathlib\ndef task_func(source_path, destination_path):\n    if not pathlib.Path(source_path).is_dir():\n        raise ValueError(\"If source_path does not exist or is not a directory.\")\n    shutil.copytree(source_path, destination_path)\n    return (source_path, pathlib.Path(destination_path).glob('*'))", "raw_solution": "import shutil\nimport pathlib\n\ndef task_func(source_path, destination_path):\n    if not pathlib.Path(source_path).is_dir():\n        raise ValueError(\"If source_path does not exist or is not a directory.\")\n    shutil.copytree(source_path, destination_path)\n    return (source_path, pathlib.Path(destination_path).glob('*'))\n```"}
{"task_id": "BigCodeBench/975", "solution": "import numpy as np\nimport pandas as pd\ndef task_func(rows, columns=[\"A\", \"B\", \"C\", \"D\", \"E\"], seed=0) -> pd.DataFrame:\n    np.random.seed(seed)\n    df = pd.DataFrame(np.random.rand(rows, len(columns)), columns=columns)\n    df = df.sample(frac=1, random_state=seed)\n    return df", "raw_solution": "import numpy as np\nimport pandas as pd\n\ndef task_func(rows, columns=[\"A\", \"B\", \"C\", \"D\", \"E\"], seed=0) -> pd.DataFrame:\n    np.random.seed(seed)\n    df = pd.DataFrame(np.random.rand(rows, len(columns)), columns=columns)\n    df = df.sample(frac=1, random_state=seed)\n    return df\n```"}
{"task_id": "BigCodeBench/976", "solution": "import numpy as np\nimport pandas as pd\nfrom sklearn.preprocessing import StandardScaler\ndef task_func(records: np.ndarray, random_seed: int = 0) -> pd.DataFrame:\n    if len(records.shape) != 2:\n        raise ValueError(\"If records is not 2D.\")\n    np.random.seed(random_seed)\n    shuffled_features = np.random.permutation(records.shape[1])\n    shuffled_records = records[:, shuffled_features]\n    scaler = StandardScaler()\n    scaled_records = scaler.fit_transform(shuffled_records)\n    df = pd.DataFrame(scaled_records, columns=[f\"f{i+1}\" for i in range(records.shape[1])])\n    return df", "raw_solution": "import numpy as np\nimport pandas as pd\nfrom sklearn.preprocessing import StandardScaler\n\ndef task_func(records: np.ndarray, random_seed: int = 0) -> pd.DataFrame:\n    if len(records.shape) != 2:\n        raise ValueError(\"If records is not 2D.\")\n    np.random.seed(random_seed)\n    shuffled_features = np.random.permutation(records.shape[1])\n    shuffled_records = records[:, shuffled_features]\n    scaler = StandardScaler()\n    scaled_records = scaler.fit_transform(shuffled_records)\n    df = pd.DataFrame(scaled_records, columns=[f\"f{i+1}\" for i in range(records.shape[1])])\n    return df\n```"}
{"task_id": "BigCodeBench/977", "solution": "import numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\ndef task_func(array, features=None, seed=None):\n    if len(array) == 0 or len(array[0]) == 0:\n        raise ValueError('array is empty or not 2-dimensional')\n    if features is not None and len(features) != len(array[0]):\n        raise ValueError('features does not match the number of columns in array')\n    if seed is not None:\n        np.random.seed(seed)\n    if features is None:\n        features = [str(i) for i in range(len(array[0]))]\n    sns.heatmap(array, xticklabels=features)\n    plt.show()", "raw_solution": "import numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\ndef task_func(array, features=None, seed=None):\n    if len(array) == 0 or len(array[0]) == 0:\n        raise ValueError('array is empty or not 2-dimensional')\n    if features is not None and len(features) != len(array[0]):\n        raise ValueError('features does not match the number of columns in array')\n    if seed is not None:\n        np.random.seed(seed)\n    if features is None:\n        features = [str(i) for i in range(len(array[0]))]\n    sns.heatmap(array, xticklabels=features)\n    plt.show()\n```"}
{"task_id": "BigCodeBench/978", "solution": "import numpy as np\nimport pandas as pd\nfrom sklearn.decomposition import PCA\ndef task_func(array, seed=None):\n    if array.ndim != 2:\n        raise ValueError(\"If the input array is not 2D.\")\n    if seed is not None:\n        np.random.seed(seed)\n    pca = PCA(n_components=2)\n    pca.fit(array)\n    return pd.DataFrame(pca.components_, columns=['PC1', 'PC2'])", "raw_solution": "import numpy as np\nimport pandas as pd\nfrom sklearn.decomposition import PCA\n\ndef task_func(array, seed=None):\n    if array.ndim != 2:\n        raise ValueError(\"If the input array is not 2D.\")\n    if seed is not None:\n        np.random.seed(seed)\n    pca = PCA(n_components=2)\n    pca.fit(array)\n    return pd.DataFrame(pca.components_, columns=['PC1', 'PC2'])\n```"}
{"task_id": "BigCodeBench/979", "solution": "import numpy as np\nimport pandas as pd\nfrom sklearn.ensemble import RandomForestClassifier\ndef task_func(\n    feature_array,\n    target_array,\n    feature_names=[\"f1\", \"f2\", \"f3\", \"f4\", \"f5\"],\n    target_name=\"target\",\n    seed=None,\n):\n    # Shuffle the columns of the feature array\n    shuffled_feature_array = feature_array[:, np.random.permutation(feature_array.shape[1])]\n    \n    # Train a Random Forest Classifier on the shuffled data\n    rf_classifier = RandomForestClassifier(random_state=seed)\n    rf_classifier.fit(shuffled_feature_array, target_array)\n    \n    return rf_classifier", "raw_solution": "import numpy as np\nimport pandas as pd\nfrom sklearn.ensemble import RandomForestClassifier\n\ndef task_func(\n    feature_array,\n    target_array,\n    feature_names=[\"f1\", \"f2\", \"f3\", \"f4\", \"f5\"],\n    target_name=\"target\",\n    seed=None,\n):\n    # Shuffle the columns of the feature array\n    shuffled_feature_array = feature_array[:, np.random.permutation(feature_array.shape[1])]\n    \n    # Train a Random Forest Classifier on the shuffled data\n    rf_classifier = RandomForestClassifier(random_state=seed)\n    rf_classifier.fit(shuffled_feature_array, target_array)\n    \n    return rf_classifier\n```"}
{"task_id": "BigCodeBench/980", "solution": "import numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import StandardScaler\ndef task_func(df):\n    if df.empty or df.select_dtypes(include=['number']).empty:\n        raise ValueError(\"If the DataFrame is empty or if no numeric columns are present.\")\n    scaler = StandardScaler()\n    df_scaled = scaler.fit_transform(df.select_dtypes(include=['number']))\n    corr_matrix = df_scaled.corr()\n    fig, ax = plt.subplots(figsize=(10, 10))\n    sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', ax=ax)\n    return df_scaled, fig", "raw_solution": "import numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import StandardScaler\ndef task_func(df):\n    if df.empty or df.select_dtypes(include=['number']).empty:\n        raise ValueError(\"If the DataFrame is empty or if no numeric columns are present.\")\n    scaler = StandardScaler()\n    df_scaled = scaler.fit_transform(df.select_dtypes(include=['number']))\n    corr_matrix = df_scaled.corr()\n    fig, ax = plt.subplots(figsize=(10, 10))\n    sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', ax=ax)\n    return df_scaled, fig\n```"}
{"task_id": "BigCodeBench/981", "solution": "import pandas as pd\nfrom datetime import datetime\nimport random\ndef task_func(start_date, end_date, num_series, seed=None):\n    if start_date > end_date:\n        raise ValueError(\"start_date is later than end_date\")\n    if num_series < 1:\n        raise ValueError(\"num_series is less than 1\")\n    random.seed(seed)\n    dates = pd.date_range(start=start_date, end=end_date)\n    series = [random.randint(0, 100) for _ in range(num_series)]\n    df = pd.DataFrame(series, index=dates, columns=[\"Value\"])\n    df.plot(title=\"Random Time Series\", xlabel=\"Date\", ylabel=\"Value\")\n    return df, plt.gca()", "raw_solution": "import pandas as pd\nfrom datetime import datetime\nimport random\ndef task_func(start_date, end_date, num_series, seed=None):\n    if start_date > end_date:\n        raise ValueError(\"start_date is later than end_date\")\n    if num_series < 1:\n        raise ValueError(\"num_series is less than 1\")\n    random.seed(seed)\n    dates = pd.date_range(start=start_date, end=end_date)\n    series = [random.randint(0, 100) for _ in range(num_series)]\n    df = pd.DataFrame(series, index=dates, columns=[\"Value\"])\n    df.plot(title=\"Random Time Series\", xlabel=\"Date\", ylabel=\"Value\")\n    return df, plt.gca()\n```"}
{"task_id": "BigCodeBench/982", "solution": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import norm\ndef task_func(df, column, bins=30, density=True, alpha=0.6, color=\"g\", seed=None):\n    if seed is not None:\n        np.random.seed(seed)\n    df[column] = np.random.normal(loc=df[column].mean(), scale=df[column].std(), size=len(df))\n    plt.hist(df[column], bins=bins, density=density, alpha=alpha, color=color)\n    x = np.linspace(df[column].min(), df[column].max(), 100)\n    y = norm.pdf(x, loc=df[column].mean(), scale=df[column].std())\n    plt.plot(x, y, color=color)\n    return plt.gca()", "raw_solution": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import norm\ndef task_func(df, column, bins=30, density=True, alpha=0.6, color=\"g\", seed=None):\n    if seed is not None:\n        np.random.seed(seed)\n    df[column] = np.random.normal(loc=df[column].mean(), scale=df[column].std(), size=len(df))\n    plt.hist(df[column], bins=bins, density=density, alpha=alpha, color=color)\n    x = np.linspace(df[column].min(), df[column].max(), 100)\n    y = norm.pdf(x, loc=df[column].mean(), scale=df[column].std())\n    plt.plot(x, y, color=color)\n    return plt.gca()\n```"}
{"task_id": "BigCodeBench/983", "solution": "import seaborn as sns\nimport numpy as np\ndef task_func(df):\n    if df.empty:\n        raise ValueError(\"If the DataFrame is empty.\")\n    if not df.select_dtypes(include=[np.number]).empty:\n        raise TypeError(\"If the DataFrame contains non-numeric data types.\")\n    covariance_df = df.cov()\n    pair_plot = sns.pairplot(df)\n    return covariance_df, pair_plot", "raw_solution": "import seaborn as sns\nimport numpy as np\ndef task_func(df):\n    if df.empty:\n        raise ValueError(\"If the DataFrame is empty.\")\n    if not df.select_dtypes(include=[np.number]).empty:\n        raise TypeError(\"If the DataFrame contains non-numeric data types.\")\n    covariance_df = df.cov()\n    pair_plot = sns.pairplot(df)\n    return covariance_df, pair_plot\n```"}
{"task_id": "BigCodeBench/984", "solution": "import matplotlib.pyplot as plt\nfrom sklearn.linear_model import LinearRegression\ndef task_func(df, x_column, y_column):\n    plt.scatter(df[x_column], df[y_column])\n    model = LinearRegression()\n    model.fit(df[x_column].values.reshape(-1, 1), df[y_column].values.reshape(-1, 1))\n    y_pred = model.predict(df[x_column].values.reshape(-1, 1))\n    plt.plot(df[x_column], y_pred, color='red')\n    return plt.axes()", "raw_solution": "import matplotlib.pyplot as plt\nfrom sklearn.linear_model import LinearRegression\n\ndef task_func(df, x_column, y_column):\n    plt.scatter(df[x_column], df[y_column])\n    model = LinearRegression()\n    model.fit(df[x_column].values.reshape(-1, 1), df[y_column].values.reshape(-1, 1))\n    y_pred = model.predict(df[x_column].values.reshape(-1, 1))\n    plt.plot(df[x_column], y_pred, color='red')\n    return plt.axes()\n```"}
{"task_id": "BigCodeBench/985", "solution": "import pandas as pd\nimport json\nimport os\nimport math\ndef task_func(json_data, output_dir=\".\", file_name=\"country_population_report.csv\"):\n    if not isinstance(json_data, str):\n        raise ValueError(\"JSON data must be a string\")\n    if not os.path.exists(output_dir):\n        os.makedirs(output_dir)\n    if not os.path.isfile(output_dir + \"/\" + file_name):\n        raise IOError(\"File cannot be written to the specified directory\")\n    try:\n        data = json.loads(json_data)\n    except json.JSONDecodeError:\n        raise ValueError(\"Malformed JSON data\")\n    if not isinstance(data, list):\n        raise ValueError(\"JSON data must be a list\")\n    df = pd.DataFrame(columns=[\"Country\", \"Population\"])\n    for item in data:\n        if not isinstance(item, dict):\n            raise ValueError(\"JSON data must be a list of dictionaries\")\n        if not isinstance(item[\"Country\"], str):\n            raise ValueError(\"Country name must be a string\")\n        if not isinstance(item[\"Population\"], (int, float)) or item[\"Population\"] < 0:\n            raise ValueError(\"Population must be a non-negative numeric value\")\n        df = df.append({\"Country\": item[\"Country\"], \"Population\": math.floor(item[\"Population\"])}, ignore_index=True)\n    df.to_csv(output_dir + \"/\" + file_name, index=False)\n    return output_dir + \"/\" + file_name, df", "raw_solution": "import pandas as pd\nimport json\nimport os\nimport math\ndef task_func(json_data, output_dir=\".\", file_name=\"country_population_report.csv\"):\n    if not isinstance(json_data, str):\n        raise ValueError(\"JSON data must be a string\")\n    if not os.path.exists(output_dir):\n        os.makedirs(output_dir)\n    if not os.path.isfile(output_dir + \"/\" + file_name):\n        raise IOError(\"File cannot be written to the specified directory\")\n    try:\n        data = json.loads(json_data)\n    except json.JSONDecodeError:\n        raise ValueError(\"Malformed JSON data\")\n    if not isinstance(data, list):\n        raise ValueError(\"JSON data must be a list\")\n    df = pd.DataFrame(columns=[\"Country\", \"Population\"])\n    for item in data:\n        if not isinstance(item, dict):\n            raise ValueError(\"JSON data must be a list of dictionaries\")\n        if not isinstance(item[\"Country\"], str):\n            raise ValueError(\"Country name must be a string\")\n        if not isinstance(item[\"Population\"], (int, float)) or item[\"Population\"] < 0:\n            raise ValueError(\"Population must be a non-negative numeric value\")\n        df = df.append({\"Country\": item[\"Country\"], \"Population\": math.floor(item[\"Population\"])}, ignore_index=True)\n    df.to_csv(output_dir + \"/\" + file_name, index=False)\n    return output_dir + \"/\" + file_name, df\n```"}
{"task_id": "BigCodeBench/986", "solution": "import json\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pandas as pd\ndef task_func(json_data: str, key_path: list):\n    try:\n        data = json.loads(json_data)\n        for key in key_path:\n            data = data[key]\n        if not isinstance(data, (int, float)):\n            raise ValueError(\"No numeric data is found\")\n        if not data:\n            raise ValueError(\"The data string is empty or corrupted\")\n        df = pd.DataFrame([data])\n        sns.boxplot(data=df)\n        plt.show()\n    except KeyError:\n        raise ValueError(\"KeyError: If a specified key is not found\")\n    except ValueError as e:\n        raise ValueError(e)", "raw_solution": "import json\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pandas as pd\ndef task_func(json_data: str, key_path: list):\n    try:\n        data = json.loads(json_data)\n        for key in key_path:\n            data = data[key]\n        if not isinstance(data, (int, float)):\n            raise ValueError(\"No numeric data is found\")\n        if not data:\n            raise ValueError(\"The data string is empty or corrupted\")\n        df = pd.DataFrame([data])\n        sns.boxplot(data=df)\n        plt.show()\n    except KeyError:\n        raise ValueError(\"KeyError: If a specified key is not found\")\n    except ValueError as e:\n        raise ValueError(e)\n```"}
{"task_id": "BigCodeBench/987", "solution": "import json\nimport pandas as pd\nfrom sklearn.preprocessing import MinMaxScaler\nimport matplotlib.pyplot as plt\ndef task_func(json_data: str, data_key: str):\n    try:\n        data = json.loads(json_data)\n        original_data = pd.Series(data[data_key])\n        scaler = MinMaxScaler()\n        normalized_data = scaler.fit_transform(original_data.values.reshape(-1, 1))\n        if len(normalized_data) == 0:\n            return (original_data, None, None)\n        else:\n            return (original_data, pd.Series(normalized_data.flatten()), plt.axes())\n    except KeyError:\n        raise Exception(\"Key path is not found in the given data.\")", "raw_solution": "import json\nimport pandas as pd\nfrom sklearn.preprocessing import MinMaxScaler\nimport matplotlib.pyplot as plt\n\ndef task_func(json_data: str, data_key: str):\n    try:\n        data = json.loads(json_data)\n        original_data = pd.Series(data[data_key])\n        scaler = MinMaxScaler()\n        normalized_data = scaler.fit_transform(original_data.values.reshape(-1, 1))\n        if len(normalized_data) == 0:\n            return (original_data, None, None)\n        else:\n            return (original_data, pd.Series(normalized_data.flatten()), plt.axes())\n    except KeyError:\n        raise Exception(\"Key path is not found in the given data.\")\n```"}
{"task_id": "BigCodeBench/988", "solution": "import os\nimport re\nfrom pathlib import Path\ndef task_func(dir_path: str, predicates: list) -> dict:\n    if not predicates:\n        raise ValueError(\"If no valid predicates are provided.\")\n    if not os.path.exists(dir_path) or not os.path.isdir(dir_path):\n        raise FileNotFoundError(\"If the specified directory does not exist or is not a directory.\")\n    result = {}\n    for item in os.listdir(dir_path):\n        item_path = Path(dir_path) / item\n        for predicate in predicates:\n            if predicate(item_path):\n                result[item] = True\n                break\n        else:\n            result[item] = False\n    return result", "raw_solution": "import os\nimport re\nfrom pathlib import Path\ndef task_func(dir_path: str, predicates: list) -> dict:\n    if not predicates:\n        raise ValueError(\"If no valid predicates are provided.\")\n    if not os.path.exists(dir_path) or not os.path.isdir(dir_path):\n        raise FileNotFoundError(\"If the specified directory does not exist or is not a directory.\")\n    result = {}\n    for item in os.listdir(dir_path):\n        item_path = Path(dir_path) / item\n        for predicate in predicates:\n            if predicate(item_path):\n                result[item] = True\n                break\n        else:\n            result[item] = False\n    return result\n```"}
{"task_id": "BigCodeBench/989", "solution": "import random\nimport string\ndef task_func(length: int, predicates: list, seed: int = None):\n    if length < 0:\n        raise ValueError(\"The specified length is negative.\")\n    if seed is not None:\n        random.seed(seed)\n    text = ''.join(random.choice(string.ascii_letters + string.digits + string.punctuation) for _ in range(length))\n    characteristics = {}\n    for predicate in predicates:\n        if predicate == 'uppercase':\n            characteristics['uppercase'] = any(c.isupper() for c in text)\n        elif predicate == 'lowercase':\n            characteristics['lowercase'] = any(c.islower() for c in text)\n        elif predicate == 'digit':\n            characteristics['digit'] = any(c.isdigit() for c in text)\n        elif predicate == 'punctuation':\n            characteristics['punctuation'] = any(c in string.punctuation for c in text)\n        else:\n            raise KeyError(\"Invalid predicate provided.\")\n    return (text, characteristics)", "raw_solution": "import random\nimport string\ndef task_func(length: int, predicates: list, seed: int = None):\n    if length < 0:\n        raise ValueError(\"The specified length is negative.\")\n    if seed is not None:\n        random.seed(seed)\n    text = ''.join(random.choice(string.ascii_letters + string.digits + string.punctuation) for _ in range(length))\n    characteristics = {}\n    for predicate in predicates:\n        if predicate == 'uppercase':\n            characteristics['uppercase'] = any(c.isupper() for c in text)\n        elif predicate == 'lowercase':\n            characteristics['lowercase'] = any(c.islower() for c in text)\n        elif predicate == 'digit':\n            characteristics['digit'] = any(c.isdigit() for c in text)\n        elif predicate == 'punctuation':\n            characteristics['punctuation'] = any(c in string.punctuation for c in text)\n        else:\n            raise KeyError(\"Invalid predicate provided.\")\n    return (text, characteristics)\n```"}
{"task_id": "BigCodeBench/990", "solution": "import binascii\nimport base64\nimport urllib.parse\nimport codecs\ndef task_func(hex_string):\n    # decode hexadecimal string to bytes\n    bytes_string = binascii.unhexlify(hex_string)\n    \n    # convert bytes to UTF-8 string\n    utf8_string = bytes_string.decode('utf-8')\n    \n    # encode UTF-8 string into various formats\n    hex_string = utf8_string.encode('hex')\n    base64_string = base64.b64encode(utf8_string.encode('utf-8')).decode('utf-8')\n    utf16_string = utf8_string.encode('utf-16')\n    utf32_string = utf8_string.encode('utf-32')\n    ascii_string = utf8_string.encode('ascii')\n    url_string = urllib.parse.quote(utf8_string)\n    rot13_string = codecs.encode(utf8_string, 'rot13')\n    \n    # return dictionary with encoded strings\n    return {'hex': hex_string, 'base64': base64_string, 'utf-8': utf8_string, 'utf-16': utf16_string, 'utf-32': utf32_string, 'ASCII': ascii_string, 'URL': url_string, 'ROT13': rot13_string}", "raw_solution": "import binascii\nimport base64\nimport urllib.parse\nimport codecs\n\ndef task_func(hex_string):\n    # decode hexadecimal string to bytes\n    bytes_string = binascii.unhexlify(hex_string)\n    \n    # convert bytes to UTF-8 string\n    utf8_string = bytes_string.decode('utf-8')\n    \n    # encode UTF-8 string into various formats\n    hex_string = utf8_string.encode('hex')\n    base64_string = base64.b64encode(utf8_string.encode('utf-8')).decode('utf-8')\n    utf16_string = utf8_string.encode('utf-16')\n    utf32_string = utf8_string.encode('utf-32')\n    ascii_string = utf8_string.encode('ascii')\n    url_string = urllib.parse.quote(utf8_string)\n    rot13_string = codecs.encode(utf8_string, 'rot13')\n    \n    # return dictionary with encoded strings\n    return {'hex': hex_string, 'base64': base64_string, 'utf-8': utf8_string, 'utf-16': utf16_string, 'utf-32': utf32_string, 'ASCII': ascii_string, 'URL': url_string, 'ROT13': rot13_string}\n```"}
{"task_id": "BigCodeBench/991", "solution": "import binascii\nimport string\nimport random\ndef task_func(length):\n    hex_str = binascii.hexlify(random.getrandbits(length * 8)).decode('utf-8')\n    ascii_str = hex_str.decode('hex')\n    return ascii_str", "raw_solution": "import binascii\nimport string\nimport random\n\ndef task_func(length):\n    hex_str = binascii.hexlify(random.getrandbits(length * 8)).decode('utf-8')\n    ascii_str = hex_str.decode('hex')\n    return ascii_str\n```"}
{"task_id": "BigCodeBench/992", "solution": "import sys\nimport sqlite3\nPATH_TO_APPEND = \"path/to/whatever\"\nDATABASE = \"path/to/database.db\"\ndef task_func(path_to_append=PATH_TO_APPEND, database=DATABASE):\n    # Append the path to sys.path\n    sys.path.append(path_to_append)\n    # Connect to the database\n    conn = sqlite3.connect(database)\n    c = conn.cursor()\n    # Create the table if it doesn't exist\n    c.execute('''CREATE TABLE IF NOT EXISTS paths (path TEXT PRIMARY KEY)''')\n    # Insert the path into the database\n    c.execute('''INSERT OR IGNORE INTO paths (path) VALUES (?)''', (path_to_append,))\n    # Commit the changes and close the connection\n    conn.commit()\n    conn.close()\n    # Return the path that was appended to sys.path and inserted into the database\n    return path_to_append", "raw_solution": "import sys\nimport sqlite3\n# Constants\nPATH_TO_APPEND = \"path/to/whatever\"\nDATABASE = \"path/to/database.db\"\ndef task_func(path_to_append=PATH_TO_APPEND, database=DATABASE):\n    # Append the path to sys.path\n    sys.path.append(path_to_append)\n    # Connect to the database\n    conn = sqlite3.connect(database)\n    c = conn.cursor()\n    # Create the table if it doesn't exist\n    c.execute('''CREATE TABLE IF NOT EXISTS paths (path TEXT PRIMARY KEY)''')\n    # Insert the path into the database\n    c.execute('''INSERT OR IGNORE INTO paths (path) VALUES (?)''', (path_to_append,))\n    # Commit the changes and close the connection\n    conn.commit()\n    conn.close()\n    # Return the path that was appended to sys.path and inserted into the database\n    return path_to_append\n```"}
{"task_id": "BigCodeBench/993", "solution": "import re\nfrom scipy.stats import gaussian_kde\nfrom scipy import linalg\nimport matplotlib.pyplot as plt\ndef task_func(text):\n    # Remove non-alphanumeric characters and convert to lowercase\n    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text).lower()\n    # Split the text into words\n    words = text.split()\n    # Calculate the lengths of the words\n    lengths = [len(word) for word in words]\n    # Create a histogram of the word lengths\n    plt.hist(lengths, bins=range(1, 21), alpha=0.5, color='blue', edgecolor='black')\n    # Calculate the KDE of the word lengths\n    kde = gaussian_kde(lengths)\n    # Create a range of word lengths to plot the KDE\n    x = range(1, 21)\n    # Plot the KDE\n    plt.plot(x, kde(x), color='red', linewidth=2)\n    # Show the plot\n    plt.show()\n    # Return the Axes object showing the histogram and KDE\n    return plt.gca()", "raw_solution": "import re\nfrom scipy.stats import gaussian_kde\nfrom scipy import linalg\nimport matplotlib.pyplot as plt\n\ndef task_func(text):\n    # Remove non-alphanumeric characters and convert to lowercase\n    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text).lower()\n    # Split the text into words\n    words = text.split()\n    # Calculate the lengths of the words\n    lengths = [len(word) for word in words]\n    # Create a histogram of the word lengths\n    plt.hist(lengths, bins=range(1, 21), alpha=0.5, color='blue', edgecolor='black')\n    # Calculate the KDE of the word lengths\n    kde = gaussian_kde(lengths)\n    # Create a range of word lengths to plot the KDE\n    x = range(1, 21)\n    # Plot the KDE\n    plt.plot(x, kde(x), color='red', linewidth=2)\n    # Show the plot\n    plt.show()\n    # Return the Axes object showing the histogram and KDE\n    return plt.gca()\n```"}
{"task_id": "BigCodeBench/994", "solution": "import requests\nimport pandas as pd\nfrom bs4 import BeautifulSoup\ndef task_func(url: str, csv_file_path: str) -> list:\n    try:\n        response = requests.get(url, timeout=5)\n        response.raise_for_status()\n    except requests.RequestException as e:\n        raise RuntimeError(f\"Error fetching URL: {e}\")\n    \n    soup = BeautifulSoup(response.text, 'html.parser')\n    data = []\n    for container in soup.find_all('div', class_='container'):\n        title = container.find('h1').text if container.find('h1') else 'No Title'\n        date = container.find('span', class_='date').text if container.find('span', class_='date') else 'No Date'\n        author = container.find('span', class_='author').text if container.find('span', class_='author') else 'No Author'\n        data.append((title, date, author))\n    \n    df = pd.DataFrame(data, columns=['Title', 'Date', 'Author'])\n    df.to_csv(csv_file_path, index=False)\n    \n    return data", "raw_solution": "import requests\nimport pandas as pd\nfrom bs4 import BeautifulSoup\n\ndef task_func(url: str, csv_file_path: str) -> list:\n    try:\n        response = requests.get(url, timeout=5)\n        response.raise_for_status()\n    except requests.RequestException as e:\n        raise RuntimeError(f\"Error fetching URL: {e}\")\n    \n    soup = BeautifulSoup(response.text, 'html.parser')\n    data = []\n    for container in soup.find_all('div', class_='container'):\n        title = container.find('h1').text if container.find('h1') else 'No Title'\n        date = container.find('span', class_='date').text if container.find('span', class_='date') else 'No Date'\n        author = container.find('span', class_='author').text if container.find('span', class_='author') else 'No Author'\n        data.append((title, date, author))\n    \n    df = pd.DataFrame(data, columns=['Title', 'Date', 'Author'])\n    df.to_csv(csv_file_path, index=False)\n    \n    return data\n```"}
{"task_id": "BigCodeBench/995", "solution": "import os\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\ndef task_func(file_path: str, plot_path: str) -> (float, float, str):\n    if not os.path.exists(file_path):\n        raise FileNotFoundError(\"File not found\")\n    df = pd.read_csv(file_path)\n    data = df.values.flatten()\n    mean = np.mean(data)\n    median = np.median(data)\n    plt.plot(range(len(data)), data)\n    plt.title(\"Data Visualization\")\n    plt.xlabel(\"Index\")\n    plt.ylabel(\"Value\")\n    plt.savefig(plot_path)\n    return mean, median, plot_path", "raw_solution": "import os\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\n\ndef task_func(file_path: str, plot_path: str) -> (float, float, str):\n    if not os.path.exists(file_path):\n        raise FileNotFoundError(\"File not found\")\n    df = pd.read_csv(file_path)\n    data = df.values.flatten()\n    mean = np.mean(data)\n    median = np.median(data)\n    plt.plot(range(len(data)), data)\n    plt.title(\"Data Visualization\")\n    plt.xlabel(\"Index\")\n    plt.ylabel(\"Value\")\n    plt.savefig(plot_path)\n    return mean, median, plot_path\n```"}
{"task_id": "BigCodeBench/996", "solution": "import requests\nimport json\nfrom bs4 import BeautifulSoup\ndef task_func(url: str, file_name: str = \"Output.txt\") -> str:\n    response = requests.get(url)\n    soup = BeautifulSoup(response.text, 'html.parser')\n    title = soup.find('title').get_text() if soup.find('title') else None\n    with open(file_name, 'a') as f:\n        f.write(title + '\\n')\n    return file_name", "raw_solution": "import requests\nimport json\nfrom bs4 import BeautifulSoup\n\ndef task_func(url: str, file_name: str = \"Output.txt\") -> str:\n    response = requests.get(url)\n    soup = BeautifulSoup(response.text, 'html.parser')\n    title = soup.find('title').get_text() if soup.find('title') else None\n    with open(file_name, 'a') as f:\n        f.write(title + '\\n')\n    return file_name\n```"}
{"task_id": "BigCodeBench/997", "solution": "import urllib.request\nimport os\nimport zipfile\nTARGET_DIR = \"downloaded_files\"\nTARGET_ZIP_FILE = \"downloaded_files.zip\"\ndef task_func(url):\n    # Create target directory if it does not exist\n    if not os.path.exists(TARGET_DIR):\n        os.makedirs(TARGET_DIR)\n    # Download zip file\n    urllib.request.urlretrieve(url, os.path.join(TARGET_DIR, TARGET_ZIP_FILE))\n    # Extract zip file\n    with zipfile.ZipFile(os.path.join(TARGET_DIR, TARGET_ZIP_FILE), 'r') as zip_ref:\n        zip_ref.extractall(TARGET_DIR)\n    # Delete zip file\n    os.remove(os.path.join(TARGET_DIR, TARGET_ZIP_FILE))\n    # Return path of directory where contents of zip file are extracted\n    return os.path.join(TARGET_DIR, os.listdir(TARGET_DIR)[0])", "raw_solution": "import urllib.request\nimport os\nimport zipfile\n# Constants\nTARGET_DIR = \"downloaded_files\"\nTARGET_ZIP_FILE = \"downloaded_files.zip\"\ndef task_func(url):\n    # Create target directory if it does not exist\n    if not os.path.exists(TARGET_DIR):\n        os.makedirs(TARGET_DIR)\n    # Download zip file\n    urllib.request.urlretrieve(url, os.path.join(TARGET_DIR, TARGET_ZIP_FILE))\n    # Extract zip file\n    with zipfile.ZipFile(os.path.join(TARGET_DIR, TARGET_ZIP_FILE), 'r') as zip_ref:\n        zip_ref.extractall(TARGET_DIR)\n    # Delete zip file\n    os.remove(os.path.join(TARGET_DIR, TARGET_ZIP_FILE))\n    # Return path of directory where contents of zip file are extracted\n    return os.path.join(TARGET_DIR, os.listdir(TARGET_DIR)[0])\n```"}
{"task_id": "BigCodeBench/998", "solution": "import urllib.request\nimport os\nimport hashlib\nimport tarfile\nTARGET_TAR_FILE = \"downloaded_files.tar.gz\"\nEXPECTED_MD5_CHECKSUM = \"d41d8cd98f00b204e9800998ecf8427e\"\ndef task_func(url):\n    try:\n        # Download the tar.gz file\n        urllib.request.urlretrieve(url, TARGET_TAR_FILE)\n        # Open the tar.gz file\n        with tarfile.open(TARGET_TAR_FILE, 'r:gz') as tar:\n            # Extract the contents of the tar.gz file\n            tar.extractall()\n        # Calculate the MD5 checksum of the extracted files\n        md5 = hashlib.md5()\n        for root, dirs, files in os.walk('.'):\n            for file in files:\n                file_path = os.path.join(root, file)\n                with open(file_path, 'rb') as f:\n                    md5.update(f.read())\n        # Compare the calculated MD5 checksum with the expected value\n        if md5.hexdigest() == EXPECTED_MD5_CHECKSUM:\n            return True\n        else:\n            return False\n    except Exception as e:\n        print(f\"Error: {e}\")\n        return False", "raw_solution": "import urllib.request\nimport os\nimport hashlib\nimport tarfile\n# Constants\nTARGET_TAR_FILE = \"downloaded_files.tar.gz\"\nEXPECTED_MD5_CHECKSUM = \"d41d8cd98f00b204e9800998ecf8427e\"\ndef task_func(url):\n    try:\n        # Download the tar.gz file\n        urllib.request.urlretrieve(url, TARGET_TAR_FILE)\n        # Open the tar.gz file\n        with tarfile.open(TARGET_TAR_FILE, 'r:gz') as tar:\n            # Extract the contents of the tar.gz file\n            tar.extractall()\n        # Calculate the MD5 checksum of the extracted files\n        md5 = hashlib.md5()\n        for root, dirs, files in os.walk('.'):\n            for file in files:\n                file_path = os.path.join(root, file)\n                with open(file_path, 'rb') as f:\n                    md5.update(f.read())\n        # Compare the calculated MD5 checksum with the expected value\n        if md5.hexdigest() == EXPECTED_MD5_CHECKSUM:\n            return True\n        else:\n            return False\n    except Exception as e:\n        print(f\"Error: {e}\")\n        return False\n```"}
{"task_id": "BigCodeBench/999", "solution": "import urllib.request\nimport os\nimport csv\nimport collections\ndef task_func(url, column_name, csv_file_path):\n    try:\n        urllib.request.urlretrieve(url, csv_file_path)\n    except Exception as e:\n        print(f\"Error downloading file: {e}\")\n        return None\n\n    try:\n        with open(csv_file_path, mode='r', newline='') as file:\n            reader = csv.DictReader(file)\n            column_data = [row[column_name] for row in reader]\n    except Exception as e:\n        print(f\"Error reading file: {e}\")\n        os.remove(csv_file_path)\n        return None\n\n    try:\n        value_counts = collections.Counter(column_data)\n    except Exception as e:\n        print(f\"Error counting values: {e}\")\n        os.remove(csv_file_path)\n        return None\n\n    os.remove(csv_file_path)\n    return value_counts", "raw_solution": "import urllib.request\nimport os\nimport csv\nimport collections\n\ndef task_func(url, column_name, csv_file_path):\n    try:\n        urllib.request.urlretrieve(url, csv_file_path)\n    except Exception as e:\n        print(f\"Error downloading file: {e}\")\n        return None\n\n    try:\n        with open(csv_file_path, mode='r', newline='') as file:\n            reader = csv.DictReader(file)\n            column_data = [row[column_name] for row in reader]\n    except Exception as e:\n        print(f\"Error reading file: {e}\")\n        os.remove(csv_file_path)\n        return None\n\n    try:\n        value_counts = collections.Counter(column_data)\n    except Exception as e:\n        print(f\"Error counting values: {e}\")\n        os.remove(csv_file_path)\n        return None\n\n    os.remove(csv_file_path)\n    return value_counts\n```"}
{"task_id": "BigCodeBench/1000", "solution": "import urllib.request\nimport os\nimport json\nimport pandas as pd\nTARGET_JSON_FILE = \"downloaded_file.json\"\ndef task_func(url):\n    # Retrieve the JSON file from the given URL\n    urllib.request.urlretrieve(url, TARGET_JSON_FILE)\n    # Open and read the file\n    with open(TARGET_JSON_FILE, 'r') as f:\n        data = json.load(f)\n    # Convert the JSON content into a pandas DataFrame\n    df = pd.DataFrame(data)\n    # Delete the temporary JSON file\n    os.remove(TARGET_JSON_FILE)\n    return df", "raw_solution": "import urllib.request\nimport os\nimport json\nimport pandas as pd\n# Constants\nTARGET_JSON_FILE = \"downloaded_file.json\"\ndef task_func(url):\n    # Retrieve the JSON file from the given URL\n    urllib.request.urlretrieve(url, TARGET_JSON_FILE)\n    # Open and read the file\n    with open(TARGET_JSON_FILE, 'r') as f:\n        data = json.load(f)\n    # Convert the JSON content into a pandas DataFrame\n    df = pd.DataFrame(data)\n    # Delete the temporary JSON file\n    os.remove(TARGET_JSON_FILE)\n    return df\n```"}
{"task_id": "BigCodeBench/1001", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\ndef task_func(csv_file_path: str):\n    df = pd.read_csv(csv_file_path)\n    df['column1'] = (df['column1'] - df['column1'].mean()) / df['column1'].std()\n    plt.title('Plot Title: {0} : {1}'.format('Normalized Column 1', 'Index'))\n    plt.xlabel('Index: {0} : {1}'.format('Normalized Value', 'Frequency'))\n    plt.ylabel('Frequency: {0} : {1}'.format('Normalized Value', 'Index'))\n    return plt.axes()", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\n\ndef task_func(csv_file_path: str):\n    df = pd.read_csv(csv_file_path)\n    df['column1'] = (df['column1'] - df['column1'].mean()) / df['column1'].std()\n    plt.title('Plot Title: {0} : {1}'.format('Normalized Column 1', 'Index'))\n    plt.xlabel('Index: {0} : {1}'.format('Normalized Value', 'Frequency'))\n    plt.ylabel('Frequency: {0} : {1}'.format('Normalized Value', 'Index'))\n    return plt.axes()\n```"}
{"task_id": "BigCodeBench/1002", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\ndef task_func(data, column_name=\"target_column\"):\n    try:\n        df = pd.DataFrame(data)\n        if column_name not in df.columns:\n            raise ValueError(\"Column name does not exist in the DataFrame\")\n        df[column_name] = pd.to_numeric(df[column_name], errors='coerce')\n        if df[column_name].dtype == 'float64':\n            df[column_name] = df[column_name].astype('int64')\n        df[column_name] = df[column_name].astype('category')\n        ax = df[column_name].hist()\n        ax.set_title('Histogram of ' + column_name)\n        ax.set_xlabel(column_name)\n        return df, ax\n    except ValueError as e:\n        print(e)\n        return None, None", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\n\ndef task_func(data, column_name=\"target_column\"):\n    try:\n        df = pd.DataFrame(data)\n        if column_name not in df.columns:\n            raise ValueError(\"Column name does not exist in the DataFrame\")\n        df[column_name] = pd.to_numeric(df[column_name], errors='coerce')\n        if df[column_name].dtype == 'float64':\n            df[column_name] = df[column_name].astype('int64')\n        df[column_name] = df[column_name].astype('category')\n        ax = df[column_name].hist()\n        ax.set_title('Histogram of ' + column_name)\n        ax.set_xlabel(column_name)\n        return df, ax\n    except ValueError as e:\n        print(e)\n        return None, None\n```"}
{"task_id": "BigCodeBench/1003", "solution": "import urllib.request\nfrom lxml import etree\nimport pandas as pd\ndef task_func(url):\n    try:\n        response = urllib.request.urlopen(url)\n        xml_data = response.read()\n        root = etree.fromstring(xml_data)\n        df = pd.DataFrame(columns=[child.tag for child in root[0]])\n        for item in root:\n            row = {}\n            for child in item:\n                row[child.tag] = child.text\n            df = df.append(row, ignore_index=True)\n        return df\n    except Exception as e:\n        raise ValueError(\"XML structure does not match expected format.\")", "raw_solution": "import urllib.request\nfrom lxml import etree\nimport pandas as pd\n\ndef task_func(url):\n    try:\n        response = urllib.request.urlopen(url)\n        xml_data = response.read()\n        root = etree.fromstring(xml_data)\n        df = pd.DataFrame(columns=[child.tag for child in root[0]])\n        for item in root:\n            row = {}\n            for child in item:\n                row[child.tag] = child.text\n            df = df.append(row, ignore_index=True)\n        return df\n    except Exception as e:\n        raise ValueError(\"XML structure does not match expected format.\")\n```"}
{"task_id": "BigCodeBench/1004", "solution": "import urllib.request\nimport re\nfrom collections import Counter\nimport matplotlib.pyplot as plt\ndef task_func(url):\n    # Download the text file from the specified URL\n    response = urllib.request.urlopen(url)\n    text = response.read().decode('utf-8')\n    \n    # Process the text to count the frequency of each word\n    words = re.findall(r'\\b\\w+\\b', text.lower())\n    word_counts = Counter(words)\n    \n    # Plot a bar chart showing the ten most frequently occurring words\n    top_words = word_counts.most_common(10)\n    x = [word[0] for word in top_words]\n    y = [word[1] for word in top_words]\n    plt.bar(x, y)\n    plt.xlabel('Words')\n    plt.ylabel('Frequency')\n    plt.title('Top 10 Words')\n    plt.show()\n    \n    return word_counts, plt.gca()", "raw_solution": "import urllib.request\nimport re\nfrom collections import Counter\nimport matplotlib.pyplot as plt\n\ndef task_func(url):\n    # Download the text file from the specified URL\n    response = urllib.request.urlopen(url)\n    text = response.read().decode('utf-8')\n    \n    # Process the text to count the frequency of each word\n    words = re.findall(r'\\b\\w+\\b', text.lower())\n    word_counts = Counter(words)\n    \n    # Plot a bar chart showing the ten most frequently occurring words\n    top_words = word_counts.most_common(10)\n    x = [word[0] for word in top_words]\n    y = [word[1] for word in top_words]\n    plt.bar(x, y)\n    plt.xlabel('Words')\n    plt.ylabel('Frequency')\n    plt.title('Top 10 Words')\n    plt.show()\n    \n    return word_counts, plt.gca()\n```"}
{"task_id": "BigCodeBench/1005", "solution": "import urllib.request\nimport zipfile\nimport os\nimport urllib.error\ndef task_func(\n    url: str,\n    save_path: str = \"downloaded_file.zip\",\n    extract_path: str = \"extracted_files\",\n) -> str:\n    try:\n        urllib.request.urlretrieve(url, save_path)\n        with zipfile.ZipFile(save_path, 'r') as zip_ref:\n            zip_ref.extractall(extract_path)\n        return os.path.join(extract_path, os.listdir(extract_path)[0])\n    except urllib.error.URLError as e:\n        return f\"URL Error: {e.reason}\"", "raw_solution": "import urllib.request\nimport zipfile\nimport os\nimport urllib.error\n\ndef task_func(\n    url: str,\n    save_path: str = \"downloaded_file.zip\",\n    extract_path: str = \"extracted_files\",\n) -> str:\n    try:\n        urllib.request.urlretrieve(url, save_path)\n        with zipfile.ZipFile(save_path, 'r') as zip_ref:\n            zip_ref.extractall(extract_path)\n        return os.path.join(extract_path, os.listdir(extract_path)[0])\n    except urllib.error.URLError as e:\n        return f\"URL Error: {e.reason}\"\n```"}
{"task_id": "BigCodeBench/1006", "solution": "import os\nimport requests\nfrom zipfile import ZipFile, BadZipFile\ndef task_func(url, download_path=\"mnt/data/downloads/\"):\n    try:\n        # Download the file\n        response = requests.get(url)\n        response.raise_for_status()\n        file_path = os.path.join(download_path, os.path.basename(url))\n        with open(file_path, 'wb') as f:\n            f.write(response.content)\n        \n        # Extract the file\n        with ZipFile(file_path, 'r') as zip_ref:\n            zip_ref.extractall(download_path)\n        \n        # Return the path to the extracted contents\n        return os.path.join(download_path, os.path.basename(url))\n    except requests.exceptions.RequestException as e:\n        return f\"Error: Unable to download the file from the provided URL.\"\n    except BadZipFile as e:\n        return f\"Error: The downloaded file is not a valid ZIP file.\"\n    except Exception as e:\n        return f\"Error: {e}\"", "raw_solution": "import os\nimport requests\nfrom zipfile import ZipFile, BadZipFile\n\ndef task_func(url, download_path=\"mnt/data/downloads/\"):\n    try:\n        # Download the file\n        response = requests.get(url)\n        response.raise_for_status()\n        file_path = os.path.join(download_path, os.path.basename(url))\n        with open(file_path, 'wb') as f:\n            f.write(response.content)\n        \n        # Extract the file\n        with ZipFile(file_path, 'r') as zip_ref:\n            zip_ref.extractall(download_path)\n        \n        # Return the path to the extracted contents\n        return os.path.join(download_path, os.path.basename(url))\n    except requests.exceptions.RequestException as e:\n        return f\"Error: Unable to download the file from the provided URL.\"\n    except BadZipFile as e:\n        return f\"Error: The downloaded file is not a valid ZIP file.\"\n    except Exception as e:\n        return f\"Error: {e}\"\n```"}
{"task_id": "BigCodeBench/1007", "solution": "import requests\nimport pandas as pd\ndef task_func(url: str) -> pd.DataFrame:\n    try:\n        response = requests.get(url, timeout=5)\n        response.raise_for_status()\n        data = response.json()\n        return pd.DataFrame(data)\n    except requests.RequestException as e:\n        raise SystemError(f\"Network-related issue: {e}\")\n    except ValueError as e:\n        raise ValueError(f\"Invalid JSON format: {e}\")", "raw_solution": "import requests\nimport pandas as pd\n\ndef task_func(url: str) -> pd.DataFrame:\n    try:\n        response = requests.get(url, timeout=5)\n        response.raise_for_status()\n        data = response.json()\n        return pd.DataFrame(data)\n    except requests.RequestException as e:\n        raise SystemError(f\"Network-related issue: {e}\")\n    except ValueError as e:\n        raise ValueError(f\"Invalid JSON format: {e}\")\n```"}
{"task_id": "BigCodeBench/1008", "solution": "import requests\nfrom bs4 import BeautifulSoup\nimport pandas as pd\nfrom io import StringIO\ndef task_func(url, table_id):\n    try:\n        response = requests.get(url)\n        response.raise_for_status()\n    except requests.exceptions.HTTPError as e:\n        raise ValueError(\"HTTP request failed: \" + str(e))\n    soup = BeautifulSoup(response.content, 'html.parser')\n    table = soup.find('table', {'id': table_id})\n    if table is None:\n        raise ValueError(\"Table with the specified ID not found.\")\n    rows = table.find_all('tr')\n    if len(rows) == 0:\n        return pd.DataFrame()\n    headers = [th.text.strip() for th in rows[0].find_all('th')]\n    data = []\n    for row in rows[1:]:\n        row_data = [td.text.strip() for td in row.find_all('td')]\n        data.append(row_data)\n    df = pd.DataFrame(data, columns=headers)\n    return df", "raw_solution": "import requests\nfrom bs4 import BeautifulSoup\nimport pandas as pd\nfrom io import StringIO\n\ndef task_func(url, table_id):\n    try:\n        response = requests.get(url)\n        response.raise_for_status()\n    except requests.exceptions.HTTPError as e:\n        raise ValueError(\"HTTP request failed: \" + str(e))\n    soup = BeautifulSoup(response.content, 'html.parser')\n    table = soup.find('table', {'id': table_id})\n    if table is None:\n        raise ValueError(\"Table with the specified ID not found.\")\n    rows = table.find_all('tr')\n    if len(rows) == 0:\n        return pd.DataFrame()\n    headers = [th.text.strip() for th in rows[0].find_all('th')]\n    data = []\n    for row in rows[1:]:\n        row_data = [td.text.strip() for td in row.find_all('td')]\n        data.append(row_data)\n    df = pd.DataFrame(data, columns=headers)\n    return df\n```"}
{"task_id": "BigCodeBench/1009", "solution": "import xml.etree.ElementTree as ET\nimport csv\ndef task_func(xml_content, output_csv_path):\n    try:\n        root = ET.fromstring(xml_content)\n        with open(output_csv_path, 'w', newline='') as f:\n            writer = csv.writer(f)\n            for child in root:\n                writer.writerow([child.tag, child.text])\n    except ET.ParseError as e:\n        raise IOError(f\"Error parsing XML: {e}\")\n    except IOError as e:\n        raise IOError(f\"Error writing to CSV: {e}\")", "raw_solution": "import xml.etree.ElementTree as ET\nimport csv\n\ndef task_func(xml_content, output_csv_path):\n    try:\n        root = ET.fromstring(xml_content)\n        with open(output_csv_path, 'w', newline='') as f:\n            writer = csv.writer(f)\n            for child in root:\n                writer.writerow([child.tag, child.text])\n    except ET.ParseError as e:\n        raise IOError(f\"Error parsing XML: {e}\")\n    except IOError as e:\n        raise IOError(f\"Error writing to CSV: {e}\")\n```"}
{"task_id": "BigCodeBench/1010", "solution": "import requests\nfrom PIL import Image\nimport io\ndef task_func(url):\n    try:\n        response = requests.get(url, timeout=5)\n        response.raise_for_status()\n        image = Image.open(io.BytesIO(response.content))\n        return image\n    except requests.exceptions.RequestException as e:\n        raise ValueError(\"This exception is raised in the following scenarios: The URL is invalid or cannot be reached within the timeout period (5 seconds). The response from the server is not a successful HTTP status code (i.e., not in the range 200-299). The content fetched from the URL is not a valid image format that can be handled by PIL.\")", "raw_solution": "import requests\nfrom PIL import Image\nimport io\ndef task_func(url):\n    try:\n        response = requests.get(url, timeout=5)\n        response.raise_for_status()\n        image = Image.open(io.BytesIO(response.content))\n        return image\n    except requests.exceptions.RequestException as e:\n        raise ValueError(\"This exception is raised in the following scenarios: The URL is invalid or cannot be reached within the timeout period (5 seconds). The response from the server is not a successful HTTP status code (i.e., not in the range 200-299). The content fetched from the URL is not a valid image format that can be handled by PIL.\")\n```"}
{"task_id": "BigCodeBench/1011", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\ndef task_func(csv_file_path, col1_name=\"column1\", col2_name=\"column2\"):\n    df = pd.read_csv(csv_file_path)\n    grouped = df.groupby(col1_name)\n    means = grouped[col2_name].mean()\n    fig, ax = plt.subplots()\n    means.plot(kind='bar', ax=ax)\n    ax.set_title(f\"Mean of {col2_name} Grouped by {col1_name}\")\n    ax.set_xlabel(col1_name)\n    ax.set_ylabel(f\"Mean of {col2_name}\")\n    return ax", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\n\ndef task_func(csv_file_path, col1_name=\"column1\", col2_name=\"column2\"):\n    df = pd.read_csv(csv_file_path)\n    grouped = df.groupby(col1_name)\n    means = grouped[col2_name].mean()\n    fig, ax = plt.subplots()\n    means.plot(kind='bar', ax=ax)\n    ax.set_title(f\"Mean of {col2_name} Grouped by {col1_name}\")\n    ax.set_xlabel(col1_name)\n    ax.set_ylabel(f\"Mean of {col2_name}\")\n    return ax\n```"}
{"task_id": "BigCodeBench/1012", "solution": "import requests\nfrom pathlib import Path\nimport zipfile\nDOWNLOAD_DIR = Path(\"downloads\")\nZIP_DIR = Path(\"unzipped_files\")\ndef task_func(url, filename):\n    try:\n        # Download the zip file\n        response = requests.get(url)\n        response.raise_for_status()\n        # Save the zip file\n        with open(DOWNLOAD_DIR / filename, \"wb\") as f:\n            f.write(response.content)\n        # Extract the zip file\n        with zipfile.ZipFile(DOWNLOAD_DIR / filename, \"r\") as zip_ref:\n            zip_ref.extractall(ZIP_DIR)\n        # Return the status message and the list of filenames\n        return (\"Success\", list(ZIP_DIR.iterdir()))\n    except requests.exceptions.RequestException as e:\n        # Return the status message and an empty list if the download fails\n        return (\"Error\", [])\n    except zipfile.BadZipFile as e:\n        # Return the status message and an empty list if there is an issue with file handling or extraction\n        return (\"Error\", [])", "raw_solution": "import requests\nfrom pathlib import Path\nimport zipfile\n# Constants\nDOWNLOAD_DIR = Path(\"downloads\")\nZIP_DIR = Path(\"unzipped_files\")\ndef task_func(url, filename):\n    try:\n        # Download the zip file\n        response = requests.get(url)\n        response.raise_for_status()\n        # Save the zip file\n        with open(DOWNLOAD_DIR / filename, \"wb\") as f:\n            f.write(response.content)\n        # Extract the zip file\n        with zipfile.ZipFile(DOWNLOAD_DIR / filename, \"r\") as zip_ref:\n            zip_ref.extractall(ZIP_DIR)\n        # Return the status message and the list of filenames\n        return (\"Success\", list(ZIP_DIR.iterdir()))\n    except requests.exceptions.RequestException as e:\n        # Return the status message and an empty list if the download fails\n        return (\"Error\", [])\n    except zipfile.BadZipFile as e:\n        # Return the status message and an empty list if there is an issue with file handling or extraction\n        return (\"Error\", [])\n```"}
{"task_id": "BigCodeBench/1013", "solution": "import requests\nfrom urllib.parse import urljoin\nfrom bs4 import BeautifulSoup\nimport csv\ndef task_func(\n    url: str,\n    base_url: str = \"https://www.example.com\",\n    csv_file: str = \"scraped_data.csv\",\n) -> int:\n    # Send a GET request to the URL\n    response = requests.get(url)\n    # Parse the HTML content of the page\n    soup = BeautifulSoup(response.content, \"html.parser\")\n    # Find all hyperlinks on the page\n    links = soup.find_all(\"a\")\n    # Create a set to store unique absolute links\n    unique_links = set()\n    # Iterate over all links\n    for link in links:\n        # Get the href attribute of the link\n        href = link.get(\"href\")\n        # If the href attribute is not None, add it to the set of unique links\n        if href is not None:\n            # Join the base URL and the href attribute to create an absolute URL\n            absolute_url = urljoin(base_url, href)\n            # Add the absolute URL to the set of unique links\n            unique_links.add(absolute_url)\n    # Write the unique links to a CSV file\n    with open(csv_file, \"w\", newline=\"\") as file:\n        writer = csv.writer(file)\n        writer.writerow([\"URL\"])\n        for link in unique_links:\n            writer.writerow([link])\n    # Return the number of unique links scraped from the webpage\n    return len(unique_links)", "raw_solution": "import requests\nfrom urllib.parse import urljoin\nfrom bs4 import BeautifulSoup\nimport csv\ndef task_func(\n    url: str,\n    base_url: str = \"https://www.example.com\",\n    csv_file: str = \"scraped_data.csv\",\n) -> int:\n    # Send a GET request to the URL\n    response = requests.get(url)\n    # Parse the HTML content of the page\n    soup = BeautifulSoup(response.content, \"html.parser\")\n    # Find all hyperlinks on the page\n    links = soup.find_all(\"a\")\n    # Create a set to store unique absolute links\n    unique_links = set()\n    # Iterate over all links\n    for link in links:\n        # Get the href attribute of the link\n        href = link.get(\"href\")\n        # If the href attribute is not None, add it to the set of unique links\n        if href is not None:\n            # Join the base URL and the href attribute to create an absolute URL\n            absolute_url = urljoin(base_url, href)\n            # Add the absolute URL to the set of unique links\n            unique_links.add(absolute_url)\n    # Write the unique links to a CSV file\n    with open(csv_file, \"w\", newline=\"\") as file:\n        writer = csv.writer(file)\n        writer.writerow([\"URL\"])\n        for link in unique_links:\n            writer.writerow([link])\n    # Return the number of unique links scraped from the webpage\n    return len(unique_links)\n```"}
{"task_id": "BigCodeBench/1014", "solution": "import requests\nimport pandas as pd\ndef task_func(api_url):\n    if not isinstance(api_url, str):\n        raise TypeError('The api_url is not a string.')\n    try:\n        response = requests.get(api_url)\n        response.raise_for_status()\n    except requests.HTTPError as e:\n        raise e\n    data = response.json()\n    if not data:\n        return pd.DataFrame(), None\n    df = pd.DataFrame(data)\n    return df, df.plot()", "raw_solution": "import requests\nimport pandas as pd\n\ndef task_func(api_url):\n    if not isinstance(api_url, str):\n        raise TypeError('The api_url is not a string.')\n    try:\n        response = requests.get(api_url)\n        response.raise_for_status()\n    except requests.HTTPError as e:\n        raise e\n    data = response.json()\n    if not data:\n        return pd.DataFrame(), None\n    df = pd.DataFrame(data)\n    return df, df.plot()\n```"}
{"task_id": "BigCodeBench/1015", "solution": "import requests\nfrom lxml import html\nimport pandas as pd\nimport sqlite3\ndef task_func(webpage_url: str, database_name: str = \"my_database.db\") -> int:\n    try:\n        response = requests.get(webpage_url)\n        response.raise_for_status()\n    except requests.RequestException as e:\n        print(f\"Error: {e}\")\n        return 0\n\n    tree = html.fromstring(response.text)\n    table = tree.xpath('//table[@id=\"my_table\"]')[0]\n    rows = table.xpath('.//tr')\n    if len(rows) == 0:\n        print(\"Error: No table found\")\n        return 0\n\n    df = pd.read_html(str(table))[0]\n    conn = sqlite3.connect(database_name)\n    df.to_sql(\"my_table\", conn, if_exists=\"replace\", index=False)\n    conn.close()\n    return len(df)", "raw_solution": "import requests\nfrom lxml import html\nimport pandas as pd\nimport sqlite3\n\ndef task_func(webpage_url: str, database_name: str = \"my_database.db\") -> int:\n    try:\n        response = requests.get(webpage_url)\n        response.raise_for_status()\n    except requests.RequestException as e:\n        print(f\"Error: {e}\")\n        return 0\n\n    tree = html.fromstring(response.text)\n    table = tree.xpath('//table[@id=\"my_table\"]')[0]\n    rows = table.xpath('.//tr')\n    if len(rows) == 0:\n        print(\"Error: No table found\")\n        return 0\n\n    df = pd.read_html(str(table))[0]\n    conn = sqlite3.connect(database_name)\n    df.to_sql(\"my_table\", conn, if_exists=\"replace\", index=False)\n    conn.close()\n    return len(df)\n```"}
{"task_id": "BigCodeBench/1016", "solution": "import requests\nfrom PIL import Image\nimport numpy as np\nimport matplotlib.pyplot as plt\ndef task_func(url: str) -> \"matplotlib.axes._axes.Axes\":\n    try:\n        response = requests.get(url)\n        response.raise_for_status()\n        img = Image.open(BytesIO(response.content))\n        img = img.convert('L')\n        img_array = np.array(img)\n        fig, ax = plt.subplots()\n        ax.hist(img_array.ravel(), bins=256)\n        return ax\n    except ValueError as e:\n        raise ValueError(f\"Invalid URL or error downloading image: {e}\")\n    except IOError as e:\n        raise IOError(f\"Error in opening or processing image: {e}\")", "raw_solution": "import requests\nfrom PIL import Image\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef task_func(url: str) -> \"matplotlib.axes._axes.Axes\":\n    try:\n        response = requests.get(url)\n        response.raise_for_status()\n        img = Image.open(BytesIO(response.content))\n        img = img.convert('L')\n        img_array = np.array(img)\n        fig, ax = plt.subplots()\n        ax.hist(img_array.ravel(), bins=256)\n        return ax\n    except ValueError as e:\n        raise ValueError(f\"Invalid URL or error downloading image: {e}\")\n    except IOError as e:\n        raise IOError(f\"Error in opening or processing image: {e}\")\n```"}
{"task_id": "BigCodeBench/1017", "solution": "import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import classification_report\ndef task_func(csv_file_path, target_column=\"target\", test_size=0.2, n_estimators=100):\n    try:\n        df = pd.read_csv(csv_file_path)\n        if target_column not in df.columns:\n            raise ValueError(\"The specified target_column is not found in the CSV file.\")\n        X = df.drop(target_column, axis=1)\n        y = df[target_column]\n        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42)\n        clf = RandomForestClassifier(n_estimators=n_estimators)\n        clf.fit(X_train, y_train)\n        y_pred = clf.predict(X_test)\n        report = classification_report(y_test, y_pred)\n        return report\n    except Exception as e:\n        return str(e)", "raw_solution": "import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import classification_report\n\ndef task_func(csv_file_path, target_column=\"target\", test_size=0.2, n_estimators=100):\n    try:\n        df = pd.read_csv(csv_file_path)\n        if target_column not in df.columns:\n            raise ValueError(\"The specified target_column is not found in the CSV file.\")\n        X = df.drop(target_column, axis=1)\n        y = df[target_column]\n        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42)\n        clf = RandomForestClassifier(n_estimators=n_estimators)\n        clf.fit(X_train, y_train)\n        y_pred = clf.predict(X_test)\n        report = classification_report(y_test, y_pred)\n        return report\n    except Exception as e:\n        return str(e)\n```"}
{"task_id": "BigCodeBench/1018", "solution": "from bs4 import BeautifulSoup\nimport requests\nURL = \"http://example.com\"\ndef task_func(url=URL, from_encoding=\"cp1251\", use_lxml=False):\n    try:\n        response = requests.get(url)\n        if response.status_code == 200:\n            if use_lxml:\n                soup = BeautifulSoup(response.content, 'lxml', from_encoding=from_encoding)\n            else:\n                soup = BeautifulSoup(response.content, from_encoding=from_encoding)\n            return soup\n        else:\n            return None\n    except requests.exceptions.RequestException as e:\n        return None", "raw_solution": "from bs4 import BeautifulSoup\nimport requests\n# Constants\nURL = \"http://example.com\"\ndef task_func(url=URL, from_encoding=\"cp1251\", use_lxml=False):\n    try:\n        response = requests.get(url)\n        if response.status_code == 200:\n            if use_lxml:\n                soup = BeautifulSoup(response.content, 'lxml', from_encoding=from_encoding)\n            else:\n                soup = BeautifulSoup(response.content, from_encoding=from_encoding)\n            return soup\n        else:\n            return None\n    except requests.exceptions.RequestException as e:\n        return None\n```"}
{"task_id": "BigCodeBench/1019", "solution": "from PIL import Image\nimport codecs\nimport pytesseract\nIMAGE_PATH = \"image.png\"\ndef task_func(filename=IMAGE_PATH, from_encoding=\"cp1251\", to_encoding=\"utf8\"):\n    try:\n        # Open the image file\n        img = Image.open(filename)\n        # Extract text using OCR\n        text = pytesseract.image_to_string(img)\n        # Convert the text encoding\n        try:\n            text = text.decode(from_encoding)\n            text = text.encode(to_encoding)\n        except (ValueError, LookupError):\n            pass\n        return text.decode(to_encoding)\n    except Exception as e:\n        return \"\"", "raw_solution": "from PIL import Image\nimport codecs\nimport pytesseract\nIMAGE_PATH = \"image.png\"\n\ndef task_func(filename=IMAGE_PATH, from_encoding=\"cp1251\", to_encoding=\"utf8\"):\n    try:\n        # Open the image file\n        img = Image.open(filename)\n        # Extract text using OCR\n        text = pytesseract.image_to_string(img)\n        # Convert the text encoding\n        try:\n            text = text.decode(from_encoding)\n            text = text.encode(to_encoding)\n        except (ValueError, LookupError):\n            pass\n        return text.decode(to_encoding)\n    except Exception as e:\n        return \"\"\n```"}
{"task_id": "BigCodeBench/1020", "solution": "import json\nimport requests\nimport chardet\nAPI_URL = \"http://api.example.com/data\"\ndef task_func(url=API_URL, from_encoding=None, to_encoding=\"utf8\"):\n    try:\n        # Initiate an HTTP GET request to the specified URL with a 5-second timeout\n        response = requests.get(url, timeout=5)\n        # Retrieve the response content in raw bytes\n        raw_content = response.content\n        # Detect the encoding of the response content\n        if from_encoding is None:\n            encoding = chardet.detect(raw_content)['encoding']\n        else:\n            encoding = from_encoding\n        # Decode the raw content to a string using the detected encoding\n        decoded_content = raw_content.decode(encoding)\n        # Re-encode the string to the specified encoding\n        reencoded_content = decoded_content.encode(to_encoding)\n        # Parse the re-encoded content as JSON\n        data = json.loads(reencoded_content)\n        return data\n    except requests.exceptions.Timeout:\n        return None\n    except requests.exceptions.RequestException as e:\n        return None\n    except ValueError as e:\n        return {}\n    except json.JSONDecodeError as e:\n        return {}", "raw_solution": "import json\nimport requests\nimport chardet\n# Constants\nAPI_URL = \"http://api.example.com/data\"\ndef task_func(url=API_URL, from_encoding=None, to_encoding=\"utf8\"):\n    try:\n        # Initiate an HTTP GET request to the specified URL with a 5-second timeout\n        response = requests.get(url, timeout=5)\n        # Retrieve the response content in raw bytes\n        raw_content = response.content\n        # Detect the encoding of the response content\n        if from_encoding is None:\n            encoding = chardet.detect(raw_content)['encoding']\n        else:\n            encoding = from_encoding\n        # Decode the raw content to a string using the detected encoding\n        decoded_content = raw_content.decode(encoding)\n        # Re-encode the string to the specified encoding\n        reencoded_content = decoded_content.encode(to_encoding)\n        # Parse the re-encoded content as JSON\n        data = json.loads(reencoded_content)\n        return data\n    except requests.exceptions.Timeout:\n        return None\n    except requests.exceptions.RequestException as e:\n        return None\n    except ValueError as e:\n        return {}\n    except json.JSONDecodeError as e:\n        return {}\n```"}
{"task_id": "BigCodeBench/1021", "solution": "import binascii\nimport hashlib\ndef task_func(input_string, verify_hash=None):\n    if not isinstance(input_string, str):\n        raise TypeError(\"Input must be a string\")\n    if verify_hash is not None and not isinstance(verify_hash, str):\n        raise TypeError(\"verify_hash must be a string or None\")\n    sha256 = hashlib.sha256(input_string.encode('utf-8')).hexdigest()\n    if verify_hash is not None and sha256 != verify_hash:\n        return None\n    return sha256", "raw_solution": "import binascii\nimport hashlib\ndef task_func(input_string, verify_hash=None):\n    if not isinstance(input_string, str):\n        raise TypeError(\"Input must be a string\")\n    if verify_hash is not None and not isinstance(verify_hash, str):\n        raise TypeError(\"verify_hash must be a string or None\")\n    sha256 = hashlib.sha256(input_string.encode('utf-8')).hexdigest()\n    if verify_hash is not None and sha256 != verify_hash:\n        return None\n    return sha256\n```"}
{"task_id": "BigCodeBench/1022", "solution": "import pandas as pd\nimport os\nfrom datetime import datetime\nfrom pandas.errors import EmptyDataError\ndef task_func(csv_file_path, column_name, date_format=\"%Y-%m-%d\"):\n    if not os.path.exists(csv_file_path):\n        raise FileNotFoundError(\"File not found at the given path.\")\n    if column_name not in pd.read_csv(csv_file_path).columns:\n        raise ValueError(\"The specified column is not present in the CSV file.\")\n    try:\n        df = pd.read_csv(csv_file_path)\n        df[column_name] = pd.to_datetime(df[column_name], format=date_format)\n        current_date = datetime.now().date()\n        df = df[df[column_name] >= current_date]\n        df = df.sort_values(by=column_name)\n        return df\n    except EmptyDataError:\n        return pd.DataFrame()", "raw_solution": "import pandas as pd\nimport os\nfrom datetime import datetime\nfrom pandas.errors import EmptyDataError\n\ndef task_func(csv_file_path, column_name, date_format=\"%Y-%m-%d\"):\n    if not os.path.exists(csv_file_path):\n        raise FileNotFoundError(\"File not found at the given path.\")\n    if column_name not in pd.read_csv(csv_file_path).columns:\n        raise ValueError(\"The specified column is not present in the CSV file.\")\n    try:\n        df = pd.read_csv(csv_file_path)\n        df[column_name] = pd.to_datetime(df[column_name], format=date_format)\n        current_date = datetime.now().date()\n        df = df[df[column_name] >= current_date]\n        df = df.sort_values(by=column_name)\n        return df\n    except EmptyDataError:\n        return pd.DataFrame()\n```"}
{"task_id": "BigCodeBench/1023", "solution": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\ndef task_func(dataframe):\n    if dataframe.empty:\n        raise ValueError(\"Input DataFrame is empty.\")\n    if not dataframe.select_dtypes(include=[np.number]).columns.tolist():\n        raise TypeError(\"DataFrame has non-numeric columns.\")\n    if len(dataframe.columns) < 2:\n        raise ValueError(\"DataFrame has fewer than two columns.\")\n    corr_matrix = dataframe.corr()\n    max_corr = corr_matrix.abs().max().max()\n    max_corr_cols = corr_matrix.abs().idxmax().tolist()\n    ax = plt.scatter(max_corr_cols[0], max_corr_cols[1], color='red')\n    ax.set_xlabel(max_corr_cols[0])\n    ax.set_ylabel(max_corr_cols[1])\n    plt.show()\n    return ax", "raw_solution": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef task_func(dataframe):\n    if dataframe.empty:\n        raise ValueError(\"Input DataFrame is empty.\")\n    if not dataframe.select_dtypes(include=[np.number]).columns.tolist():\n        raise TypeError(\"DataFrame has non-numeric columns.\")\n    if len(dataframe.columns) < 2:\n        raise ValueError(\"DataFrame has fewer than two columns.\")\n    corr_matrix = dataframe.corr()\n    max_corr = corr_matrix.abs().max().max()\n    max_corr_cols = corr_matrix.abs().idxmax().tolist()\n    ax = plt.scatter(max_corr_cols[0], max_corr_cols[1], color='red')\n    ax.set_xlabel(max_corr_cols[0])\n    ax.set_ylabel(max_corr_cols[1])\n    plt.show()\n    return ax\n```"}
{"task_id": "BigCodeBench/1024", "solution": "import numpy as np\nimport pandas as pd\nimport seaborn as sns\nPLOT_TITLE = \"Value Distribution\"\ndef task_func(data_dict):\n    # Create a pandas DataFrame from the input dictionary\n    df = pd.DataFrame(data_dict)\n    # Remove None values\n    df = df.dropna()\n    # Check if the DataFrame is empty or if all values are identical\n    if df.empty or df.nunique() == 1:\n        return None\n    # Calculate the minimum and maximum values in the DataFrame\n    min_val = df.min().min()\n    max_val = df.max().max()\n    # Dynamically set the number of bins for the histogram based on the number of data points\n    num_bins = min(11, int((max_val - min_val) / len(df)))\n    # Create evenly spaced bin edges between the minimum and maximum values\n    bin_edges = np.linspace(min_val, max_val, num_bins + 1)\n    # Generate a histogram of the data values using seaborn\n    sns.histplot(df, bins=bin_edges, kde=False, color='blue', alpha=0.7)\n    # Set the plot title to the predefined constant\n    plt.title(PLOT_TITLE)\n    # Return the histogram plot object\n    return plt.gca()", "raw_solution": "import numpy as np\nimport pandas as pd\nimport seaborn as sns\n# Constants\nPLOT_TITLE = \"Value Distribution\"\ndef task_func(data_dict):\n    # Create a pandas DataFrame from the input dictionary\n    df = pd.DataFrame(data_dict)\n    # Remove None values\n    df = df.dropna()\n    # Check if the DataFrame is empty or if all values are identical\n    if df.empty or df.nunique() == 1:\n        return None\n    # Calculate the minimum and maximum values in the DataFrame\n    min_val = df.min().min()\n    max_val = df.max().max()\n    # Dynamically set the number of bins for the histogram based on the number of data points\n    num_bins = min(11, int((max_val - min_val) / len(df)))\n    # Create evenly spaced bin edges between the minimum and maximum values\n    bin_edges = np.linspace(min_val, max_val, num_bins + 1)\n    # Generate a histogram of the data values using seaborn\n    sns.histplot(df, bins=bin_edges, kde=False, color='blue', alpha=0.7)\n    # Set the plot title to the predefined constant\n    plt.title(PLOT_TITLE)\n    # Return the histogram plot object\n    return plt.gca()\n```"}
{"task_id": "BigCodeBench/1025", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import MinMaxScaler\nPLOT_TITLE = \"Scaled Values\"\ndef task_func(data_dict):\n    # Create a pandas DataFrame from the input dictionary\n    df = pd.DataFrame(data_dict)\n    # Create a MinMaxScaler object\n    scaler = MinMaxScaler()\n    # Fit and transform the DataFrame\n    scaled_df = scaler.fit_transform(df)\n    # Create a matplotlib Axes object\n    ax = plt.axes()\n    # Plot the scaled data\n    ax.plot(scaled_df)\n    # Set the plot title\n    ax.set_title(PLOT_TITLE)\n    # Return the scaled DataFrame and the Axes object\n    return scaled_df, ax", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import MinMaxScaler\n# Constants\nPLOT_TITLE = \"Scaled Values\"\ndef task_func(data_dict):\n    # Create a pandas DataFrame from the input dictionary\n    df = pd.DataFrame(data_dict)\n    # Create a MinMaxScaler object\n    scaler = MinMaxScaler()\n    # Fit and transform the DataFrame\n    scaled_df = scaler.fit_transform(df)\n    # Create a matplotlib Axes object\n    ax = plt.axes()\n    # Plot the scaled data\n    ax.plot(scaled_df)\n    # Set the plot title\n    ax.set_title(PLOT_TITLE)\n    # Return the scaled DataFrame and the Axes object\n    return scaled_df, ax\n```"}
{"task_id": "BigCodeBench/1026", "solution": "import numpy as np\nfrom scipy.stats import ttest_ind\nimport matplotlib.pyplot as plt\ndef task_func(kwargs):\n    group1 = kwargs['group1']\n    group2 = kwargs['group2']\n    alpha = kwargs.get('alpha', 0.05)\n    nan_policy = kwargs.get('nan_policy', 'omit')\n    threshold = kwargs.get('threshold', 1e-8)\n\n    # Remove NaN values\n    group1 = group1[~np.isnan(group1)]\n    group2 = group2[~np.isnan(group2)]\n\n    # Check for sufficient non-NaN data points and adequate variance in each group\n    if len(group1) < 2 or len(group2) < 2 or np.var(group1) < threshold or np.var(group2) < threshold:\n        raise ValueError('Insufficient non-NaN data points or inadequate variance in one or both groups')\n\n    # Perform t-test\n    t_stat, p_value = ttest_ind(group1, group2, nan_policy=nan_policy)\n\n    # Generate descriptive statistics for each group\n    group1_stats = {'mean': np.mean(group1), 'std': np.std(group1)}\n    group2_stats = {'mean': np.mean(group2), 'std': np.std(group2)}\n\n    # Generate boxplot and histograms for data visualization\n    fig, (ax_boxplot, ax_histogram) = plt.subplots(1, 2, figsize=(10, 5))\n    ax_boxplot.boxplot([group1, group2], labels=['group1', 'group2'])\n    ax_histogram.hist([group1, group2], bins=30, alpha=0.5, label=['group1', 'group2'])\n    ax_boxplot.set_title('Boxplot of group1 and group2')\n    ax_histogram.set_title('Histogram of group1 and group2')\n    ax_boxplot.legend()\n    ax_histogram.legend()\n\n    # Return the results\n    return {\n        'significant': p_value < alpha,\n        'group1_stats': group1_stats,\n        'group2_stats': group2_stats,\n        'ax_boxplot': ax_boxplot,\n        'ax_histogram': ax_histogram\n    }", "raw_solution": "import numpy as np\nfrom scipy.stats import ttest_ind\nimport matplotlib.pyplot as plt\n\ndef task_func(kwargs):\n    group1 = kwargs['group1']\n    group2 = kwargs['group2']\n    alpha = kwargs.get('alpha', 0.05)\n    nan_policy = kwargs.get('nan_policy', 'omit')\n    threshold = kwargs.get('threshold', 1e-8)\n\n    # Remove NaN values\n    group1 = group1[~np.isnan(group1)]\n    group2 = group2[~np.isnan(group2)]\n\n    # Check for sufficient non-NaN data points and adequate variance in each group\n    if len(group1) < 2 or len(group2) < 2 or np.var(group1) < threshold or np.var(group2) < threshold:\n        raise ValueError('Insufficient non-NaN data points or inadequate variance in one or both groups')\n\n    # Perform t-test\n    t_stat, p_value = ttest_ind(group1, group2, nan_policy=nan_policy)\n\n    # Generate descriptive statistics for each group\n    group1_stats = {'mean': np.mean(group1), 'std': np.std(group1)}\n    group2_stats = {'mean': np.mean(group2), 'std': np.std(group2)}\n\n    # Generate boxplot and histograms for data visualization\n    fig, (ax_boxplot, ax_histogram) = plt.subplots(1, 2, figsize=(10, 5))\n    ax_boxplot.boxplot([group1, group2], labels=['group1', 'group2'])\n    ax_histogram.hist([group1, group2], bins=30, alpha=0.5, label=['group1', 'group2'])\n    ax_boxplot.set_title('Boxplot of group1 and group2')\n    ax_histogram.set_title('Histogram of group1 and group2')\n    ax_boxplot.legend()\n    ax_histogram.legend()\n\n    # Return the results\n    return {\n        'significant': p_value < alpha,\n        'group1_stats': group1_stats,\n        'group2_stats': group2_stats,\n        'ax_boxplot': ax_boxplot,\n        'ax_histogram': ax_histogram\n    }\n```"}
{"task_id": "BigCodeBench/1027", "solution": "import binascii\nimport urllib.parse\ndef task_func(url):\n    try:\n        query = urllib.parse.urlparse(url).query\n        if 'q' not in query:\n            return None\n        hex_str = query.split('q=')[1]\n        if not hex_str:\n            return None\n        try:\n            decoded_str = binascii.unhexlify(hex_str).decode('utf-8')\n            return decoded_str\n        except binascii.Error:\n            return None\n    except Exception as e:\n        return None", "raw_solution": "import binascii\nimport urllib.parse\n\ndef task_func(url):\n    try:\n        query = urllib.parse.urlparse(url).query\n        if 'q' not in query:\n            return None\n        hex_str = query.split('q=')[1]\n        if not hex_str:\n            return None\n        try:\n            decoded_str = binascii.unhexlify(hex_str).decode('utf-8')\n            return decoded_str\n        except binascii.Error:\n            return None\n    except Exception as e:\n        return None\n```"}
{"task_id": "BigCodeBench/1028", "solution": "import subprocess\nimport time\nimport json\nimport platform\nLOGFILE_PATH = \"logfile.log\"\ndef task_func(interval, duration):\n    if interval <= 0 or duration <= 0:\n        raise ValueError(\"Interval and duration must be greater than zero\")\n    if platform.system() == \"Windows\":\n        command = \"wmic cpu get loadpercentage /value\"\n    elif platform.system() == \"Linux\":\n        command = \"top -bn 1 | grep Cpu | awk '{print $2}'\"\n    else:\n        raise ValueError(\"Unsupported operating system\")\n    with open(LOGFILE_PATH, \"w\") as f:\n        while time.time() < duration:\n            try:\n                output = subprocess.check_output(command, shell=True)\n                f.write(json.dumps({\"timestamp\": time.time(), \"cpu_usage\": float(output.strip())}) + \"\\n\")\n            except subprocess.CalledProcessError as e:\n                f.write(json.dumps({\"timestamp\": time.time(), \"error\": str(e)}) + \"\\n\")\n            time.sleep(interval)\n    return LOGFILE_PATH", "raw_solution": "import subprocess\nimport time\nimport json\nimport platform\nLOGFILE_PATH = \"logfile.log\"\n\ndef task_func(interval, duration):\n    if interval <= 0 or duration <= 0:\n        raise ValueError(\"Interval and duration must be greater than zero\")\n    if platform.system() == \"Windows\":\n        command = \"wmic cpu get loadpercentage /value\"\n    elif platform.system() == \"Linux\":\n        command = \"top -bn 1 | grep Cpu | awk '{print $2}'\"\n    else:\n        raise ValueError(\"Unsupported operating system\")\n    with open(LOGFILE_PATH, \"w\") as f:\n        while time.time() < duration:\n            try:\n                output = subprocess.check_output(command, shell=True)\n                f.write(json.dumps({\"timestamp\": time.time(), \"cpu_usage\": float(output.strip())}) + \"\\n\")\n            except subprocess.CalledProcessError as e:\n                f.write(json.dumps({\"timestamp\": time.time(), \"error\": str(e)}) + \"\\n\")\n            time.sleep(interval)\n    return LOGFILE_PATH\n```"}
{"task_id": "BigCodeBench/1029", "solution": "import pandas as pd\nimport numpy as np\ndef task_func(rows=100, columns=3):\n    alphabet_list = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n    df = pd.DataFrame(np.random.choice(alphabet_list, size=(rows, columns)))\n    return df", "raw_solution": "import pandas as pd\nimport numpy as np\n\ndef task_func(rows=100, columns=3):\n    alphabet_list = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n    df = pd.DataFrame(np.random.choice(alphabet_list, size=(rows, columns)))\n    return df\n```"}
{"task_id": "BigCodeBench/1030", "solution": "import itertools\nimport string\nimport pandas as pd\ndef task_func():\n    alphabet = string.ascii_lowercase\n    combinations = list(itertools.product(alphabet, repeat=3))\n    df = pd.DataFrame(combinations, columns=['a', 'b', 'c'])\n    return df", "raw_solution": "import itertools\nimport string\nimport pandas as pd\n\ndef task_func():\n    alphabet = string.ascii_lowercase\n    combinations = list(itertools.product(alphabet, repeat=3))\n    df = pd.DataFrame(combinations, columns=['a', 'b', 'c'])\n    return df\n```"}
{"task_id": "BigCodeBench/1031", "solution": "import random\nimport string\nimport pandas as pd\ndef task_func(n_rows=1000):\n    if n_rows <= 0:\n        raise ValueError(\"If n_rows is less than or equal to 0.\")\n    letters = string.ascii_lowercase\n    strings = [''.join(random.choice(letters) for _ in range(3)) for _ in range(n_rows)]\n    df = pd.DataFrame(strings, columns=['string'])\n    top_30 = df['string'].value_counts().head(30)\n    ax = top_30.plot(kind='bar')\n    return ax", "raw_solution": "import random\nimport string\nimport pandas as pd\ndef task_func(n_rows=1000):\n    if n_rows <= 0:\n        raise ValueError(\"If n_rows is less than or equal to 0.\")\n    letters = string.ascii_lowercase\n    strings = [''.join(random.choice(letters) for _ in range(3)) for _ in range(n_rows)]\n    df = pd.DataFrame(strings, columns=['string'])\n    top_30 = df['string'].value_counts().head(30)\n    ax = top_30.plot(kind='bar')\n    return ax\n```"}
{"task_id": "BigCodeBench/1032", "solution": "import matplotlib.pyplot as plt\nimport random\nimport string\nimport pandas as pd\nimport seaborn as sns\nLETTERS = list(string.ascii_lowercase)\ndef task_func(rows=1000, string_length=3):\n    if rows == 0:\n        print(\"No data to generate heatmap.\")\n        return None\n    strings = []\n    for _ in range(rows):\n        strings.append(''.join(random.choice(LETTERS) for _ in range(string_length)))\n    df = pd.DataFrame(strings, columns=['string'])\n    df = pd.get_dummies(df['string'], prefix='letter')\n    df = df.sum(axis=0)\n    sns.heatmap(df, annot=True, cmap='coolwarm')\n    plt.show()", "raw_solution": "import matplotlib.pyplot as plt\nimport random\nimport string\nimport pandas as pd\nimport seaborn as sns\n# Constants\nLETTERS = list(string.ascii_lowercase)\n\ndef task_func(rows=1000, string_length=3):\n    if rows == 0:\n        print(\"No data to generate heatmap.\")\n        return None\n    strings = []\n    for _ in range(rows):\n        strings.append(''.join(random.choice(LETTERS) for _ in range(string_length)))\n    df = pd.DataFrame(strings, columns=['string'])\n    df = pd.get_dummies(df['string'], prefix='letter')\n    df = df.sum(axis=0)\n    sns.heatmap(df, annot=True, cmap='coolwarm')\n    plt.show()\n```"}
{"task_id": "BigCodeBench/1033", "solution": "import itertools\nimport string\nimport pandas as pd\ndef task_func():\n    # Generate all possible 3-letter combinations of the alphabet\n    combinations = list(itertools.product(string.ascii_lowercase, repeat=3))\n    \n    # Create a DataFrame from these combinations\n    df = pd.DataFrame(combinations, columns=['first', 'second', 'third'])\n    \n    # Plot a histogram to show the frequency of each letter appearing as the first letter in these combinations\n    df['first'].value_counts().plot(kind='bar')\n    \n    return (combinations, df['first'].value_counts().plot(kind='bar'))", "raw_solution": "import itertools\nimport string\nimport pandas as pd\n\ndef task_func():\n    # Generate all possible 3-letter combinations of the alphabet\n    combinations = list(itertools.product(string.ascii_lowercase, repeat=3))\n    \n    # Create a DataFrame from these combinations\n    df = pd.DataFrame(combinations, columns=['first', 'second', 'third'])\n    \n    # Plot a histogram to show the frequency of each letter appearing as the first letter in these combinations\n    df['first'].value_counts().plot(kind='bar')\n    \n    return (combinations, df['first'].value_counts().plot(kind='bar'))\n```"}
{"task_id": "BigCodeBench/1034", "solution": "import pandas as pd\nimport numpy as np\ndef task_func(s1, s2):\n    s1 = pd.Series(s1)\n    s2 = pd.Series(s2)\n    threshold = 200\n    common_categories = s1[s1 > threshold].index.intersection(s2[s2 > threshold].index)\n    if len(common_categories) == 0:\n        return None, 0.0\n    bar_plot = s1[common_categories].plot(kind='bar')\n    bar_plot.set_title('Sales Data Comparison')\n    bar_plot.set_xlabel('Categories')\n    bar_plot.set_ylabel('Sales')\n    return bar_plot, np.linalg.norm(s1[common_categories] - s2[common_categories])", "raw_solution": "import pandas as pd\nimport numpy as np\nCATEGORIES = [\"Electronics\", \"Clothing\", \"Home Decor\", \"Automotive\", \"Books\"]\ndef task_func(s1, s2):\n    s1 = pd.Series(s1)\n    s2 = pd.Series(s2)\n    threshold = 200\n    common_categories = s1[s1 > threshold].index.intersection(s2[s2 > threshold].index)\n    if len(common_categories) == 0:\n        return None, 0.0\n    bar_plot = s1[common_categories].plot(kind='bar')\n    bar_plot.set_title('Sales Data Comparison')\n    bar_plot.set_xlabel('Categories')\n    bar_plot.set_ylabel('Sales')\n    return bar_plot, np.linalg.norm(s1[common_categories] - s2[common_categories])\n```"}
{"task_id": "BigCodeBench/1035", "solution": "import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix\nimport numpy as np\nimport matplotlib.pyplot as plt\ndef task_func(feature: pd.Series, target: pd.Series) -> (np.ndarray, plt.Axes):\n    # Split the data into training and testing sets\n    X_train, X_test, y_train, y_test = train_test_split(feature, target, test_size=0.2, random_state=42)\n    \n    # Train the logistic regression model\n    model = LogisticRegression()\n    model.fit(X_train, y_train)\n    \n    # Predict the target for the test set\n    y_pred = model.predict(X_test)\n    \n    # Plot the confusion matrix\n    cm = confusion_matrix(y_test, y_pred)\n    fig, ax = plt.subplots()\n    ax.imshow(cm, cmap='Blues')\n    ax.set_xticks(np.arange(len(cm)))\n    ax.set_yticks(np.arange(len(cm)))\n    ax.set_xticklabels(feature.unique())\n    ax.set_yticklabels(target.unique())\n    ax.set_xlabel('Predicted')\n    ax.set_ylabel('Actual')\n    ax.set_title('Confusion Matrix')\n    for i in range(len(cm)):\n        for j in range(len(cm)):\n            ax.text(j, i, cm[i, j], ha='center', va='center', color='white' if cm[i, j] > cm.max() / 2 else 'black')\n    plt.show()\n    \n    return cm, ax", "raw_solution": "import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef task_func(feature: pd.Series, target: pd.Series) -> (np.ndarray, plt.Axes):\n    # Split the data into training and testing sets\n    X_train, X_test, y_train, y_test = train_test_split(feature, target, test_size=0.2, random_state=42)\n    \n    # Train the logistic regression model\n    model = LogisticRegression()\n    model.fit(X_train, y_train)\n    \n    # Predict the target for the test set\n    y_pred = model.predict(X_test)\n    \n    # Plot the confusion matrix\n    cm = confusion_matrix(y_test, y_pred)\n    fig, ax = plt.subplots()\n    ax.imshow(cm, cmap='Blues')\n    ax.set_xticks(np.arange(len(cm)))\n    ax.set_yticks(np.arange(len(cm)))\n    ax.set_xticklabels(feature.unique())\n    ax.set_yticklabels(target.unique())\n    ax.set_xlabel('Predicted')\n    ax.set_ylabel('Actual')\n    ax.set_title('Confusion Matrix')\n    for i in range(len(cm)):\n        for j in range(len(cm)):\n            ax.text(j, i, cm[i, j], ha='center', va='center', color='white' if cm[i, j] > cm.max() / 2 else 'black')\n    plt.show()\n    \n    return cm, ax\n```"}
{"task_id": "BigCodeBench/1036", "solution": "import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\ndef task_func(s1, s2):\n    sns.set(style=\"whitegrid\")\n    ax = sns.swarmplot(x=s1, y=s2)\n    intersection_count = len(s1[s1.isin(s2)])\n    ax.plot(s1[s1.isin(s2)], s2[s1.isin(s2)], 'r--')\n    plt.show()\n    return ax, intersection_count", "raw_solution": "import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\ndef task_func(s1, s2):\n    sns.set(style=\"whitegrid\")\n    ax = sns.swarmplot(x=s1, y=s2)\n    intersection_count = len(s1[s1.isin(s2)])\n    ax.plot(s1[s1.isin(s2)], s2[s1.isin(s2)], 'r--')\n    plt.show()\n    return ax, intersection_count\n```"}
{"task_id": "BigCodeBench/1037", "solution": "import pandas as pd\nfrom sklearn.cluster import KMeans\nimport matplotlib.pyplot as plt\ndef task_func(s1, s2, n_clusters=3):\n    if not isinstance(s1, pd.Series) or not isinstance(s2, pd.Series):\n        raise ValueError(\"s1 and s2 must be pandas Series\")\n    if len(s1) != len(s2):\n        raise ValueError(\"s1 and s2 must have the same length\")\n    combined = pd.concat([s1, s2])\n    kmeans = KMeans(n_clusters=n_clusters)\n    labels = kmeans.fit_predict(combined)\n    plt.scatter(combined, labels, c=kmeans.labels_)\n    plt.title(\"K-Means Clustering\")\n    plt.legend()\n    return labels, plt.gca()", "raw_solution": "import pandas as pd\nfrom sklearn.cluster import KMeans\nimport matplotlib.pyplot as plt\n\ndef task_func(s1, s2, n_clusters=3):\n    if not isinstance(s1, pd.Series) or not isinstance(s2, pd.Series):\n        raise ValueError(\"s1 and s2 must be pandas Series\")\n    if len(s1) != len(s2):\n        raise ValueError(\"s1 and s2 must have the same length\")\n    combined = pd.concat([s1, s2])\n    kmeans = KMeans(n_clusters=n_clusters)\n    labels = kmeans.fit_predict(combined)\n    plt.scatter(combined, labels, c=kmeans.labels_)\n    plt.title(\"K-Means Clustering\")\n    plt.legend()\n    return labels, plt.gca()\n```"}
{"task_id": "BigCodeBench/1038", "solution": "from datetime import datetime\nimport json\ndef task_func(client_socket):\n    # Get current server time\n    server_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n    # Create a greeting message\n    greeting = f\"Hello! The current server time is {server_time}.\"\n    # Send the JSON-formatted message to the client\n    client_socket.sendall(json.dumps({\"greeting\": greeting}).encode())", "raw_solution": "from datetime import datetime\nimport json\nSERVER_ADDRESS = \"localhost\"\nBUFFER_SIZE = 1024\ndef task_func(client_socket):\n    # Get current server time\n    server_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n    # Create a greeting message\n    greeting = f\"Hello! The current server time is {server_time}.\"\n    # Send the JSON-formatted message to the client\n    client_socket.sendall(json.dumps({\"greeting\": greeting}).encode())\n```"}
{"task_id": "BigCodeBench/1039", "solution": "import ssl\nimport os\nimport hashlib\ndef task_func(client_socket, cert_file, key_file, buffer_size=1024):\n    try:\n        # Create a secure SSL/TLS context\n        context = ssl.create_default_context(ssl.Purpose.CLIENT_AUTH)\n        context.load_cert_chain(cert_file, key_file)\n        context.verify_mode = ssl.CERT_REQUIRED\n\n        # Wrap the socket with the SSL/TLS context\n        secure_socket = context.wrap_socket(client_socket, server_side=True)\n\n        # Receive the file path from the client\n        file_path = secure_socket.recv(buffer_size).decode('utf-8')\n\n        # Check if the file exists\n        if not os.path.exists(file_path):\n            return 'File not found'\n\n        # Open the file and read its contents\n        with open(file_path, 'rb') as file:\n            file_contents = file.read()\n\n        # Calculate the SHA256 hash of the file contents\n        sha256_hash = hashlib.sha256(file_contents).hexdigest()\n\n        # Send the SHA256 hash back to the client\n        secure_socket.sendall(sha256_hash.encode('utf-8'))\n\n        # Close the secure socket\n        secure_socket.close()\n\n        return sha256_hash\n    except Exception as e:\n        # Return an error message if an exception occurs\n        return str(e)", "raw_solution": "import ssl\nimport os\nimport hashlib\n\ndef task_func(client_socket, cert_file, key_file, buffer_size=1024):\n    try:\n        # Create a secure SSL/TLS context\n        context = ssl.create_default_context(ssl.Purpose.CLIENT_AUTH)\n        context.load_cert_chain(cert_file, key_file)\n        context.verify_mode = ssl.CERT_REQUIRED\n\n        # Wrap the socket with the SSL/TLS context\n        secure_socket = context.wrap_socket(client_socket, server_side=True)\n\n        # Receive the file path from the client\n        file_path = secure_socket.recv(buffer_size).decode('utf-8')\n\n        # Check if the file exists\n        if not os.path.exists(file_path):\n            return 'File not found'\n\n        # Open the file and read its contents\n        with open(file_path, 'rb') as file:\n            file_contents = file.read()\n\n        # Calculate the SHA256 hash of the file contents\n        sha256_hash = hashlib.sha256(file_contents).hexdigest()\n\n        # Send the SHA256 hash back to the client\n        secure_socket.sendall(sha256_hash.encode('utf-8'))\n\n        # Close the secure socket\n        secure_socket.close()\n\n        return sha256_hash\n    except Exception as e:\n        # Return an error message if an exception occurs\n        return str(e)\n```"}
{"task_id": "BigCodeBench/1040", "solution": "import socket\nimport select\nimport queue\nfrom datetime import datetime, timedelta\ndef task_func(\n    server_address=\"localhost\", server_port=12345, buffer_size=1024, run_duration=5\n):\n    server = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n    server.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\n    server.bind((server_address, server_port))\n    server.listen(5)\n    print(f\"Server started on {server_address}:{server_port}\")\n    start_time = datetime.now()\n    end_time = start_time + timedelta(seconds=run_duration)\n    while datetime.now() < end_time:\n        readable, writable, exceptional = select.select([server], [], [])\n        for s in readable:\n            data = s.recv(buffer_size)\n            if data:\n                s.sendall(data)\n            else:\n                s.close()\n    server.close()\n    print(f\"Server stopped after {run_duration} seconds\")", "raw_solution": "import socket\nimport select\nimport queue\nfrom datetime import datetime, timedelta\n\ndef task_func(\n    server_address=\"localhost\", server_port=12345, buffer_size=1024, run_duration=5\n):\n    server = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n    server.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\n    server.bind((server_address, server_port))\n    server.listen(5)\n    print(f\"Server started on {server_address}:{server_port}\")\n    start_time = datetime.now()\n    end_time = start_time + timedelta(seconds=run_duration)\n    while datetime.now() < end_time:\n        readable, writable, exceptional = select.select([server], [], [])\n        for s in readable:\n            data = s.recv(buffer_size)\n            if data:\n                s.sendall(data)\n            else:\n                s.close()\n    server.close()\n    print(f\"Server stopped after {run_duration} seconds\")\n```"}
{"task_id": "BigCodeBench/1041", "solution": "import re\nimport os\ndef task_func(request):\n    # Extract the filename from the request\n    filename = re.search(r'filename=\"([^\"]+)\"', request).group(1)\n    # Check if the file exists in the server's directory\n    if os.path.exists(filename):\n        # Read the file content\n        with open(filename, 'rb') as f:\n            content = f.read()\n        # Return the HTTP response\n        return f'HTTP/1.1 200 OK\\r\\nContent-Length: {len(content)}\\r\\n\\r\\n{content}'\n    else:\n        # Return an error message\n        return 'HTTP/1.1 404 Not Found\\r\\n\\r\\nFile not found'", "raw_solution": "import re\nimport os\n\ndef task_func(request):\n    # Extract the filename from the request\n    filename = re.search(r'filename=\"([^\"]+)\"', request).group(1)\n    # Check if the file exists in the server's directory\n    if os.path.exists(filename):\n        # Read the file content\n        with open(filename, 'rb') as f:\n            content = f.read()\n        # Return the HTTP response\n        return f'HTTP/1.1 200 OK\\r\\nContent-Length: {len(content)}\\r\\n\\r\\n{content}'\n    else:\n        # Return an error message\n        return 'HTTP/1.1 404 Not Found\\r\\n\\r\\nFile not found'\n```"}
{"task_id": "BigCodeBench/1042", "solution": "import smtplib\nfrom email.message import EmailMessage\nimport getpass\nSMTP_SERVER = \"smtp.gmail.com\"\nSMTP_PORT = 587\ndef task_func(client_socket):\n    sender_email = input(\"Enter your email: \")\n    recipient_email = input(\"Enter recipient's email: \")\n    sender_password = getpass.getpass(\"Enter your email password: \")\n    email = EmailMessage()\n    email['From'] = sender_email\n    email['To'] = recipient_email\n    email['Subject'] = \"Test Email\"\n    email.set_content(\"This is a test email sent from a client socket.\")\n    with smtplib.SMTP(SMTP_SERVER, SMTP_PORT) as server:\n        server.starttls()\n        server.login(sender_email, sender_password)\n        server.send_message(email)\n    return None", "raw_solution": "import smtplib\nfrom email.message import EmailMessage\nimport getpass\nSERVER_ADDRESS = \"localhost\"\nSERVER_PORT = 25\nBUFFER_SIZE = 1024\nSMTP_SERVER = \"smtp.gmail.com\"\nSMTP_PORT = 587\ndef task_func(client_socket):\n    sender_email = input(\"Enter your email: \")\n    recipient_email = input(\"Enter recipient's email: \")\n    sender_password = getpass.getpass(\"Enter your email password: \")\n    email = EmailMessage()\n    email['From'] = sender_email\n    email['To'] = recipient_email\n    email['Subject'] = \"Test Email\"\n    email.set_content(\"This is a test email sent from a client socket.\")\n    with smtplib.SMTP(SMTP_SERVER, SMTP_PORT) as server:\n        server.starttls()\n        server.login(sender_email, sender_password)\n        server.send_message(email)\n    return None\n```"}
{"task_id": "BigCodeBench/1043", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nCATEGORIES = [\"A\", \"B\", \"C\", \"D\", \"E\"]\ndef task_func(data_list):\n    if not data_list:\n        raise ValueError(\"The data list is empty.\")\n    all_categories = CATEGORIES + [category for category in data_list if category not in CATEGORIES]\n    category_counts = pd.Series(data_list).value_counts().reindex(all_categories, fill_value=0)\n    width = 0.8\n    align = \"center\"\n    ax = plt.bar(all_categories, category_counts, width=width, align=align)\n    plt.show()", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\n# Constants\nCATEGORIES = [\"A\", \"B\", \"C\", \"D\", \"E\"]\ndef task_func(data_list):\n    if not data_list:\n        raise ValueError(\"The data list is empty.\")\n    all_categories = CATEGORIES + [category for category in data_list if category not in CATEGORIES]\n    category_counts = pd.Series(data_list).value_counts().reindex(all_categories, fill_value=0)\n    width = 0.8\n    align = \"center\"\n    ax = plt.bar(all_categories, category_counts, width=width, align=align)\n    plt.show()\n```"}
{"task_id": "BigCodeBench/1044", "solution": "import pandas as pd\nfrom datetime import datetime\ndef task_func(date_str, booking_data):\n    try:\n        date = datetime.strptime(date_str, \"%Y-%m-%d\")\n    except ValueError:\n        raise ValueError(\"Invalid date format or date is in the past.\")\n    booking_status = booking_data.loc[booking_data['date'] == date, 'status'].value_counts()\n    booking_status = pd.DataFrame(booking_status, index=booking_status.index, columns=['count'])\n    booking_status.index.name = 'room'\n    booking_status.columns.name = 'status'\n    booking_status.plot(kind='bar', figsize=(10, 5))\n    return booking_status, booking_status.plot", "raw_solution": "import pandas as pd\nfrom datetime import datetime\n# Constants\nROOMS = [\"Room1\", \"Room2\", \"Room3\", \"Room4\", \"Room5\"]\ndef task_func(date_str, booking_data):\n    try:\n        date = datetime.strptime(date_str, \"%Y-%m-%d\")\n    except ValueError:\n        raise ValueError(\"Invalid date format or date is in the past.\")\n    booking_status = booking_data.loc[booking_data['date'] == date, 'status'].value_counts()\n    booking_status = pd.DataFrame(booking_status, index=booking_status.index, columns=['count'])\n    booking_status.index.name = 'room'\n    booking_status.columns.name = 'status'\n    booking_status.plot(kind='bar', figsize=(10, 5))\n    return booking_status, booking_status.plot\n```"}
{"task_id": "BigCodeBench/1045", "solution": "from datetime import datetime\nimport numpy as np\nfrom dateutil.parser import parse\nLEAP_SECONDS = np.array(\n    [\n        1972,\n        1973,\n        1974,\n        1975,\n        1976,\n        1977,\n        1978,\n        1979,\n        1980,\n        1981,\n        1982,\n        1983,\n        1985,\n        1988,\n        1990,\n        1993,\n        1994,\n        1997,\n        1999,\n        2006,\n        2009,\n        2012,\n        2015,\n        2016,\n        2020,\n    ]\n)\ndef task_func(date_str):\n    date = parse(date_str)\n    start = datetime(date.year, 1, 1)\n    end = datetime.now()\n    delta = end - start\n    total_seconds = delta.total_seconds()\n    leap_seconds = 0\n    for year in LEAP_SECONDS:\n        if year <= date.year:\n            leap_seconds += 1\n    return total_seconds + leap_seconds", "raw_solution": "from datetime import datetime\nimport numpy as np\nfrom dateutil.parser import parse\nLEAP_SECONDS = np.array(\n    [\n        1972,\n        1973,\n        1974,\n        1975,\n        1976,\n        1977,\n        1978,\n        1979,\n        1980,\n        1981,\n        1982,\n        1983,\n        1985,\n        1988,\n        1990,\n        1993,\n        1994,\n        1997,\n        1999,\n        2006,\n        2009,\n        2012,\n        2015,\n        2016,\n        2020,\n    ]\n)\n\ndef task_func(date_str):\n    date = parse(date_str)\n    start = datetime(date.year, 1, 1)\n    end = datetime.now()\n    delta = end - start\n    total_seconds = delta.total_seconds()\n    leap_seconds = 0\n    for year in LEAP_SECONDS:\n        if year <= date.year:\n            leap_seconds += 1\n    return total_seconds + leap_seconds\n```"}
{"task_id": "BigCodeBench/1046", "solution": "from datetime import datetime\nimport pandas as pd\nfrom itertools import product\nEMPLOYEES = [\"John\", \"Alice\", \"Bob\", \"Charlie\", \"Dave\"]\ndef task_func(date_str):\n    # Convert date string to datetime object\n    date = datetime.strptime(date_str, \"%Y-%m-%d\")\n    # Generate a list of dates for the next 10 days\n    dates = [date + datetime.timedelta(days=i) for i in range(10)]\n    # Create a DataFrame with 'Employee' and 'Date' columns\n    df = pd.DataFrame({'Employee': EMPLOYEES, 'Date': dates})\n    return df", "raw_solution": "from datetime import datetime\nimport pandas as pd\nfrom itertools import product\n# Constants\nEMPLOYEES = [\"John\", \"Alice\", \"Bob\", \"Charlie\", \"Dave\"]\ndef task_func(date_str):\n    # Convert date string to datetime object\n    date = datetime.strptime(date_str, \"%Y-%m-%d\")\n    # Generate a list of dates for the next 10 days\n    dates = [date + datetime.timedelta(days=i) for i in range(10)]\n    # Create a DataFrame with 'Employee' and 'Date' columns\n    df = pd.DataFrame({'Employee': EMPLOYEES, 'Date': dates})\n    return df\n```"}
{"task_id": "BigCodeBench/1047", "solution": "from datetime import datetime\nimport random\nimport matplotlib.pyplot as plt\ndef task_func(date_str):\n    date = datetime.strptime(date_str, '%Y-%m-%d')\n    day = date.day\n    integers = [random.randint(1, 100) for _ in range(day)]\n    fig, ax = plt.subplots()\n    ax.plot(integers)\n    return ax", "raw_solution": "from datetime import datetime\nimport random\nimport matplotlib.pyplot as plt\n\ndef task_func(date_str):\n    date = datetime.strptime(date_str, '%Y-%m-%d')\n    day = date.day\n    integers = [random.randint(1, 100) for _ in range(day)]\n    fig, ax = plt.subplots()\n    ax.plot(integers)\n    return ax\n```"}
{"task_id": "BigCodeBench/1048", "solution": "from datetime import datetime\nimport numpy as np\nimport matplotlib.pyplot as plt\ndef task_func(date_str):\n    date = datetime.strptime(date_str, '%Y-%m-%d')\n    day = date.day\n    x = np.linspace(0, 2 * np.pi, 1000)\n    y = np.sin(day * x)\n    fig, ax = plt.subplots()\n    ax.plot(x, y)\n    return ax", "raw_solution": "from datetime import datetime\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef task_func(date_str):\n    date = datetime.strptime(date_str, '%Y-%m-%d')\n    day = date.day\n    x = np.linspace(0, 2 * np.pi, 1000)\n    y = np.sin(day * x)\n    fig, ax = plt.subplots()\n    ax.plot(x, y)\n    return ax\n```"}
{"task_id": "BigCodeBench/1049", "solution": "import re\nimport pandas as pd\ndef task_func(input_string: str) -> pd.DataFrame:\n    lines = input_string.split('\\n')\n    lines = [line.strip() for line in lines if line.strip()]\n    lines = [re.sub(r'\\t', ' ', line) for line in lines]\n    return pd.DataFrame({'Text': lines})", "raw_solution": "import re\nimport pandas as pd\n\ndef task_func(input_string: str) -> pd.DataFrame:\n    lines = input_string.split('\\n')\n    lines = [line.strip() for line in lines if line.strip()]\n    lines = [re.sub(r'\\t', ' ', line) for line in lines]\n    return pd.DataFrame({'Text': lines})\n```"}
{"task_id": "BigCodeBench/1050", "solution": "import os\nimport hashlib\nDIRECTORY = \"./hashed_files\"\ndef task_func(input_string):\n    # Create the directory if it does not exist\n    if not os.path.exists(DIRECTORY):\n        os.makedirs(DIRECTORY)\n    # Split the input string into lines\n    lines = input_string.splitlines()\n    # Hash each non-empty line and save the hashes to files\n    file_paths = []\n    for i, line in enumerate(lines):\n        if line.strip():\n            # Generate the SHA256 hash of the line\n            hash_obj = hashlib.sha256(line.encode())\n            hash_str = hash_obj.hexdigest()\n            # Create the file path\n            file_path = os.path.join(DIRECTORY, hash_str[:10] + '.txt')\n            # Write the hash to the file\n            with open(file_path, 'w') as f:\n                f.write(hash_str)\n            # Add the file path to the list\n            file_paths.append(file_path)\n    return file_paths", "raw_solution": "import os\nimport hashlib\n# Constants\nDIRECTORY = \"./hashed_files\"\ndef task_func(input_string):\n    # Create the directory if it does not exist\n    if not os.path.exists(DIRECTORY):\n        os.makedirs(DIRECTORY)\n    # Split the input string into lines\n    lines = input_string.splitlines()\n    # Hash each non-empty line and save the hashes to files\n    file_paths = []\n    for i, line in enumerate(lines):\n        if line.strip():\n            # Generate the SHA256 hash of the line\n            hash_obj = hashlib.sha256(line.encode())\n            hash_str = hash_obj.hexdigest()\n            # Create the file path\n            file_path = os.path.join(DIRECTORY, hash_str[:10] + '.txt')\n            # Write the hash to the file\n            with open(file_path, 'w') as f:\n                f.write(hash_str)\n            # Add the file path to the list\n            file_paths.append(file_path)\n    return file_paths\n```"}
{"task_id": "BigCodeBench/1051", "solution": "import collections\nimport numpy as np\nimport matplotlib.pyplot as plt\ndef task_func(data_dict):\n    if not data_dict:\n        return None, \"The distribution is uniform.\"\n    counts = collections.Counter(data_dict)\n    avg_count = sum(counts.values()) / len(counts)\n    uniform = True\n    for count in counts.values():\n        if abs(count - avg_count) > 1e-5:\n            uniform = False\n            break\n    if uniform:\n        fig, ax = plt.subplots()\n        ax.hist(counts.values(), bins=min(10, len(counts)))\n        ax.set_xticks(list(counts.keys()))\n        return ax, \"The distribution is uniform.\"\n    else:\n        fig, ax = plt.subplots()\n        ax.hist(counts.values(), bins=min(10, len(counts)))\n        ax.set_xticks(list(counts.keys()))\n        return ax, \"The distribution is not uniform.\"", "raw_solution": "import collections\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef task_func(data_dict):\n    if not data_dict:\n        return None, \"The distribution is uniform.\"\n    counts = collections.Counter(data_dict)\n    avg_count = sum(counts.values()) / len(counts)\n    uniform = True\n    for count in counts.values():\n        if abs(count - avg_count) > 1e-5:\n            uniform = False\n            break\n    if uniform:\n        fig, ax = plt.subplots()\n        ax.hist(counts.values(), bins=min(10, len(counts)))\n        ax.set_xticks(list(counts.keys()))\n        return ax, \"The distribution is uniform.\"\n    else:\n        fig, ax = plt.subplots()\n        ax.hist(counts.values(), bins=min(10, len(counts)))\n        ax.set_xticks(list(counts.keys()))\n        return ax, \"The distribution is not uniform.\"\n```"}
{"task_id": "BigCodeBench/1052", "solution": "import pandas as pd\nfrom sklearn.feature_extraction.text import CountVectorizer\nimport matplotlib.pyplot as plt\nSTOP_WORDS = [\"a\", \"an\", \"the\", \"in\", \"on\", \"at\", \"and\", \"or\"]\ndef task_func(file_path, save_path=None):\n    # Load data\n    df = pd.read_csv(file_path)\n    if df.empty:\n        print(\"The input file is empty.\")\n        return None\n    # Remove stopwords\n    df['text'] = df['text'].apply(lambda x: ' '.join([word for word in x.split() if word not in STOP_WORDS]))\n    # Vectorize text\n    vectorizer = CountVectorizer()\n    X = vectorizer.fit_transform(df['text'])\n    # Get top 10 words\n    top_words = vectorizer.get_feature_names_out().tolist()[:10]\n    # Create histogram\n    fig, ax = plt.subplots()\n    ax.hist(X.toarray().sum(axis=0), bins=len(top_words))\n    ax.set_xticks(range(len(top_words)))\n    ax.set_xticklabels(top_words)\n    ax.set_title('Top 10 Words')\n    ax.set_xlabel('Word')\n    ax.set_ylabel('Frequency')\n    # Save plot if save_path is provided\n    if save_path:\n        plt.savefig(save_path)\n    # Display plot if save_path is not provided\n    else:\n        plt.show()\n    return ax", "raw_solution": "import pandas as pd\nfrom sklearn.feature_extraction.text import CountVectorizer\nimport matplotlib.pyplot as plt\n# Constants\nSTOP_WORDS = [\"a\", \"an\", \"the\", \"in\", \"on\", \"at\", \"and\", \"or\"]\ndef task_func(file_path, save_path=None):\n    # Load data\n    df = pd.read_csv(file_path)\n    if df.empty:\n        print(\"The input file is empty.\")\n        return None\n    # Remove stopwords\n    df['text'] = df['text'].apply(lambda x: ' '.join([word for word in x.split() if word not in STOP_WORDS]))\n    # Vectorize text\n    vectorizer = CountVectorizer()\n    X = vectorizer.fit_transform(df['text'])\n    # Get top 10 words\n    top_words = vectorizer.get_feature_names_out().tolist()[:10]\n    # Create histogram\n    fig, ax = plt.subplots()\n    ax.hist(X.toarray().sum(axis=0), bins=len(top_words))\n    ax.set_xticks(range(len(top_words)))\n    ax.set_xticklabels(top_words)\n    ax.set_title('Top 10 Words')\n    ax.set_xlabel('Word')\n    ax.set_ylabel('Frequency')\n    # Save plot if save_path is provided\n    if save_path:\n        plt.savefig(save_path)\n    # Display plot if save_path is not provided\n    else:\n        plt.show()\n    return ax\n```"}
{"task_id": "BigCodeBench/1053", "solution": "import pandas as pd\nfrom sklearn.feature_extraction.text import CountVectorizer\nimport matplotlib.pyplot as plt\nSTOP_WORDS = [\"a\", \"an\", \"the\", \"in\", \"on\", \"at\", \"and\", \"or\"]\ndef task_func(file_path, save_path=None):\n    try:\n        # Read the CSV file\n        df = pd.read_csv(file_path)\n        # Split the text into words\n        text = df['Text'].str.split()\n        # Flatten the list of lists\n        text = [item for sublist in text for item in sublist]\n        # Remove stopwords\n        text = [word for word in text if word not in STOP_WORDS]\n        # Count the frequency of each word\n        vectorizer = CountVectorizer()\n        X = vectorizer.fit_transform(text)\n        # Get the top 10 most common words\n        top_words = vectorizer.get_feature_names_out().tolist()[:10]\n        # Create a histogram of the top 10 most common words\n        plt.figure(figsize=(10, 5))\n        plt.bar(top_words, X.sum(axis=0).tolist()[0])\n        plt.xlabel('Words')\n        plt.ylabel('Frequency')\n        plt.title('Top 10 Most Common Words')\n        # Save the plot to a file if save_path is provided\n        if save_path:\n            plt.savefig(save_path)\n        # Return the Axes object of the plot if save_path is not provided\n        else:\n            return plt.gca()\n    except FileNotFoundError:\n        print(f\"File not found: {file_path}\")\n    except Exception as e:\n        print(f\"Error: {e}\")", "raw_solution": "import pandas as pd\nfrom sklearn.feature_extraction.text import CountVectorizer\nimport matplotlib.pyplot as plt\n# Constants\nSTOP_WORDS = [\"a\", \"an\", \"the\", \"in\", \"on\", \"at\", \"and\", \"or\"]\ndef task_func(file_path, save_path=None):\n    try:\n        # Read the CSV file\n        df = pd.read_csv(file_path)\n        # Split the text into words\n        text = df['Text'].str.split()\n        # Flatten the list of lists\n        text = [item for sublist in text for item in sublist]\n        # Remove stopwords\n        text = [word for word in text if word not in STOP_WORDS]\n        # Count the frequency of each word\n        vectorizer = CountVectorizer()\n        X = vectorizer.fit_transform(text)\n        # Get the top 10 most common words\n        top_words = vectorizer.get_feature_names_out().tolist()[:10]\n        # Create a histogram of the top 10 most common words\n        plt.figure(figsize=(10, 5))\n        plt.bar(top_words, X.sum(axis=0).tolist()[0])\n        plt.xlabel('Words')\n        plt.ylabel('Frequency')\n        plt.title('Top 10 Most Common Words')\n        # Save the plot to a file if save_path is provided\n        if save_path:\n            plt.savefig(save_path)\n        # Return the Axes object of the plot if save_path is not provided\n        else:\n            return plt.gca()\n    except FileNotFoundError:\n        print(f\"File not found: {file_path}\")\n    except Exception as e:\n        print(f\"Error: {e}\")\n```"}
{"task_id": "BigCodeBench/1054", "solution": "import csv\nimport numpy as np\nimport scipy.stats as stats\nimport matplotlib.pyplot as plt\ndef task_func(file_path):\n    try:\n        with open(file_path, newline='') as file:\n            reader = csv.reader(file)\n            data = [float(row[0]) for row in reader]\n    except FileNotFoundError:\n        print(\"File not found.\")\n        return None\n    except Exception as e:\n        print(\"An error occurred while reading the file:\", e)\n        return None\n\n    sample = np.random.choice(data, 30, replace=False)\n    sample_mean = np.mean(sample)\n    sample_std = np.std(sample, ddof=1)\n\n    fig, ax = plt.subplots()\n    ax.hist(sample, bins='auto', density=True)\n    x = np.linspace(min(sample), max(sample), 100)\n    y = stats.norm.pdf(x, sample_mean, sample_std)\n    ax.plot(x, y, 'r')\n    ax.set_title('Histogram of Sample Data with Normal Distribution Curve')\n    ax.set_xlabel('Value')\n    ax.set_ylabel('Density')\n    plt.show()\n\n    return (sample_mean, sample_std, ax)", "raw_solution": "import csv\nimport numpy as np\nimport scipy.stats as stats\nimport matplotlib.pyplot as plt\n\ndef task_func(file_path):\n    try:\n        with open(file_path, newline='') as file:\n            reader = csv.reader(file)\n            data = [float(row[0]) for row in reader]\n    except FileNotFoundError:\n        print(\"File not found.\")\n        return None\n    except Exception as e:\n        print(\"An error occurred while reading the file:\", e)\n        return None\n\n    sample = np.random.choice(data, 30, replace=False)\n    sample_mean = np.mean(sample)\n    sample_std = np.std(sample, ddof=1)\n\n    fig, ax = plt.subplots()\n    ax.hist(sample, bins='auto', density=True)\n    x = np.linspace(min(sample), max(sample), 100)\n    y = stats.norm.pdf(x, sample_mean, sample_std)\n    ax.plot(x, y, 'r')\n    ax.set_title('Histogram of Sample Data with Normal Distribution Curve')\n    ax.set_xlabel('Value')\n    ax.set_ylabel('Density')\n    plt.show()\n\n    return (sample_mean, sample_std, ax)\n```"}
{"task_id": "BigCodeBench/1055", "solution": "import pandas as pd\nimport itertools\nimport random\ndef task_func(colors, states):\n    # Generate all possible combinations of colors and states\n    combinations = list(itertools.product(colors, states))\n    # Shuffle the combinations\n    random.shuffle(combinations)\n    # Create a DataFrame with the shuffled combinations\n    df = pd.DataFrame(combinations, columns=['Color:State'])\n    return df", "raw_solution": "import pandas as pd\nimport itertools\nimport random\n\ndef task_func(colors, states):\n    # Generate all possible combinations of colors and states\n    combinations = list(itertools.product(colors, states))\n    # Shuffle the combinations\n    random.shuffle(combinations)\n    # Create a DataFrame with the shuffled combinations\n    df = pd.DataFrame(combinations, columns=['Color:State'])\n    return df\n```"}
{"task_id": "BigCodeBench/1056", "solution": "import numpy as np\nimport random\nimport matplotlib.pyplot as plt\nLETTERS = list(\"abcdefghijklmnopqrstuvwxyz\")\nNUMBERS = list(range(1, 27))\ndef task_func(n_pairs=26):\n    if n_pairs < 1 or n_pairs > 26:\n        raise ValueError(\"n_pairs must be between 1 and 26, inclusive\")\n    pairs = [(random.choice(LETTERS), random.choice(NUMBERS)) for _ in range(n_pairs)]\n    random.shuffle(pairs)\n    counts = [random.randint(1, 9) for _ in range(n_pairs)]\n    fig, ax = plt.subplots()\n    ax.bar(pairs, counts)\n    ax.set_title(\"Random Letter:Number Pairs Chart\")\n    ax.set_xlabel(\"Letter:Number Pairs\")\n    ax.set_ylabel(\"Counts\")\n    plt.show()", "raw_solution": "import numpy as np\nimport random\nimport matplotlib.pyplot as plt\n# Constants\nLETTERS = list(\"abcdefghijklmnopqrstuvwxyz\")\nNUMBERS = list(range(1, 27))\ndef task_func(n_pairs=26):\n    if n_pairs < 1 or n_pairs > 26:\n        raise ValueError(\"n_pairs must be between 1 and 26, inclusive\")\n    pairs = [(random.choice(LETTERS), random.choice(NUMBERS)) for _ in range(n_pairs)]\n    random.shuffle(pairs)\n    counts = [random.randint(1, 9) for _ in range(n_pairs)]\n    fig, ax = plt.subplots()\n    ax.bar(pairs, counts)\n    ax.set_title(\"Random Letter:Number Pairs Chart\")\n    ax.set_xlabel(\"Letter:Number Pairs\")\n    ax.set_ylabel(\"Counts\")\n    plt.show()\n```"}
{"task_id": "BigCodeBench/1057", "solution": "import pandas as pd\nimport itertools\nimport numpy as np\ndef task_func(animals=None, foods=None):\n    if animals is None and foods is None:\n        return pd.DataFrame()\n    elif animals is None:\n        animals = ['dog', 'cat', 'bird', 'fish', 'mouse']\n    elif foods is None:\n        foods = ['meat', 'vegetables', 'fruits', 'grains', 'nuts']\n    pairs = list(itertools.product(animals, foods))\n    np.random.shuffle(pairs)\n    df = pd.DataFrame(pairs, columns=['animal', 'food'])\n    return df", "raw_solution": "import pandas as pd\nimport itertools\nimport numpy as np\n\ndef task_func(animals=None, foods=None):\n    if animals is None and foods is None:\n        return pd.DataFrame()\n    elif animals is None:\n        animals = ['dog', 'cat', 'bird', 'fish', 'mouse']\n    elif foods is None:\n        foods = ['meat', 'vegetables', 'fruits', 'grains', 'nuts']\n    pairs = list(itertools.product(animals, foods))\n    np.random.shuffle(pairs)\n    df = pd.DataFrame(pairs, columns=['animal', 'food'])\n    return df\n```"}
{"task_id": "BigCodeBench/1058", "solution": "import itertools\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nSHAPES = [\n    \"Circle\",\n    \"Square\",\n    \"Triangle\",\n    \"Rectangle\",\n    \"Pentagon\",\n    \"Hexagon\",\n    \"Heptagon\",\n    \"Octagon\",\n    \"Nonagon\",\n    \"Decagon\",\n]\nCOLORS = [\n    \"Red\",\n    \"Blue\",\n    \"Green\",\n    \"Yellow\",\n    \"Black\",\n    \"White\",\n    \"Purple\",\n    \"Orange\",\n    \"Pink\",\n    \"Brown\",\n]\ndef task_func(num_pairs=10):\n    # Generate shape-color pairs\n    pairs = list(itertools.product(SHAPES, COLORS))\n    # Select a subset of pairs\n    pairs = pairs[:num_pairs]\n    # Create a countplot\n    ax = sns.countplot(x=\"shape\", y=\"color\", data=pd.DataFrame(pairs, columns=[\"shape\", \"color\"]))\n    # Show the plot\n    plt.show()", "raw_solution": "import itertools\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n# Constants\nSHAPES = [\n    \"Circle\",\n    \"Square\",\n    \"Triangle\",\n    \"Rectangle\",\n    \"Pentagon\",\n    \"Hexagon\",\n    \"Heptagon\",\n    \"Octagon\",\n    \"Nonagon\",\n    \"Decagon\",\n]\nCOLORS = [\n    \"Red\",\n    \"Blue\",\n    \"Green\",\n    \"Yellow\",\n    \"Black\",\n    \"White\",\n    \"Purple\",\n    \"Orange\",\n    \"Pink\",\n    \"Brown\",\n]\ndef task_func(num_pairs=10):\n    # Generate shape-color pairs\n    pairs = list(itertools.product(SHAPES, COLORS))\n    # Select a subset of pairs\n    pairs = pairs[:num_pairs]\n    # Create a countplot\n    ax = sns.countplot(x=\"shape\", y=\"color\", data=pd.DataFrame(pairs, columns=[\"shape\", \"color\"]))\n    # Show the plot\n    plt.show()\n```"}
{"task_id": "BigCodeBench/1059", "solution": "import numpy as np\nimport random\nimport itertools\nimport pandas as pd\nPLANETS = [\n    \"Mercury\",\n    \"Venus\",\n    \"Earth\",\n    \"Mars\",\n    \"Jupiter\",\n    \"Saturn\",\n    \"Uranus\",\n    \"Neptune\",\n]\nELEMENTS = [\n    \"Hydrogen\",\n    \"Helium\",\n    \"Oxygen\",\n    \"Carbon\",\n    \"Nitrogen\",\n    \"Magnesium\",\n    \"Silicon\",\n    \"Iron\",\n    \"Nickel\",\n]\ndef task_func():\n    # Generate random planet-element pairs\n    pairs = list(itertools.product(PLANETS, ELEMENTS))\n    # Create DataFrame\n    df = pd.DataFrame(pairs, columns=[\"Planet\", \"Element\"])\n    return df", "raw_solution": "import numpy as np\nimport random\nimport itertools\nimport pandas as pd\n# Constants\nPLANETS = [\n    \"Mercury\",\n    \"Venus\",\n    \"Earth\",\n    \"Mars\",\n    \"Jupiter\",\n    \"Saturn\",\n    \"Uranus\",\n    \"Neptune\",\n]\nELEMENTS = [\n    \"Hydrogen\",\n    \"Helium\",\n    \"Oxygen\",\n    \"Carbon\",\n    \"Nitrogen\",\n    \"Magnesium\",\n    \"Silicon\",\n    \"Iron\",\n    \"Nickel\",\n]\ndef task_func():\n    # Generate random planet-element pairs\n    pairs = list(itertools.product(PLANETS, ELEMENTS))\n    # Create DataFrame\n    df = pd.DataFrame(pairs, columns=[\"Planet\", \"Element\"])\n    return df\n```"}
{"task_id": "BigCodeBench/1060", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\ndef task_func(df: pd.DataFrame, column_name: str) -> (str, plt.Axes):\n    if df.empty or column_name not in df.columns or df[column_name].isnull().all():\n        return \"The DataFrame is empty or the specified column has no data.\", plt.Axes()\n    else:\n        values = df[column_name].unique()\n        if len(values) == 1:\n            return \"The distribution of values is uniform.\", plt.Axes()\n        else:\n            plt.hist(df[column_name], bins=len(values), edgecolor='black', alpha=0.7)\n            plt.xlabel('Values')\n            plt.ylabel('Frequency')\n            plt.title('Distribution of values in ' + column_name)\n            return \"The distribution of values is not uniform.\", plt.gca()", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\n\ndef task_func(df: pd.DataFrame, column_name: str) -> (str, plt.Axes):\n    if df.empty or column_name not in df.columns or df[column_name].isnull().all():\n        return \"The DataFrame is empty or the specified column has no data.\", plt.Axes()\n    else:\n        values = df[column_name].unique()\n        if len(values) == 1:\n            return \"The distribution of values is uniform.\", plt.Axes()\n        else:\n            plt.hist(df[column_name], bins=len(values), edgecolor='black', alpha=0.7)\n            plt.xlabel('Values')\n            plt.ylabel('Frequency')\n            plt.title('Distribution of values in ' + column_name)\n            return \"The distribution of values is not uniform.\", plt.gca()\n```"}
{"task_id": "BigCodeBench/1061", "solution": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import norm\ndef task_func(arr: np.ndarray) -> (plt.Axes, np.ndarray):\n    # Calculate the sum of elements in each row of the array\n    row_sums = np.sum(arr, axis=1)\n    \n    # Normalize these row sums to have a mean of 0 and a standard deviation of 1\n    mean = np.mean(row_sums)\n    std = np.std(row_sums)\n    if std == 0:\n        normalized_data = np.zeros_like(row_sums)\n    else:\n        normalized_data = (row_sums - mean) / std\n    \n    # Plot a histogram of the normalized data\n    fig, ax = plt.subplots()\n    ax.hist(normalized_data, bins=30, density=True, alpha=0.6, color='green')\n    \n    # Overlay the PDF of a standard normal distribution on the histogram for comparison\n    x = np.linspace(-3, 3, 1000)\n    y = norm.pdf(x)\n    ax.plot(x, y, color='red', linewidth=2)\n    \n    # Set the range of the PDF curve to cover 99% of a standard normal distribution\n    ax.set_xlim(-3, 3)\n    ax.set_ylim(0, 0.4)\n    \n    # Set the title of the plot\n    ax.set_title(\"Histogram of Normalized Data with Standard Normal PDF\")\n    \n    return ax, normalized_data", "raw_solution": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import norm\n\ndef task_func(arr: np.ndarray) -> (plt.Axes, np.ndarray):\n    # Calculate the sum of elements in each row of the array\n    row_sums = np.sum(arr, axis=1)\n    \n    # Normalize these row sums to have a mean of 0 and a standard deviation of 1\n    mean = np.mean(row_sums)\n    std = np.std(row_sums)\n    if std == 0:\n        normalized_data = np.zeros_like(row_sums)\n    else:\n        normalized_data = (row_sums - mean) / std\n    \n    # Plot a histogram of the normalized data\n    fig, ax = plt.subplots()\n    ax.hist(normalized_data, bins=30, density=True, alpha=0.6, color='green')\n    \n    # Overlay the PDF of a standard normal distribution on the histogram for comparison\n    x = np.linspace(-3, 3, 1000)\n    y = norm.pdf(x)\n    ax.plot(x, y, color='red', linewidth=2)\n    \n    # Set the range of the PDF curve to cover 99% of a standard normal distribution\n    ax.set_xlim(-3, 3)\n    ax.set_ylim(0, 0.4)\n    \n    # Set the title of the plot\n    ax.set_title(\"Histogram of Normalized Data with Standard Normal PDF\")\n    \n    return ax, normalized_data\n```"}
{"task_id": "BigCodeBench/1062", "solution": "import pandas as pd\nfrom matplotlib import pyplot as plt\ndef task_func(arr):\n    if arr.size == 0:\n        fig, ax = plt.subplots()\n        ax.set_title('Time Series of Row Sums')\n        ax.set_xlabel('Date')\n        ax.set_ylabel('Sum')\n        ax.plot([], [], label='Empty Array')\n        ax.legend()\n        return ax\n    else:\n        dates = pd.date_range(start='2020-01-01', periods=arr.shape[0])\n        row_sums = arr.sum(axis=1)\n        df = pd.DataFrame({'Date': dates, 'Sum': row_sums})\n        fig, ax = plt.subplots()\n        ax.set_title('Time Series of Row Sums')\n        ax.set_xlabel('Date')\n        ax.set_ylabel('Sum')\n        ax.plot(df['Date'], df['Sum'], label='Non-empty Array')\n        ax.legend()\n        return ax", "raw_solution": "import pandas as pd\nfrom matplotlib import pyplot as plt\n\ndef task_func(arr):\n    if arr.size == 0:\n        fig, ax = plt.subplots()\n        ax.set_title('Time Series of Row Sums')\n        ax.set_xlabel('Date')\n        ax.set_ylabel('Sum')\n        ax.plot([], [], label='Empty Array')\n        ax.legend()\n        return ax\n    else:\n        dates = pd.date_range(start='2020-01-01', periods=arr.shape[0])\n        row_sums = arr.sum(axis=1)\n        df = pd.DataFrame({'Date': dates, 'Sum': row_sums})\n        fig, ax = plt.subplots()\n        ax.set_title('Time Series of Row Sums')\n        ax.set_xlabel('Date')\n        ax.set_ylabel('Sum')\n        ax.plot(df['Date'], df['Sum'], label='Non-empty Array')\n        ax.legend()\n        return ax\n```"}
{"task_id": "BigCodeBench/1063", "solution": "from matplotlib import pyplot as plt\nfrom sklearn.decomposition import PCA\ndef task_func(arr):\n    pca = PCA(n_components=1)\n    pca.fit(arr)\n    explained_variance_ratio = pca.explained_variance_ratio_\n    ax = plt.plot(explained_variance_ratio)\n    ax.set_title(\"Explained Variance Ratio of Principal Components\")\n    plt.show()", "raw_solution": "from matplotlib import pyplot as plt\nfrom sklearn.decomposition import PCA\n\ndef task_func(arr):\n    pca = PCA(n_components=1)\n    pca.fit(arr)\n    explained_variance_ratio = pca.explained_variance_ratio_\n    ax = plt.plot(explained_variance_ratio)\n    ax.set_title(\"Explained Variance Ratio of Principal Components\")\n    plt.show()\n```"}
{"task_id": "BigCodeBench/1064", "solution": "import numpy as np\nimport seaborn as sns\ndef task_func(arr):\n    ax = sns.heatmap(arr, cmap='viridis')\n    print('Sum of each row:')\n    for i in range(arr.shape[0]):\n        print(arr[i].sum())\n    return ax", "raw_solution": "import numpy as np\nimport seaborn as sns\n\ndef task_func(arr):\n    ax = sns.heatmap(arr, cmap='viridis')\n    print('Sum of each row:')\n    for i in range(arr.shape[0]):\n        print(arr[i].sum())\n    return ax\n```"}
{"task_id": "BigCodeBench/1065", "solution": "from scipy import fftpack\nfrom matplotlib import pyplot as plt\ndef task_func(arr):\n    # Compute the sum of each row in the 2D array\n    row_sums = [sum(row) for row in arr]\n    \n    # Compute the FFT of the row sums\n    ffts = [fftpack.fft(row_sum) for row_sum in row_sums]\n    \n    # Compute the absolute values of the FFT coefficients\n    abs_fft = [abs(coeff) for coeff in ffts]\n    \n    # Plot the absolute values of the FFT coefficients\n    plt.plot(abs_fft)\n    plt.show()\n    return plt.axes()", "raw_solution": "from scipy import fftpack\nfrom matplotlib import pyplot as plt\n\ndef task_func(arr):\n    # Compute the sum of each row in the 2D array\n    row_sums = [sum(row) for row in arr]\n    \n    # Compute the FFT of the row sums\n    ffts = [fftpack.fft(row_sum) for row_sum in row_sums]\n    \n    # Compute the absolute values of the FFT coefficients\n    abs_fft = [abs(coeff) for coeff in ffts]\n    \n    # Plot the absolute values of the FFT coefficients\n    plt.plot(abs_fft)\n    plt.show()\n    return plt.axes()\n```"}
{"task_id": "BigCodeBench/1066", "solution": "import numpy as np\nimport matplotlib.pyplot as plt\nNUM_SAMPLES = 100\nNUM_OUTLIERS = 5\ndef task_func(num_samples=NUM_SAMPLES, num_outliers=NUM_OUTLIERS):\n    # Generate normally distributed data\n    data = np.random.normal(loc=0, scale=1, size=num_samples)\n    \n    # Generate artificially introduced outliers\n    outliers = np.random.normal(loc=10, scale=2, size=num_outliers)\n    data = np.concatenate((data, outliers))\n    \n    # Calculate the IQR\n    q1 = np.percentile(data, 25)\n    q3 = np.percentile(data, 75)\n    iqr = q3 - q1\n    \n    # Detect outliers using the IQR method\n    outliers_detected = data[(data < q1 - 1.5 * iqr) | (data > q3 + 1.5 * iqr)]\n    \n    # Plot the histogram of the combined data\n    fig, ax = plt.subplots()\n    ax.hist(data, bins=30, color='blue', alpha=0.5)\n    ax.axvline(x=q1 - 1.5 * iqr, color='red', linestyle='--', linewidth=2)\n    ax.axvline(x=q3 + 1.5 * iqr, color='red', linestyle='--', linewidth=2)\n    ax.set_title('Histogram of combined data')\n    ax.set_xlabel('Value')\n    ax.set_ylabel('Frequency')\n    plt.show()\n    \n    return data, outliers_detected, ax", "raw_solution": "import numpy as np\nimport matplotlib.pyplot as plt\n# Constants\nNUM_SAMPLES = 100\nNUM_OUTLIERS = 5\n\ndef task_func(num_samples=NUM_SAMPLES, num_outliers=NUM_OUTLIERS):\n    # Generate normally distributed data\n    data = np.random.normal(loc=0, scale=1, size=num_samples)\n    \n    # Generate artificially introduced outliers\n    outliers = np.random.normal(loc=10, scale=2, size=num_outliers)\n    data = np.concatenate((data, outliers))\n    \n    # Calculate the IQR\n    q1 = np.percentile(data, 25)\n    q3 = np.percentile(data, 75)\n    iqr = q3 - q1\n    \n    # Detect outliers using the IQR method\n    outliers_detected = data[(data < q1 - 1.5 * iqr) | (data > q3 + 1.5 * iqr)]\n    \n    # Plot the histogram of the combined data\n    fig, ax = plt.subplots()\n    ax.hist(data, bins=30, color='blue', alpha=0.5)\n    ax.axvline(x=q1 - 1.5 * iqr, color='red', linestyle='--', linewidth=2)\n    ax.axvline(x=q3 + 1.5 * iqr, color='red', linestyle='--', linewidth=2)\n    ax.set_title('Histogram of combined data')\n    ax.set_xlabel('Value')\n    ax.set_ylabel('Frequency')\n    plt.show()\n    \n    return data, outliers_detected, ax\n```"}
{"task_id": "BigCodeBench/1067", "solution": "import requests\nimport logging\ndef task_func(repo_url: str) -> dict:\n    try:\n        response = requests.get(repo_url)\n        response.raise_for_status()\n    except requests.exceptions.HTTPError as e:\n        logging.error(f\"HTTP error occurred: {e}\")\n        return None\n    except requests.exceptions.RequestException as e:\n        logging.error(f\"Request error occurred: {e}\")\n        return None\n    except Exception as e:\n        logging.error(f\"An error occurred: {e}\")\n        return None\n    else:\n        repo_info = response.json()\n        if repo_info['open_issues_count'] > 100:\n            logging.warning(\"The repository has a large number of open issues.\")\n        return repo_info", "raw_solution": "import requests\nimport logging\nlogging.basicConfig(level=logging.ERROR)\n\ndef task_func(repo_url: str) -> dict:\n    try:\n        response = requests.get(repo_url)\n        response.raise_for_status()\n    except requests.exceptions.HTTPError as e:\n        logging.error(f\"HTTP error occurred: {e}\")\n        return None\n    except requests.exceptions.RequestException as e:\n        logging.error(f\"Request error occurred: {e}\")\n        return None\n    except Exception as e:\n        logging.error(f\"An error occurred: {e}\")\n        return None\n    else:\n        repo_info = response.json()\n        if repo_info['open_issues_count'] > 100:\n            logging.warning(\"The repository has a large number of open issues.\")\n        return repo_info\n```"}
{"task_id": "BigCodeBench/1068", "solution": "import warnings\nimport sqlite3\nimport pandas as pd\ndef task_func(db_path, query, warn_large_dataset=True):\n    try:\n        conn = sqlite3.connect(db_path)\n        df = pd.read_sql(query, conn)\n        if len(df) > 10000:\n            warnings.warn(\"The data contains more than 10000 rows.\")\n        return df\n    except Exception as e:\n        raise Exception(f\"Error fetching data from the database: {e}\")", "raw_solution": "import warnings\nimport sqlite3\nimport pandas as pd\n\ndef task_func(db_path, query, warn_large_dataset=True):\n    try:\n        conn = sqlite3.connect(db_path)\n        df = pd.read_sql(query, conn)\n        if len(df) > 10000:\n            warnings.warn(\"The data contains more than 10000 rows.\")\n        return df\n    except Exception as e:\n        raise Exception(f\"Error fetching data from the database: {e}\")\n```"}
{"task_id": "BigCodeBench/1069", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\ndef task_func(data_dict):\n    df = pd.DataFrame(data_dict)\n    non_uniform = []\n    for col in df.columns:\n        hist, bins = plt.hist(df[col], bins=10)\n        if not (hist == hist.max()).all():\n            non_uniform.append(col)\n    for col in non_uniform:\n        print(f\"Column {col} is not uniform.\")\n    return [plt.axes() for _ in range(len(df.columns))]", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\n\ndef task_func(data_dict):\n    df = pd.DataFrame(data_dict)\n    non_uniform = []\n    for col in df.columns:\n        hist, bins = plt.hist(df[col], bins=10)\n        if not (hist == hist.max()).all():\n            non_uniform.append(col)\n    for col in non_uniform:\n        print(f\"Column {col} is not uniform.\")\n    return [plt.axes() for _ in range(len(df.columns))]\n```"}
{"task_id": "BigCodeBench/1070", "solution": "import pandas as pd\nfrom random import shuffle\nPOSSIBLE_VALUES = [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\", \"H\", \"I\", \"J\"]\ndef task_func(list_of_lists):\n    dfs = []\n    for sublist in list_of_lists:\n        df = pd.DataFrame(columns=sublist)\n        for col in df.columns:\n            shuffle(POSSIBLE_VALUES)\n            df[col] = POSSIBLE_VALUES\n        dfs.append(df)\n    return dfs", "raw_solution": "import pandas as pd\nfrom random import shuffle\n# Constants\nPOSSIBLE_VALUES = [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\", \"H\", \"I\", \"J\"]\n\ndef task_func(list_of_lists):\n    dfs = []\n    for sublist in list_of_lists:\n        df = pd.DataFrame(columns=sublist)\n        for col in df.columns:\n            shuffle(POSSIBLE_VALUES)\n            df[col] = POSSIBLE_VALUES\n        dfs.append(df)\n    return dfs\n```"}
{"task_id": "BigCodeBench/1071", "solution": "import matplotlib.pyplot as plt\nfrom itertools import cycle\nimport numpy as np\nfrom random import shuffle\nCOLORS = [\"b\", \"g\", \"r\", \"c\", \"m\", \"y\", \"k\"]\ndef task_func(list_of_lists):\n    fig, ax = plt.subplots()\n    colors = cycle(COLORS)\n    for i, lst in enumerate(list_of_lists):\n        if not lst:\n            continue\n        shuffle(lst)\n        ax.plot(np.arange(1, len(lst) + 1), lst, color=next(colors))\n    plt.show()\n    return fig, ax", "raw_solution": "import matplotlib.pyplot as plt\nfrom itertools import cycle\nimport numpy as np\nfrom random import shuffle\nCOLORS = [\"b\", \"g\", \"r\", \"c\", \"m\", \"y\", \"k\"]\n\ndef task_func(list_of_lists):\n    fig, ax = plt.subplots()\n    colors = cycle(COLORS)\n    for i, lst in enumerate(list_of_lists):\n        if not lst:\n            continue\n        shuffle(lst)\n        ax.plot(np.arange(1, len(lst) + 1), lst, color=next(colors))\n    plt.show()\n    return fig, ax\n```"}
{"task_id": "BigCodeBench/1072", "solution": "import pandas as pd\nimport numpy as np\ndef task_func(list_of_lists):\n    series_list = []\n    for sub_list in list_of_lists:\n        series = pd.Series(np.random.permutation(len(sub_list)) + 1)\n        series.index = sub_list\n        series_list.append(series)\n    return series_list", "raw_solution": "import pandas as pd\nimport numpy as np\n\ndef task_func(list_of_lists):\n    series_list = []\n    for sub_list in list_of_lists:\n        series = pd.Series(np.random.permutation(len(sub_list)) + 1)\n        series.index = sub_list\n        series_list.append(series)\n    return series_list\n```"}
{"task_id": "BigCodeBench/1073", "solution": "import time\nimport matplotlib.pyplot as plt\ndef task_func(time_strings, time_format=\"%d/%m/%Y %H:%M:%S.%f\"):\n    try:\n        time_objects = [time.strptime(time_string, time_format) for time_string in time_strings]\n        seconds = [time_object.tm_sec for time_object in time_objects]\n        ax = plt.hist(seconds, bins=24)\n        return ax\n    except ValueError:\n        raise ValueError(\"If any time string in 'time_strings' cannot be parsed according to 'time_format'.\")", "raw_solution": "import time\nimport matplotlib.pyplot as plt\n\ndef task_func(time_strings, time_format=\"%d/%m/%Y %H:%M:%S.%f\"):\n    try:\n        time_objects = [time.strptime(time_string, time_format) for time_string in time_strings]\n        seconds = [time_object.tm_sec for time_object in time_objects]\n        ax = plt.hist(seconds, bins=24)\n        return ax\n    except ValueError:\n        raise ValueError(\"If any time string in 'time_strings' cannot be parsed according to 'time_format'.\")\n```"}
{"task_id": "BigCodeBench/1074", "solution": "import pytz\nfrom dateutil.parser import parse\nTIME_FORMAT = \"%d/%m/%y %H:%M:%S.%f\"\ndef task_func(time_string, from_tz, to_tz):\n    # Parse the input time string\n    time = parse(time_string)\n    # Convert the time to the source timezone\n    from_tz = pytz.timezone(from_tz)\n    time = from_tz.localize(time)\n    # Convert the time to the target timezone\n    to_tz = pytz.timezone(to_tz)\n    time = time.astimezone(to_tz)\n    # Format the output time string\n    return time.strftime(TIME_FORMAT)", "raw_solution": "import pytz\nfrom dateutil.parser import parse\n# Constants\nTIME_FORMAT = \"%d/%m/%y %H:%M:%S.%f\"\ndef task_func(time_string, from_tz, to_tz):\n    # Parse the input time string\n    time = parse(time_string)\n    # Convert the time to the source timezone\n    from_tz = pytz.timezone(from_tz)\n    time = from_tz.localize(time)\n    # Convert the time to the target timezone\n    to_tz = pytz.timezone(to_tz)\n    time = time.astimezone(to_tz)\n    # Format the output time string\n    return time.strftime(TIME_FORMAT)\n```"}
{"task_id": "BigCodeBench/1075", "solution": "import datetime\nimport numpy as np\nimport matplotlib.pyplot as plt\nTIME_FORMAT = \"%d/%m/%y %H:%M:%S.%f\"\ndef task_func(time_strings):\n    # Convert the input list of datetime strings to datetime objects\n    datetime_list = [datetime.datetime.strptime(time_string, TIME_FORMAT) for time_string in time_strings]\n    # Calculate the time differences between each pair of consecutive datetime objects\n    time_diffs = [datetime_list[i+1] - datetime_list[i] for i in range(len(datetime_list)-1)]\n    # Convert the time differences to seconds\n    time_diffs = [time_diff.total_seconds() for time_diff in time_diffs]\n    # Create a bar chart of the time differences\n    plt.bar(range(len(time_diffs)), time_diffs)\n    # Set the x-axis labels to the corresponding datetime strings\n    plt.xticks(range(len(time_diffs)), [time_string.strftime(TIME_FORMAT) for time_string in datetime_list[1:]])\n    # Set the y-axis label to the time differences in seconds\n    plt.ylabel('Time difference (seconds)')\n    # Show the plot\n    plt.show()\n    # Return the axes object of the plotted bar chart\n    return plt.gca()", "raw_solution": "import datetime\nimport numpy as np\nimport matplotlib.pyplot as plt\n# Constants\nTIME_FORMAT = \"%d/%m/%y %H:%M:%S.%f\"\ndef task_func(time_strings):\n    # Convert the input list of datetime strings to datetime objects\n    datetime_list = [datetime.datetime.strptime(time_string, TIME_FORMAT) for time_string in time_strings]\n    # Calculate the time differences between each pair of consecutive datetime objects\n    time_diffs = [datetime_list[i+1] - datetime_list[i] for i in range(len(datetime_list)-1)]\n    # Convert the time differences to seconds\n    time_diffs = [time_diff.total_seconds() for time_diff in time_diffs]\n    # Create a bar chart of the time differences\n    plt.bar(range(len(time_diffs)), time_diffs)\n    # Set the x-axis labels to the corresponding datetime strings\n    plt.xticks(range(len(time_diffs)), [time_string.strftime(TIME_FORMAT) for time_string in datetime_list[1:]])\n    # Set the y-axis label to the time differences in seconds\n    plt.ylabel('Time difference (seconds)')\n    # Show the plot\n    plt.show()\n    # Return the axes object of the plotted bar chart\n    return plt.gca()\n```"}
{"task_id": "BigCodeBench/1076", "solution": "from datetime import datetime\nimport pandas as pd\nTIME_FORMAT = \"%d/%m/%y %H:%M:%S.%f\"\ndef task_func(time_strings, target_tz):\n    # Convert the target timezone to a ZoneInfo object\n    target_tz = ZoneInfo(target_tz)\n    # Create an empty DataFrame to store the results\n    df = pd.DataFrame(columns=['Original Time', 'Converted Time'])\n    # Loop through each UTC time string in the input list\n    for time_str in time_strings:\n        # Convert the UTC time string to a datetime object\n        utc_time = datetime.strptime(time_str, TIME_FORMAT)\n        # Convert the datetime object to the target timezone\n        converted_time = utc_time.astimezone(target_tz)\n        # Append the original and converted time strings to the DataFrame\n        df = df.append({'Original Time': time_str, 'Converted Time': converted_time.strftime(TIME_FORMAT)}, ignore_index=True)\n    return df", "raw_solution": "from datetime import datetime\nimport pandas as pd\n# For Python versions lower than 3.9, use 'pytz' instead of 'zoneinfo'\ntry:\n    from zoneinfo import ZoneInfo\nexcept ImportError:\n    from pytz import timezone as ZoneInfo\nTIME_FORMAT = \"%d/%m/%y %H:%M:%S.%f\"\ndef task_func(time_strings, target_tz):\n    # Convert the target timezone to a ZoneInfo object\n    target_tz = ZoneInfo(target_tz)\n    # Create an empty DataFrame to store the results\n    df = pd.DataFrame(columns=['Original Time', 'Converted Time'])\n    # Loop through each UTC time string in the input list\n    for time_str in time_strings:\n        # Convert the UTC time string to a datetime object\n        utc_time = datetime.strptime(time_str, TIME_FORMAT)\n        # Convert the datetime object to the target timezone\n        converted_time = utc_time.astimezone(target_tz)\n        # Append the original and converted time strings to the DataFrame\n        df = df.append({'Original Time': time_str, 'Converted Time': converted_time.strftime(TIME_FORMAT)}, ignore_index=True)\n    return df\n```"}
{"task_id": "BigCodeBench/1077", "solution": "from datetime import datetime\nimport pytz\nimport numpy as np\ndef task_func(time_strings, timezone):\n    # Convert each timestamp to the specified timezone\n    timezones = [pytz.timezone(timezone) for time_string in time_strings]\n    time_stamps = [datetime.strptime(time_string, '%Y-%m-%d %H:%M:%S').replace(tzinfo=timezone) for time_string, timezone in zip(time_strings, timezones)]\n    \n    # Calculate the absolute time difference in seconds between each consecutive pair of timestamps\n    time_diffs = [abs(time_stamps[i+1] - time_stamps[i]) for i in range(len(time_stamps)-1)]\n    \n    # Return the mean (average) time difference\n    return np.mean(time_diffs) if time_diffs else 0.0", "raw_solution": "from datetime import datetime\nimport pytz\nimport numpy as np\n\ndef task_func(time_strings, timezone):\n    # Convert each timestamp to the specified timezone\n    timezones = [pytz.timezone(timezone) for time_string in time_strings]\n    time_stamps = [datetime.strptime(time_string, '%Y-%m-%d %H:%M:%S').replace(tzinfo=timezone) for time_string, timezone in zip(time_strings, timezones)]\n    \n    # Calculate the absolute time difference in seconds between each consecutive pair of timestamps\n    time_diffs = [abs(time_stamps[i+1] - time_stamps[i]) for i in range(len(time_stamps)-1)]\n    \n    # Return the mean (average) time difference\n    return np.mean(time_diffs) if time_diffs else 0.0\n```"}
{"task_id": "BigCodeBench/1078", "solution": "import numpy as np\nimport matplotlib.pyplot as plt\ndef task_func(arr):\n    unique, counts = np.unique(arr, return_counts=True)\n    uniform_distribution = np.all(counts == counts[0])\n    ax = plt.hist(unique, bins=np.arange(len(unique) + 1) - 0.5)\n    return uniform_distribution, ax", "raw_solution": "import numpy as np\nimport matplotlib.pyplot as plt\n\ndef task_func(arr):\n    unique, counts = np.unique(arr, return_counts=True)\n    uniform_distribution = np.all(counts == counts[0])\n    ax = plt.hist(unique, bins=np.arange(len(unique) + 1) - 0.5)\n    return uniform_distribution, ax\n```"}
{"task_id": "BigCodeBench/1079", "solution": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\ndef task_func(data):\n    # Convert string prices to float\n    data['Price'] = data['Price'].str.replace(',', '').astype(float)\n    \n    # Calculate statistical measures\n    mean = data['Price'].mean()\n    median = data['Price'].median()\n    std_dev = data['Price'].std()\n    \n    # Generate histogram\n    fig, ax = plt.subplots()\n    ax.hist(data['Price'], bins='auto', color='blue', alpha=0.7, rwidth=0.85)\n    ax.set_title('Histogram of Product Prices')\n    ax.set_xlabel('Price')\n    ax.set_ylabel('Frequency')\n    \n    return {'mean': mean, 'median': median, 'std_dev': std_dev}, ax", "raw_solution": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef task_func(data):\n    # Convert string prices to float\n    data['Price'] = data['Price'].str.replace(',', '').astype(float)\n    \n    # Calculate statistical measures\n    mean = data['Price'].mean()\n    median = data['Price'].median()\n    std_dev = data['Price'].std()\n    \n    # Generate histogram\n    fig, ax = plt.subplots()\n    ax.hist(data['Price'], bins='auto', color='blue', alpha=0.7, rwidth=0.85)\n    ax.set_title('Histogram of Product Prices')\n    ax.set_xlabel('Price')\n    ax.set_ylabel('Frequency')\n    \n    return {'mean': mean, 'median': median, 'std_dev': std_dev}, ax\n```"}
{"task_id": "BigCodeBench/1080", "solution": "import pandas as pd\nfrom sklearn.linear_model import LinearRegression\nDATA = {\n    \"Area_String\": [\"1,000\", \"2,000\", \"3,000\", \"4,000\", \"5,000\"],\n    \"Price\": [100, 200, 300, 400, 500],\n}\ndef task_func(area_string, data=DATA):\n    df = pd.DataFrame(data)\n    df['Area'] = df['Area_String'].astype(float)\n    model = LinearRegression()\n    model.fit(df[['Area']], df['Price'])\n    return model.predict([[float(area_string)]])[0]", "raw_solution": "import pandas as pd\nfrom sklearn.linear_model import LinearRegression\nDATA = {\n    \"Area_String\": [\"1,000\", \"2,000\", \"3,000\", \"4,000\", \"5,000\"],\n    \"Price\": [100, 200, 300, 400, 500],\n}\ndef task_func(area_string, data=DATA):\n    df = pd.DataFrame(data)\n    df['Area'] = df['Area_String'].astype(float)\n    model = LinearRegression()\n    model.fit(df[['Area']], df['Price'])\n    return model.predict([[float(area_string)]])[0]\n```"}
{"task_id": "BigCodeBench/1081", "solution": "import pandas as pd\nimport seaborn as sns\ndef task_func(data=None):\n    if data is None:\n        data = {'Weight_String': ['150', '160', '170', '180', '190'], 'Height': [5.5, 5.6, 5.7, 5.8, 5.9]}\n    df = pd.DataFrame(data)\n    df['Weight'] = df['Weight_String'].astype(float)\n    ax = sns.scatterplot(x='Weight', y='Height', data=df)\n    ax.set_title('Weight vs Height')\n    return ax", "raw_solution": "import pandas as pd\nimport seaborn as sns\ndef task_func(data=None):\n    if data is None:\n        data = {'Weight_String': ['150', '160', '170', '180', '190'], 'Height': [5.5, 5.6, 5.7, 5.8, 5.9]}\n    df = pd.DataFrame(data)\n    df['Weight'] = df['Weight_String'].astype(float)\n    ax = sns.scatterplot(x='Weight', y='Height', data=df)\n    ax.set_title('Weight vs Height')\n    return ax\n```"}
{"task_id": "BigCodeBench/1082", "solution": "import pandas as pd\nfrom scipy.stats import pearsonr\ndef task_func(data):\n    if data.shape[0] < 2:\n        return float('nan')\n    scores = data['scores'].astype(float)\n    grades = data['grades'].astype(str)\n    grade_map = {'A': 1, 'B': 2, 'C': 3, 'D': 4, 'F': 5}\n    encoded_grades = [grade_map[grade] for grade in grades]\n    correlation, _ = pearsonr(scores, encoded_grades)\n    return correlation", "raw_solution": "import pandas as pd\nfrom scipy.stats import pearsonr\n\ndef task_func(data):\n    if data.shape[0] < 2:\n        return float('nan')\n    scores = data['scores'].astype(float)\n    grades = data['grades'].astype(str)\n    grade_map = {'A': 1, 'B': 2, 'C': 3, 'D': 4, 'F': 5}\n    encoded_grades = [grade_map[grade] for grade in grades]\n    correlation, _ = pearsonr(scores, encoded_grades)\n    return correlation\n```"}
{"task_id": "BigCodeBench/1083", "solution": "import pandas as pd\nfrom sklearn.preprocessing import MinMaxScaler\nimport matplotlib.pyplot as plt\ndef task_func(data):\n    if 'Salary_String' not in data or 'Experience' not in data:\n        raise ValueError('Input dictionary must contain the required keys')\n    df = pd.DataFrame(data)\n    if df.empty:\n        return plt.axes()\n    try:\n        df['Salary'] = df['Salary_String'].str.replace(',', '').astype(float)\n    except ValueError as e:\n        raise ValueError('Error converting salary string to float: ' + str(e))\n    scaler = MinMaxScaler()\n    df['Salary'] = scaler.fit_transform(df[['Salary']])\n    plt.scatter(df['Experience'], df['Salary'])\n    plt.xlabel('Experience')\n    plt.ylabel('Normalized Salary')\n    return plt.axes()", "raw_solution": "import pandas as pd\nfrom sklearn.preprocessing import MinMaxScaler\nimport matplotlib.pyplot as plt\n\ndef task_func(data):\n    if 'Salary_String' not in data or 'Experience' not in data:\n        raise ValueError('Input dictionary must contain the required keys')\n    df = pd.DataFrame(data)\n    if df.empty:\n        return plt.axes()\n    try:\n        df['Salary'] = df['Salary_String'].str.replace(',', '').astype(float)\n    except ValueError as e:\n        raise ValueError('Error converting salary string to float: ' + str(e))\n    scaler = MinMaxScaler()\n    df['Salary'] = scaler.fit_transform(df[['Salary']])\n    plt.scatter(df['Experience'], df['Salary'])\n    plt.xlabel('Experience')\n    plt.ylabel('Normalized Salary')\n    return plt.axes()\n```"}
{"task_id": "BigCodeBench/1084", "solution": "import pandas as pd\nfrom sklearn.feature_selection import f_oneway\nimport matplotlib.pyplot as plt\ndef task_func(data_file_path: str):\n    # Read the CSV file\n    df = pd.read_csv(data_file_path)\n    \n    # Convert string representations of numbers with commas into floating point numbers\n    df = df.apply(pd.to_numeric, errors='coerce')\n    \n    # Calculate the mean and standard deviation for each numerical column\n    means = df.mean()\n    std_devs = df.std()\n    \n    # Generate a histogram plot for each numerical column\n    axes = []\n    for col in df.columns:\n        if pd.api.types.is_numeric_dtype(df[col]):\n            axes.append(df[col].hist(bins=30))\n    \n    # Perform an ANOVA test to check the statistical significance of differences between means of numerical columns (if applicable)\n    if len(df.columns) > 1:\n        f_stat, p_val = f_oneway(*[df[col] for col in df.columns])\n        anova_results = pd.DataFrame({'F-value': [f_stat], 'P-value': [p_val]})\n    else:\n        anova_results = pd.DataFrame()\n    \n    return means, std_devs, axes, anova_results", "raw_solution": "import pandas as pd\nfrom sklearn.feature_selection import f_oneway\nimport matplotlib.pyplot as plt\n\ndef task_func(data_file_path: str):\n    # Read the CSV file\n    df = pd.read_csv(data_file_path)\n    \n    # Convert string representations of numbers with commas into floating point numbers\n    df = df.apply(pd.to_numeric, errors='coerce')\n    \n    # Calculate the mean and standard deviation for each numerical column\n    means = df.mean()\n    std_devs = df.std()\n    \n    # Generate a histogram plot for each numerical column\n    axes = []\n    for col in df.columns:\n        if pd.api.types.is_numeric_dtype(df[col]):\n            axes.append(df[col].hist(bins=30))\n    \n    # Perform an ANOVA test to check the statistical significance of differences between means of numerical columns (if applicable)\n    if len(df.columns) > 1:\n        f_stat, p_val = f_oneway(*[df[col] for col in df.columns])\n        anova_results = pd.DataFrame({'F-value': [f_stat], 'P-value': [p_val]})\n    else:\n        anova_results = pd.DataFrame()\n    \n    return means, std_devs, axes, anova_results\n```"}
{"task_id": "BigCodeBench/1085", "solution": "import re\nfrom collections import Counter\nimport matplotlib.pyplot as plt\ndef task_func(text):\n    # Lowercase the text\n    text = text.lower()\n    # Remove punctuation\n    text = re.sub(r'[^\\w\\s]', '', text)\n    # Split into words\n    words = text.split()\n    # Count the frequency of each word\n    word_counts = Counter(words)\n    # Get the top 10 most common words\n    top_10_words = word_counts.most_common(10)\n    # Create a bar chart of the top 10 most common words\n    fig, ax = plt.subplots()\n    ax.bar([word for word, count in top_10_words], [count for word, count in top_10_words])\n    ax.set_xlabel('Word')\n    ax.set_ylabel('Count')\n    ax.set_title('Top 10 Most Common Words')\n    return top_10_words, ax", "raw_solution": "import re\nfrom collections import Counter\nimport matplotlib.pyplot as plt\n\ndef task_func(text):\n    # Lowercase the text\n    text = text.lower()\n    # Remove punctuation\n    text = re.sub(r'[^\\w\\s]', '', text)\n    # Split into words\n    words = text.split()\n    # Count the frequency of each word\n    word_counts = Counter(words)\n    # Get the top 10 most common words\n    top_10_words = word_counts.most_common(10)\n    # Create a bar chart of the top 10 most common words\n    fig, ax = plt.subplots()\n    ax.bar([word for word, count in top_10_words], [count for word, count in top_10_words])\n    ax.set_xlabel('Word')\n    ax.set_ylabel('Count')\n    ax.set_title('Top 10 Most Common Words')\n    return top_10_words, ax\n```"}
{"task_id": "BigCodeBench/1086", "solution": "import string\nimport random\nimport pandas as pd\nimport numpy as np\nNUM_SAMPLES = 1000\ndef task_func():\n    # Generate random strings\n    string_field = [random.choice(string.ascii_letters) for _ in range(NUM_SAMPLES)]\n    \n    # Generate random floats\n    float_field = [round(random.uniform(0, 10000), 2) for _ in range(NUM_SAMPLES)]\n    \n    # Create DataFrame\n    df = pd.DataFrame({'String Field': string_field, 'Float Field': float_field})\n    \n    return df", "raw_solution": "import string\nimport random\nimport pandas as pd\nimport numpy as np\n# Constants\nNUM_SAMPLES = 1000  # Number of samples\n\ndef task_func():\n    # Generate random strings\n    string_field = [random.choice(string.ascii_letters) for _ in range(NUM_SAMPLES)]\n    \n    # Generate random floats\n    float_field = [round(random.uniform(0, 10000), 2) for _ in range(NUM_SAMPLES)]\n    \n    # Create DataFrame\n    df = pd.DataFrame({'String Field': string_field, 'Float Field': float_field})\n    \n    return df\n```"}
{"task_id": "BigCodeBench/1087", "solution": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy import stats\ndef task_func(mean=123456.908, std_dev=1.2, save_plots=False):\n    sample = np.random.normal(mean, std_dev, 1000)\n    skewness = stats.skew(sample)\n    kurtosis = stats.kurtosis(sample)\n    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n    ax1.hist(sample, bins=50)\n    ax1.set_title('Histogram')\n    ax2.plot(stats.probplot(sample, dist='norm', plot=ax2))\n    ax2.set_title('QQ Plot')\n    if save_plots:\n        plt.savefig('histogram.png')\n        plt.savefig('qq_plot.png')\n    return skewness, kurtosis, [f'histogram.png', f'qq_plot.png']", "raw_solution": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy import stats\ndef task_func(mean=123456.908, std_dev=1.2, save_plots=False):\n    sample = np.random.normal(mean, std_dev, 1000)\n    skewness = stats.skew(sample)\n    kurtosis = stats.kurtosis(sample)\n    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n    ax1.hist(sample, bins=50)\n    ax1.set_title('Histogram')\n    ax2.plot(stats.probplot(sample, dist='norm', plot=ax2))\n    ax2.set_title('QQ Plot')\n    if save_plots:\n        plt.savefig('histogram.png')\n        plt.savefig('qq_plot.png')\n    return skewness, kurtosis, [f'histogram.png', f'qq_plot.png']\n```"}
{"task_id": "BigCodeBench/1088", "solution": "import numpy as np\nimport pandas as pd\nfrom sklearn.preprocessing import StandardScaler\ndef task_func(data=None):\n    if data is None:\n        data = np.random.rand(10, 5)\n    df = pd.DataFrame(data)\n    df[df < 0.5] = 0\n    scaler = StandardScaler()\n    df = scaler.fit_transform(df)\n    return df", "raw_solution": "import numpy as np\nimport pandas as pd\nfrom sklearn.preprocessing import StandardScaler\n\ndef task_func(data=None):\n    if data is None:\n        data = np.random.rand(10, 5)\n    df = pd.DataFrame(data)\n    df[df < 0.5] = 0\n    scaler = StandardScaler()\n    df = scaler.fit_transform(df)\n    return df\n```"}
{"task_id": "BigCodeBench/1089", "solution": "import numpy as np\nfrom collections import Counter\ndef task_func(list_of_tuples):\n    sum_of_values = np.sum([t[0] for t in list_of_tuples])\n    category_counts = Counter([t[1] for t in list_of_tuples])\n    return (sum_of_values, category_counts)", "raw_solution": "import numpy as np\nfrom collections import Counter\n\ndef task_func(list_of_tuples):\n    sum_of_values = np.sum([t[0] for t in list_of_tuples])\n    category_counts = Counter([t[1] for t in list_of_tuples])\n    return (sum_of_values, category_counts)\n```"}
{"task_id": "BigCodeBench/1090", "solution": "import ast\nimport json\nfrom collections import Counter\ndef task_func(file_pointer):\n    # Read the JSON data from the file pointer\n    data = json.load(file_pointer)\n    \n    # Initialize a Counter object to store the frequency of each key\n    key_freq = Counter()\n    \n    # Iterate over each dictionary in the JSON data\n    for item in data:\n        # Evaluate the string representation of the dictionary to a dictionary\n        item_dict = ast.literal_eval(item)\n        \n        # Iterate over each key in the dictionary\n        for key in item_dict:\n            # Update the frequency of the key in the Counter object\n            key_freq[key] += 1\n    \n    # Return the Counter object\n    return key_freq", "raw_solution": "import ast\nimport json\nfrom collections import Counter\n\ndef task_func(file_pointer):\n    # Read the JSON data from the file pointer\n    data = json.load(file_pointer)\n    \n    # Initialize a Counter object to store the frequency of each key\n    key_freq = Counter()\n    \n    # Iterate over each dictionary in the JSON data\n    for item in data:\n        # Evaluate the string representation of the dictionary to a dictionary\n        item_dict = ast.literal_eval(item)\n        \n        # Iterate over each key in the dictionary\n        for key in item_dict:\n            # Update the frequency of the key in the Counter object\n            key_freq[key] += 1\n    \n    # Return the Counter object\n    return key_freq\n```"}
{"task_id": "BigCodeBench/1091", "solution": "import ast\nimport os\nimport glob\ndef task_func(directory):\n    # Initialize an empty list to store the dictionaries\n    dictionaries = []\n    # Loop through all text files in the directory\n    for file in glob.glob(os.path.join(directory, '*.txt')):\n        # Open the file and read its contents\n        with open(file, 'r') as f:\n            content = f.read()\n        # Try to parse the content as a dictionary\n        try:\n            # Parse the content as a dictionary\n            dictionary = ast.literal_eval(content)\n            # Append the dictionary to the list\n            dictionaries.append(dictionary)\n        except ValueError:\n            # Raise an exception if the content is not a valid dictionary\n            raise ValueError(f\"Invalid dictionary representation in file {file}\")\n    # Return the list of dictionaries\n    return dictionaries", "raw_solution": "import ast\nimport os\nimport glob\n# Constants\nDIRECTORY = 'data'\ndef task_func(directory):\n    # Initialize an empty list to store the dictionaries\n    dictionaries = []\n    # Loop through all text files in the directory\n    for file in glob.glob(os.path.join(directory, '*.txt')):\n        # Open the file and read its contents\n        with open(file, 'r') as f:\n            content = f.read()\n        # Try to parse the content as a dictionary\n        try:\n            # Parse the content as a dictionary\n            dictionary = ast.literal_eval(content)\n            # Append the dictionary to the list\n            dictionaries.append(dictionary)\n        except ValueError:\n            # Raise an exception if the content is not a valid dictionary\n            raise ValueError(f\"Invalid dictionary representation in file {file}\")\n    # Return the list of dictionaries\n    return dictionaries\n```"}
{"task_id": "BigCodeBench/1092", "solution": "import ast\nimport requests\nfrom bs4 import BeautifulSoup\ndef task_func(url):\n    try:\n        response = requests.get(url)\n        soup = BeautifulSoup(response.text, 'html.parser')\n        scripts = soup.find_all('script')\n        result = []\n        for script in scripts:\n            script_text = script.string\n            if script_text:\n                try:\n                    script_dict = ast.literal_eval(script_text)\n                    result.append(script_dict)\n                except (SyntaxError, ValueError):\n                    pass\n        return result\n    except Exception as e:\n        print(f\"Error: {e}\")\n        return []", "raw_solution": "import ast\nimport requests\nfrom bs4 import BeautifulSoup\n\ndef task_func(url):\n    try:\n        response = requests.get(url)\n        soup = BeautifulSoup(response.text, 'html.parser')\n        scripts = soup.find_all('script')\n        result = []\n        for script in scripts:\n            script_text = script.string\n            if script_text:\n                try:\n                    script_dict = ast.literal_eval(script_text)\n                    result.append(script_dict)\n                except (SyntaxError, ValueError):\n                    pass\n        return result\n    except Exception as e:\n        print(f\"Error: {e}\")\n        return []\n```"}
{"task_id": "BigCodeBench/1093", "solution": "import ast\nimport re\ndef task_func(text_file: str) -> list:\n    with open(text_file, 'r') as f:\n        text = f.read()\n    pattern = r'\\{.*?\\}'\n    matches = re.findall(pattern, text)\n    return [ast.literal_eval(match) for match in matches]", "raw_solution": "import ast\nimport re\n\ndef task_func(text_file: str) -> list:\n    with open(text_file, 'r') as f:\n        text = f.read()\n    pattern = r'\\{.*?\\}'\n    matches = re.findall(pattern, text)\n    return [ast.literal_eval(match) for match in matches]\n```"}
{"task_id": "BigCodeBench/1094", "solution": "from nltk.tokenize import RegexpTokenizer\nfrom collections import Counter\ndef task_func(text):\n    tokenizer = RegexpTokenizer(r'\\b\\$\\w+\\b')\n    words = tokenizer.tokenize(text)\n    words = [word for word in words if word != '$']\n    word_counts = Counter(words)\n    most_common_words = word_counts.most_common(5)\n    return most_common_words", "raw_solution": "from nltk.tokenize import RegexpTokenizer\nfrom collections import Counter\n\ndef task_func(text):\n    tokenizer = RegexpTokenizer(r'\\b\\$\\w+\\b')\n    words = tokenizer.tokenize(text)\n    words = [word for word in words if word != '$']\n    word_counts = Counter(words)\n    most_common_words = word_counts.most_common(5)\n    return most_common_words\n```"}
{"task_id": "BigCodeBench/1095", "solution": "from nltk.tokenize import RegexpTokenizer\nfrom string import punctuation\nimport os\ndef task_func(text, output_filename):\n    tokenizer = RegexpTokenizer(r'\\b\\w+\\b')\n    words = tokenizer.tokenize(text)\n    words = [word for word in words if word[0] == '$' and word not in punctuation]\n    with open(output_filename, 'w') as f:\n        for word in words:\n            f.write(word + '\\n')\n    return os.path.abspath(output_filename)", "raw_solution": "from nltk.tokenize import RegexpTokenizer\nfrom string import punctuation\nimport os\n\ndef task_func(text, output_filename):\n    tokenizer = RegexpTokenizer(r'\\b\\w+\\b')\n    words = tokenizer.tokenize(text)\n    words = [word for word in words if word[0] == '$' and word not in punctuation]\n    with open(output_filename, 'w') as f:\n        for word in words:\n            f.write(word + '\\n')\n    return os.path.abspath(output_filename)\n```"}
{"task_id": "BigCodeBench/1096", "solution": "from nltk.tokenize import RegexpTokenizer\nfrom string import punctuation\nimport csv\nimport os\nPUNCTUATION = set(punctuation)\ndef task_func(text, filename):\n    tokenizer = RegexpTokenizer(r'\\b\\w+\\b')\n    words = tokenizer.tokenize(text)\n    words = [word for word in words if word[0] == '$' and word not in PUNCTUATION]\n    with open(filename, 'w', newline='') as f:\n        writer = csv.writer(f)\n        writer.writerow(['Word'])\n        writer.writerows([[word] for word in words])\n    return os.path.abspath(filename)", "raw_solution": "from nltk.tokenize import RegexpTokenizer\nfrom string import punctuation\nimport csv\nimport os\nPUNCTUATION = set(punctuation)\ndef task_func(text, filename):\n    tokenizer = RegexpTokenizer(r'\\b\\w+\\b')\n    words = tokenizer.tokenize(text)\n    words = [word for word in words if word[0] == '$' and word not in PUNCTUATION]\n    with open(filename, 'w', newline='') as f:\n        writer = csv.writer(f)\n        writer.writerow(['Word'])\n        writer.writerows([[word] for word in words])\n    return os.path.abspath(filename)\n```"}
{"task_id": "BigCodeBench/1097", "solution": "import re\nfrom string import punctuation\nPREDEFINED_STOPWORDS = {\n    \"i\", \"me\", \"my\", \"myself\", \"we\", \"our\", \"ours\", \"ourselves\", \"you\", \"your\", \"yours\", \n    \"yourself\", \"yourselves\", \"he\", \"him\", \"his\", \"himself\", \"she\", \"her\", \"hers\", \n    \"herself\", \"it\", \"its\", \"itself\", \"they\", \"them\", \"their\", \"theirs\", \"themselves\", \n    \"what\", \"which\", \"who\", \"whom\", \"this\", \"that\", \"these\", \"those\", \"am\", \"is\", \"are\", \n    \"was\", \"were\", \"be\", \"been\", \"being\", \"have\", \"has\", \"had\", \"having\", \"do\", \"does\", \n    \"did\", \"doing\", \"a\", \"an\", \"the\", \"and\", \"but\", \"if\", \"or\", \"because\", \"as\", \"until\", \n    \"while\", \"of\", \"at\", \"by\", \"for\", \"with\", \"about\", \"against\", \"between\", \"into\", \n    \"through\", \"during\", \"before\", \"after\", \"above\", \"below\", \"to\", \"from\", \"up\", \"down\", \n    \"in\", \"out\", \"on\", \"off\", \"over\", \"under\", \"again\", \"further\", \"then\", \"once\", \"more\"\n}\ndef task_func(text):\n    # Remove URLs\n    text = re.sub(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', '', text)\n    # Remove punctuation\n    text = ''.join([char for char in text if char not in punctuation])\n    # Remove stopwords\n    text = ' '.join([word for word in text.split() if word.lower() not in PREDEFINED_STOPWORDS])\n    return text", "raw_solution": "import re\nfrom string import punctuation\n# Predefined list of common stopwords\nPREDEFINED_STOPWORDS = {\n    \"i\", \"me\", \"my\", \"myself\", \"we\", \"our\", \"ours\", \"ourselves\", \"you\", \"your\", \"yours\", \n    \"yourself\", \"yourselves\", \"he\", \"him\", \"his\", \"himself\", \"she\", \"her\", \"hers\", \n    \"herself\", \"it\", \"its\", \"itself\", \"they\", \"them\", \"their\", \"theirs\", \"themselves\", \n    \"what\", \"which\", \"who\", \"whom\", \"this\", \"that\", \"these\", \"those\", \"am\", \"is\", \"are\", \n    \"was\", \"were\", \"be\", \"been\", \"being\", \"have\", \"has\", \"had\", \"having\", \"do\", \"does\", \n    \"did\", \"doing\", \"a\", \"an\", \"the\", \"and\", \"but\", \"if\", \"or\", \"because\", \"as\", \"until\", \n    \"while\", \"of\", \"at\", \"by\", \"for\", \"with\", \"about\", \"against\", \"between\", \"into\", \n    \"through\", \"during\", \"before\", \"after\", \"above\", \"below\", \"to\", \"from\", \"up\", \"down\", \n    \"in\", \"out\", \"on\", \"off\", \"over\", \"under\", \"again\", \"further\", \"then\", \"once\", \"more\"\n}\ndef task_func(text):\n    # Remove URLs\n    text = re.sub(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', '', text)\n    # Remove punctuation\n    text = ''.join([char for char in text if char not in punctuation])\n    # Remove stopwords\n    text = ' '.join([word for word in text.split() if word.lower() not in PREDEFINED_STOPWORDS])\n    return text\n```"}
{"task_id": "BigCodeBench/1098", "solution": "import re\nfrom collections import Counter\ndef task_func(text, top_n):\n    # Remove URLs from the text\n    text = re.sub(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', '', text)\n    # Split the text into words\n    words = text.split()\n    # Count the frequency of each word\n    word_counts = Counter(words)\n    # Return the top N most common words\n    return word_counts.most_common(top_n)", "raw_solution": "import re\nfrom collections import Counter\ndef task_func(text, top_n):\n    # Remove URLs from the text\n    text = re.sub(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', '', text)\n    # Split the text into words\n    words = text.split()\n    # Count the frequency of each word\n    word_counts = Counter(words)\n    # Return the top N most common words\n    return word_counts.most_common(top_n)\n```"}
{"task_id": "BigCodeBench/1099", "solution": "import re\nfrom collections import Counter\nPREDEFINED_STOPWORDS = {\n    \"i\", \"me\", \"my\", \"myself\", \"we\", \"our\", \"ours\", \"ourselves\", \"you\", \"your\", \"yours\", \n    \"yourself\", \"yourselves\", \"he\", \"him\", \"his\", \"himself\", \"she\", \"her\", \"hers\", \n    \"herself\", \"it\", \"its\", \"itself\", \"they\", \"them\", \"their\", \"theirs\", \"themselves\", \n    \"what\", \"which\", \"who\", \"whom\", \"this\", \"that\", \"these\", \"those\", \"am\", \"is\", \"are\", \n    \"was\", \"were\", \"be\", \"been\", \"being\", \"have\", \"has\", \"had\", \"having\", \"do\", \"does\", \n    \"did\", \"doing\", \"a\", \"an\", \"the\", \"and\", \"but\", \"if\", \"or\", \"because\", \"as\", \"until\", \n    \"while\", \"of\", \"at\", \"by\", \"for\", \"with\", \"about\", \"against\", \"between\", \"into\", \n    \"through\", \"during\", \"before\", \"after\", \"above\", \"below\", \"to\", \"from\", \"up\", \"down\", \n    \"in\", \"out\", \"on\", \"off\", \"over\", \"under\", \"again\", \"further\", \"then\", \"once\", \"more\"\n}\ndef task_func(text):\n    # Remove URLs from the text\n    text = re.sub(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', '', text)\n    # Split the text into words\n    words = text.split()\n    # Remove stopwords\n    words = [word for word in words if word.lower() not in PREDEFINED_STOPWORDS]\n    # Count the frequency of each word\n    word_counts = Counter(words)\n    return list(word_counts.items())", "raw_solution": "import re\nfrom collections import Counter\n# Predefined list of common stopwords\nPREDEFINED_STOPWORDS = {\n    \"i\", \"me\", \"my\", \"myself\", \"we\", \"our\", \"ours\", \"ourselves\", \"you\", \"your\", \"yours\", \n    \"yourself\", \"yourselves\", \"he\", \"him\", \"his\", \"himself\", \"she\", \"her\", \"hers\", \n    \"herself\", \"it\", \"its\", \"itself\", \"they\", \"them\", \"their\", \"theirs\", \"themselves\", \n    \"what\", \"which\", \"who\", \"whom\", \"this\", \"that\", \"these\", \"those\", \"am\", \"is\", \"are\", \n    \"was\", \"were\", \"be\", \"been\", \"being\", \"have\", \"has\", \"had\", \"having\", \"do\", \"does\", \n    \"did\", \"doing\", \"a\", \"an\", \"the\", \"and\", \"but\", \"if\", \"or\", \"because\", \"as\", \"until\", \n    \"while\", \"of\", \"at\", \"by\", \"for\", \"with\", \"about\", \"against\", \"between\", \"into\", \n    \"through\", \"during\", \"before\", \"after\", \"above\", \"below\", \"to\", \"from\", \"up\", \"down\", \n    \"in\", \"out\", \"on\", \"off\", \"over\", \"under\", \"again\", \"further\", \"then\", \"once\", \"more\"\n}\ndef task_func(text):\n    # Remove URLs from the text\n    text = re.sub(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', '', text)\n    # Split the text into words\n    words = text.split()\n    # Remove stopwords\n    words = [word for word in words if word.lower() not in PREDEFINED_STOPWORDS]\n    # Count the frequency of each word\n    word_counts = Counter(words)\n    return list(word_counts.items())\n```"}
{"task_id": "BigCodeBench/1100", "solution": "import re\nfrom sklearn.feature_extraction.text import TfidfVectorizer\ndef task_func(texts):\n    # Remove URLs from the text documents\n    texts = [re.sub(r'http\\S+', '', text) for text in texts]\n    \n    # Initialize the TfidfVectorizer\n    vectorizer = TfidfVectorizer(stop_words='english')\n    \n    # Fit and transform the text documents\n    X = vectorizer.fit_transform(texts)\n    \n    # Get the unique words (features) across all documents\n    words = vectorizer.get_feature_names_out()\n    \n    # Get the TF-IDF scores for each word in each document\n    tfidf_scores = X.toarray()\n    \n    # Round the scores to 8 decimal places for precision\n    tfidf_scores = [round(score, 8) for score in tfidf_scores]\n    \n    # Return the TF-IDF scores and the unique words\n    return (tfidf_scores, words)", "raw_solution": "import re\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\ndef task_func(texts):\n    # Remove URLs from the text documents\n    texts = [re.sub(r'http\\S+', '', text) for text in texts]\n    \n    # Initialize the TfidfVectorizer\n    vectorizer = TfidfVectorizer(stop_words='english')\n    \n    # Fit and transform the text documents\n    X = vectorizer.fit_transform(texts)\n    \n    # Get the unique words (features) across all documents\n    words = vectorizer.get_feature_names_out()\n    \n    # Get the TF-IDF scores for each word in each document\n    tfidf_scores = X.toarray()\n    \n    # Round the scores to 8 decimal places for precision\n    tfidf_scores = [round(score, 8) for score in tfidf_scores]\n    \n    # Return the TF-IDF scores and the unique words\n    return (tfidf_scores, words)\n```"}
{"task_id": "BigCodeBench/1101", "solution": "import subprocess\nimport os\nimport glob\nimport time\ndef task_func(test_dir):\n    # Get all Python files in the test directory\n    python_files = glob.glob(os.path.join(test_dir, \"*.py\"))\n    # Initialize a dictionary to store execution times\n    execution_times = {}\n    # Iterate over each Python file\n    for file in python_files:\n        # Get the file name\n        file_name = os.path.basename(file)\n        # Start the timer\n        start_time = time.time()\n        # Run the Python file using subprocess\n        subprocess.run([\"python\", file], check=True)\n        # Stop the timer\n        end_time = time.time()\n        # Calculate the execution time\n        execution_time = end_time - start_time\n        # Store the execution time in the dictionary\n        execution_times[file_name] = execution_time\n    # Return the dictionary of execution times\n    return execution_times", "raw_solution": "import subprocess\nimport os\nimport glob\nimport time\ndef task_func(test_dir):\n    # Get all Python files in the test directory\n    python_files = glob.glob(os.path.join(test_dir, \"*.py\"))\n    # Initialize a dictionary to store execution times\n    execution_times = {}\n    # Iterate over each Python file\n    for file in python_files:\n        # Get the file name\n        file_name = os.path.basename(file)\n        # Start the timer\n        start_time = time.time()\n        # Run the Python file using subprocess\n        subprocess.run([\"python\", file], check=True)\n        # Stop the timer\n        end_time = time.time()\n        # Calculate the execution time\n        execution_time = end_time - start_time\n        # Store the execution time in the dictionary\n        execution_times[file_name] = execution_time\n    # Return the dictionary of execution times\n    return execution_times\n```"}
{"task_id": "BigCodeBench/1102", "solution": "import subprocess\nimport shlex\nfrom datetime import datetime\ndef task_func(script_path: str) -> dict:\n    start_time = datetime.now()\n    process = subprocess.Popen(shlex.split(f'Rscript {script_path}'), stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n    stdout, stderr = process.communicate()\n    end_time = datetime.now()\n    return {\n        'start_time': start_time,\n        'end_time': end_time,\n        'stdout': stdout.decode('utf-8'),\n        'stderr': stderr.decode('utf-8')\n    }", "raw_solution": "import subprocess\nimport shlex\nfrom datetime import datetime\n\ndef task_func(script_path: str) -> dict:\n    start_time = datetime.now()\n    process = subprocess.Popen(shlex.split(f'Rscript {script_path}'), stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n    stdout, stderr = process.communicate()\n    end_time = datetime.now()\n    return {\n        'start_time': start_time,\n        'end_time': end_time,\n        'stdout': stdout.decode('utf-8'),\n        'stderr': stderr.decode('utf-8')\n    }\n```"}
{"task_id": "BigCodeBench/1103", "solution": "import subprocess\nimport shutil\nimport os\ndef task_func(script_path: str, temp_dir: str) -> str:\n    try:\n        # Create a temporary directory\n        os.makedirs(temp_dir, exist_ok=True)\n        \n        # Copy the script to the temporary directory\n        shutil.copy(script_path, temp_dir)\n        \n        # Change the current working directory to the temporary directory\n        os.chdir(temp_dir)\n        \n        # Execute the script\n        subprocess.run(['python', script_path], check=True)\n        \n        # Return success message\n        return \"Script executed successfully!\"\n    except subprocess.CalledProcessError:\n        # Return failure message\n        return \"Script execution failed!\"", "raw_solution": "import subprocess\nimport shutil\nimport os\n\ndef task_func(script_path: str, temp_dir: str) -> str:\n    try:\n        # Create a temporary directory\n        os.makedirs(temp_dir, exist_ok=True)\n        \n        # Copy the script to the temporary directory\n        shutil.copy(script_path, temp_dir)\n        \n        # Change the current working directory to the temporary directory\n        os.chdir(temp_dir)\n        \n        # Execute the script\n        subprocess.run(['python', script_path], check=True)\n        \n        # Return success message\n        return \"Script executed successfully!\"\n    except subprocess.CalledProcessError:\n        # Return failure message\n        return \"Script execution failed!\"\n```"}
{"task_id": "BigCodeBench/1104", "solution": "import subprocess\nimport os\nimport threading\ndef task_func(script_path: str, timeout: int = 60) -> str:\n    try:\n        # Start the script in a new thread\n        process = subprocess.Popen(['python', script_path], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n        thread = threading.Thread(target=process.communicate)\n        thread.start()\n        \n        # Wait for the script to finish or timeout\n        thread.join(timeout)\n        \n        # If the script is still running, terminate it\n        if thread.is_alive():\n            process.terminate()\n            return \"Terminating process due to timeout.\"\n        else:\n            return \"Script executed successfully.\"\n    except FileNotFoundError:\n        return \"File not found.\"", "raw_solution": "import subprocess\nimport os\nimport threading\n\ndef task_func(script_path: str, timeout: int = 60) -> str:\n    try:\n        # Start the script in a new thread\n        process = subprocess.Popen(['python', script_path], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n        thread = threading.Thread(target=process.communicate)\n        thread.start()\n        \n        # Wait for the script to finish or timeout\n        thread.join(timeout)\n        \n        # If the script is still running, terminate it\n        if thread.is_alive():\n            process.terminate()\n            return \"Terminating process due to timeout.\"\n        else:\n            return \"Script executed successfully.\"\n    except FileNotFoundError:\n        return \"File not found.\"\n```"}
{"task_id": "BigCodeBench/1105", "solution": "import subprocess\nimport os\nimport time\nimport glob\ndef task_func(r_script_path: str, output_path: str, duration: int) -> (bool, str):\n    start_time = time.time()\n    try:\n        subprocess.run(['Rscript', r_script_path], check=True)\n    except subprocess.CalledProcessError:\n        return (False, 'File not generated within the specified duration.')\n    end_time = time.time()\n    if end_time - start_time > duration:\n        return (False, 'File not generated within the specified duration.')\n    if os.path.exists(output_path):\n        return (True, 'File generated successfully within the specified duration.')\n    return (False, 'File not generated within the specified duration.')", "raw_solution": "import subprocess\nimport os\nimport time\nimport glob\n\ndef task_func(r_script_path: str, output_path: str, duration: int) -> (bool, str):\n    start_time = time.time()\n    try:\n        subprocess.run(['Rscript', r_script_path], check=True)\n    except subprocess.CalledProcessError:\n        return (False, 'File not generated within the specified duration.')\n    end_time = time.time()\n    if end_time - start_time > duration:\n        return (False, 'File not generated within the specified duration.')\n    if os.path.exists(output_path):\n        return (True, 'File generated successfully within the specified duration.')\n    return (False, 'File not generated within the specified duration.')\n```"}
{"task_id": "BigCodeBench/1106", "solution": "from datetime import datetime\nimport os\nfrom pathlib import Path\nDATE_FORMAT = '%Y-%m-%d %H:%M:%S'\ndef task_func(file_path):\n    # Get the creation time of the file\n    creation_time = os.path.getctime(file_path)\n    # Convert the creation time to a formatted string\n    formatted_time = datetime.fromtimestamp(creation_time).strftime(DATE_FORMAT)\n    return formatted_time", "raw_solution": "from datetime import datetime\nimport os\nfrom pathlib import Path\n\n# Constants\nDATE_FORMAT = '%Y-%m-%d %H:%M:%S'\n\ndef task_func(file_path):\n    # Get the creation time of the file\n    creation_time = os.path.getctime(file_path)\n    # Convert the creation time to a formatted string\n    formatted_time = datetime.fromtimestamp(creation_time).strftime(DATE_FORMAT)\n    return formatted_time\n```"}
{"task_id": "BigCodeBench/1107", "solution": "from datetime import datetime\nimport pytz\nDATE_FORMAT = '%Y-%m-%d %H:%M:%S'\ndef task_func(unix_timestamp, target_timezone):\n    # Convert Unix timestamp to datetime object\n    dt = datetime.fromtimestamp(unix_timestamp)\n    \n    # Create timezone object\n    tz = pytz.timezone(target_timezone)\n    \n    # Convert datetime object to timezone-aware datetime object\n    dt = tz.localize(dt)\n    \n    # Format datetime object as string\n    return dt.strftime(DATE_FORMAT)", "raw_solution": "from datetime import datetime\nimport pytz\n\n# Constants\nDATE_FORMAT = '%Y-%m-%d %H:%M:%S'\n\ndef task_func(unix_timestamp, target_timezone):\n    # Convert Unix timestamp to datetime object\n    dt = datetime.fromtimestamp(unix_timestamp)\n    \n    # Create timezone object\n    tz = pytz.timezone(target_timezone)\n    \n    # Convert datetime object to timezone-aware datetime object\n    dt = tz.localize(dt)\n    \n    # Format datetime object as string\n    return dt.strftime(DATE_FORMAT)\n```"}
{"task_id": "BigCodeBench/1108", "solution": "from collections import Counter\nimport re\ndef task_func(result):\n    # Extract the url values from the dictionary list\n    urls = [d['url'] for d in result]\n    \n    # Count the occurrences of each url\n    url_counts = Counter(urls)\n    \n    # Find the most common url\n    most_common_url = url_counts.most_common(1)[0][0]\n    \n    # Return a dictionary with the most common url and its count\n    return {'dict': {'most_common_url': most_common_url, 'count': url_counts[most_common_url]}}", "raw_solution": "from collections import Counter\nimport re\n\ndef task_func(result):\n    # Extract the url values from the dictionary list\n    urls = [d['url'] for d in result]\n    \n    # Count the occurrences of each url\n    url_counts = Counter(urls)\n    \n    # Find the most common url\n    most_common_url = url_counts.most_common(1)[0][0]\n    \n    # Return a dictionary with the most common url and its count\n    return {'dict': {'most_common_url': most_common_url, 'count': url_counts[most_common_url]}}\n```"}
{"task_id": "BigCodeBench/1109", "solution": "import os\nfrom nltk import word_tokenize\ndef task_func(file_path='File.txt'):\n    with open(file_path, 'r') as f:\n        tokens = word_tokenize(f.read())\n    return tokens", "raw_solution": "import os\nfrom nltk import word_tokenize\ndef task_func(file_path='File.txt'):\n    with open(file_path, 'r') as f:\n        tokens = word_tokenize(f.read())\n    return tokens\n```"}
{"task_id": "BigCodeBench/1110", "solution": "from collections import Counter\nfrom operator import itemgetter\nimport itertools\ndef task_func(word_dict):\n    letter_freq = {}\n    for word in word_dict:\n        for letter in word:\n            if letter in letter_freq:\n                letter_freq[letter] += 1\n            else:\n                letter_freq[letter] = 1\n    return letter_freq", "raw_solution": "from collections import Counter\nfrom operator import itemgetter\nimport itertools\n\ndef task_func(word_dict):\n    letter_freq = {}\n    for word in word_dict:\n        for letter in word:\n            if letter in letter_freq:\n                letter_freq[letter] += 1\n            else:\n                letter_freq[letter] = 1\n    return letter_freq\n```"}
{"task_id": "BigCodeBench/1111", "solution": "from collections import Counter\nfrom operator import itemgetter\nimport itertools\nANIMAL = ['cat', 'camel', 'cow', 'dog', 'elephant', 'fox', 'giraffe', 'hippo', 'iguana', 'jaguar']\ndef task_func(animal_dict):\n    animal_dict = {k: v for k, v in animal_dict.items() if k in ANIMAL}\n    letter_counts = Counter(''.join(animal_dict.values()))\n    sorted_letter_counts = sorted(letter_counts.items(), key=itemgetter(1), reverse=True)\n    return {k: v for k, v in sorted_letter_counts}", "raw_solution": "from collections import Counter\nfrom operator import itemgetter\nimport itertools\n#CONSTANT\nANIMAL = ['cat', 'camel', 'cow', 'dog', 'elephant', 'fox', 'giraffe', 'hippo', 'iguana', 'jaguar']\n\ndef task_func(animal_dict):\n    animal_dict = {k: v for k, v in animal_dict.items() if k in ANIMAL}\n    letter_counts = Counter(''.join(animal_dict.values()))\n    sorted_letter_counts = sorted(letter_counts.items(), key=itemgetter(1), reverse=True)\n    return {k: v for k, v in sorted_letter_counts}\n```"}
{"task_id": "BigCodeBench/1112", "solution": "import csv\nimport random\nDATA = ['Temperature', 'Humidity', 'Pressure']\nRANGE = {\n    'Temperature': (-50, 50),\n    'Humidity': (0, 100),\n    'Pressure': (980, 1040)\n}\ndef task_func(file_name=\"data.csv\"):\n    with open(file_name, 'w', newline='') as file:\n        writer = csv.writer(file)\n        writer.writerow(DATA)\n        for i in range(24):\n            row = [random.randint(RANGE[data][0], RANGE[data][1]) for data in DATA]\n            writer.writerow(row)\n    return file_name", "raw_solution": "import csv\nimport random\n# Constants\nDATA = ['Temperature', 'Humidity', 'Pressure']\nRANGE = {\n    'Temperature': (-50, 50),\n    'Humidity': (0, 100),\n    'Pressure': (980, 1040)\n}\ndef task_func(file_name=\"data.csv\"):\n    with open(file_name, 'w', newline='') as file:\n        writer = csv.writer(file)\n        writer.writerow(DATA)\n        for i in range(24):\n            row = [random.randint(RANGE[data][0], RANGE[data][1]) for data in DATA]\n            writer.writerow(row)\n    return file_name\n```"}
{"task_id": "BigCodeBench/1113", "solution": "import csv\nimport collections\ndef task_func(csv_file, emp_prefix='EMP$$'):\n    with open(csv_file, newline='') as f:\n        reader = csv.reader(f)\n        next(reader)  # skip header\n        emp_count = collections.defaultdict(int)\n        for row in reader:\n            emp_id = row[0].split(emp_prefix)[1]\n            emp_count[emp_id] += 1\n    return dict(emp_count)", "raw_solution": "import csv\nimport collections\ndef task_func(csv_file, emp_prefix='EMP$$'):\n    with open(csv_file, newline='') as f:\n        reader = csv.reader(f)\n        next(reader)  # skip header\n        emp_count = collections.defaultdict(int)\n        for row in reader:\n            emp_id = row[0].split(emp_prefix)[1]\n            emp_count[emp_id] += 1\n    return dict(emp_count)\n```"}
{"task_id": "BigCodeBench/1114", "solution": "from collections import defaultdict\nfrom random import randint\ndef task_func(dict1):\n    return {k: [randint(1000, 10000) for _ in range(randint(1, 10))] for k in dict1 if k.startswith('EMP$$')}", "raw_solution": "from collections import defaultdict\nfrom random import randint\n\ndef task_func(dict1):\n    return {k: [randint(1000, 10000) for _ in range(randint(1, 10))] for k in dict1 if k.startswith('EMP$$')}\n```"}
{"task_id": "BigCodeBench/1115", "solution": "import random\nfrom string import ascii_uppercase\ndef task_func(dict1):\n    employee_ids = []\n    for department in dict1:\n        employee_ids.append(department + ''.join(random.choice(ascii_uppercase) for i in range(5)))\n    return employee_ids", "raw_solution": "import random\nfrom string import ascii_uppercase\n\ndef task_func(dict1):\n    employee_ids = []\n    for department in dict1:\n        employee_ids.append(department + ''.join(random.choice(ascii_uppercase) for i in range(5)))\n    return employee_ids\n```"}
{"task_id": "BigCodeBench/1116", "solution": "import random\nimport statistics\nAGE_RANGE = (22, 60)\ndef task_func(dict1):\n    # Generate random ages for each employee within the range [22, 60]\n    ages = [random.randint(AGE_RANGE[0], AGE_RANGE[1]) for _ in range(len(dict1))]\n    # Calculate mean, median, and mode(s) of employee ages\n    mean = statistics.mean(ages)\n    median = statistics.median(ages)\n    mode = statistics.mode(ages)\n    return (mean, median, mode)", "raw_solution": "import random\nimport statistics\n# Constants\nAGE_RANGE = (22, 60)\ndef task_func(dict1):\n    # Generate random ages for each employee within the range [22, 60]\n    ages = [random.randint(AGE_RANGE[0], AGE_RANGE[1]) for _ in range(len(dict1))]\n    # Calculate mean, median, and mode(s) of employee ages\n    mean = statistics.mean(ages)\n    median = statistics.median(ages)\n    mode = statistics.mode(ages)\n    return (mean, median, mode)\n```"}
{"task_id": "BigCodeBench/1117", "solution": "import collections\nimport random\nimport json\nPREFICES = ['EMP$$', 'MAN$$', 'DEV$$', 'HR$$']\nLEVELS = ['Junior', 'Mid', 'Senior']\ndef task_func(department_data):\n    # Initialize the output dictionary\n    output = {}\n    # Iterate over each department code\n    for prefix in PREFICES:\n        # Generate a list of employee levels for the department\n        levels = [random.choice(LEVELS) for _ in range(department_data[prefix])]\n        # Add the department code and its employee levels to the output dictionary\n        output[prefix] = levels\n    # Return the output dictionary as a JSON object\n    return json.dumps(output)", "raw_solution": "import collections\nimport random\nimport json\n# Constants\nPREFICES = ['EMP$$', 'MAN$$', 'DEV$$', 'HR$$']\nLEVELS = ['Junior', 'Mid', 'Senior']\ndef task_func(department_data):\n    # Initialize the output dictionary\n    output = {}\n    # Iterate over each department code\n    for prefix in PREFICES:\n        # Generate a list of employee levels for the department\n        levels = [random.choice(LEVELS) for _ in range(department_data[prefix])]\n        # Add the department code and its employee levels to the output dictionary\n        output[prefix] = levels\n    # Return the output dictionary as a JSON object\n    return json.dumps(output)\n```"}
{"task_id": "BigCodeBench/1118", "solution": "import json\nimport csv\nimport requests\nfrom io import StringIO\nCSV_URL = 'https://example.com/data.csv'\nJSON_FILE = 'data.json'\ndef task_func(csv_url=CSV_URL, json_file_path=JSON_FILE):\n    # Download CSV file\n    response = requests.get(csv_url)\n    response.raise_for_status()\n    csv_file = StringIO(response.text)\n    \n    # Convert CSV to JSON\n    json_data = []\n    csv_reader = csv.DictReader(csv_file)\n    for row in csv_reader:\n        json_data.append(row)\n    \n    # Save JSON to file\n    with open(json_file_path, 'w') as f:\n        json.dump(json_data, f)\n    \n    return json_file_path", "raw_solution": "import json\nimport csv\nimport requests\nfrom io import StringIO\n# Constants\nCSV_URL = 'https://example.com/data.csv'\nJSON_FILE = 'data.json'\ndef task_func(csv_url=CSV_URL, json_file_path=JSON_FILE):\n    # Download CSV file\n    response = requests.get(csv_url)\n    response.raise_for_status()\n    csv_file = StringIO(response.text)\n    \n    # Convert CSV to JSON\n    json_data = []\n    csv_reader = csv.DictReader(csv_file)\n    for row in csv_reader:\n        json_data.append(row)\n    \n    # Save JSON to file\n    with open(json_file_path, 'w') as f:\n        json.dump(json_data, f)\n    \n    return json_file_path\n```"}
{"task_id": "BigCodeBench/1119", "solution": "import codecs\nimport random\nimport string\nimport hashlib\ndef task_func(password_length=10, salt=\"salty\"):\n    # Generate a random password\n    password = ''.join(random.choice(string.ascii_letters + string.digits + string.punctuation) for i in range(password_length))\n    \n    # Hash the password using SHA256 algorithm after mixing it with a specified salt\n    hashed_password = hashlib.sha256((password + salt).encode()).hexdigest()\n    \n    return hashed_password", "raw_solution": "import codecs\nimport random\nimport string\nimport hashlib\n\ndef task_func(password_length=10, salt=\"salty\"):\n    # Generate a random password\n    password = ''.join(random.choice(string.ascii_letters + string.digits + string.punctuation) for i in range(password_length))\n    \n    # Hash the password using SHA256 algorithm after mixing it with a specified salt\n    hashed_password = hashlib.sha256((password + salt).encode()).hexdigest()\n    \n    return hashed_password\n```"}
{"task_id": "BigCodeBench/1120", "solution": "import re\nimport urllib.parse\nimport requests\nimport json\ndef task_func(myString, API_KEY):\n    urls = re.findall(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', myString)\n    geolocation_data = {}\n    for url in urls:\n        parsed_url = urllib.parse.urlparse(url)\n        domain = parsed_url.netloc\n        response = requests.get(f'http://api.ip-api.com/json/{domain}?key={API_KEY}')\n        if response.status_code == 200:\n            geolocation_data[domain] = response.json()\n        else:\n            geolocation_data[domain] = None\n    return geolocation_data", "raw_solution": "import re\nimport urllib.parse\nimport requests\nimport json\ndef task_func(myString, API_KEY):\n    urls = re.findall(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', myString)\n    geolocation_data = {}\n    for url in urls:\n        parsed_url = urllib.parse.urlparse(url)\n        domain = parsed_url.netloc\n        response = requests.get(f'http://api.ip-api.com/json/{domain}?key={API_KEY}')\n        if response.status_code == 200:\n            geolocation_data[domain] = response.json()\n        else:\n            geolocation_data[domain] = None\n    return geolocation_data\n```"}
{"task_id": "BigCodeBench/1121", "solution": "import re\nimport urllib.parse\nimport requests\nimport json\ndef task_func(myString, API_KEY):\n    urls = re.findall(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', myString)\n    geolocation_data = {}\n    for url in urls:\n        parsed_url = urllib.parse.urlparse(url)\n        domain = parsed_url.netloc\n        response = requests.get(f'http://api.ip-api.com/json/{domain}?key={API_KEY}')\n        if response.status_code == 200:\n            geolocation_data[domain] = response.json()\n        else:\n            geolocation_data[domain] = None\n    return geolocation_data", "raw_solution": "import re\nimport urllib.parse\nimport requests\nimport json\ndef task_func(myString, API_KEY):\n    urls = re.findall(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', myString)\n    geolocation_data = {}\n    for url in urls:\n        parsed_url = urllib.parse.urlparse(url)\n        domain = parsed_url.netloc\n        response = requests.get(f'http://api.ip-api.com/json/{domain}?key={API_KEY}')\n        if response.status_code == 200:\n            geolocation_data[domain] = response.json()\n        else:\n            geolocation_data[domain] = None\n    return geolocation_data\n```"}
{"task_id": "BigCodeBench/1122", "solution": "import re\nimport socket\nimport urllib.parse\ndef task_func(myString):\n    urls = re.findall(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', myString)\n    result = {}\n    for url in urls:\n        domain = urllib.parse.urlparse(url).netloc\n        try:\n            ip = socket.gethostbyname(domain)\n            result[domain] = ip\n        except socket.gaierror:\n            result[domain] = None\n    return result", "raw_solution": "import re\nimport socket\nimport urllib.parse\ndef task_func(myString):\n    urls = re.findall(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', myString)\n    result = {}\n    for url in urls:\n        domain = urllib.parse.urlparse(url).netloc\n        try:\n            ip = socket.gethostbyname(domain)\n            result[domain] = ip\n        except socket.gaierror:\n            result[domain] = None\n    return result\n```"}
{"task_id": "BigCodeBench/1123", "solution": "import re\nimport urllib.parse\nimport ssl\nimport socket\ndef task_func(myString):\n    # Extract all URLs from the string\n    urls = re.findall(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', myString)\n    # Initialize an empty dictionary to store the results\n    results = {}\n    # Iterate over each URL\n    for url in urls:\n        # Parse the URL to get the domain\n        parsed_url = urllib.parse.urlparse(url)\n        domain = parsed_url.netloc\n        # Ignore HTTP URLs\n        if parsed_url.scheme != 'https':\n            continue\n        # Try to retrieve the SSL certificate\n        try:\n            context = ssl.create_default_context()\n            with socket.create_connection((domain, 443)) as sock:\n                with context.wrap_socket(sock, server_hostname=domain) as ssock:\n                    cert = ssock.getpeercert()\n                    # Extract the expiration date from the certificate\n                    expiration_date = cert['notAfter']\n                    # Add the domain and expiration date to the results dictionary\n                    results[domain] = expiration_date\n        except ssl.SSLError:\n            # Ignore HTTPS URLs where the SSL certificate cannot be retrieved\n            continue\n    # Return the results dictionary\n    return results", "raw_solution": "import re\nimport urllib.parse\nimport ssl\nimport socket\ndef task_func(myString):\n    # Extract all URLs from the string\n    urls = re.findall(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', myString)\n    # Initialize an empty dictionary to store the results\n    results = {}\n    # Iterate over each URL\n    for url in urls:\n        # Parse the URL to get the domain\n        parsed_url = urllib.parse.urlparse(url)\n        domain = parsed_url.netloc\n        # Ignore HTTP URLs\n        if parsed_url.scheme != 'https':\n            continue\n        # Try to retrieve the SSL certificate\n        try:\n            context = ssl.create_default_context()\n            with socket.create_connection((domain, 443)) as sock:\n                with context.wrap_socket(sock, server_hostname=domain) as ssock:\n                    cert = ssock.getpeercert()\n                    # Extract the expiration date from the certificate\n                    expiration_date = cert['notAfter']\n                    # Add the domain and expiration date to the results dictionary\n                    results[domain] = expiration_date\n        except ssl.SSLError:\n            # Ignore HTTPS URLs where the SSL certificate cannot be retrieved\n            continue\n    # Return the results dictionary\n    return results\n```"}
{"task_id": "BigCodeBench/1124", "solution": "import re\nfrom urllib.parse import urlparse\nfrom bs4 import BeautifulSoup\nimport requests\ndef task_func(myString):\n    # Extract the URL from the string\n    url = re.search(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', myString)\n    if url:\n        url = url.group(0)\n    else:\n        return \"No valid URL found in the provided string.\"\n    \n    # Fetch the content of the URL\n    try:\n        response = requests.get(url)\n        response.raise_for_status()\n    except requests.exceptions.RequestException as e:\n        return f\"Unable to fetch the content of the URL: {url}\"\n    \n    # Parse the content of the URL\n    soup = BeautifulSoup(response.text, 'html.parser')\n    \n    # Extract the title of the webpage\n    title = soup.find('title')\n    if title:\n        return title.get_text()\n    else:\n        return \"No title tag found in the webpage.\"", "raw_solution": "import re\nfrom urllib.parse import urlparse\nfrom bs4 import BeautifulSoup\nimport requests\n\ndef task_func(myString):\n    # Extract the URL from the string\n    url = re.search(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', myString)\n    if url:\n        url = url.group(0)\n    else:\n        return \"No valid URL found in the provided string.\"\n    \n    # Fetch the content of the URL\n    try:\n        response = requests.get(url)\n        response.raise_for_status()\n    except requests.exceptions.RequestException as e:\n        return f\"Unable to fetch the content of the URL: {url}\"\n    \n    # Parse the content of the URL\n    soup = BeautifulSoup(response.text, 'html.parser')\n    \n    # Extract the title of the webpage\n    title = soup.find('title')\n    if title:\n        return title.get_text()\n    else:\n        return \"No title tag found in the webpage.\"\n```"}
{"task_id": "BigCodeBench/1125", "solution": "import re\nimport json\nimport requests\ndef task_func(myString, token):\n    # Extract the URL from the string\n    url = re.search(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', myString).group(0)\n    # Create the JSON payload\n    payload = {'url': url}\n    # Create the headers\n    headers = {'Authorization': f'Bearer {token}'}\n    # Send the POST request\n    response = requests.post('https://api.example.com/url', headers=headers, data=json.dumps(payload))\n    # Return the response\n    return response.json()", "raw_solution": "import re\nimport json\nimport requests\n\ndef task_func(myString, token):\n    # Extract the URL from the string\n    url = re.search(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', myString).group(0)\n    # Create the JSON payload\n    payload = {'url': url}\n    # Create the headers\n    headers = {'Authorization': f'Bearer {token}'}\n    # Send the POST request\n    response = requests.post('https://api.example.com/url', headers=headers, data=json.dumps(payload))\n    # Return the response\n    return response.json()\n```"}
{"task_id": "BigCodeBench/1126", "solution": "import re\nimport hashlib\ndef task_func(input_str):\n    cleaned_str = re.sub(r'[^a-zA-Z0-9]', '', input_str)\n    return hashlib.sha256(cleaned_str.encode()).hexdigest()", "raw_solution": "import re\nimport hashlib\n\ndef task_func(input_str):\n    cleaned_str = re.sub(r'[^a-zA-Z0-9]', '', input_str)\n    return hashlib.sha256(cleaned_str.encode()).hexdigest()\n```"}
{"task_id": "BigCodeBench/1127", "solution": "import os\nimport re\nimport hashlib\ndef task_func(path, delimiter):\n    components = path.split(delimiter)\n    result = []\n    for component in components:\n        if os.path.isfile(component):\n            hash_obj = hashlib.sha256()\n            with open(component, 'rb') as f:\n                for byte_block in iter(lambda: f.read(4096), b\"\"):\n                    hash_obj.update(byte_block)\n            result.append((component, hash_obj.hexdigest()))\n        else:\n            result.append((component, None))\n    return result", "raw_solution": "import os\nimport re\nimport hashlib\n\ndef task_func(path, delimiter):\n    components = path.split(delimiter)\n    result = []\n    for component in components:\n        if os.path.isfile(component):\n            hash_obj = hashlib.sha256()\n            with open(component, 'rb') as f:\n                for byte_block in iter(lambda: f.read(4096), b\"\"):\n                    hash_obj.update(byte_block)\n            result.append((component, hash_obj.hexdigest()))\n        else:\n            result.append((component, None))\n    return result\n```"}
{"task_id": "BigCodeBench/1128", "solution": "import json\nimport os\nimport hashlib\nimport base64\nimport time\ndef task_func(file_path, unknown_key):\n    with open(file_path, 'r') as f:\n        data = json.load(f)\n    value = data['A'][unknown_key]['maindata'][0]['Info']\n    hash_object = hashlib.sha256(value.encode())\n    hash_value = base64.b64encode(hash_object.digest()).decode()\n    timestamp = time.strftime('%Y%m%d%H%M%S')\n    file_name = f\"{timestamp}_{hash_value}.txt\"\n    with open(file_name, 'w') as f:\n        f.write(hash_value)\n    return os.path.abspath(file_name)", "raw_solution": "import json\nimport os\nimport hashlib\nimport base64\nimport time\ndef task_func(file_path, unknown_key):\n    with open(file_path, 'r') as f:\n        data = json.load(f)\n    value = data['A'][unknown_key]['maindata'][0]['Info']\n    hash_object = hashlib.sha256(value.encode())\n    hash_value = base64.b64encode(hash_object.digest()).decode()\n    timestamp = time.strftime('%Y%m%d%H%M%S')\n    file_name = f\"{timestamp}_{hash_value}.txt\"\n    with open(file_name, 'w') as f:\n        f.write(hash_value)\n    return os.path.abspath(file_name)\n```"}
{"task_id": "BigCodeBench/1129", "solution": "import json\nimport requests\nimport os\nfrom datetime import datetime\ndef task_func(json_data, unknown_key, save_dir=None):\n    # Parse the JSON data\n    data = json.loads(json_data)\n    \n    # Find the URL associated with the specified key\n    url = data.get(unknown_key)\n    \n    # If the URL is not found, return an error message\n    if url is None:\n        return \"Error: URL not found\"\n    \n    # Download the file from the URL\n    response = requests.get(url)\n    \n    # If the download fails, return an error message\n    if response.status_code != 200:\n        return \"Error: Failed to download file\"\n    \n    # Get the current timestamp\n    timestamp = datetime.now().strftime('%Y%m%d%H%M%S%f')\n    \n    # Construct the filename\n    filename = f\"{unknown_key}_{timestamp}.txt\"\n    \n    # Save the file to the specified directory or in the current working directory\n    if save_dir is not None:\n        file_path = os.path.join(save_dir, filename)\n    else:\n        file_path = os.path.join(os.getcwd(), filename)\n    \n    # Write the file to disk\n    with open(file_path, 'wb') as f:\n        f.write(response.content)\n    \n    # Return the absolute path of the downloaded file\n    return file_path", "raw_solution": "import json\nimport requests\nimport os\nfrom datetime import datetime\n\ndef task_func(json_data, unknown_key, save_dir=None):\n    # Parse the JSON data\n    data = json.loads(json_data)\n    \n    # Find the URL associated with the specified key\n    url = data.get(unknown_key)\n    \n    # If the URL is not found, return an error message\n    if url is None:\n        return \"Error: URL not found\"\n    \n    # Download the file from the URL\n    response = requests.get(url)\n    \n    # If the download fails, return an error message\n    if response.status_code != 200:\n        return \"Error: Failed to download file\"\n    \n    # Get the current timestamp\n    timestamp = datetime.now().strftime('%Y%m%d%H%M%S%f')\n    \n    # Construct the filename\n    filename = f\"{unknown_key}_{timestamp}.txt\"\n    \n    # Save the file to the specified directory or in the current working directory\n    if save_dir is not None:\n        file_path = os.path.join(save_dir, filename)\n    else:\n        file_path = os.path.join(os.getcwd(), filename)\n    \n    # Write the file to disk\n    with open(file_path, 'wb') as f:\n        f.write(response.content)\n    \n    # Return the absolute path of the downloaded file\n    return file_path\n```"}
{"task_id": "BigCodeBench/1130", "solution": "import os\nimport hashlib\nimport json\nfrom pathlib import Path\ndef task_func(directory: str) -> str:\n    hashes = {}\n    for root, dirs, files in os.walk(directory):\n        for file in files:\n            file_path = os.path.join(root, file)\n            with open(file_path, 'rb') as f:\n                file_hash = hashlib.sha256(f.read()).hexdigest()\n                hashes[file_path] = file_hash\n    with open('hashes.json', 'w') as f:\n        json.dump(hashes, f)\n    return 'hashes.json'", "raw_solution": "import os\nimport hashlib\nimport json\nfrom pathlib import Path\n\ndef task_func(directory: str) -> str:\n    hashes = {}\n    for root, dirs, files in os.walk(directory):\n        for file in files:\n            file_path = os.path.join(root, file)\n            with open(file_path, 'rb') as f:\n                file_hash = hashlib.sha256(f.read()).hexdigest()\n                hashes[file_path] = file_hash\n    with open('hashes.json', 'w') as f:\n        json.dump(hashes, f)\n    return 'hashes.json'\n```"}
{"task_id": "BigCodeBench/1131", "solution": "import hashlib\nimport binascii\ndef task_func(salt, cursor):\n    if not isinstance(salt, str):\n        raise TypeError(\"salt must be a string\")\n    cursor.execute(\"SELECT id, password FROM users\")\n    users = cursor.fetchall()\n    updated = 0\n    for user in users:\n        old_password = user[1]\n        old_password_hash = hashlib.sha256(old_password.encode()).hexdigest()\n        new_password_hash = hashlib.sha256((old_password_hash + salt).encode()).hexdigest()\n        if old_password_hash != new_password_hash:\n            cursor.execute(\"UPDATE users SET password = ? WHERE id = ?\", (new_password_hash, user[0]))\n            updated += 1\n    return updated", "raw_solution": "import hashlib\nimport binascii\ndef task_func(salt, cursor):\n    if not isinstance(salt, str):\n        raise TypeError(\"salt must be a string\")\n    cursor.execute(\"SELECT id, password FROM users\")\n    users = cursor.fetchall()\n    updated = 0\n    for user in users:\n        old_password = user[1]\n        old_password_hash = hashlib.sha256(old_password.encode()).hexdigest()\n        new_password_hash = hashlib.sha256((old_password_hash + salt).encode()).hexdigest()\n        if old_password_hash != new_password_hash:\n            cursor.execute(\"UPDATE users SET password = ? WHERE id = ?\", (new_password_hash, user[0]))\n            updated += 1\n    return updated\n```"}
{"task_id": "BigCodeBench/1132", "solution": "import os\nimport hashlib\nimport base64\ndef task_func(password, PREFIX=\"ME\", SALT_LENGTH=16):\n    if SALT_LENGTH < 0:\n        raise ValueError(\"SALT_LENGTH cannot be negative\")\n    salt = os.urandom(SALT_LENGTH)\n    hashed = hashlib.sha256(PREFIX.encode() + password.encode() + salt).hexdigest()\n    return base64.b64encode(hashed.encode()).decode()", "raw_solution": "import os\nimport hashlib\nimport base64\ndef task_func(password, PREFIX=\"ME\", SALT_LENGTH=16):\n    if SALT_LENGTH < 0:\n        raise ValueError(\"SALT_LENGTH cannot be negative\")\n    salt = os.urandom(SALT_LENGTH)\n    hashed = hashlib.sha256(PREFIX.encode() + password.encode() + salt).hexdigest()\n    return base64.b64encode(hashed.encode()).decode()\n```"}
{"task_id": "BigCodeBench/1133", "solution": "import json\nimport requests\ndef task_func(API_URL, endpoint, PREFIX):\n    try:\n        response = requests.get(API_URL + endpoint)\n        response.raise_for_status()\n        data = response.json()\n        filename = PREFIX + endpoint + '.json'\n        with open(filename, 'w') as f:\n            json.dump(data, f)\n        return filename\n    except requests.exceptions.RequestException as e:\n        raise RuntimeError(f'Error fetching data from API: {e}')\n    except json.JSONDecodeError as e:\n        raise RuntimeError(f'Error decoding JSON data: {e}')", "raw_solution": "import json\nimport requests\n\ndef task_func(API_URL, endpoint, PREFIX):\n    try:\n        response = requests.get(API_URL + endpoint)\n        response.raise_for_status()\n        data = response.json()\n        filename = PREFIX + endpoint + '.json'\n        with open(filename, 'w') as f:\n            json.dump(data, f)\n        return filename\n    except requests.exceptions.RequestException as e:\n        raise RuntimeError(f'Error fetching data from API: {e}')\n    except json.JSONDecodeError as e:\n        raise RuntimeError(f'Error decoding JSON data: {e}')\n```"}
{"task_id": "BigCodeBench/1134", "solution": "import os\nimport glob\nimport hashlib\ndef task_func(source_dir, target_dir, prefix='#Hash: '):\n    if not os.path.exists(source_dir):\n        raise FileNotFoundError(\"Source directory does not exist\")\n    for file_path in glob.glob(os.path.join(source_dir, '*')):\n        with open(file_path, 'rb') as f:\n            content = f.read()\n        hash_obj = hashlib.md5(content)\n        hash_str = hash_obj.hexdigest()\n        new_file_path = os.path.join(target_dir, os.path.basename(file_path))\n        with open(new_file_path, 'w') as f:\n            f.write(prefix + hash_str + '\\n' + content.decode('utf-8'))\n    return glob.glob(os.path.join(target_dir, '*'))", "raw_solution": "import os\nimport glob\nimport hashlib\ndef task_func(source_dir, target_dir, prefix='#Hash: '):\n    if not os.path.exists(source_dir):\n        raise FileNotFoundError(\"Source directory does not exist\")\n    for file_path in glob.glob(os.path.join(source_dir, '*')):\n        with open(file_path, 'rb') as f:\n            content = f.read()\n        hash_obj = hashlib.md5(content)\n        hash_str = hash_obj.hexdigest()\n        new_file_path = os.path.join(target_dir, os.path.basename(file_path))\n        with open(new_file_path, 'w') as f:\n            f.write(prefix + hash_str + '\\n' + content.decode('utf-8'))\n    return glob.glob(os.path.join(target_dir, '*'))\n```"}
{"task_id": "BigCodeBench/1135", "solution": "import collections\nimport json\nimport requests\ndef task_func(user, API_URL = 'https://api.github.com/users/'):\n    # Query the GitHub API for all repositories of a given user\n    response = requests.get(API_URL + user)\n    # Parse the response to extract the names and creation dates\n    repositories = response.json()['repos']\n    # Sort the repositories by their creation date\n    repositories.sort(key=lambda x: x['created_at'])\n    # Return the repository names sorted by their creation dates\n    return [repo['name'] for repo in repositories]", "raw_solution": "import collections\nimport json\nimport requests\ndef task_func(user, API_URL = 'https://api.github.com/users/'):\n    # Query the GitHub API for all repositories of a given user\n    response = requests.get(API_URL + user)\n    # Parse the response to extract the names and creation dates\n    repositories = response.json()['repos']\n    # Sort the repositories by their creation date\n    repositories.sort(key=lambda x: x['created_at'])\n    # Return the repository names sorted by their creation dates\n    return [repo['name'] for repo in repositories]\n```"}
{"task_id": "BigCodeBench/1136", "solution": "import bs4\nimport requests\nimport re\nimport csv\ndef task_func(url=\"http://example.com\", csv_path=\"emails.csv\", \n          regex=r\"\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,7}\\b\", \n          headers={'User-Agent': 'Mozilla/5.0'}):\n    response = requests.get(url, headers=headers)\n    soup = bs4.BeautifulSoup(response.text, 'html.parser')\n    emails = re.findall(regex, soup.get_text())\n    with open(csv_path, 'w', newline='') as file:\n        writer = csv.writer(file)\n        writer.writerow([\"Emails\"])\n        if emails:\n            writer.writerow(emails)\n    return csv_path", "raw_solution": "import bs4\nimport requests\nimport re\nimport csv\n\ndef task_func(url=\"http://example.com\", csv_path=\"emails.csv\", \n          regex=r\"\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,7}\\b\", \n          headers={'User-Agent': 'Mozilla/5.0'}):\n    response = requests.get(url, headers=headers)\n    soup = bs4.BeautifulSoup(response.text, 'html.parser')\n    emails = re.findall(regex, soup.get_text())\n    with open(csv_path, 'w', newline='') as file:\n        writer = csv.writer(file)\n        writer.writerow([\"Emails\"])\n        if emails:\n            writer.writerow(emails)\n    return csv_path\n```"}
{"task_id": "BigCodeBench/1137", "solution": "import bs4\nimport requests\nimport re\nimport json\ndef task_func(url: str, output_path: str) -> list:\n    response = requests.get(url)\n    soup = bs4.BeautifulSoup(response.text, 'html.parser')\n    phone_numbers = []\n    for phone in soup.find_all('a', href=re.compile(r'^tel:')):\n        phone_numbers.append(phone['href'][4:])\n    with open(output_path, 'w') as f:\n        json.dump(phone_numbers, f)\n    return phone_numbers", "raw_solution": "import bs4\nimport requests\nimport re\nimport json\ndef task_func(url: str, output_path: str) -> list:\n    response = requests.get(url)\n    soup = bs4.BeautifulSoup(response.text, 'html.parser')\n    phone_numbers = []\n    for phone in soup.find_all('a', href=re.compile(r'^tel:')):\n        phone_numbers.append(phone['href'][4:])\n    with open(output_path, 'w') as f:\n        json.dump(phone_numbers, f)\n    return phone_numbers\n```"}
{"task_id": "BigCodeBench/1138", "solution": "import numpy as np\nimport itertools\ndef task_func(matrix):\n    sorted_matrix = np.sort(matrix, axis=0)\n    unique_combinations = list(itertools.combinations(sorted_matrix, 2))\n    return sorted_matrix, unique_combinations", "raw_solution": "import numpy as np\nimport itertools\n\ndef task_func(matrix):\n    sorted_matrix = np.sort(matrix, axis=0)\n    unique_combinations = list(itertools.combinations(sorted_matrix, 2))\n    return sorted_matrix, unique_combinations\n```"}
{"task_id": "BigCodeBench/1139", "solution": "import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nimport numpy as np\ndef task_func(data):\n    # Convert the data to a pandas DataFrame\n    df = pd.DataFrame(data, columns=['Hours', 'Scores'])\n    \n    # Split the data into training and testing sets\n    X_train, X_test, y_train, y_test = train_test_split(df[['Hours']], df['Scores'], test_size=0.2, random_state=42)\n    \n    # Create a linear regression model\n    model = LinearRegression()\n    \n    # Train the model\n    model.fit(X_train, y_train)\n    \n    # Predict the scores for the test set\n    y_pred = model.predict(X_test)\n    \n    # Calculate the mean squared error\n    mse = np.mean((y_test - y_pred) ** 2)\n    \n    return mse", "raw_solution": "import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nimport numpy as np\n\ndef task_func(data):\n    # Convert the data to a pandas DataFrame\n    df = pd.DataFrame(data, columns=['Hours', 'Scores'])\n    \n    # Split the data into training and testing sets\n    X_train, X_test, y_train, y_test = train_test_split(df[['Hours']], df['Scores'], test_size=0.2, random_state=42)\n    \n    # Create a linear regression model\n    model = LinearRegression()\n    \n    # Train the model\n    model.fit(X_train, y_train)\n    \n    # Predict the scores for the test set\n    y_pred = model.predict(X_test)\n    \n    # Calculate the mean squared error\n    mse = np.mean((y_test - y_pred) ** 2)\n    \n    return mse\n```"}
